[
  {
    "id": "http://zotero.org/users/14620155/items/2G6F9ABT",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
    "language": "en",
    "page": "15546-15555",
    "source": "openaccess.thecvf.com",
    "title": "Enhancing Visual Document Understanding with Contrastive Learning in Large Visual-Language Models",
    "URL": "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Enhancing_Visual_Document_Understanding_with_Contrastive_Learning_in_Large_Visual-Language_CVPR_2024_paper.html",
    "author": [
      {
        "family": "Li",
        "given": "Xin"
      },
      {
        "family": "Wu",
        "given": "Yunfei"
      },
      {
        "family": "Jiang",
        "given": "Xinghua"
      },
      {
        "family": "Guo",
        "given": "Zhihao"
      },
      {
        "family": "Gong",
        "given": "Mingming"
      },
      {
        "family": "Cao",
        "given": "Haoyu"
      },
      {
        "family": "Liu",
        "given": "Yinsong"
      },
      {
        "family": "Jiang",
        "given": "Deqiang"
      },
      {
        "family": "Sun",
        "given": "Xing"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 9]]
    },
    "issued": {
      "date-parts": [["2024"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/PYB9APGT",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
    "language": "en",
    "page": "15556-15566",
    "source": "openaccess.thecvf.com",
    "title": "RoDLA: Benchmarking the Robustness of Document Layout Analysis Models",
    "title-short": "RoDLA",
    "URL": "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_RoDLA_Benchmarking_the_Robustness_of_Document_Layout_Analysis_Models_CVPR_2024_paper.html",
    "author": [
      {
        "family": "Chen",
        "given": "Yufan"
      },
      {
        "family": "Zhang",
        "given": "Jiaming"
      },
      {
        "family": "Peng",
        "given": "Kunyu"
      },
      {
        "family": "Zheng",
        "given": "Junwei"
      },
      {
        "family": "Liu",
        "given": "Ruiping"
      },
      {
        "family": "Torr",
        "given": "Philip"
      },
      {
        "family": "Stiefelhagen",
        "given": "Rainer"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 9]]
    },
    "issued": {
      "date-parts": [["2024"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/QN5CLLQB",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
    "language": "en",
    "page": "28150-28159",
    "source": "openaccess.thecvf.com",
    "title": "Text Grouping Adapter: Adapting Pre-trained Text Detector for Layout Analysis",
    "title-short": "Text Grouping Adapter",
    "URL": "https://openaccess.thecvf.com/content/CVPR2024/html/Bi_Text_Grouping_Adapter_Adapting_Pre-trained_Text_Detector_for_Layout_Analysis_CVPR_2024_paper.html",
    "author": [
      {
        "family": "Bi",
        "given": "Tianci"
      },
      {
        "family": "Zhang",
        "given": "Xiaoyi"
      },
      {
        "family": "Zhang",
        "given": "Zhizheng"
      },
      {
        "family": "Xie",
        "given": "Wenxuan"
      },
      {
        "family": "Lan",
        "given": "Cuiling"
      },
      {
        "family": "Lu",
        "given": "Yan"
      },
      {
        "family": "Zheng",
        "given": "Nanning"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 9]]
    },
    "issued": {
      "date-parts": [["2024"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/DYY9ZUW4",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
    "language": "en",
    "page": "15665-15674",
    "source": "openaccess.thecvf.com",
    "title": "LayoutFormer: Hierarchical Text Detection Towards Scene Text Understanding",
    "title-short": "LayoutFormer",
    "URL": "https://openaccess.thecvf.com/content/CVPR2024/html/Liang_LayoutFormer_Hierarchical_Text_Detection_Towards_Scene_Text_Understanding_CVPR_2024_paper.html",
    "author": [
      {
        "family": "Liang",
        "given": "Min"
      },
      {
        "family": "Ma",
        "given": "Jia-Wei"
      },
      {
        "family": "Zhu",
        "given": "Xiaobin"
      },
      {
        "family": "Qin",
        "given": "Jingyan"
      },
      {
        "family": "Yin",
        "given": "Xu-Cheng"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 9]]
    },
    "issued": {
      "date-parts": [["2024"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/74WBT7TP",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
    "language": "en",
    "page": "15534-15545",
    "source": "openaccess.thecvf.com",
    "title": "HRVDA: High-Resolution Visual Document Assistant",
    "title-short": "HRVDA",
    "URL": "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_HRVDA_High-Resolution_Visual_Document_Assistant_CVPR_2024_paper.html",
    "author": [
      {
        "family": "Liu",
        "given": "Chaohu"
      },
      {
        "family": "Yin",
        "given": "Kun"
      },
      {
        "family": "Cao",
        "given": "Haoyu"
      },
      {
        "family": "Jiang",
        "given": "Xinghua"
      },
      {
        "family": "Li",
        "given": "Xin"
      },
      {
        "family": "Liu",
        "given": "Yinsong"
      },
      {
        "family": "Jiang",
        "given": "Deqiang"
      },
      {
        "family": "Sun",
        "given": "Xing"
      },
      {
        "family": "Xu",
        "given": "Linli"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 9]]
    },
    "issued": {
      "date-parts": [["2024"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/EV2SNYAF",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
    "language": "en",
    "page": "15630-15640",
    "source": "openaccess.thecvf.com",
    "title": "LayoutLLM: Layout Instruction Tuning with Large Language Models for Document Understanding",
    "title-short": "LayoutLLM",
    "URL": "https://openaccess.thecvf.com/content/CVPR2024/html/Luo_LayoutLLM_Layout_Instruction_Tuning_with_Large_Language_Models_for_Document_CVPR_2024_paper.html",
    "author": [
      {
        "family": "Luo",
        "given": "Chuwei"
      },
      {
        "family": "Shen",
        "given": "Yufan"
      },
      {
        "family": "Zhu",
        "given": "Zhaoqing"
      },
      {
        "family": "Zheng",
        "given": "Qi"
      },
      {
        "family": "Yu",
        "given": "Zhi"
      },
      {
        "family": "Yao",
        "given": "Cong"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 9]]
    },
    "issued": {
      "date-parts": [["2024"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/9V4WNB4D",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
    "language": "en",
    "page": "15641-15653",
    "source": "openaccess.thecvf.com",
    "title": "OmniParser: A Unified Framework for Text Spotting Key Information Extraction and Table Recognition",
    "title-short": "OmniParser",
    "URL": "https://openaccess.thecvf.com/content/CVPR2024/html/Wan_OmniParser_A_Unified_Framework_for_Text_Spotting_Key_Information_Extraction_CVPR_2024_paper.html",
    "author": [
      {
        "family": "Wan",
        "given": "Jianqiang"
      },
      {
        "family": "Song",
        "given": "Sibo"
      },
      {
        "family": "Yu",
        "given": "Wenwen"
      },
      {
        "family": "Liu",
        "given": "Yuliang"
      },
      {
        "family": "Cheng",
        "given": "Wenqing"
      },
      {
        "family": "Huang",
        "given": "Fei"
      },
      {
        "family": "Bai",
        "given": "Xiang"
      },
      {
        "family": "Yao",
        "given": "Cong"
      },
      {
        "family": "Yang",
        "given": "Zhibo"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 9]]
    },
    "issued": {
      "date-parts": [["2024"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/H7MDHUUA",
    "type": "paper-conference",
    "abstract": "Scientific knowledge is predominantly stored in books and scientific journals, often in the form of PDFs. However, the PDF format leads to a loss of semantic information, particularly for mathematical expressions. We propose Nougat (Neural Optical Understanding for Academic Documents), a Visual Transformer model that performs an Optical Character Recognition (OCR) task for processing scientific documents into a markup language, and demonstrate the effectiveness of our model on a new dataset of scientific documents. The proposed approach offers a promising solution to enhance the accessibility of scientific knowledge in the digital age, by bridging the gap between human- readable documents and machine-readable text. We release the models and code to accelerate future work on scientific text recognition.",
    "event-title": "The Twelfth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "Nougat: Neural Optical Understanding for Academic Documents",
    "title-short": "Nougat",
    "URL": "https://openreview.net/forum?id=fUtxNAKpdV",
    "author": [
      {
        "family": "Blecher",
        "given": "Lukas"
      },
      {
        "family": "Cucurull",
        "given": "Guillem"
      },
      {
        "family": "Scialom",
        "given": "Thomas"
      },
      {
        "family": "Stojnic",
        "given": "Robert"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 10]]
    },
    "issued": {
      "date-parts": [["2023", 10, 13]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/JQ3J3AIZ",
    "type": "paper-conference",
    "abstract": "Research in document image understanding is hindered by limited high-quality document data. To address this, we introduce ADOPD, a comprehensive dataset for document page decomposition. ADOPD stands out with its data-driven approach for document taxonomy discovery during data collection, complemented by dense annotations. Our approach integrates large-scale pretrained models with a human-in-the-loop process to guarantee diversity and balance in the resulting data collection. Leveraging our data-driven document taxonomy, we collect and densely annotate document images, addressing four document image understanding tasks: Doc2Mask, Doc2Box, Doc2Tag, and Doc2Seq. Specifically, for each image, the annotations include human-labeled entity masks, text bounding boxes, as well as automatically generated tags and captions that have been manually cleaned. We conduct comprehensive experimental analyses to validate our data and assess the four tasks using various models. We envision ADOPD as a foundational dataset with the potential to drive future research in document understanding.",
    "event-title": "The Twelfth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "ADOPD: A Large-Scale Document Page Decomposition Dataset",
    "title-short": "ADOPD",
    "URL": "https://openreview.net/forum?id=x1ptaXpOYa",
    "author": [
      {
        "family": "Gu",
        "given": "Jiuxiang"
      },
      {
        "family": "Shi",
        "given": "Xiangxi"
      },
      {
        "family": "Kuen",
        "given": "Jason"
      },
      {
        "family": "Qi",
        "given": "Lu"
      },
      {
        "family": "Zhang",
        "given": "Ruiyi"
      },
      {
        "family": "Liu",
        "given": "Anqi"
      },
      {
        "family": "Nenkova",
        "given": "Ani"
      },
      {
        "family": "Sun",
        "given": "Tong"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 10]]
    },
    "issued": {
      "date-parts": [["2023", 10, 13]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/9S75VQVZ",
    "type": "paper-conference",
    "abstract": "Table understanding capability of Large Language Models (LLMs) has been extensively studied through the task of question-answering (QA) over tables. Typically, only a small part of the whole table is relevant to derive the answer for a given question. The irrelevant parts act as noise and are distracting information, resulting in sub-optimal performance due to the vulnerability of LLMs to noise. To mitigate this, we propose CABINET (Content RelevAnce-Based NoIse ReductioN for TablE QuesTion-Answering) – a framework to enable LLMs to focus on relevant tabular data by suppressing extraneous information. CABINET comprises an Unsupervised Relevance Scorer (URS), trained differentially with the QA LLM, that weighs the table content based on its relevance to the input question before feeding it to the question answering LLM (QA LLM). To further aid the relevance scorer, CABINET employs a weakly supervised module that generates a parsing statement describing the criteria of rows and columns relevant to the question and highlights the content of corresponding table cells. CABINET significantly outperforms various tabular LLM baselines, as well as GPT3-based in-context learning methods, is more robust to noise, maintains outperformance on tables of varying sizes, and establishes new SoTA performance on WikiTQ, FeTaQA, and WikiSQL datasets. We release our code and datasets here.",
    "event-title": "The Twelfth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "CABINET: Content Relevance-based Noise Reduction for Table Question Answering",
    "title-short": "CABINET",
    "URL": "https://openreview.net/forum?id=SQrHpTllXa",
    "author": [
      {
        "family": "Patnaik",
        "given": "Sohan"
      },
      {
        "family": "Changwal",
        "given": "Heril"
      },
      {
        "family": "Aggarwal",
        "given": "Milan"
      },
      {
        "family": "Bhatia",
        "given": "Sumit"
      },
      {
        "family": "Kumar",
        "given": "Yaman"
      },
      {
        "family": "Krishnamurthy",
        "given": "Balaji"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 10]]
    },
    "issued": {
      "date-parts": [["2023", 10, 13]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/CET2PLGU",
    "type": "paper-conference",
    "abstract": "Vision-Language Models (VLMs) have made remarkable progress in document-based Visual Question Answering (i.e., responding to queries about the contents of an input document provided as an image). In this work, we show these models can memorize responses for training samples and regurgitate them even when the relevant visual information has been removed. This includes Personal Identifiable Information (PII) repeated once in the training set, indicating these models could divulge memorised sensitive information and therefore pose a privacy risk. We quantitatively measure the extractability of information in controlled experiments and differentiate between cases where it arises from generalization capabilities or from memorization. We further investigate the factors that influence memorization across multiple state-of-the-art models and propose an effective heuristic countermeasure that empirically prevents the extractability of PII.",
    "event-title": "Forty-first International Conference on Machine Learning",
    "language": "en",
    "source": "openreview.net",
    "title": "Extracting Training Data From Document-Based VQA Models",
    "URL": "https://openreview.net/forum?id=qTX1vxzs8b",
    "author": [
      {
        "family": "Pinto",
        "given": "Francesco"
      },
      {
        "family": "Rauschmayr",
        "given": "Nathalie"
      },
      {
        "family": "Tramèr",
        "given": "Florian"
      },
      {
        "family": "Torr",
        "given": "Philip"
      },
      {
        "family": "Tombari",
        "given": "Federico"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 10]]
    },
    "issued": {
      "date-parts": [["2024", 6, 6]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/E2TXPVVP",
    "type": "paper-conference",
    "abstract": "Transferring knowledge across diverse data modalities is receiving increasing attention in machine learning. This paper tackles the task of leveraging expert-derived, yet expensive, tabular data to enhance image-based predictions when tabular data is unavailable during inference. The primary challenges stem from the inherent complexity of accurately mapping diverse tabular data to visual contexts, coupled with the necessity to devise distinct strategies for numerical and categorical tabular attributes. We propose CHannel tAbulaR alignment with optiMal tranSport (Charms), which establishes an alignment between image channels and tabular attributes, enabling selective knowledge transfer that is pertinent to visual features. Specifically, Charms measures similarity distributions across modalities to effectively differentiate and transfer relevant tabular features, with a focus on morphological characteristics, enhancing the capabilities of visual classifiers. By maximizing the mutual information between image channels and tabular features, knowledge from both numerical and categorical tabular attributes are extracted. Experimental results demonstrate that Charms not only enhances the performance of image classifiers but also improves their interpretability by effectively utilizing tabular knowledge.",
    "event-title": "Forty-first International Conference on Machine Learning",
    "language": "en",
    "source": "openreview.net",
    "title": "Tabular Insights, Visual Impacts: Transferring Expertise from Tables to Images",
    "title-short": "Tabular Insights, Visual Impacts",
    "URL": "https://openreview.net/forum?id=v7I5FtL2pV",
    "author": [
      {
        "family": "Jiang",
        "given": "Jun-Peng"
      },
      {
        "family": "Ye",
        "given": "Han-Jia"
      },
      {
        "family": "Wang",
        "given": "Leye"
      },
      {
        "family": "Yang",
        "given": "Yang"
      },
      {
        "family": "Jiang",
        "given": "Yuan"
      },
      {
        "family": "Zhan",
        "given": "De-Chuan"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 10]]
    },
    "issued": {
      "date-parts": [["2024", 6, 6]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/DPQIKSFU",
    "type": "paper-conference",
    "abstract": "Structured data, which constitutes a significant portion of existing data types, has been a long-standing research topic in the field of machine learning. Various representation learning methods for tabular data have been proposed, ranging from encoder-decoder structures to Transformers. Among these, Transformer-based methods have achieved state-of-the-art performance not only in tabular data but also in various other fields, including computer vision and natural language processing. However, recent studies have revealed that self-attention, a key component of Transformers, can lead to an oversmoothing issue. We show that Transformers for tabular data also face this problem. To tackle the problem, we suggest a novel self-attention layer for tabular data, leveraging matrix polynomials. This proposed layer serves as a replacement for the original self-attention layer, contributing to the improvement of model scalability. In our experiments with three representative table learning models equipped with our proposed layer, we illustrate that the layer effectively mitigates the oversmoothing problem and enhances the representation performance of the existing methods, outperforming the state-of-the-art table representation methods.",
    "event-title": "Forty-first International Conference on Machine Learning",
    "language": "en",
    "source": "openreview.net",
    "title": "Polynomial-based Self-Attention for Table Representation Learning",
    "URL": "https://openreview.net/forum?id=QZd3rvlP76",
    "author": [
      {
        "family": "Kim",
        "given": "Jayoung"
      },
      {
        "family": "Shin",
        "given": "Yehjin"
      },
      {
        "family": "Choi",
        "given": "Jeongwhan"
      },
      {
        "family": "Wi",
        "given": "Hyowon"
      },
      {
        "family": "Park",
        "given": "Noseong"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 10]]
    },
    "issued": {
      "date-parts": [["2024", 6, 6]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/FRPYTNA9",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision",
    "language": "en",
    "page": "903-913",
    "source": "openaccess.thecvf.com",
    "title": "Hierarchical Text Spotter for Joint Text Spotting and Layout Analysis",
    "URL": "https://openaccess.thecvf.com/content/WACV2024/html/Long_Hierarchical_Text_Spotter_for_Joint_Text_Spotting_and_Layout_Analysis_WACV_2024_paper.html",
    "author": [
      {
        "family": "Long",
        "given": "Shangbang"
      },
      {
        "family": "Qin",
        "given": "Siyang"
      },
      {
        "family": "Fujii",
        "given": "Yasuhisa"
      },
      {
        "family": "Bissacco",
        "given": "Alessandro"
      },
      {
        "family": "Raptis",
        "given": "Michalis"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 10]]
    },
    "issued": {
      "date-parts": [["2024"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/UH67FMPM",
    "type": "paper-conference",
    "abstract": "Self-supervised pre-training techniques have achieved remarkable progress in Document AI. Most multimodal pre-trained models use a masked language modeling objective to learn bidirectional representations on the text modality, but they differ in pre-training objectives for the image modality. This discrepancy adds difficulty to multimodal representation learning. In this paper, we propose LayoutLMv3 to pre-train multimodal Transformers for Document AI with unified text and image masking. Additionally, LayoutLMv3 is pre-trained with a word-patch alignment objective to learn cross-modal alignment by predicting whether the corresponding image patch of a text word is masked. The simple unified architecture and training objectives make LayoutLMv3 a general-purpose pre-trained model for both text-centric and image-centric Document AI tasks. Experimental results show that LayoutLMv3 achieves state-of-the-art performance not only in text-centric tasks, including form understanding, receipt understanding, and document visual question answering, but also in image-centric tasks such as document image classification and document layout analysis. The code and models are publicly available at https://aka.ms/layoutlmv3.",
    "collection-title": "MM '22",
    "container-title": "Proceedings of the 30th ACM International Conference on Multimedia",
    "DOI": "10.1145/3503161.3548112",
    "event-place": "New York, NY, USA",
    "ISBN": "978-1-4503-9203-7",
    "language": "en-US",
    "page": "4083–4091",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "source": "ACM Digital Library",
    "title": "LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking",
    "title-short": "LayoutLMv3",
    "URL": "https://doi.org/10.1145/3503161.3548112",
    "author": [
      {
        "family": "Huang",
        "given": "Yupan"
      },
      {
        "family": "Lv",
        "given": "Tengchao"
      },
      {
        "family": "Cui",
        "given": "Lei"
      },
      {
        "family": "Lu",
        "given": "Yutong"
      },
      {
        "family": "Wei",
        "given": "Furu"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 10]]
    },
    "issued": {
      "date-parts": [["2022", 10, 10]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/IVB5PR7Q",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF International Conference on Computer Vision",
    "language": "en",
    "page": "19462-19472",
    "source": "openaccess.thecvf.com",
    "title": "Vision Grid Transformer for Document Layout Analysis",
    "URL": "https://openaccess.thecvf.com/content/ICCV2023/html/Da_Vision_Grid_Transformer_for_Document_Layout_Analysis_ICCV_2023_paper.html",
    "author": [
      {
        "family": "Da",
        "given": "Cheng"
      },
      {
        "family": "Luo",
        "given": "Chuwei"
      },
      {
        "family": "Zheng",
        "given": "Qi"
      },
      {
        "family": "Yao",
        "given": "Cong"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 10]]
    },
    "issued": {
      "date-parts": [["2023"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/AG7689IE",
    "type": "article",
    "abstract": "Extracting table contents from documents such as scientific papers and financial reports and converting them into a format that can be processed by large language models is an important task in knowledge information processing. End-to-end approaches, which recognize not only table structure but also cell contents, achieved performance comparable to state-of-the-art models using external character recognition systems, and have potential for further improvements. In addition, these models can now recognize long tables with hundreds of cells by introducing local attention. However, the models recognize table structure in one direction from the header to the footer, and cell content recognition is performed independently for each cell, so there is no opportunity to retrieve useful information from the neighbor cells. In this paper, we propose a multi-cell content decoder and bidirectional mutual learning mechanism to improve the end-to-end approach. The effectiveness is demonstrated on two large datasets, and the experimental results show comparable performance to state-of-the-art models, even for long tables with large numbers of cells.",
    "DOI": "10.48550/arXiv.2404.13268",
    "language": "en-US",
    "note": "arXiv:2404.13268 [cs]",
    "number": "arXiv:2404.13268",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Multi-Cell Decoder and Mutual Learning for Table Structure and Character Recognition",
    "URL": "http://arxiv.org/abs/2404.13268",
    "author": [
      {
        "family": "Kawakatsu",
        "given": "Takaya"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 11]]
    },
    "issued": {
      "date-parts": [["2024", 5, 12]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/HBXCW83Y",
    "type": "article",
    "abstract": "Vision-language models (VLMs) are achieving increasingly strong performance on multimodal tasks. However, reasoning capabilities remain limited particularly for smaller VLMs, while those of large-language models (LLMs) have seen numerous improvements. We propose a technique to transfer capabilities from LLMs to VLMs. On the recently introduced ChartQA, our method obtains state-of-the-art performance when applied on the PaLI3-5B VLM by \\citet{chen2023pali3}, while also enabling much better performance on PlotQA and FigureQA. We first improve the chart representation by continuing the pre-training stage using an improved version of the chart-to-table translation task by \\citet{liu2023deplot}. We then propose constructing a 20x larger dataset than the original training set. To improve general reasoning capabilities and improve numerical operations, we synthesize reasoning traces using the table representation of charts. Lastly, our model is fine-tuned using the multitask loss introduced by \\citet{hsieh2023distilling}. Our variant ChartPaLI-5B outperforms even 10x larger models such as PaLIX-55B without using an upstream OCR system, while keeping inference time constant compared to the PaLI3-5B baseline. When rationales are further refined with a simple program-of-thought prompt \\cite{chen2023program}, our model outperforms the recently introduced Gemini Ultra and GPT-4V.",
    "DOI": "10.48550/arXiv.2403.12596",
    "language": "en-US",
    "note": "arXiv:2403.12596 [cs]",
    "number": "arXiv:2403.12596",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Chart-based Reasoning: Transferring Capabilities from LLMs to VLMs",
    "title-short": "Chart-based Reasoning",
    "URL": "http://arxiv.org/abs/2403.12596",
    "author": [
      {
        "family": "Carbune",
        "given": "Victor"
      },
      {
        "family": "Mansoor",
        "given": "Hassan"
      },
      {
        "family": "Liu",
        "given": "Fangyu"
      },
      {
        "family": "Aralikatte",
        "given": "Rahul"
      },
      {
        "family": "Baechler",
        "given": "Gilles"
      },
      {
        "family": "Chen",
        "given": "Jindong"
      },
      {
        "family": "Sharma",
        "given": "Abhanshu"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 11]]
    },
    "issued": {
      "date-parts": [["2024", 3, 19]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/WIU5AUTG",
    "type": "article",
    "abstract": "Enterprise documents such as forms, invoices, receipts, reports, contracts, and other similar records, often carry rich semantics at the intersection of textual and spatial modalities. The visual cues offered by their complex layouts play a crucial role in comprehending these documents effectively. In this paper, we present DocLLM, a lightweight extension to traditional large language models (LLMs) for reasoning over visual documents, taking into account both textual semantics and spatial layout. Our model differs from existing multimodal LLMs by avoiding expensive image encoders and focuses exclusively on bounding box information to incorporate the spatial layout structure. Specifically, the cross-alignment between text and spatial modalities is captured by decomposing the attention mechanism in classical transformers to a set of disentangled matrices. Furthermore, we devise a pre-training objective that learns to infill text segments. This approach allows us to address irregular layouts and heterogeneous content frequently encountered in visual documents. The pre-trained model is fine-tuned using a large-scale instruction dataset, covering four core document intelligence tasks. We demonstrate that our solution outperforms SotA LLMs on 14 out of 16 datasets across all tasks, and generalizes well to 4 out of 5 previously unseen datasets.",
    "DOI": "10.48550/arXiv.2401.00908",
    "language": "en-US",
    "note": "arXiv:2401.00908 [cs]",
    "number": "arXiv:2401.00908",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "DocLLM: A layout-aware generative language model for multimodal document understanding",
    "title-short": "DocLLM",
    "URL": "http://arxiv.org/abs/2401.00908",
    "author": [
      {
        "family": "Wang",
        "given": "Dongsheng"
      },
      {
        "family": "Raman",
        "given": "Natraj"
      },
      {
        "family": "Sibue",
        "given": "Mathieu"
      },
      {
        "family": "Ma",
        "given": "Zhiqiang"
      },
      {
        "family": "Babkin",
        "given": "Petr"
      },
      {
        "family": "Kaur",
        "given": "Simerjot"
      },
      {
        "family": "Pei",
        "given": "Yulong"
      },
      {
        "family": "Nourbakhsh",
        "given": "Armineh"
      },
      {
        "family": "Liu",
        "given": "Xiaomo"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 12]]
    },
    "issued": {
      "date-parts": [["2023", 12, 31]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/CK28GCTV",
    "type": "article",
    "abstract": "Although great progress has been made by previous table understanding methods including recent approaches based on large language models (LLMs), they rely heavily on the premise that given tables must be converted into a certain text sequence (such as Markdown or HTML) to serve as model input. However, it is difficult to access such high-quality textual table representations in some real-world scenarios, and table images are much more accessible. Therefore, how to directly understand tables using intuitive visual information is a crucial and urgent challenge for developing more practical applications. In this paper, we propose a new problem, multimodal table understanding, where the model needs to generate correct responses to various table-related requests based on the given table image. To facilitate both the model training and evaluation, we construct a large-scale dataset named MMTab, which covers a wide spectrum of table images, instructions and tasks. On this basis, we develop Table-LLaVA, a generalist tabular multimodal large language model (MLLM), which significantly outperforms recent open-source MLLM baselines on 23 benchmarks under held-in and held-out settings. The code and data is available at this https://github.com/SpursGoZmy/Table-LLaVA",
    "DOI": "10.48550/arXiv.2406.08100",
    "language": "en-US",
    "note": "arXiv:2406.08100 [cs]",
    "number": "arXiv:2406.08100",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Multimodal Table Understanding",
    "URL": "http://arxiv.org/abs/2406.08100",
    "author": [
      {
        "family": "Zheng",
        "given": "Mingyu"
      },
      {
        "family": "Feng",
        "given": "Xinwei"
      },
      {
        "family": "Si",
        "given": "Qingyi"
      },
      {
        "family": "She",
        "given": "Qiaoqiao"
      },
      {
        "family": "Lin",
        "given": "Zheng"
      },
      {
        "family": "Jiang",
        "given": "Wenbin"
      },
      {
        "family": "Wang",
        "given": "Weiping"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 12]]
    },
    "issued": {
      "date-parts": [["2024", 6, 12]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/YJPG825R",
    "type": "article",
    "abstract": "Large language models have exhibited intriguing in-context learning capability, achieving promising zero- and few-shot performance without updating the parameters. However, conventional in-context learning is usually restricted by length constraints, rendering it ineffective to absorb supervision from a large number of examples. In order to go beyond few shots, we introduce structured prompting that breaks the length limit and scales in-context learning to thousands of examples. Specifically, demonstration examples are separately encoded with well-designed position embeddings, and then they are jointly attended by the test example using a rescaled attention mechanism. So we can scale the number of exemplars with linear complexity instead of quadratic complexity with respect to length. Experimental results on a diverse set of tasks show that our approach improves end-task performance and reduces evaluation variance over conventional in-context learning as the number of demonstration examples increases. Code has been released at https://aka.ms/structured-prompting.",
    "DOI": "10.48550/arXiv.2212.06713",
    "note": "arXiv:2212.06713 [cs]",
    "number": "arXiv:2212.06713",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Structured Prompting: Scaling In-Context Learning to 1,000 Examples",
    "title-short": "Structured Prompting",
    "URL": "http://arxiv.org/abs/2212.06713",
    "author": [
      {
        "family": "Hao",
        "given": "Yaru"
      },
      {
        "family": "Sun",
        "given": "Yutao"
      },
      {
        "family": "Dong",
        "given": "Li"
      },
      {
        "family": "Han",
        "given": "Zhixiong"
      },
      {
        "family": "Gu",
        "given": "Yuxian"
      },
      {
        "family": "Wei",
        "given": "Furu"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 12]]
    },
    "issued": {
      "date-parts": [["2022", 12, 13]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/GCMLVJQD",
    "type": "article",
    "abstract": "An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA.",
    "DOI": "10.48550/arXiv.2106.09685",
    "note": "arXiv:2106.09685 [cs]",
    "number": "arXiv:2106.09685",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "LoRA: Low-Rank Adaptation of Large Language Models",
    "title-short": "LoRA",
    "URL": "http://arxiv.org/abs/2106.09685",
    "author": [
      {
        "family": "Hu",
        "given": "Edward J."
      },
      {
        "family": "Shen",
        "given": "Yelong"
      },
      {
        "family": "Wallis",
        "given": "Phillip"
      },
      {
        "family": "Allen-Zhu",
        "given": "Zeyuan"
      },
      {
        "family": "Li",
        "given": "Yuanzhi"
      },
      {
        "family": "Wang",
        "given": "Shean"
      },
      {
        "family": "Wang",
        "given": "Lu"
      },
      {
        "family": "Chen",
        "given": "Weizhu"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 12]]
    },
    "issued": {
      "date-parts": [["2021", 10, 16]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/7D4X69XQ",
    "type": "article-journal",
    "container-title": "Advances in Neural Information Processing Systems",
    "language": "en",
    "page": "43852-43879",
    "source": "proceedings.neurips.cc",
    "title": "LayoutPrompter: Awaken the Design Ability of Large Language Models",
    "title-short": "LayoutPrompter",
    "URL": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/88a129e44f25a571ae8b838057c46855-Abstract-Conference.html",
    "volume": "36",
    "author": [
      {
        "family": "Lin",
        "given": "Jiawei"
      },
      {
        "family": "Guo",
        "given": "Jiaqi"
      },
      {
        "family": "Sun",
        "given": "Shizhao"
      },
      {
        "family": "Yang",
        "given": "Zijiang"
      },
      {
        "family": "Lou",
        "given": "Jian-Guang"
      },
      {
        "family": "Zhang",
        "given": "Dongmei"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 12]]
    },
    "issued": {
      "date-parts": [["2023", 12, 15]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/XIAIZBVB",
    "type": "article",
    "abstract": "We propose fine-tuning large language models for generation of stable materials. While unorthodox, fine-tuning large language models on text-encoded atomistic data is simple to implement yet reliable, with around 90% of sampled structures obeying physical constraints on atom positions and charges. Using energy above hull calculations from both learned ML potentials and gold-standard DFT calculations, we show that our strongest model (fine-tuned LLaMA-2 70B) can generate materials predicted to be metastable at about twice the rate (49% vs 28%) of CDVAE, a competing diffusion model. Because of text prompting's inherent flexibility, our models can simultaneously be used for unconditional generation of stable material, infilling of partial structures and text-conditional generation. Finally, we show that language models' ability to capture key symmetries of crystal structures improves with model scale, suggesting that the biases of pretrained LLMs are surprisingly well-suited for atomistic data.",
    "DOI": "10.48550/arXiv.2402.04379",
    "note": "arXiv:2402.04379 [cond-mat]\nTLDR: It is shown that language models' ability to capture key symmetries of crystal structures improves with model scale, suggesting that the biases of pretrained LLMs are surprisingly well-suited for atomistic data.",
    "number": "arXiv:2402.04379",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Fine-Tuned Language Models Generate Stable Inorganic Materials as Text",
    "URL": "http://arxiv.org/abs/2402.04379",
    "author": [
      {
        "family": "Gruver",
        "given": "Nate"
      },
      {
        "family": "Sriram",
        "given": "Anuroop"
      },
      {
        "family": "Madotto",
        "given": "Andrea"
      },
      {
        "family": "Wilson",
        "given": "Andrew Gordon"
      },
      {
        "family": "Zitnick",
        "given": "C. Lawrence"
      },
      {
        "family": "Ulissi",
        "given": "Zachary"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 12]]
    },
    "issued": {
      "date-parts": [["2024", 2, 6]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/JEPKUMH6",
    "type": "article",
    "abstract": "We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community.",
    "DOI": "10.48550/arXiv.2302.13971",
    "note": "arXiv:2302.13971 [cs]",
    "number": "arXiv:2302.13971",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "LLaMA: Open and Efficient Foundation Language Models",
    "title-short": "LLaMA",
    "URL": "http://arxiv.org/abs/2302.13971",
    "author": [
      {
        "family": "Touvron",
        "given": "Hugo"
      },
      {
        "family": "Lavril",
        "given": "Thibaut"
      },
      {
        "family": "Izacard",
        "given": "Gautier"
      },
      {
        "family": "Martinet",
        "given": "Xavier"
      },
      {
        "family": "Lachaux",
        "given": "Marie-Anne"
      },
      {
        "family": "Lacroix",
        "given": "Timothée"
      },
      {
        "family": "Rozière",
        "given": "Baptiste"
      },
      {
        "family": "Goyal",
        "given": "Naman"
      },
      {
        "family": "Hambro",
        "given": "Eric"
      },
      {
        "family": "Azhar",
        "given": "Faisal"
      },
      {
        "family": "Rodriguez",
        "given": "Aurelien"
      },
      {
        "family": "Joulin",
        "given": "Armand"
      },
      {
        "family": "Grave",
        "given": "Edouard"
      },
      {
        "family": "Lample",
        "given": "Guillaume"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 12]]
    },
    "issued": {
      "date-parts": [["2023", 2, 27]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/F6FBFFD9",
    "type": "article-journal",
    "container-title": "Advances in Neural Information Processing Systems",
    "language": "en",
    "page": "53728-53741",
    "source": "proceedings.neurips.cc",
    "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model",
    "title-short": "Direct Preference Optimization",
    "URL": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/a85b405ed65c6477a4fe8302b5e06ce7-Abstract-Conference.html",
    "volume": "36",
    "author": [
      {
        "family": "Rafailov",
        "given": "Rafael"
      },
      {
        "family": "Sharma",
        "given": "Archit"
      },
      {
        "family": "Mitchell",
        "given": "Eric"
      },
      {
        "family": "Manning",
        "given": "Christopher D."
      },
      {
        "family": "Ermon",
        "given": "Stefano"
      },
      {
        "family": "Finn",
        "given": "Chelsea"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 12]]
    },
    "issued": {
      "date-parts": [["2023", 12, 15]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/S8XIJ7F6",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
    "language": "en",
    "page": "24185-24198",
    "source": "openaccess.thecvf.com",
    "title": "InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks",
    "title-short": "InternVL",
    "URL": "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_InternVL_Scaling_up_Vision_Foundation_Models_and_Aligning_for_Generic_CVPR_2024_paper.html",
    "author": [
      {
        "family": "Chen",
        "given": "Zhe"
      },
      {
        "family": "Wu",
        "given": "Jiannan"
      },
      {
        "family": "Wang",
        "given": "Wenhai"
      },
      {
        "family": "Su",
        "given": "Weijie"
      },
      {
        "family": "Chen",
        "given": "Guo"
      },
      {
        "family": "Xing",
        "given": "Sen"
      },
      {
        "family": "Zhong",
        "given": "Muyan"
      },
      {
        "family": "Zhang",
        "given": "Qinglong"
      },
      {
        "family": "Zhu",
        "given": "Xizhou"
      },
      {
        "family": "Lu",
        "given": "Lewei"
      },
      {
        "family": "Li",
        "given": "Bin"
      },
      {
        "family": "Luo",
        "given": "Ping"
      },
      {
        "family": "Lu",
        "given": "Tong"
      },
      {
        "family": "Qiao",
        "given": "Yu"
      },
      {
        "family": "Dai",
        "given": "Jifeng"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 12]]
    },
    "issued": {
      "date-parts": [["2024"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/GQ87QGYX",
    "type": "article",
    "abstract": "Tables contain factual and quantitative data accompanied by various structures and contents that pose challenges for machine comprehension. Previous methods generally design task-specific architectures and objectives for individual tasks, resulting in modal isolation and intricate workflows. In this paper, we present a novel large vision-language model, TabPedia, equipped with a concept synergy mechanism. In this mechanism, all the involved diverse visual table understanding (VTU) tasks and multi-source visual embeddings are abstracted as concepts. This unified framework allows TabPedia to seamlessly integrate VTU tasks, such as table detection, table structure recognition, table querying, and table question answering, by leveraging the capabilities of large language models (LLMs). Moreover, the concept synergy mechanism enables table perception-related and comprehension-related tasks to work in harmony, as they can effectively leverage the needed clues from the corresponding source perception embeddings. Furthermore, to better evaluate the VTU task in real-world scenarios, we establish a new and comprehensive table VQA benchmark, ComTQA, featuring approximately 9,000 QA pairs. Extensive quantitative and qualitative experiments on both table perception and comprehension tasks, conducted across various public benchmarks, validate the effectiveness of our TabPedia. The superior performance further confirms the feasibility of using LLMs for understanding visual tables when all concepts work in synergy. The benchmark ComTQA has been open-sourced at https://huggingface.co/datasets/ByteDance/ComTQA. The source code and model will be released later.",
    "DOI": "10.48550/arXiv.2406.01326",
    "language": "en-US",
    "note": "arXiv:2406.01326 [cs]",
    "number": "arXiv:2406.01326",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "TabPedia: Towards Comprehensive Visual Table Understanding with Concept Synergy",
    "title-short": "TabPedia",
    "URL": "http://arxiv.org/abs/2406.01326",
    "author": [
      {
        "family": "Zhao",
        "given": "Weichao"
      },
      {
        "family": "Feng",
        "given": "Hao"
      },
      {
        "family": "Liu",
        "given": "Qi"
      },
      {
        "family": "Tang",
        "given": "Jingqun"
      },
      {
        "family": "Wei",
        "given": "Shu"
      },
      {
        "family": "Wu",
        "given": "Binghong"
      },
      {
        "family": "Liao",
        "given": "Lei"
      },
      {
        "family": "Ye",
        "given": "Yongjie"
      },
      {
        "family": "Liu",
        "given": "Hao"
      },
      {
        "family": "Li",
        "given": "Houqiang"
      },
      {
        "family": "Huang",
        "given": "Can"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 12]]
    },
    "issued": {
      "date-parts": [["2024", 6, 3]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/37DEIM9N",
    "type": "paper-conference",
    "abstract": "The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.",
    "container-title": "Advances in Neural Information Processing Systems",
    "language": "en-US",
    "publisher": "Curran Associates, Inc.",
    "source": "Neural Information Processing Systems",
    "title": "Attention is All you Need",
    "URL": "https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html",
    "volume": "30",
    "author": [
      {
        "family": "Vaswani",
        "given": "Ashish"
      },
      {
        "family": "Shazeer",
        "given": "Noam"
      },
      {
        "family": "Parmar",
        "given": "Niki"
      },
      {
        "family": "Uszkoreit",
        "given": "Jakob"
      },
      {
        "family": "Jones",
        "given": "Llion"
      },
      {
        "family": "Gomez",
        "given": "Aidan N"
      },
      {
        "family": "Kaiser",
        "given": "Ł",
        "dropping-particle": "ukasz"
      },
      {
        "family": "Polosukhin",
        "given": "Illia"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 12]]
    },
    "issued": {
      "date-parts": [["2017"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/U2SM7JJ4",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
    "language": "en",
    "page": "13480-13491",
    "source": "openaccess.thecvf.com",
    "title": "Enhancing Vision-Language Pre-training with Rich Supervisions",
    "URL": "https://openaccess.thecvf.com/content/CVPR2024/html/Gao_Enhancing_Vision-Language_Pre-training_with_Rich_Supervisions_CVPR_2024_paper.html",
    "author": [
      {
        "family": "Gao",
        "given": "Yuan"
      },
      {
        "family": "Shi",
        "given": "Kunyu"
      },
      {
        "family": "Zhu",
        "given": "Pengkai"
      },
      {
        "family": "Belval",
        "given": "Edouard"
      },
      {
        "family": "Nuriel",
        "given": "Oren"
      },
      {
        "family": "Appalaraju",
        "given": "Srikar"
      },
      {
        "family": "Ghadar",
        "given": "Shabnam"
      },
      {
        "family": "Tu",
        "given": "Zhuowen"
      },
      {
        "family": "Mahadevan",
        "given": "Vijay"
      },
      {
        "family": "Soatto",
        "given": "Stefano"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 12]]
    },
    "issued": {
      "date-parts": [["2024"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/BSRU6CWU",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
    "language": "en",
    "page": "26763-26773",
    "source": "openaccess.thecvf.com",
    "title": "Monkey: Image Resolution and Text Label Are Important Things for Large Multi-modal Models",
    "title-short": "Monkey",
    "URL": "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Monkey_Image_Resolution_and_Text_Label_Are_Important_Things_for_CVPR_2024_paper.html",
    "author": [
      {
        "family": "Li",
        "given": "Zhang"
      },
      {
        "family": "Yang",
        "given": "Biao"
      },
      {
        "family": "Liu",
        "given": "Qiang"
      },
      {
        "family": "Ma",
        "given": "Zhiyin"
      },
      {
        "family": "Zhang",
        "given": "Shuo"
      },
      {
        "family": "Yang",
        "given": "Jingxu"
      },
      {
        "family": "Sun",
        "given": "Yabo"
      },
      {
        "family": "Liu",
        "given": "Yuliang"
      },
      {
        "family": "Bai",
        "given": "Xiang"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 13]]
    },
    "issued": {
      "date-parts": [["2024"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/QC35JFBQ",
    "type": "article",
    "abstract": "We present TextMonkey, a large multimodal model (LMM) tailored for text-centric tasks. Our approach introduces enhancement across several dimensions: By adopting Shifted Window Attention with zero-initialization, we achieve cross-window connectivity at higher input resolutions and stabilize early training; We hypothesize that images may contain redundant tokens, and by using similarity to filter out significant tokens, we can not only streamline the token length but also enhance the model's performance. Moreover, by expanding our model's capabilities to encompass text spotting and grounding, and incorporating positional information into responses, we enhance interpretability. It also learns to perform screenshot tasks through finetuning. Evaluation on 12 benchmarks shows notable improvements: 5.2% in Scene Text-Centric tasks (including STVQA, TextVQA, and OCRVQA), 6.9% in Document-Oriented tasks (such as DocVQA, InfoVQA, ChartVQA, DeepForm, Kleister Charity, and WikiTableQuestions), and 2.8% in Key Information Extraction tasks (comprising FUNSD, SROIE, and POIE). It outperforms in scene text spotting with a 10.9\\% increase and sets a new standard on OCRBench, a comprehensive benchmark consisting of 29 OCR-related assessments, with a score of 561, surpassing previous open-sourced large multimodal models for document understanding. Code will be released at https://github.com/Yuliang-Liu/Monkey.",
    "DOI": "10.48550/arXiv.2403.04473",
    "language": "en-US",
    "note": "arXiv:2403.04473 [cs]",
    "number": "arXiv:2403.04473",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "TextMonkey: An OCR-Free Large Multimodal Model for Understanding Document",
    "title-short": "TextMonkey",
    "URL": "http://arxiv.org/abs/2403.04473",
    "author": [
      {
        "family": "Liu",
        "given": "Yuliang"
      },
      {
        "family": "Yang",
        "given": "Biao"
      },
      {
        "family": "Liu",
        "given": "Qiang"
      },
      {
        "family": "Li",
        "given": "Zhang"
      },
      {
        "family": "Ma",
        "given": "Zhiyin"
      },
      {
        "family": "Zhang",
        "given": "Shuo"
      },
      {
        "family": "Bai",
        "given": "Xiang"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 13]]
    },
    "issued": {
      "date-parts": [["2024", 3, 15]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/N46BYKBG",
    "type": "article",
    "abstract": "We present Kosmos-2.5, a multimodal literate model for machine reading of text-intensive images. Pre-trained on large-scale text-intensive images, Kosmos-2.5 excels in two distinct yet cooperative transcription tasks: (1) generating spatially-aware text blocks, where each block of text is assigned its spatial coordinates within the image, and (2) producing structured text output that captures styles and structures into the markdown format. This unified multimodal literate capability is achieved through a shared Transformer architecture, task-specific prompts, and flexible text representations. We evaluate Kosmos-2.5 on end-to-end document-level text recognition and image-to-markdown text generation. Furthermore, the model can be readily adapted for any text-intensive image understanding task with different prompts through supervised fine-tuning, making it a general-purpose tool for real-world applications involving text-rich images. This work also paves the way for the future scaling of multimodal large language models.",
    "DOI": "10.48550/arXiv.2309.11419",
    "language": "en-US",
    "note": "arXiv:2309.11419 [cs]",
    "number": "arXiv:2309.11419",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Kosmos-2.5: A Multimodal Literate Model",
    "title-short": "Kosmos-2.5",
    "URL": "http://arxiv.org/abs/2309.11419",
    "author": [
      {
        "family": "Lv",
        "given": "Tengchao"
      },
      {
        "family": "Huang",
        "given": "Yupan"
      },
      {
        "family": "Chen",
        "given": "Jingye"
      },
      {
        "family": "Cui",
        "given": "Lei"
      },
      {
        "family": "Ma",
        "given": "Shuming"
      },
      {
        "family": "Chang",
        "given": "Yaoyao"
      },
      {
        "family": "Huang",
        "given": "Shaohan"
      },
      {
        "family": "Wang",
        "given": "Wenhui"
      },
      {
        "family": "Dong",
        "given": "Li"
      },
      {
        "family": "Luo",
        "given": "Weiyao"
      },
      {
        "family": "Wu",
        "given": "Shaoxiang"
      },
      {
        "family": "Wang",
        "given": "Guoxin"
      },
      {
        "family": "Zhang",
        "given": "Cha"
      },
      {
        "family": "Wei",
        "given": "Furu"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 13]]
    },
    "issued": {
      "date-parts": [["2023", 9, 20]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/E64JXM2M",
    "type": "article",
    "abstract": "Large language models (LLMs) have revolutionized the field of artificial intelligence, enabling natural language processing tasks that were previously thought to be exclusive to humans. In this work, we introduce Qwen, the first installment of our large language model series. Qwen is a comprehensive language model series that encompasses distinct models with varying parameter counts. It includes Qwen, the base pretrained language models, and Qwen-Chat, the chat models finetuned with human alignment techniques. The base language models consistently demonstrate superior performance across a multitude of downstream tasks, and the chat models, particularly those trained using Reinforcement Learning from Human Feedback (RLHF), are highly competitive. The chat models possess advanced tool-use and planning capabilities for creating agent applications, showcasing impressive performance even when compared to bigger models on complex tasks like utilizing a code interpreter. Furthermore, we have developed coding-specialized models, Code-Qwen and Code-Qwen-Chat, as well as mathematics-focused models, Math-Qwen-Chat, which are built upon base language models. These models demonstrate significantly improved performance in comparison with open-source models, and slightly fall behind the proprietary models.",
    "DOI": "10.48550/arXiv.2309.16609",
    "language": "en-US",
    "note": "arXiv:2309.16609 [cs]\nTLDR: Qwen is a comprehensive language model series that encompasses distinct models with varying parameter counts, and includes Qwen, the base pretrained language models, and Qwen-Chat, the chat models finetuned with human alignment techniques.",
    "number": "arXiv:2309.16609",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Qwen Technical Report",
    "URL": "http://arxiv.org/abs/2309.16609",
    "author": [
      {
        "family": "Bai",
        "given": "Jinze"
      },
      {
        "family": "Bai",
        "given": "Shuai"
      },
      {
        "family": "Chu",
        "given": "Yunfei"
      },
      {
        "family": "Cui",
        "given": "Zeyu"
      },
      {
        "family": "Dang",
        "given": "Kai"
      },
      {
        "family": "Deng",
        "given": "Xiaodong"
      },
      {
        "family": "Fan",
        "given": "Yang"
      },
      {
        "family": "Ge",
        "given": "Wenbin"
      },
      {
        "family": "Han",
        "given": "Yu"
      },
      {
        "family": "Huang",
        "given": "Fei"
      },
      {
        "family": "Hui",
        "given": "Binyuan"
      },
      {
        "family": "Ji",
        "given": "Luo"
      },
      {
        "family": "Li",
        "given": "Mei"
      },
      {
        "family": "Lin",
        "given": "Junyang"
      },
      {
        "family": "Lin",
        "given": "Runji"
      },
      {
        "family": "Liu",
        "given": "Dayiheng"
      },
      {
        "family": "Liu",
        "given": "Gao"
      },
      {
        "family": "Lu",
        "given": "Chengqiang"
      },
      {
        "family": "Lu",
        "given": "Keming"
      },
      {
        "family": "Ma",
        "given": "Jianxin"
      },
      {
        "family": "Men",
        "given": "Rui"
      },
      {
        "family": "Ren",
        "given": "Xingzhang"
      },
      {
        "family": "Ren",
        "given": "Xuancheng"
      },
      {
        "family": "Tan",
        "given": "Chuanqi"
      },
      {
        "family": "Tan",
        "given": "Sinan"
      },
      {
        "family": "Tu",
        "given": "Jianhong"
      },
      {
        "family": "Wang",
        "given": "Peng"
      },
      {
        "family": "Wang",
        "given": "Shijie"
      },
      {
        "family": "Wang",
        "given": "Wei"
      },
      {
        "family": "Wu",
        "given": "Shengguang"
      },
      {
        "family": "Xu",
        "given": "Benfeng"
      },
      {
        "family": "Xu",
        "given": "Jin"
      },
      {
        "family": "Yang",
        "given": "An"
      },
      {
        "family": "Yang",
        "given": "Hao"
      },
      {
        "family": "Yang",
        "given": "Jian"
      },
      {
        "family": "Yang",
        "given": "Shusheng"
      },
      {
        "family": "Yao",
        "given": "Yang"
      },
      {
        "family": "Yu",
        "given": "Bowen"
      },
      {
        "family": "Yuan",
        "given": "Hongyi"
      },
      {
        "family": "Yuan",
        "given": "Zheng"
      },
      {
        "family": "Zhang",
        "given": "Jianwei"
      },
      {
        "family": "Zhang",
        "given": "Xingxuan"
      },
      {
        "family": "Zhang",
        "given": "Yichang"
      },
      {
        "family": "Zhang",
        "given": "Zhenru"
      },
      {
        "family": "Zhou",
        "given": "Chang"
      },
      {
        "family": "Zhou",
        "given": "Jingren"
      },
      {
        "family": "Zhou",
        "given": "Xiaohuan"
      },
      {
        "family": "Zhu",
        "given": "Tianhang"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 13]]
    },
    "issued": {
      "date-parts": [["2023", 9, 28]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/N88D2PR3",
    "type": "article",
    "abstract": "In this work, we introduce the Qwen-VL series, a set of large-scale vision-language models (LVLMs) designed to perceive and understand both texts and images. Starting from the Qwen-LM as a foundation, we endow it with visual capacity by the meticulously designed (i) visual receptor, (ii) input-output interface, (iii) 3-stage training pipeline, and (iv) multilingual multimodal cleaned corpus. Beyond the conventional image description and question-answering, we implement the grounding and text-reading ability of Qwen-VLs by aligning image-caption-box tuples. The resulting models, including Qwen-VL and Qwen-VL-Chat, set new records for generalist models under similar model scales on a broad range of visual-centric benchmarks (e.g., image captioning, question answering, visual grounding) and different settings (e.g., zero-shot, few-shot). Moreover, on real-world dialog benchmarks, our instruction-tuned Qwen-VL-Chat also demonstrates superiority compared to existing vision-language chatbots. Code, demo and models are available at https://github.com/QwenLM/Qwen-VL.",
    "DOI": "10.48550/arXiv.2308.12966",
    "language": "en-US",
    "note": "arXiv:2308.12966 [cs]",
    "number": "arXiv:2308.12966",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond",
    "title-short": "Qwen-VL",
    "URL": "http://arxiv.org/abs/2308.12966",
    "author": [
      {
        "family": "Bai",
        "given": "Jinze"
      },
      {
        "family": "Bai",
        "given": "Shuai"
      },
      {
        "family": "Yang",
        "given": "Shusheng"
      },
      {
        "family": "Wang",
        "given": "Shijie"
      },
      {
        "family": "Tan",
        "given": "Sinan"
      },
      {
        "family": "Wang",
        "given": "Peng"
      },
      {
        "family": "Lin",
        "given": "Junyang"
      },
      {
        "family": "Zhou",
        "given": "Chang"
      },
      {
        "family": "Zhou",
        "given": "Jingren"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 13]]
    },
    "issued": {
      "date-parts": [["2023", 10, 12]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/5ARC35CA",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
    "language": "en",
    "page": "26296-26306",
    "source": "openaccess.thecvf.com",
    "title": "Improved Baselines with Visual Instruction Tuning",
    "URL": "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Improved_Baselines_with_Visual_Instruction_Tuning_CVPR_2024_paper.html",
    "author": [
      {
        "family": "Liu",
        "given": "Haotian"
      },
      {
        "family": "Li",
        "given": "Chunyuan"
      },
      {
        "family": "Li",
        "given": "Yuheng"
      },
      {
        "family": "Lee",
        "given": "Yong Jae"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 13]]
    },
    "issued": {
      "date-parts": [["2024"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/3GV7NAI7",
    "type": "article",
    "abstract": "This work presents DocPedia, a novel large multimodal model (LMM) for versatile OCR-free document understanding, capable of parsing images up to 2,560$\\times$2,560 resolution. Unlike existing work either struggle with high-resolution documents or give up the large language model thus vision or language ability constrained, our DocPedia directly processes visual input in the frequency domain rather than the pixel space. The unique characteristic enables DocPedia to capture a greater amount of visual and textual information using a limited number of visual tokens. To consistently enhance both perception and comprehension abilities of our model, we develop a dual-stage training strategy and enrich instructions/annotations of all training tasks covering multiple document types. Extensive quantitative and qualitative experiments conducted on various publicly available benchmarks confirm the mutual benefits of jointly learning perception and comprehension tasks. The results provide further evidence of the effectiveness and superior performance of our DocPedia over other methods.",
    "DOI": "10.48550/arXiv.2311.11810",
    "language": "en-US",
    "note": "arXiv:2311.11810 [cs]",
    "number": "arXiv:2311.11810",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "DocPedia: Unleashing the Power of Large Multimodal Model in the Frequency Domain for Versatile Document Understanding",
    "title-short": "DocPedia",
    "URL": "http://arxiv.org/abs/2311.11810",
    "author": [
      {
        "family": "Feng",
        "given": "Hao"
      },
      {
        "family": "Liu",
        "given": "Qi"
      },
      {
        "family": "Liu",
        "given": "Hao"
      },
      {
        "family": "Zhou",
        "given": "Wengang"
      },
      {
        "family": "Li",
        "given": "Houqiang"
      },
      {
        "family": "Huang",
        "given": "Can"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 13]]
    },
    "issued": {
      "date-parts": [["2023", 11, 30]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/CANZGDBD",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
    "language": "en",
    "page": "13613-13623",
    "source": "openaccess.thecvf.com",
    "title": "Synthesize Step-by-Step: Tools Templates and LLMs as Data Generators for Reasoning-Based Chart VQA",
    "title-short": "Synthesize Step-by-Step",
    "URL": "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Synthesize_Step-by-Step_Tools_Templates_and_LLMs_as_Data_Generators_for_CVPR_2024_paper.html",
    "author": [
      {
        "family": "Li",
        "given": "Zhuowan"
      },
      {
        "family": "Jasani",
        "given": "Bhavan"
      },
      {
        "family": "Tang",
        "given": "Peng"
      },
      {
        "family": "Ghadar",
        "given": "Shabnam"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 15]]
    },
    "issued": {
      "date-parts": [["2024"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/RKKEPN2A",
    "type": "article-journal",
    "abstract": "We study the problem of completing various visual document understanding (VDU) tasks, e.g., question answering and information extraction, on real-world documents through human-written instructions. To this end, we propose InstructDoc, the first large-scale collection of 30 publicly available VDU datasets, each with diverse instructions in a unified format, which covers a wide range of 12 tasks and includes open document types/formats. Furthermore, to enhance the generalization performance on VDU tasks, we design a new instruction-based document reading and understanding model, InstructDr, that connects document images, image encoders, and large language models (LLMs) through a trainable bridging module. Experiments demonstrate that InstructDr can effectively adapt to new VDU datasets, tasks, and domains via given instructions and outperforms existing multimodal LLMs and ChatGPT without specific training.",
    "container-title": "Proceedings of the AAAI Conference on Artificial Intelligence",
    "DOI": "10.1609/aaai.v38i17.29874",
    "ISSN": "2374-3468",
    "issue": "17",
    "language": "en",
    "license": "Copyright (c) 2024 Association for the Advancement of Artificial Intelligence",
    "note": "number: 17",
    "page": "19071-19079",
    "source": "ojs.aaai.org",
    "title": "InstructDoc: A Dataset for Zero-Shot Generalization of Visual Document Understanding with Instructions",
    "title-short": "InstructDoc",
    "URL": "https://ojs.aaai.org/index.php/AAAI/article/view/29874",
    "volume": "38",
    "author": [
      {
        "family": "Tanaka",
        "given": "Ryota"
      },
      {
        "family": "Iki",
        "given": "Taichi"
      },
      {
        "family": "Nishida",
        "given": "Kyosuke"
      },
      {
        "family": "Saito",
        "given": "Kuniko"
      },
      {
        "family": "Suzuki",
        "given": "Jun"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 15]]
    },
    "issued": {
      "date-parts": [["2024", 3, 24]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/7ZBCHQ5J",
    "type": "article",
    "abstract": "Structure information is critical for understanding the semantics of text-rich images, such as documents, tables, and charts. Existing Multimodal Large Language Models (MLLMs) for Visual Document Understanding are equipped with text recognition ability but lack general structure understanding abilities for text-rich document images. In this work, we emphasize the importance of structure information in Visual Document Understanding and propose the Unified Structure Learning to boost the performance of MLLMs. Our Unified Structure Learning comprises structure-aware parsing tasks and multi-grained text localization tasks across 5 domains: document, webpage, table, chart, and natural image. To better encode structure information, we design a simple and effective vision-to-text module H-Reducer, which can not only maintain the layout information but also reduce the length of visual features by merging horizontal adjacent patches through convolution, enabling the LLM to understand high-resolution images more efficiently. Furthermore, by constructing structure-aware text sequences and multi-grained pairs of texts and bounding boxes for publicly available text-rich images, we build a comprehensive training set DocStruct4M to support structure learning. Finally, we construct a small but high-quality reasoning tuning dataset DocReason25K to trigger the detailed explanation ability in the document domain. Our model DocOwl 1.5 achieves state-of-the-art performance on 10 visual document understanding benchmarks, improving the SOTA performance of MLLMs with a 7B LLM by more than 10 points in 5/10 benchmarks. Our codes, models, and datasets are publicly available at https://github.com/X-PLUG/mPLUG-DocOwl/tree/main/DocOwl1.5.",
    "DOI": "10.48550/arXiv.2403.12895",
    "language": "en-US",
    "note": "arXiv:2403.12895 [cs]",
    "number": "arXiv:2403.12895",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding",
    "title-short": "mPLUG-DocOwl 1.5",
    "URL": "http://arxiv.org/abs/2403.12895",
    "author": [
      {
        "family": "Hu",
        "given": "Anwen"
      },
      {
        "family": "Xu",
        "given": "Haiyang"
      },
      {
        "family": "Ye",
        "given": "Jiabo"
      },
      {
        "family": "Yan",
        "given": "Ming"
      },
      {
        "family": "Zhang",
        "given": "Liang"
      },
      {
        "family": "Zhang",
        "given": "Bo"
      },
      {
        "family": "Li",
        "given": "Chen"
      },
      {
        "family": "Zhang",
        "given": "Ji"
      },
      {
        "family": "Jin",
        "given": "Qin"
      },
      {
        "family": "Huang",
        "given": "Fei"
      },
      {
        "family": "Zhou",
        "given": "Jingren"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 15]]
    },
    "issued": {
      "date-parts": [["2024", 3, 19]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/Z69C4P6W",
    "type": "article",
    "abstract": "Chart understanding plays a pivotal role when applying Multimodal Large Language Models (MLLMs) to real-world tasks such as analyzing scientific papers or financial reports. However, existing datasets often focus on oversimplified and homogeneous charts with template-based questions, leading to an over-optimistic measure of progress. We demonstrate that although open-source models can appear to outperform strong proprietary models on these benchmarks, a simple stress test with slightly different charts or questions can deteriorate performance by up to 34.5%. In this work, we propose CharXiv, a comprehensive evaluation suite involving 2,323 natural, challenging, and diverse charts from arXiv papers. CharXiv includes two types of questions: 1) descriptive questions about examining basic chart elements and 2) reasoning questions that require synthesizing information across complex visual elements in the chart. To ensure quality, all charts and questions are handpicked, curated, and verified by human experts. Our results reveal a substantial, previously underestimated gap between the reasoning skills of the strongest proprietary model (i.e., GPT-4o), which achieves 47.1% accuracy, and the strongest open-source model (i.e., InternVL Chat V1.5), which achieves 29.2%. All models lag far behind human performance of 80.5%, underscoring weaknesses in the chart understanding capabilities of existing MLLMs. We hope CharXiv facilitates future research on MLLM chart understanding by providing a more realistic and faithful measure of progress. Project page and leaderboard: https://charxiv.github.io/",
    "DOI": "10.48550/arXiv.2406.18521",
    "language": "en-US",
    "note": "arXiv:2406.18521 [cs]",
    "number": "arXiv:2406.18521",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "CharXiv: Charting Gaps in Realistic Chart Understanding in Multimodal LLMs",
    "title-short": "CharXiv",
    "URL": "http://arxiv.org/abs/2406.18521",
    "author": [
      {
        "family": "Wang",
        "given": "Zirui"
      },
      {
        "family": "Xia",
        "given": "Mengzhou"
      },
      {
        "family": "He",
        "given": "Luxi"
      },
      {
        "family": "Chen",
        "given": "Howard"
      },
      {
        "family": "Liu",
        "given": "Yitao"
      },
      {
        "family": "Zhu",
        "given": "Richard"
      },
      {
        "family": "Liang",
        "given": "Kaiqu"
      },
      {
        "family": "Wu",
        "given": "Xindi"
      },
      {
        "family": "Liu",
        "given": "Haotian"
      },
      {
        "family": "Malladi",
        "given": "Sadhika"
      },
      {
        "family": "Chevalier",
        "given": "Alexis"
      },
      {
        "family": "Arora",
        "given": "Sanjeev"
      },
      {
        "family": "Chen",
        "given": "Danqi"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 17]]
    },
    "issued": {
      "date-parts": [["2024", 6, 26]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/68YFQYBF",
    "type": "article",
    "abstract": "Multi-modal large language models have demonstrated impressive performances on most vision-language tasks. However, the model generally lacks the understanding capabilities for specific domain data, particularly when it comes to interpreting chart figures. This is mainly due to the lack of relevant multi-modal instruction tuning datasets. In this article, we create a high-quality instruction-tuning dataset leveraging GPT-4. We develop a multi-step data generation process in which different steps are responsible for generating tabular data, creating chart figures, and designing instruction tuning data separately. Our method's flexibility enables us to generate diverse, high-quality instruction-tuning data consistently and efficiently while maintaining a low resource expenditure. Additionally, it allows us to incorporate a wider variety of chart and task types not yet featured in existing datasets. Next, we introduce ChartLlama, a multi-modal large language model that we've trained using our created dataset. ChartLlama outperforms all prior methods in ChartQA, Chart-to-text, and Chart-extraction evaluation benchmarks. Additionally, ChartLlama significantly improves upon the baseline in our specially compiled chart dataset, which includes new chart and task types. The results of ChartLlama confirm the value and huge potential of our proposed data generation method in enhancing chart comprehension.",
    "DOI": "10.48550/arXiv.2311.16483",
    "language": "en-US",
    "note": "arXiv:2311.16483 [cs]",
    "number": "arXiv:2311.16483",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "ChartLlama: A Multimodal LLM for Chart Understanding and Generation",
    "title-short": "ChartLlama",
    "URL": "http://arxiv.org/abs/2311.16483",
    "author": [
      {
        "family": "Han",
        "given": "Yucheng"
      },
      {
        "family": "Zhang",
        "given": "Chi"
      },
      {
        "family": "Chen",
        "given": "Xin"
      },
      {
        "family": "Yang",
        "given": "Xu"
      },
      {
        "family": "Wang",
        "given": "Zhibin"
      },
      {
        "family": "Yu",
        "given": "Gang"
      },
      {
        "family": "Fu",
        "given": "Bin"
      },
      {
        "family": "Zhang",
        "given": "Hanwang"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 17]]
    },
    "issued": {
      "date-parts": [["2023", 11, 27]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/WNULV8ZP",
    "type": "article",
    "abstract": "Charts play a vital role in data visualization, understanding data patterns, and informed decision-making. However, their unique combination of graphical elements (e.g., bars, lines) and textual components (e.g., labels, legends) poses challenges for general-purpose multimodal models. While vision-language models trained on chart data excel in comprehension, they struggle with generalization. To address these challenges, we propose ChartAssistant, a chart-based vision-language model for universal chart comprehension and reasoning. ChartAssistant leverages ChartSFT, a comprehensive dataset covering diverse chart-related tasks with basic (e.g. bars and pies) and specialized (e.g. radars, and bubbles) chart types. It undergoes a two-stage training process, starting with pre-training on chart-to-table parsing to align chart and text, followed by multitask instruction-following fine-tuning. This approach enables ChartAssistant to achieve competitive performance across various chart tasks. Experimental results demonstrate significant performance gains over the state-of-the-art UniChart and Chartllama method, especially outperforming them on real-world chart data with zero-shot setting. The code and data are available at https://github.com/OpenGVLab/ChartAst.",
    "DOI": "10.48550/arXiv.2401.02384",
    "language": "en-US",
    "note": "arXiv:2401.02384 [cs]",
    "number": "arXiv:2401.02384",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "ChartAssisstant: A Universal Chart Multimodal Language Model via Chart-to-Table Pre-training and Multitask Instruction Tuning",
    "title-short": "ChartAssisstant",
    "URL": "http://arxiv.org/abs/2401.02384",
    "author": [
      {
        "family": "Meng",
        "given": "Fanqing"
      },
      {
        "family": "Shao",
        "given": "Wenqi"
      },
      {
        "family": "Lu",
        "given": "Quanfeng"
      },
      {
        "family": "Gao",
        "given": "Peng"
      },
      {
        "family": "Zhang",
        "given": "Kaipeng"
      },
      {
        "family": "Qiao",
        "given": "Yu"
      },
      {
        "family": "Luo",
        "given": "Ping"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 17]]
    },
    "issued": {
      "date-parts": [["2024", 2, 15]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/QFLRZRBN",
    "type": "article",
    "abstract": "Chart parsing poses a significant challenge due to the diversity of styles, values, texts, and so forth. Even advanced large vision-language models (LVLMs) with billions of parameters struggle to handle such tasks satisfactorily. To address this, we propose OneChart: a reliable agent specifically devised for the structural extraction of chart information. Similar to popular LVLMs, OneChart incorporates an autoregressive main body. Uniquely, to enhance the reliability of the numerical parts of the output, we introduce an auxiliary token placed at the beginning of the total tokens along with an additional decoder. The numerically optimized (auxiliary) token allows subsequent tokens for chart parsing to capture enhanced numerical features through causal attention. Furthermore, with the aid of the auxiliary token, we have devised a self-evaluation mechanism that enables the model to gauge the reliability of its chart parsing results by providing confidence scores for the generated content. Compared to current state-of-the-art (SOTA) chart parsing models, e.g., DePlot, ChartVLM, ChartAst, OneChart significantly outperforms in Average Precision (AP) for chart structural extraction across multiple public benchmarks, despite enjoying only 0.2 billion parameters. Moreover, as a chart parsing agent, it also brings 10%+ accuracy gains for the popular LVLM (LLaVA-1.6) in the downstream ChartQA benchmark.",
    "DOI": "10.48550/arXiv.2404.09987",
    "language": "en-US",
    "note": "arXiv:2404.09987 [cs]",
    "number": "arXiv:2404.09987",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "OneChart: Purify the Chart Structural Extraction via One Auxiliary Token",
    "title-short": "OneChart",
    "URL": "http://arxiv.org/abs/2404.09987",
    "author": [
      {
        "family": "Chen",
        "given": "Jinyue"
      },
      {
        "family": "Kong",
        "given": "Lingyu"
      },
      {
        "family": "Wei",
        "given": "Haoran"
      },
      {
        "family": "Liu",
        "given": "Chenglong"
      },
      {
        "family": "Ge",
        "given": "Zheng"
      },
      {
        "family": "Zhao",
        "given": "Liang"
      },
      {
        "family": "Sun",
        "given": "Jianjian"
      },
      {
        "family": "Han",
        "given": "Chunrui"
      },
      {
        "family": "Zhang",
        "given": "Xiangyu"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 17]]
    },
    "issued": {
      "date-parts": [["2024", 4, 25]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/THJKJBPL",
    "type": "article",
    "abstract": "Recently, many versatile Multi-modal Large Language Models (MLLMs) have emerged continuously. However, their capacity to query information depicted in visual charts and engage in reasoning based on the queried contents remains under-explored. In this paper, to comprehensively and rigorously benchmark the ability of the off-the-shelf MLLMs in the chart domain, we construct ChartX, a multi-modal evaluation set covering 18 chart types, 7 chart tasks, 22 disciplinary topics, and high-quality chart data. Besides, we develop ChartVLM to offer a new perspective on handling multi-modal tasks that strongly depend on interpretable patterns, such as reasoning tasks in the field of charts or geometric images. We evaluate the chart-related ability of mainstream MLLMs and our ChartVLM on the proposed ChartX evaluation set. Extensive experiments demonstrate that ChartVLM surpasses both versatile and chart-related large models, achieving results comparable to GPT-4V. We believe that our study can pave the way for further exploration in creating a more comprehensive chart evaluation set and developing more interpretable multi-modal models. Both ChartX and ChartVLM are available at: https://github.com/UniModal4Reasoning/ChartVLM",
    "DOI": "10.48550/arXiv.2402.12185",
    "language": "en-US",
    "note": "arXiv:2402.12185 [cs]",
    "number": "arXiv:2402.12185",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "ChartX & ChartVLM: A Versatile Benchmark and Foundation Model for Complicated Chart Reasoning",
    "title-short": "ChartX & ChartVLM",
    "URL": "http://arxiv.org/abs/2402.12185",
    "author": [
      {
        "family": "Xia",
        "given": "Renqiu"
      },
      {
        "family": "Zhang",
        "given": "Bo"
      },
      {
        "family": "Ye",
        "given": "Hancheng"
      },
      {
        "family": "Yan",
        "given": "Xiangchao"
      },
      {
        "family": "Liu",
        "given": "Qi"
      },
      {
        "family": "Zhou",
        "given": "Hongbin"
      },
      {
        "family": "Chen",
        "given": "Zijun"
      },
      {
        "family": "Dou",
        "given": "Min"
      },
      {
        "family": "Shi",
        "given": "Botian"
      },
      {
        "family": "Yan",
        "given": "Junchi"
      },
      {
        "family": "Qiao",
        "given": "Yu"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 17]]
    },
    "issued": {
      "date-parts": [["2024", 2, 19]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/TWITB8CK",
    "type": "article",
    "abstract": "Charts are important for presenting and explaining complex data relationships. Recently, multimodal large language models (MLLMs) have shown remarkable capabilities in various chart understanding tasks. However, the sheer size of these models in terms of parameters and computational requirements limits their use in resource-constrained environments. In this paper, we present TinyChart, an efficient MLLM for chart understanding with only 3B parameters. TinyChart overcomes two key challenges in efficient chart understanding: (1) reduce the burden of learning numerical computations through a Program-of-Thoughts (PoT) learning strategy, which trains the model to generate Python programs for numerical calculations, and (2) reduce lengthy vision feature sequences produced by the vision transformer for high-resolution images through a Vision Token Merging module, which gradually merges most similar vision tokens. Extensive experiments demonstrate that our 3B TinyChart achieves SOTA performance on a variety of chart understanding benchmarks including ChartQA, Chart-to-Text, Chart-to-Table, OpenCQA, and ChartX. It outperforms several chart understanding MLLM with up to 13B parameters such as ChartLlama and ChartAst, and close-sourced general-purpose MLLM GPT-4V on ChartQA. It also demonstrates its superior efficiency with higher throughput during inference due to a smaller model scale and more efficient vision encoding. Our code and model are available at https://github.com/X-PLUG/mPLUG-DocOwl/tree/main/TinyChart.",
    "DOI": "10.48550/arXiv.2404.16635",
    "language": "en-US",
    "note": "arXiv:2404.16635 [cs]",
    "number": "arXiv:2404.16635",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "TinyChart: Efficient Chart Understanding with Visual Token Merging and Program-of-Thoughts Learning",
    "title-short": "TinyChart",
    "URL": "http://arxiv.org/abs/2404.16635",
    "author": [
      {
        "family": "Zhang",
        "given": "Liang"
      },
      {
        "family": "Hu",
        "given": "Anwen"
      },
      {
        "family": "Xu",
        "given": "Haiyang"
      },
      {
        "family": "Yan",
        "given": "Ming"
      },
      {
        "family": "Xu",
        "given": "Yichen"
      },
      {
        "family": "Jin",
        "given": "Qin"
      },
      {
        "family": "Zhang",
        "given": "Ji"
      },
      {
        "family": "Huang",
        "given": "Fei"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 17]]
    },
    "issued": {
      "date-parts": [["2024", 4, 25]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/GABRN37M",
    "type": "article",
    "abstract": "With the rapid development of large language models (LLMs) and their integration into large multimodal models (LMMs), there has been impressive progress in zero-shot completion of user-oriented vision-language tasks. However, a gap remains in the domain of chart image understanding due to the distinct abstract components in charts. To address this, we introduce a large-scale MultiModal Chart Instruction (\\textbf{MMC-Instruction}) dataset comprising 600k instances supporting diverse tasks and chart types. Leveraging this data, we develop MultiModal Chart Assistant (\\textbf{MMCA}), an LMM that achieves state-of-the-art performance on existing chart QA benchmarks. Recognizing the need for a comprehensive evaluation of LMM chart understanding, we also propose a MultiModal Chart Benchmark (\\textbf{MMC-Benchmark}), a comprehensive human-annotated benchmark with nine distinct tasks evaluating reasoning capabilities over charts. Extensive experiments on MMC-Benchmark reveal the limitations of existing LMMs on correctly interpreting charts, even for the most recent GPT-4V model. Our work provides an instruction-tuning methodology and benchmark to advance multimodal understanding of charts. Code and data are available at https://github.com/FuxiaoLiu/MMC.",
    "DOI": "10.48550/arXiv.2311.10774",
    "language": "en-US",
    "note": "arXiv:2311.10774 [cs]",
    "number": "arXiv:2311.10774",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "MMC: Advancing Multimodal Chart Understanding with Large-scale Instruction Tuning",
    "title-short": "MMC",
    "URL": "http://arxiv.org/abs/2311.10774",
    "author": [
      {
        "family": "Liu",
        "given": "Fuxiao"
      },
      {
        "family": "Wang",
        "given": "Xiaoyang"
      },
      {
        "family": "Yao",
        "given": "Wenlin"
      },
      {
        "family": "Chen",
        "given": "Jianshu"
      },
      {
        "family": "Song",
        "given": "Kaiqiang"
      },
      {
        "family": "Cho",
        "given": "Sangwoo"
      },
      {
        "family": "Yacoob",
        "given": "Yaser"
      },
      {
        "family": "Yu",
        "given": "Dong"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 18]]
    },
    "issued": {
      "date-parts": [["2024", 4, 15]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/HYUJYVQA",
    "type": "article",
    "abstract": "Charts provide visual representations of data and are widely used for analyzing information, addressing queries, and conveying insights to others. Various chart-related downstream tasks have emerged recently, such as question-answering and summarization. A common strategy to solve these tasks is to fine-tune various models originally trained on vision tasks language. However, such task-specific models are not capable of solving a wide range of chart-related tasks, constraining their real-world applicability. To overcome these challenges, we introduce ChartInstruct: a novel chart-specific vision-language Instruction-following dataset comprising 191K instructions generated with 71K charts. We then present two distinct systems for instruction tuning on such datasets: (1) an end-to-end model that connects a vision encoder for chart understanding with a LLM; and (2) a pipeline model that employs a two-step approach to extract chart data tables and input them into the LLM. In experiments on four downstream tasks, we first show the effectiveness of our model--achieving a new set of state-of-the-art results. Further evaluation shows that our instruction-tuning approach supports a wide array of real-world chart comprehension and reasoning scenarios, thereby expanding the scope and applicability of our models to new kinds of tasks.",
    "DOI": "10.48550/arXiv.2403.09028",
    "language": "en-US",
    "note": "arXiv:2403.09028 [cs]",
    "number": "arXiv:2403.09028",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "ChartInstruct: Instruction Tuning for Chart Comprehension and Reasoning",
    "title-short": "ChartInstruct",
    "URL": "http://arxiv.org/abs/2403.09028",
    "author": [
      {
        "family": "Masry",
        "given": "Ahmed"
      },
      {
        "family": "Shahmohammadi",
        "given": "Mehrad"
      },
      {
        "family": "Parvez",
        "given": "Md Rizwan"
      },
      {
        "family": "Hoque",
        "given": "Enamul"
      },
      {
        "family": "Joty",
        "given": "Shafiq"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 18]]
    },
    "issued": {
      "date-parts": [["2024", 3, 13]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/JNHV969L",
    "type": "paper-conference",
    "abstract": "High-quality alt text is crucial for making scientific figures accessible to blind and low-vision readers. Crafting complete, accurate alt text is challenging even for domain experts, as published figures often depict complex visual information and readers have varied informational needs. These challenges, along with high diversity in figure types and domain-specific details, also limit the usefulness of fully automated approaches. Consequently, the prevalence of high-quality alt text is very low in scientific papers today. We investigate whether and how human-AI collaborative editing systems can help address the difficulty of writing high-quality alt text for complex scientific figures. We present FigurA11y, an interactive system that generates draft alt text and provides suggestions for author revisions using a pipeline driven by extracted figure and paper metadata. We test two versions, motivated by prior work on visual accessibility and writing support. The base Draft+Revise&nbsp;version provides authors with an automatically generated draft description to revise, along with extracted figure metadata and figure-specific alt text guidelines to support the revision process. The full Interactive Assistance&nbsp;version further adds contextualized suggestions: text snippets to iteratively produce descriptions, and hypothetical user questions with possible answers to reveal potential ambiguities and resolutions. In a study of authors (N=14), we found the system assisted them in efficiently producing descriptive alt text. Generated drafts and interface elements enabled authors to quickly initiate and edit detailed descriptions. Additionally, interactive suggestions from the full system prompted more iteration and highlighted aspects for authors to consider, resulting in greater deviation from the drafts without increased average cognitive load or manual effort.",
    "collection-title": "IUI '24",
    "container-title": "Proceedings of the 29th International Conference on Intelligent User Interfaces",
    "DOI": "10.1145/3640543.3645212",
    "event-place": "New York, NY, USA",
    "ISBN": "979-8-4007-0508-3",
    "language": "en-US",
    "page": "886–906",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "source": "ACM Digital Library",
    "title": "FigurA11y: AI Assistance for Writing Scientific Alt Text",
    "title-short": "FigurA11y",
    "URL": "https://doi.org/10.1145/3640543.3645212",
    "author": [
      {
        "family": "Singh",
        "given": "Nikhil"
      },
      {
        "family": "Wang",
        "given": "Lucy Lu"
      },
      {
        "family": "Bragg",
        "given": "Jonathan"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 17]]
    },
    "issued": {
      "date-parts": [["2024", 4, 5]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/A7IFI55L",
    "type": "article",
    "abstract": "We introduce TableLLM, a robust large language model (LLM) with 13 billion parameters, purpose-built for proficiently handling tabular data manipulation tasks, whether they are embedded within documents or spreadsheets, catering to real-world office scenarios. We propose a distant supervision method for training, which comprises a reasoning process extension strategy, aiding in training LLMs to understand reasoning patterns more effectively as well as a cross-way validation strategy, ensuring the quality of the automatically generated data. To evaluate the performance of TableLLM, we have crafted a benchmark tailored to address both document and spreadsheet formats as well as constructed a well-organized evaluation pipeline capable of handling both scenarios. Thorough evaluations underscore the advantages of TableLLM when compared to various existing general-purpose and tabular data-focused LLMs. We have publicly released the model checkpoint, source code, benchmarks, and a web application for user interaction.Our codes and data are publicly available at https://github.com/TableLLM/TableLLM.",
    "DOI": "10.48550/arXiv.2403.19318",
    "language": "en-US",
    "note": "arXiv:2403.19318 [cs]",
    "number": "arXiv:2403.19318",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "TableLLM: Enabling Tabular Data Manipulation by LLMs in Real Office Usage Scenarios",
    "title-short": "TableLLM",
    "URL": "http://arxiv.org/abs/2403.19318",
    "author": [
      {
        "family": "Zhang",
        "given": "Xiaokang"
      },
      {
        "family": "Zhang",
        "given": "Jing"
      },
      {
        "family": "Ma",
        "given": "Zeyao"
      },
      {
        "family": "Li",
        "given": "Yang"
      },
      {
        "family": "Zhang",
        "given": "Bohan"
      },
      {
        "family": "Li",
        "given": "Guanlin"
      },
      {
        "family": "Yao",
        "given": "Zijun"
      },
      {
        "family": "Xu",
        "given": "Kangli"
      },
      {
        "family": "Zhou",
        "given": "Jinchang"
      },
      {
        "family": "Zhang-Li",
        "given": "Daniel"
      },
      {
        "family": "Yu",
        "given": "Jifan"
      },
      {
        "family": "Zhao",
        "given": "Shu"
      },
      {
        "family": "Li",
        "given": "Juanzi"
      },
      {
        "family": "Tang",
        "given": "Jie"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 18]]
    },
    "issued": {
      "date-parts": [["2024", 4, 1]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/X2TQM8TY",
    "type": "article",
    "abstract": "Building cross-model intelligence that can understand charts and communicate the salient information hidden behind them is an appealing challenge in the vision and language(V+L) community. The capability to uncover the underlined table data of chart figures is a critical key to automatic chart understanding. We introduce ChartT5, a V+L model that learns how to interpret table information from chart images via cross-modal pre-training on plot table pairs. Specifically, we propose two novel pre-training objectives: Masked Header Prediction (MHP) and Masked Value Prediction (MVP) to facilitate the model with different skills to interpret the table information. We have conducted extensive experiments on chart question answering and chart summarization to verify the effectiveness of the proposed pre-training strategies. In particular, on the ChartQA benchmark, our ChartT5 outperforms the state-of-the-art non-pretraining methods by over 8% performance gains.",
    "DOI": "10.48550/arXiv.2305.18641",
    "language": "en-US",
    "note": "arXiv:2305.18641 [cs]",
    "number": "arXiv:2305.18641",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Enhanced Chart Understanding in Vision and Language Task via Cross-modal Pre-training on Plot Table Pairs",
    "URL": "http://arxiv.org/abs/2305.18641",
    "author": [
      {
        "family": "Zhou",
        "given": "Mingyang"
      },
      {
        "family": "Fung",
        "given": "Yi R."
      },
      {
        "family": "Chen",
        "given": "Long"
      },
      {
        "family": "Thomas",
        "given": "Christopher"
      },
      {
        "family": "Ji",
        "given": "Heng"
      },
      {
        "family": "Chang",
        "given": "Shih-Fu"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 18]]
    },
    "issued": {
      "date-parts": [["2023", 5, 29]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/RMZKP84U",
    "type": "article",
    "abstract": "Visual language data such as plots, charts, and infographics are ubiquitous in the human world. However, state-of-the-art vision-language models do not perform well on these data. We propose MatCha (Math reasoning and Chart derendering pretraining) to enhance visual language models' capabilities in jointly modeling charts/plots and language data. Specifically, we propose several pretraining tasks that cover plot deconstruction and numerical reasoning which are the key capabilities in visual language modeling. We perform the MatCha pretraining starting from Pix2Struct, a recently proposed image-to-text visual language model. On standard benchmarks such as PlotQA and ChartQA, the MatCha model outperforms state-of-the-art methods by as much as nearly 20%. We also examine how well MatCha pretraining transfers to domains such as screenshots, textbook diagrams, and document figures and observe overall improvement, verifying the usefulness of MatCha pretraining on broader visual language tasks.",
    "DOI": "10.48550/arXiv.2212.09662",
    "language": "en-US",
    "note": "arXiv:2212.09662 [cs]\nTLDR: This work proposes MatCha (Math reasoning and Chart derendering pretraining) to enhance visual language models’ capabilities in jointly modeling charts/plots and language data, and proposes several pretraining tasks that cover plot deconstruction and numerical reasoning which are the key capabilities in visual language modeling.",
    "number": "arXiv:2212.09662",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "MatCha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering",
    "title-short": "MatCha",
    "URL": "http://arxiv.org/abs/2212.09662",
    "author": [
      {
        "family": "Liu",
        "given": "Fangyu"
      },
      {
        "family": "Piccinno",
        "given": "Francesco"
      },
      {
        "family": "Krichene",
        "given": "Syrine"
      },
      {
        "family": "Pang",
        "given": "Chenxi"
      },
      {
        "family": "Lee",
        "given": "Kenton"
      },
      {
        "family": "Joshi",
        "given": "Mandar"
      },
      {
        "family": "Altun",
        "given": "Yasemin"
      },
      {
        "family": "Collier",
        "given": "Nigel"
      },
      {
        "family": "Eisenschlos",
        "given": "Julian Martin"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 18]]
    },
    "issued": {
      "date-parts": [["2023", 5, 23]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/XH5VVTNJ",
    "type": "article",
    "abstract": "Charts are very popular for analyzing data, visualizing key insights and answering complex reasoning questions about data. To facilitate chart-based data analysis using natural language, several downstream tasks have been introduced recently such as chart question answering and chart summarization. However, most of the methods that solve these tasks use pretraining on language or vision-language tasks that do not attempt to explicitly model the structure of the charts (e.g., how data is visually encoded and how chart elements are related to each other). To address this, we first build a large corpus of charts covering a wide variety of topics and visual styles. We then present UniChart, a pretrained model for chart comprehension and reasoning. UniChart encodes the relevant text, data, and visual elements of charts and then uses a chart-grounded text decoder to generate the expected output in natural language. We propose several chart-specific pretraining tasks that include: (i) low-level tasks to extract the visual elements (e.g., bars, lines) and data from charts, and (ii) high-level tasks to acquire chart understanding and reasoning skills. We find that pretraining the model on a large corpus with chart-specific low- and high-level tasks followed by finetuning on three down-streaming tasks results in state-of-the-art performance on three downstream tasks.",
    "DOI": "10.48550/arXiv.2305.14761",
    "language": "en-US",
    "note": "arXiv:2305.14761 [cs]",
    "number": "arXiv:2305.14761",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "UniChart: A Universal Vision-language Pretrained Model for Chart Comprehension and Reasoning",
    "title-short": "UniChart",
    "URL": "http://arxiv.org/abs/2305.14761",
    "author": [
      {
        "family": "Masry",
        "given": "Ahmed"
      },
      {
        "family": "Kavehzadeh",
        "given": "Parsa"
      },
      {
        "family": "Do",
        "given": "Xuan Long"
      },
      {
        "family": "Hoque",
        "given": "Enamul"
      },
      {
        "family": "Joty",
        "given": "Shafiq"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 18]]
    },
    "issued": {
      "date-parts": [["2023", 10, 10]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/GALWR9LI",
    "type": "paper-conference",
    "abstract": "Visually-situated language is ubiquitous—sources range from textbooks with diagrams to web pages with images and tables, to mobile apps with buttons and forms. Perhaps due to this diversity, previous work has typically relied on domain-specific recipes with limited sharing of the underlying data, model architectures, and objectives. We present Pix2Struct, a pretrained image-to-text model for purely visual language understanding, which can be finetuned on tasks containing visually-situated language. Pix2Struct is pretrained by learning to parse masked screenshots of web pages into simplified HTML. The web, with its richness of visual elements cleanly reflected in the HTML structure, provides a large source of pretraining data well suited to the diversity of downstream tasks. Intuitively, this objective subsumes common pretraining signals such as OCR, language modeling, and image captioning. In addition to the novel pretraining strategy, we introduce a variable-resolution input representation and a more flexible integration of language and vision inputs, where language prompts such as questions are rendered directly on top of the input image. For the first time, we show that a single pretrained model can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images.",
    "container-title": "Proceedings of the 40th International Conference on Machine Learning",
    "event-title": "International Conference on Machine Learning",
    "language": "en",
    "note": "ISSN: 2640-3498",
    "page": "18893-18912",
    "publisher": "PMLR",
    "source": "proceedings.mlr.press",
    "title": "Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding",
    "title-short": "Pix2Struct",
    "URL": "https://proceedings.mlr.press/v202/lee23g.html",
    "author": [
      {
        "family": "Lee",
        "given": "Kenton"
      },
      {
        "family": "Joshi",
        "given": "Mandar"
      },
      {
        "family": "Turc",
        "given": "Iulia Raluca"
      },
      {
        "family": "Hu",
        "given": "Hexiang"
      },
      {
        "family": "Liu",
        "given": "Fangyu"
      },
      {
        "family": "Eisenschlos",
        "given": "Julian Martin"
      },
      {
        "family": "Khandelwal",
        "given": "Urvashi"
      },
      {
        "family": "Shaw",
        "given": "Peter"
      },
      {
        "family": "Chang",
        "given": "Ming-Wei"
      },
      {
        "family": "Toutanova",
        "given": "Kristina"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 18]]
    },
    "issued": {
      "date-parts": [["2023", 7, 3]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/AKVAX9FC",
    "type": "article",
    "abstract": "Visual language such as charts and plots is ubiquitous in the human world. Comprehending plots and charts requires strong reasoning skills. Prior state-of-the-art (SOTA) models require at least tens of thousands of training examples and their reasoning capabilities are still much limited, especially on complex human-written queries. This paper presents the first one-shot solution to visual language reasoning. We decompose the challenge of visual language reasoning into two steps: (1) plot-to-text translation, and (2) reasoning over the translated text. The key in this method is a modality conversion module, named as DePlot, which translates the image of a plot or chart to a linearized table. The output of DePlot can then be directly used to prompt a pretrained large language model (LLM), exploiting the few-shot reasoning capabilities of LLMs. To obtain DePlot, we standardize the plot-to-table task by establishing unified task formats and metrics, and train DePlot end-to-end on this task. DePlot can then be used off-the-shelf together with LLMs in a plug-and-play fashion. Compared with a SOTA model finetuned on more than >28k data points, DePlot+LLM with just one-shot prompting achieves a 24.0% improvement over finetuned SOTA on human-written queries from the task of chart QA.",
    "DOI": "10.48550/arXiv.2212.10505",
    "language": "en-US",
    "note": "arXiv:2212.10505 [cs]",
    "number": "arXiv:2212.10505",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "DePlot: One-shot visual language reasoning by plot-to-table translation",
    "title-short": "DePlot",
    "URL": "http://arxiv.org/abs/2212.10505",
    "author": [
      {
        "family": "Liu",
        "given": "Fangyu"
      },
      {
        "family": "Eisenschlos",
        "given": "Julian Martin"
      },
      {
        "family": "Piccinno",
        "given": "Francesco"
      },
      {
        "family": "Krichene",
        "given": "Syrine"
      },
      {
        "family": "Pang",
        "given": "Chenxi"
      },
      {
        "family": "Lee",
        "given": "Kenton"
      },
      {
        "family": "Joshi",
        "given": "Mandar"
      },
      {
        "family": "Chen",
        "given": "Wenhu"
      },
      {
        "family": "Collier",
        "given": "Nigel"
      },
      {
        "family": "Altun",
        "given": "Yasemin"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 18]]
    },
    "issued": {
      "date-parts": [["2023", 5, 23]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/S434G2GL",
    "type": "article",
    "abstract": "Recent advancements in large vision-language models (LVLMs) have led to significant progress in generating natural language descriptions for visual content and thus enhancing various applications. One issue with these powerful models is that they sometimes produce texts that are factually inconsistent with the visual input. While there has been some effort to mitigate such inconsistencies in natural image captioning, the factuality of generated captions for structured document images, such as charts, has not received as much scrutiny, posing a potential threat to information reliability in critical applications. This work delves into the factuality aspect by introducing a comprehensive typology of factual errors in generated chart captions. A large-scale human annotation effort provides insight into the error patterns and frequencies in captions crafted by various chart captioning models, ultimately forming the foundation of a novel dataset, CHOCOLATE. Our analysis reveals that even state-of-the-art models, including GPT-4V, frequently produce captions laced with factual inaccuracies. In response to this challenge, we establish the new task of Chart Caption Factual Error Correction and introduce CHARTVE, a model for visual entailment that outperforms proprietary and open-source LVLMs in evaluating factual consistency. Furthermore, we propose C2TFEC, an interpretable two-stage framework that excels at correcting factual errors. This work inaugurates a new domain in factual error correction for chart captions, presenting a novel evaluation mechanism, and demonstrating an effective approach to ensuring the factuality of generated chart captions. The code and data as well as the continuously updated benchmark can be found at: https://khuangaf.github.io/CHOCOLATE/.",
    "DOI": "10.48550/arXiv.2312.10160",
    "language": "en-US",
    "note": "arXiv:2312.10160 [cs]",
    "number": "arXiv:2312.10160",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Do LVLMs Understand Charts? Analyzing and Correcting Factual Errors in Chart Captioning",
    "title-short": "Do LVLMs Understand Charts?",
    "URL": "http://arxiv.org/abs/2312.10160",
    "author": [
      {
        "family": "Huang",
        "given": "Kung-Hsiang"
      },
      {
        "family": "Zhou",
        "given": "Mingyang"
      },
      {
        "family": "Chan",
        "given": "Hou Pong"
      },
      {
        "family": "Fung",
        "given": "Yi R."
      },
      {
        "family": "Wang",
        "given": "Zhenhailong"
      },
      {
        "family": "Zhang",
        "given": "Lingyu"
      },
      {
        "family": "Chang",
        "given": "Shih-Fu"
      },
      {
        "family": "Ji",
        "given": "Heng"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 18]]
    },
    "issued": {
      "date-parts": [["2024", 5, 30]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/5J9J8AD3",
    "type": "article",
    "abstract": "A number of tasks have been proposed recently to facilitate easy access to charts such as chart QA and summarization. The dominant paradigm to solve these tasks has been to fine-tune a pretrained model on the task data. However, this approach is not only expensive but also not generalizable to unseen tasks. On the other hand, large language models (LLMs) have shown impressive generalization capabilities to unseen tasks with zero- or few-shot prompting. However, their application to chart-related tasks is not trivial as these tasks typically involve considering not only the underlying data but also the visual features in the chart image. We propose PromptChart, a multimodal few-shot prompting framework with LLMs for chart-related applications. By analyzing the tasks carefully, we have come up with a set of prompting guidelines for each task to elicit the best few-shot performance from LLMs. We further propose a strategy to inject visual information into the prompts. Our experiments on three different chart-related information consumption tasks show that with properly designed prompts LLMs can excel on the benchmarks, achieving state-of-the-art.",
    "DOI": "10.48550/arXiv.2312.10610",
    "language": "en-US",
    "note": "arXiv:2312.10610 [cs]",
    "number": "arXiv:2312.10610",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Do LLMs Work on Charts? Designing Few-Shot Prompts for Chart Question Answering and Summarization",
    "title-short": "Do LLMs Work on Charts?",
    "URL": "http://arxiv.org/abs/2312.10610",
    "author": [
      {
        "family": "Do",
        "given": "Xuan Long"
      },
      {
        "family": "Hassanpour",
        "given": "Mohammad"
      },
      {
        "family": "Masry",
        "given": "Ahmed"
      },
      {
        "family": "Kavehzadeh",
        "given": "Parsa"
      },
      {
        "family": "Hoque",
        "given": "Enamul"
      },
      {
        "family": "Joty",
        "given": "Shafiq"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 18]]
    },
    "issued": {
      "date-parts": [["2023", 12, 17]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/LKJHYW4K",
    "type": "article",
    "abstract": "Visual language reasoning requires a system to extract text or numbers from information-dense images like charts or plots and perform logical or arithmetic reasoning to arrive at an answer. To tackle this task, existing work relies on either (1) an end-to-end vision-language model trained on a large amount of data, or (2) a two-stage pipeline where a captioning model converts the image into text that is further read by another large language model to deduce the answer. However, the former approach forces the model to answer a complex question with one single step, and the latter approach is prone to inaccurate or distracting information in the converted text that can confuse the language model. In this work, we propose a dual-system for multi-step multimodal reasoning, which consists of a \"System-1\" step for visual information extraction and a \"System-2\" step for deliberate reasoning. Given an input, System-2 breaks down the question into atomic sub-steps, each guiding System-1 to extract the information required for reasoning from the image. Experiments on chart and plot datasets show that our method with a pre-trained System-2 module performs competitively compared to prior work on in- and out-of-distribution data. By fine-tuning the System-2 module (LLaMA-2 70B) on only a small amount of data on multi-step reasoning, the accuracy of our method is further improved and surpasses the best fully-supervised end-to-end approach by 5.7% and a pipeline approach with FlanPaLM (540B) by 7.5% on a challenging dataset with human-authored questions.",
    "DOI": "10.48550/arXiv.2310.02804",
    "language": "en-US",
    "note": "arXiv:2310.02804 [cs]",
    "number": "arXiv:2310.02804",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "DOMINO: A Dual-System for Multi-step Visual Language Reasoning",
    "title-short": "DOMINO",
    "URL": "http://arxiv.org/abs/2310.02804",
    "author": [
      {
        "family": "Wang",
        "given": "Peifang"
      },
      {
        "family": "Golovneva",
        "given": "Olga"
      },
      {
        "family": "Aghajanyan",
        "given": "Armen"
      },
      {
        "family": "Ren",
        "given": "Xiang"
      },
      {
        "family": "Chen",
        "given": "Muhao"
      },
      {
        "family": "Celikyilmaz",
        "given": "Asli"
      },
      {
        "family": "Fazel-Zarandi",
        "given": "Maryam"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 18]]
    },
    "issued": {
      "date-parts": [["2023", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/W6HV7KBJ",
    "type": "article",
    "abstract": "Charts are common in literature across different scientific fields, conveying rich information easily accessible to readers. Current chart-related tasks focus on either chart perception which refers to extracting information from the visual charts, or performing reasoning given the extracted data, e.g. in a tabular form. In this paper, we aim to establish a unified and label-efficient learning paradigm for joint perception and reasoning tasks, which can be generally applicable to different downstream tasks, beyond the question-answering task as specifically studied in peer works. Specifically, StructChart first reformulates the chart information from the popular tubular form (specifically linearized CSV) to the proposed Structured Triplet Representations (STR), which is more friendly for reducing the task gap between chart perception and reasoning due to the employed structured information extraction for charts. We then propose a Structuring Chart-oriented Representation Metric (SCRM) to quantitatively evaluate the performance for the chart perception task. To enrich the dataset for training, we further explore the possibility of leveraging the Large Language Model (LLM), enhancing the chart diversity in terms of both chart visual style and its statistical information. Extensive experiments are conducted on various chart-related tasks, demonstrating the effectiveness and promising potential for a unified chart perception-reasoning paradigm to push the frontier of chart understanding.",
    "DOI": "10.48550/arXiv.2309.11268",
    "language": "en-US",
    "note": "arXiv:2309.11268 [cs]",
    "number": "arXiv:2309.11268",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "StructChart: Perception, Structuring, Reasoning for Visual Chart Understanding",
    "title-short": "StructChart",
    "URL": "http://arxiv.org/abs/2309.11268",
    "author": [
      {
        "family": "Xia",
        "given": "Renqiu"
      },
      {
        "family": "Zhang",
        "given": "Bo"
      },
      {
        "family": "Peng",
        "given": "Haoyang"
      },
      {
        "family": "Ye",
        "given": "Hancheng"
      },
      {
        "family": "Yan",
        "given": "Xiangchao"
      },
      {
        "family": "Ye",
        "given": "Peng"
      },
      {
        "family": "Shi",
        "given": "Botian"
      },
      {
        "family": "Qiao",
        "given": "Yu"
      },
      {
        "family": "Yan",
        "given": "Junchi"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 18]]
    },
    "issued": {
      "date-parts": [["2024", 2, 18]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/GF8A99J5",
    "type": "article",
    "abstract": "In this paper, we explore a forward-thinking question: Is GPT-4V effective at low-level data analysis tasks on charts? To this end, we first curate a large-scale dataset, named ChartInsights, consisting of 89,388 quartets (chart, task, question, answer) and covering 10 widely-used low-level data analysis tasks on 7 chart types. Firstly, we conduct systematic evaluations to understand the capabilities and limitations of 18 advanced MLLMs, which include 12 open-source models and 6 closed-source models. Starting with a standard textual prompt approach, the average accuracy rate across the 18 MLLMs is 36.17%. Among all the models, GPT-4V achieves the highest accuracy, reaching 56.13%. To understand the limitations of multimodal large models in low-level data analysis tasks, we have designed various experiments to conduct an in-depth test of capabilities of GPT-4V. We further investigate how visual modifications to charts, such as altering visual elements (e.g. changing color schemes) and introducing perturbations (e.g. adding image noise), affect performance of GPT-4V. Secondly, we present 12 experimental findings. These findings suggest potential of GPT-4V to revolutionize interaction with charts and uncover the gap between human analytic needs and capabilities of GPT-4V. Thirdly, we propose a novel textual prompt strategy, named Chain-of-Charts, tailored for low-level analysis tasks, which boosts model performance by 24.36%, resulting in an accuracy of 80.49%. Furthermore, by incorporating a visual prompt strategy that directs attention of GPT-4V to question-relevant visual elements, we further improve accuracy to 83.83%. Our study not only sheds light on the capabilities and limitations of GPT-4V in low-level data analysis tasks but also offers valuable insights for future research.",
    "DOI": "10.48550/arXiv.2405.07001",
    "language": "en-US",
    "note": "arXiv:2405.07001 [cs]\nversion: 1",
    "number": "arXiv:2405.07001",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Evaluating Task-based Effectiveness of MLLMs on Charts",
    "URL": "http://arxiv.org/abs/2405.07001",
    "author": [
      {
        "family": "Wu",
        "given": "Yifan"
      },
      {
        "family": "Yan",
        "given": "Lutao"
      },
      {
        "family": "Luo",
        "given": "Yuyu"
      },
      {
        "family": "Wang",
        "given": "Yunhai"
      },
      {
        "family": "Tang",
        "given": "Nan"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 18]]
    },
    "issued": {
      "date-parts": [["2024", 5, 11]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/88SPBQFG",
    "type": "article",
    "abstract": "Tables are recognized for their high information density and widespread usage, serving as essential sources of information. Seeking information from tables (TIS) is a crucial capability for Large Language Models (LLMs), serving as the foundation of knowledge-based Q&A systems. However, this field presently suffers from an absence of thorough and reliable evaluation. This paper introduces a more reliable benchmark for Table Information Seeking (TabIS). To avoid the unreliable evaluation caused by text similarity-based metrics, TabIS adopts a single-choice question format (with two options per question) instead of a text generation format. We establish an effective pipeline for generating options, ensuring their difficulty and quality. Experiments conducted on 12 LLMs reveal that while the performance of GPT-4-turbo is marginally satisfactory, both other proprietary and open-source models perform inadequately. Further analysis shows that LLMs exhibit a poor understanding of table structures, and struggle to balance between TIS performance and robustness against pseudo-relevant tables (common in retrieval-augmented systems). These findings uncover the limitations and potential challenges of LLMs in seeking information from tables. We release our data and code to facilitate further research in this field.",
    "DOI": "10.48550/arXiv.2406.04113",
    "language": "en-US",
    "note": "arXiv:2406.04113 [cs]",
    "number": "arXiv:2406.04113",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Uncovering Limitations of Large Language Models in Information Seeking from Tables",
    "URL": "http://arxiv.org/abs/2406.04113",
    "author": [
      {
        "family": "Pang",
        "given": "Chaoxu"
      },
      {
        "family": "Cao",
        "given": "Yixuan"
      },
      {
        "family": "Yang",
        "given": "Chunhao"
      },
      {
        "family": "Luo",
        "given": "Ping"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 18]]
    },
    "issued": {
      "date-parts": [["2024", 6, 6]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/9LR7DZCI",
    "type": "article",
    "abstract": "In the past year, Multimodal Large Language Models (MLLMs) have demonstrated remarkable performance in tasks such as visual question answering, visual understanding and reasoning. However, the extensive model size and high training and inference costs have hindered the widespread application of MLLMs in academia and industry. Thus, studying efficient and lightweight MLLMs has enormous potential, especially in edge computing scenarios. In this survey, we provide a comprehensive and systematic review of the current state of efficient MLLMs. Specifically, we summarize the timeline of representative efficient MLLMs, research state of efficient structures and strategies, and the applications. Finally, we discuss the limitations of current efficient MLLM research and promising future directions. Please refer to our GitHub repository for more details: https://github.com/lijiannuist/Efficient-Multimodal-LLMs-Survey.",
    "DOI": "10.48550/arXiv.2405.10739",
    "language": "en-US",
    "note": "arXiv:2405.10739 [cs]",
    "number": "arXiv:2405.10739",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Efficient Multimodal Large Language Models: A Survey",
    "title-short": "Efficient Multimodal Large Language Models",
    "URL": "http://arxiv.org/abs/2405.10739",
    "author": [
      {
        "family": "Jin",
        "given": "Yizhang"
      },
      {
        "family": "Li",
        "given": "Jian"
      },
      {
        "family": "Liu",
        "given": "Yexin"
      },
      {
        "family": "Gu",
        "given": "Tianjun"
      },
      {
        "family": "Wu",
        "given": "Kai"
      },
      {
        "family": "Jiang",
        "given": "Zhengkai"
      },
      {
        "family": "He",
        "given": "Muyang"
      },
      {
        "family": "Zhao",
        "given": "Bo"
      },
      {
        "family": "Tan",
        "given": "Xin"
      },
      {
        "family": "Gan",
        "given": "Zhenye"
      },
      {
        "family": "Wang",
        "given": "Yabiao"
      },
      {
        "family": "Wang",
        "given": "Chengjie"
      },
      {
        "family": "Ma",
        "given": "Lizhuang"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 18]]
    },
    "issued": {
      "date-parts": [["2024", 5, 17]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/TJEF82U5",
    "type": "article",
    "abstract": "Multimodal Large Language Models (MLLMs) have shown impressive results on various multimodal tasks. However, most existing MLLMs are not well suited for document-oriented tasks, which require fine-grained image perception and information compression. In this paper, we present TextHawk, a MLLM that is specifically designed for document-oriented tasks, while preserving the general capabilities of MLLMs. TextHawk is aimed to explore efficient fine-grained perception by designing four dedicated components. Firstly, a ReSampling and ReArrangement (ReSA) module is proposed to reduce the redundancy in the document texts and lower the computational cost of the MLLM. We explore encoding the positions of each local feature by presenting Scalable Positional Embeddings (SPEs), which can preserve the scalability of various image sizes. A Query Proposal Network (QPN) is then adopted to initialize the queries dynamically among different sub-images. To further enhance the fine-grained visual perceptual ability of the MLLM, we design a Multi-Level Cross-Attention (MLCA) mechanism that captures the hierarchical structure and semantic relations of document images. Furthermore, we create a new instruction-tuning dataset for document-oriented tasks by enriching the multimodal document data with Gemini Pro. We conduct extensive experiments on both general and document-oriented MLLM benchmarks, and show that TextHawk outperforms the state-of-the-art methods, demonstrating its effectiveness and superiority in fine-grained document perception and general abilities.",
    "DOI": "10.48550/arXiv.2404.09204",
    "language": "en-US",
    "note": "arXiv:2404.09204 [cs]",
    "number": "arXiv:2404.09204",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "TextHawk: Exploring Efficient Fine-Grained Perception of Multimodal Large Language Models",
    "title-short": "TextHawk",
    "URL": "http://arxiv.org/abs/2404.09204",
    "author": [
      {
        "family": "Yu",
        "given": "Ya-Qi"
      },
      {
        "family": "Liao",
        "given": "Minghui"
      },
      {
        "family": "Wu",
        "given": "Jihao"
      },
      {
        "family": "Liao",
        "given": "Yongxin"
      },
      {
        "family": "Zheng",
        "given": "Xiaoyu"
      },
      {
        "family": "Zeng",
        "given": "Wei"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 18]]
    },
    "issued": {
      "date-parts": [["2024", 4, 14]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/NJIYTI4B",
    "type": "article",
    "abstract": "We present SPHINX, a versatile multi-modal large language model (MLLM) with a joint mixing of model weights, tuning tasks, and visual embeddings. First, for stronger vision-language alignment, we unfreeze the large language model (LLM) during pre-training, and introduce a weight mix strategy between LLMs trained by real-world and synthetic data. By directly integrating the weights from two domains, the mixed LLM can efficiently incorporate diverse semantics with favorable robustness. Then, to enable multi-purpose capabilities, we mix a variety of tasks for joint visual instruction tuning, and design task-specific instructions to avoid inter-task conflict. In addition to the basic visual question answering, we include more challenging tasks such as region-level understanding, caption grounding, document layout detection, and human pose estimation, contributing to mutual enhancement over different scenarios. Additionally, we propose to extract comprehensive visual embeddings from various network architectures, pre-training paradigms, and information granularity, providing language models with more robust image representations. Based on our proposed joint mixing, SPHINX exhibits superior multi-modal understanding capabilities on a wide range of applications. On top of this, we further propose an efficient strategy aiming to better capture fine-grained appearances of high-resolution images. With a mixing of different scales and high-resolution sub-images, SPHINX attains exceptional visual parsing and reasoning performance on existing evaluation benchmarks. We hope our work may cast a light on the exploration of joint mixing in future MLLM research. Code is released at https://github.com/Alpha-VLLM/LLaMA2-Accessory.",
    "DOI": "10.48550/ARXIV.2311.07575",
    "license": "arXiv.org perpetual, non-exclusive license",
    "note": "version: 1",
    "publisher": "arXiv",
    "source": "DOI.org (Datacite)",
    "title": "SPHINX: The Joint Mixing of Weights, Tasks, and Visual Embeddings for Multi-modal Large Language Models",
    "title-short": "SPHINX",
    "URL": "https://arxiv.org/abs/2311.07575",
    "author": [
      {
        "family": "Lin",
        "given": "Ziyi"
      },
      {
        "family": "Liu",
        "given": "Chris"
      },
      {
        "family": "Zhang",
        "given": "Renrui"
      },
      {
        "family": "Gao",
        "given": "Peng"
      },
      {
        "family": "Qiu",
        "given": "Longtian"
      },
      {
        "family": "Xiao",
        "given": "Han"
      },
      {
        "family": "Qiu",
        "given": "Han"
      },
      {
        "family": "Lin",
        "given": "Chen"
      },
      {
        "family": "Shao",
        "given": "Wenqi"
      },
      {
        "family": "Chen",
        "given": "Keqin"
      },
      {
        "family": "Han",
        "given": "Jiaming"
      },
      {
        "family": "Huang",
        "given": "Siyuan"
      },
      {
        "family": "Zhang",
        "given": "Yichi"
      },
      {
        "family": "He",
        "given": "Xuming"
      },
      {
        "family": "Li",
        "given": "Hongsheng"
      },
      {
        "family": "Qiao",
        "given": "Yu"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 18]]
    },
    "issued": {
      "date-parts": [["2023"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/VDTT8VU2",
    "type": "article",
    "abstract": "Charts are very popular for analyzing data. When exploring charts, people often ask a variety of complex reasoning questions that involve several logical and arithmetic operations. They also commonly refer to visual features of a chart in their questions. However, most existing datasets do not focus on such complex reasoning questions as their questions are template-based and answers come from a fixed-vocabulary. In this work, we present a large-scale benchmark covering 9.6K human-written questions as well as 23.1K questions generated from human-written chart summaries. To address the unique challenges in our benchmark involving visual and logical reasoning over charts, we present two transformer-based models that combine visual features and the data table of the chart in a unified way to answer questions. While our models achieve the state-of-the-art results on the previous datasets as well as on our benchmark, the evaluation also reveals several challenges in answering complex reasoning questions.",
    "DOI": "10.48550/arXiv.2203.10244",
    "language": "en-US",
    "note": "arXiv:2203.10244 [cs]",
    "number": "arXiv:2203.10244",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "ChartQA: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning",
    "title-short": "ChartQA",
    "URL": "http://arxiv.org/abs/2203.10244",
    "author": [
      {
        "family": "Masry",
        "given": "Ahmed"
      },
      {
        "family": "Long",
        "given": "Do Xuan"
      },
      {
        "family": "Tan",
        "given": "Jia Qing"
      },
      {
        "family": "Joty",
        "given": "Shafiq"
      },
      {
        "family": "Hoque",
        "given": "Enamul"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 18]]
    },
    "issued": {
      "date-parts": [["2022", 3, 19]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/QICUSGEV",
    "type": "article",
    "abstract": "Data visualization in the form of charts plays a pivotal role in data analysis, offering critical insights and aiding in informed decision-making. Automatic chart understanding has witnessed significant advancements with the rise of large foundation models in recent years. Foundation models, such as large language models, have revolutionized various natural language processing tasks and are increasingly being applied to chart understanding tasks. This survey paper provides a comprehensive overview of the recent developments, challenges, and future directions in chart understanding within the context of these foundation models. We review fundamental building blocks crucial for studying chart understanding tasks. Additionally, we explore various tasks and their evaluation metrics and sources of both charts and textual inputs. Various modeling strategies are then examined, encompassing both classification-based and generation-based approaches, along with tool augmentation techniques that enhance chart understanding performance. Furthermore, we discuss the state-of-the-art performance of each task and discuss how we can improve the performance. Challenges and future directions are addressed, highlighting the importance of several topics, such as domain-specific charts, lack of efforts in developing evaluation metrics, and agent-oriented settings. This survey paper serves as a comprehensive resource for researchers and practitioners in the fields of natural language processing, computer vision, and data analysis, providing valuable insights and directions for future research in chart understanding leveraging large foundation models. The studies mentioned in this paper, along with emerging new research, will be continually updated at: https://github.com/khuangaf/Awesome-Chart-Understanding.",
    "DOI": "10.48550/arXiv.2403.12027",
    "language": "en-US",
    "note": "arXiv:2403.12027 [cs]",
    "number": "arXiv:2403.12027",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "From Pixels to Insights: A Survey on Automatic Chart Understanding in the Era of Large Foundation Models",
    "title-short": "From Pixels to Insights",
    "URL": "http://arxiv.org/abs/2403.12027",
    "author": [
      {
        "family": "Huang",
        "given": "Kung-Hsiang"
      },
      {
        "family": "Chan",
        "given": "Hou Pong"
      },
      {
        "family": "Fung",
        "given": "Yi R."
      },
      {
        "family": "Qiu",
        "given": "Haoyi"
      },
      {
        "family": "Zhou",
        "given": "Mingyang"
      },
      {
        "family": "Joty",
        "given": "Shafiq"
      },
      {
        "family": "Chang",
        "given": "Shih-Fu"
      },
      {
        "family": "Ji",
        "given": "Heng"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 19]]
    },
    "issued": {
      "date-parts": [["2024", 3, 25]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/X4C7KCAA",
    "type": "paper-conference",
    "abstract": "Understanding document images (e.g., invoices) is a core but challenging task since it requires complex functions such as reading text and a holistic understanding of the document. Current Visual Document Understanding (VDU) methods outsource the task of reading text to off-the-shelf Optical Character Recognition (OCR) engines and focus on the understanding task with the OCR outputs. Although such OCR-based approaches have shown promising performance, they suffer from 1) high computational costs for using OCR; 2) inflexibility of OCR models on languages or types of documents; 3) OCR error propagation to the subsequent process. To address these issues, in this paper, we introduce a novel OCR-free VDU model named Donut, which stands for Document understanding transformer. As the first step in OCR-free VDU research, we propose a simple architecture (i.e., Transformer) with a pre-training objective (i.e., cross-entropy loss). Donut is conceptually simple yet effective. Through extensive experiments and analyses, we show a simple OCR-free VDU model, Donut, achieves state-of-the-art performances on various VDU tasks in terms of both speed and accuracy. In addition, we offer a synthetic data generator that helps the model pre-training to be flexible in various languages and domains. The code, trained model, and synthetic data are available at https://github.com/clovaai/donut.",
    "container-title": "Computer Vision – ECCV 2022",
    "DOI": "10.1007/978-3-031-19815-1_29",
    "event-place": "Cham",
    "ISBN": "978-3-031-19815-1",
    "language": "en",
    "page": "498-517",
    "publisher": "Springer Nature Switzerland",
    "publisher-place": "Cham",
    "source": "Springer Link",
    "title": "OCR-Free Document Understanding Transformer",
    "author": [
      {
        "family": "Kim",
        "given": "Geewook"
      },
      {
        "family": "Hong",
        "given": "Teakgyu"
      },
      {
        "family": "Yim",
        "given": "Moonbin"
      },
      {
        "family": "Nam",
        "given": "JeongYeon"
      },
      {
        "family": "Park",
        "given": "Jinyoung"
      },
      {
        "family": "Yim",
        "given": "Jinyeong"
      },
      {
        "family": "Hwang",
        "given": "Wonseok"
      },
      {
        "family": "Yun",
        "given": "Sangdoo"
      },
      {
        "family": "Han",
        "given": "Dongyoon"
      },
      {
        "family": "Park",
        "given": "Seunghyun"
      }
    ],
    "editor": [
      {
        "family": "Avidan",
        "given": "Shai"
      },
      {
        "family": "Brostow",
        "given": "Gabriel"
      },
      {
        "family": "Cissé",
        "given": "Moustapha"
      },
      {
        "family": "Farinella",
        "given": "Giovanni Maria"
      },
      {
        "family": "Hassner",
        "given": "Tal"
      }
    ],
    "issued": {
      "date-parts": [["2022"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/E7C8WJGW",
    "type": "paper-conference",
    "abstract": "Visually-situated language is ubiquitous—sources range from textbooks with diagrams to web pages with images and tables, to mobile apps with buttons and forms. Perhaps due to this diversity, previous work has typically relied on domain-specific recipes with limited sharing of the underlying data, model architectures, and objectives. We present Pix2Struct, a pretrained image-to-text model for purely visual language understanding, which can be finetuned on tasks containing visually-situated language. Pix2Struct is pretrained by learning to parse masked screenshots of web pages into simplified HTML. The web, with its richness of visual elements cleanly reflected in the HTML structure, provides a large source of pretraining data well suited to the diversity of downstream tasks. Intuitively, this objective subsumes common pretraining signals such as OCR, language modeling, and image captioning. In addition to the novel pretraining strategy, we introduce a variable-resolution input representation and a more flexible integration of language and vision inputs, where language prompts such as questions are rendered directly on top of the input image. For the first time, we show that a single pretrained model can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images.",
    "container-title": "Proceedings of the 40th International Conference on Machine Learning",
    "event-title": "International Conference on Machine Learning",
    "language": "en",
    "note": "ISSN: 2640-3498",
    "page": "18893-18912",
    "publisher": "PMLR",
    "source": "proceedings.mlr.press",
    "title": "Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding",
    "title-short": "Pix2Struct",
    "URL": "https://proceedings.mlr.press/v202/lee23g.html",
    "author": [
      {
        "family": "Lee",
        "given": "Kenton"
      },
      {
        "family": "Joshi",
        "given": "Mandar"
      },
      {
        "family": "Turc",
        "given": "Iulia Raluca"
      },
      {
        "family": "Hu",
        "given": "Hexiang"
      },
      {
        "family": "Liu",
        "given": "Fangyu"
      },
      {
        "family": "Eisenschlos",
        "given": "Julian Martin"
      },
      {
        "family": "Khandelwal",
        "given": "Urvashi"
      },
      {
        "family": "Shaw",
        "given": "Peter"
      },
      {
        "family": "Chang",
        "given": "Ming-Wei"
      },
      {
        "family": "Toutanova",
        "given": "Kristina"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 19]]
    },
    "issued": {
      "date-parts": [["2023", 7, 3]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/VIZDFZSL",
    "type": "article",
    "abstract": "We present SPHINX, a versatile multi-modal large language model (MLLM) with a joint mixing of model weights, tuning tasks, and visual embeddings. First, for stronger vision-language alignment, we unfreeze the large language model (LLM) during pre-training, and introduce a weight mix strategy between LLMs trained by real-world and synthetic data. By directly integrating the weights from two domains, the mixed LLM can efficiently incorporate diverse semantics with favorable robustness. Then, to enable multi-purpose capabilities, we mix a variety of tasks for joint visual instruction tuning, and design task-specific instructions to avoid inter-task conflict. In addition to the basic visual question answering, we include more challenging tasks such as region-level understanding, caption grounding, document layout detection, and human pose estimation, contributing to mutual enhancement over different scenarios. Additionally, we propose to extract comprehensive visual embeddings from various network architectures, pre-training paradigms, and information granularity, providing language models with more robust image representations. Based on our proposed joint mixing, SPHINX exhibits superior multi-modal understanding capabilities on a wide range of applications. On top of this, we further propose an efficient strategy aiming to better capture fine-grained appearances of high-resolution images. With a mixing of different scales and high-resolution sub-images, SPHINX attains exceptional visual parsing and reasoning performance on existing evaluation benchmarks. We hope our work may cast a light on the exploration of joint mixing in future MLLM research. Code is released at https://github.com/Alpha-VLLM/LLaMA2-Accessory.",
    "DOI": "10.48550/arXiv.2311.07575",
    "note": "arXiv:2311.07575 [cs]",
    "number": "arXiv:2311.07575",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "SPHINX: The Joint Mixing of Weights, Tasks, and Visual Embeddings for Multi-modal Large Language Models",
    "title-short": "SPHINX",
    "URL": "http://arxiv.org/abs/2311.07575",
    "author": [
      {
        "family": "Lin",
        "given": "Ziyi"
      },
      {
        "family": "Liu",
        "given": "Chris"
      },
      {
        "family": "Zhang",
        "given": "Renrui"
      },
      {
        "family": "Gao",
        "given": "Peng"
      },
      {
        "family": "Qiu",
        "given": "Longtian"
      },
      {
        "family": "Xiao",
        "given": "Han"
      },
      {
        "family": "Qiu",
        "given": "Han"
      },
      {
        "family": "Lin",
        "given": "Chen"
      },
      {
        "family": "Shao",
        "given": "Wenqi"
      },
      {
        "family": "Chen",
        "given": "Keqin"
      },
      {
        "family": "Han",
        "given": "Jiaming"
      },
      {
        "family": "Huang",
        "given": "Siyuan"
      },
      {
        "family": "Zhang",
        "given": "Yichi"
      },
      {
        "family": "He",
        "given": "Xuming"
      },
      {
        "family": "Li",
        "given": "Hongsheng"
      },
      {
        "family": "Qiao",
        "given": "Yu"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 19]]
    },
    "issued": {
      "date-parts": [["2023", 11, 13]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/QPC6WEFX",
    "type": "article",
    "abstract": "Multimodal Large Language Models (MLLMs) have shown impressive capabilities in image understanding and generation. However, current benchmarks fail to accurately evaluate the chart comprehension of MLLMs due to limited chart types and inappropriate metrics. To address this, we propose ChartBench, a comprehensive benchmark designed to assess chart comprehension and data reliability through complex visual reasoning. ChartBench includes 42 categories, 66.6k charts, and 600k question-answer pairs. Notably, many charts lack data point annotations, which requires MLLMs to derive values similar to human understanding by leveraging inherent chart elements such as color, legends, and coordinate systems. We also design an enhanced evaluation metric, Acc+, to evaluate MLLMs without extensive manual or costly LLM-based evaluations. Furthermore, we propose two baselines based on the chain of thought and supervised fine-tuning to improve model performance on unannotated charts. Extensive experimental evaluations of 18 open-sourced and 3 proprietary MLLMs reveal their limitations in chart comprehension and offer valuable insights for further research. Code and dataset are publicly available at https://chartbench.github.io.",
    "DOI": "10.48550/arXiv.2312.15915",
    "language": "en-US",
    "note": "arXiv:2312.15915 [cs]",
    "number": "arXiv:2312.15915",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "ChartBench: A Benchmark for Complex Visual Reasoning in Charts",
    "title-short": "ChartBench",
    "URL": "http://arxiv.org/abs/2312.15915",
    "author": [
      {
        "family": "Xu",
        "given": "Zhengzhuo"
      },
      {
        "family": "Du",
        "given": "Sinan"
      },
      {
        "family": "Qi",
        "given": "Yiyan"
      },
      {
        "family": "Xu",
        "given": "Chengjin"
      },
      {
        "family": "Yuan",
        "given": "Chun"
      },
      {
        "family": "Guo",
        "given": "Jian"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 19]]
    },
    "issued": {
      "date-parts": [["2024", 6, 18]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/B7PUJIIR",
    "type": "article",
    "abstract": "Recently, Multimodal Large Language Model (MLLM) represented by GPT-4V has been a new rising research hotspot, which uses powerful Large Language Models (LLMs) as a brain to perform multimodal tasks. The surprising emergent capabilities of MLLM, such as writing stories based on images and OCR-free math reasoning, are rare in traditional multimodal methods, suggesting a potential path to artificial general intelligence. To this end, both academia and industry have endeavored to develop MLLMs that can compete with or even better than GPT-4V, pushing the limit of research at a surprising speed. In this paper, we aim to trace and summarize the recent progress of MLLMs. First of all, we present the basic formulation of MLLM and delineate its related concepts, including architecture, training strategy and data, as well as evaluation. Then, we introduce research topics about how MLLMs can be extended to support more granularity, modalities, languages, and scenarios. We continue with multimodal hallucination and extended techniques, including Multimodal ICL (M-ICL), Multimodal CoT (M-CoT), and LLM-Aided Visual Reasoning (LAVR). To conclude the paper, we discuss existing challenges and point out promising research directions. In light of the fact that the era of MLLM has only just begun, we will keep updating this survey and hope it can inspire more research. An associated GitHub link collecting the latest papers is available at https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models.",
    "DOI": "10.48550/arXiv.2306.13549",
    "language": "en-US",
    "note": "arXiv:2306.13549 [cs]",
    "number": "arXiv:2306.13549",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "A Survey on Multimodal Large Language Models",
    "URL": "http://arxiv.org/abs/2306.13549",
    "author": [
      {
        "family": "Yin",
        "given": "Shukang"
      },
      {
        "family": "Fu",
        "given": "Chaoyou"
      },
      {
        "family": "Zhao",
        "given": "Sirui"
      },
      {
        "family": "Li",
        "given": "Ke"
      },
      {
        "family": "Sun",
        "given": "Xing"
      },
      {
        "family": "Xu",
        "given": "Tong"
      },
      {
        "family": "Chen",
        "given": "Enhong"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 19]]
    },
    "issued": {
      "date-parts": [["2024", 4, 1]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/XLT7VFMX",
    "type": "article",
    "abstract": "Playing Large Vision Language Models (LVLMs) in 2023 is trendy among the AI community. However, the relatively large number of parameters (more than 7B) of popular LVLMs makes it difficult to train and deploy on consumer GPUs, discouraging many researchers with limited resources. Imagine how cool it would be to experience all the features of current LVLMs on an old GTX1080ti (our only game card). Accordingly, we present Vary-toy in this report, a small-size Vary along with Qwen-1.8B as the base ``large'' language model. In Vary-toy, we introduce an improved vision vocabulary, allowing the model to not only possess all features of Vary but also gather more generality. Specifically, we replace negative samples of natural images with positive sample data driven by object detection in the procedure of generating vision vocabulary, more sufficiently utilizing the capacity of the vocabulary network and enabling it to efficiently encode visual information corresponding to natural objects. For experiments, Vary-toy can achieve 65.6% ANLS on DocVQA, 59.1% accuracy on ChartQA, 88.1% accuracy on RefCOCO, and 29% on MMVet. The code will be publicly available on the homepage.",
    "DOI": "10.48550/arXiv.2401.12503",
    "language": "en-US",
    "note": "arXiv:2401.12503 [cs]\nTLDR: In Vary-toy, an improved vision vocabulary is introduced, allowing the model to not only possess all features of Vary but also gather more generality, more sufficiently utilizing the capacity of the vocabulary network and enabling it to efficiently encode visual information corresponding to natural objects.",
    "number": "arXiv:2401.12503",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Small Language Model Meets with Reinforced Vision Vocabulary",
    "URL": "http://arxiv.org/abs/2401.12503",
    "author": [
      {
        "family": "Wei",
        "given": "Haoran"
      },
      {
        "family": "Kong",
        "given": "Lingyu"
      },
      {
        "family": "Chen",
        "given": "Jinyue"
      },
      {
        "family": "Zhao",
        "given": "Liang"
      },
      {
        "family": "Ge",
        "given": "Zheng"
      },
      {
        "family": "Yu",
        "given": "En"
      },
      {
        "family": "Sun",
        "given": "Jianjian"
      },
      {
        "family": "Han",
        "given": "Chunrui"
      },
      {
        "family": "Zhang",
        "given": "Xiangyu"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 19]]
    },
    "issued": {
      "date-parts": [["2024", 1, 23]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/KT5W3Q7M",
    "type": "article",
    "abstract": "Large language models, which are often trained for hundreds of thousands of compute days, have shown remarkable capabilities for zero- and few-shot learning. Given their computational cost, these models are difficult to replicate without significant capital. For the few that are available through APIs, no access is granted to the full model weights, making them difficult to study. We present Open Pre-trained Transformers (OPT), a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, which we aim to fully and responsibly share with interested researchers. We show that OPT-175B is comparable to GPT-3, while requiring only 1/7th the carbon footprint to develop. We are also releasing our logbook detailing the infrastructure challenges we faced, along with code for experimenting with all of the released models.",
    "DOI": "10.48550/arXiv.2205.01068",
    "language": "en-US",
    "note": "arXiv:2205.01068 [cs]",
    "number": "arXiv:2205.01068",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "OPT: Open Pre-trained Transformer Language Models",
    "title-short": "OPT",
    "URL": "http://arxiv.org/abs/2205.01068",
    "author": [
      {
        "family": "Zhang",
        "given": "Susan"
      },
      {
        "family": "Roller",
        "given": "Stephen"
      },
      {
        "family": "Goyal",
        "given": "Naman"
      },
      {
        "family": "Artetxe",
        "given": "Mikel"
      },
      {
        "family": "Chen",
        "given": "Moya"
      },
      {
        "family": "Chen",
        "given": "Shuohui"
      },
      {
        "family": "Dewan",
        "given": "Christopher"
      },
      {
        "family": "Diab",
        "given": "Mona"
      },
      {
        "family": "Li",
        "given": "Xian"
      },
      {
        "family": "Lin",
        "given": "Xi Victoria"
      },
      {
        "family": "Mihaylov",
        "given": "Todor"
      },
      {
        "family": "Ott",
        "given": "Myle"
      },
      {
        "family": "Shleifer",
        "given": "Sam"
      },
      {
        "family": "Shuster",
        "given": "Kurt"
      },
      {
        "family": "Simig",
        "given": "Daniel"
      },
      {
        "family": "Koura",
        "given": "Punit Singh"
      },
      {
        "family": "Sridhar",
        "given": "Anjali"
      },
      {
        "family": "Wang",
        "given": "Tianlu"
      },
      {
        "family": "Zettlemoyer",
        "given": "Luke"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 19]]
    },
    "issued": {
      "date-parts": [["2022", 6, 21]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/Y2SP9AKH",
    "type": "article",
    "abstract": "Playing Large Vision Language Models (LVLMs) in 2023 is trendy among the AI community. However, the relatively large number of parameters (more than 7B) of popular LVLMs makes it difficult to train and deploy on consumer GPUs, discouraging many researchers with limited resources. Imagine how cool it would be to experience all the features of current LVLMs on an old GTX1080ti (our only game card). Accordingly, we present Vary-toy in this report, a small-size Vary along with Qwen-1.8B as the base ``large'' language model. In Vary-toy, we introduce an improved vision vocabulary, allowing the model to not only possess all features of Vary but also gather more generality. Specifically, we replace negative samples of natural images with positive sample data driven by object detection in the procedure of generating vision vocabulary, more sufficiently utilizing the capacity of the vocabulary network and enabling it to efficiently encode visual information corresponding to natural objects. For experiments, Vary-toy can achieve 65.6% ANLS on DocVQA, 59.1% accuracy on ChartQA, 88.1% accuracy on RefCOCO, and 29% on MMVet. The code will be publicly available on the homepage.",
    "DOI": "10.48550/arXiv.2401.12503",
    "language": "en-US",
    "note": "arXiv:2401.12503 [cs]",
    "number": "arXiv:2401.12503",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Small Language Model Meets with Reinforced Vision Vocabulary",
    "URL": "http://arxiv.org/abs/2401.12503",
    "author": [
      {
        "family": "Wei",
        "given": "Haoran"
      },
      {
        "family": "Kong",
        "given": "Lingyu"
      },
      {
        "family": "Chen",
        "given": "Jinyue"
      },
      {
        "family": "Zhao",
        "given": "Liang"
      },
      {
        "family": "Ge",
        "given": "Zheng"
      },
      {
        "family": "Yu",
        "given": "En"
      },
      {
        "family": "Sun",
        "given": "Jianjian"
      },
      {
        "family": "Han",
        "given": "Chunrui"
      },
      {
        "family": "Zhang",
        "given": "Xiangyu"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 21]]
    },
    "issued": {
      "date-parts": [["2024", 1, 23]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/GJPVGJSX",
    "type": "article",
    "abstract": "Visually-situated language is ubiquitous -- sources range from textbooks with diagrams to web pages with images and tables, to mobile apps with buttons and forms. Perhaps due to this diversity, previous work has typically relied on domain-specific recipes with limited sharing of the underlying data, model architectures, and objectives. We present Pix2Struct, a pretrained image-to-text model for purely visual language understanding, which can be finetuned on tasks containing visually-situated language. Pix2Struct is pretrained by learning to parse masked screenshots of web pages into simplified HTML. The web, with its richness of visual elements cleanly reflected in the HTML structure, provides a large source of pretraining data well suited to the diversity of downstream tasks. Intuitively, this objective subsumes common pretraining signals such as OCR, language modeling, image captioning. In addition to the novel pretraining strategy, we introduce a variable-resolution input representation and a more flexible integration of language and vision inputs, where language prompts such as questions are rendered directly on top of the input image. For the first time, we show that a single pretrained model can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images.",
    "DOI": "10.48550/ARXIV.2210.03347",
    "language": "en-US",
    "license": "Creative Commons Attribution 4.0 International",
    "note": "version: 2",
    "publisher": "arXiv",
    "source": "DOI.org (Datacite)",
    "title": "Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding",
    "title-short": "Pix2Struct",
    "URL": "https://arxiv.org/abs/2210.03347",
    "author": [
      {
        "family": "Lee",
        "given": "Kenton"
      },
      {
        "family": "Joshi",
        "given": "Mandar"
      },
      {
        "family": "Turc",
        "given": "Iulia"
      },
      {
        "family": "Hu",
        "given": "Hexiang"
      },
      {
        "family": "Liu",
        "given": "Fangyu"
      },
      {
        "family": "Eisenschlos",
        "given": "Julian"
      },
      {
        "family": "Khandelwal",
        "given": "Urvashi"
      },
      {
        "family": "Shaw",
        "given": "Peter"
      },
      {
        "family": "Chang",
        "given": "Ming-Wei"
      },
      {
        "family": "Toutanova",
        "given": "Kristina"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 21]]
    },
    "issued": {
      "date-parts": [["2022"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/L9ATEJ44",
    "type": "article",
    "abstract": "Given the ubiquity of charts as a data analysis, visualization, and decision-making tool across industries and sciences, there has been a growing interest in developing pre-trained foundation models as well as general purpose instruction-tuned models for chart understanding and reasoning. However, existing methods suffer crucial drawbacks across two critical axes affecting the performance of chart representation models: they are trained on data generated from underlying data tables of the charts, ignoring the visual trends and patterns in chart images, and use weakly aligned vision-language backbone models for domain-specific training, limiting their generalizability when encountering charts in the wild. We address these important drawbacks and introduce ChartGemma, a novel chart understanding and reasoning model developed over PaliGemma. Rather than relying on underlying data tables, ChartGemma is trained on instruction-tuning data generated directly from chart images, thus capturing both high-level trends and low-level visual information from a diverse set of charts. Our simple approach achieves state-of-the-art results across $5$ benchmarks spanning chart summarization, question answering, and fact-checking, and our elaborate qualitative studies on real-world charts show that ChartGemma generates more realistic and factually correct summaries compared to its contemporaries. We release the code, model checkpoints, dataset, and demos at https://github.com/vis-nlp/ChartGemma.",
    "DOI": "10.48550/arXiv.2407.04172",
    "language": "en-US",
    "note": "arXiv:2407.04172 [cs]",
    "number": "arXiv:2407.04172",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "ChartGemma: Visual Instruction-tuning for Chart Reasoning in the Wild",
    "title-short": "ChartGemma",
    "URL": "http://arxiv.org/abs/2407.04172",
    "author": [
      {
        "family": "Masry",
        "given": "Ahmed"
      },
      {
        "family": "Thakkar",
        "given": "Megh"
      },
      {
        "family": "Bajaj",
        "given": "Aayush"
      },
      {
        "family": "Kartha",
        "given": "Aaryaman"
      },
      {
        "family": "Hoque",
        "given": "Enamul"
      },
      {
        "family": "Joty",
        "given": "Shafiq"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 22]]
    },
    "issued": {
      "date-parts": [["2024", 7, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/LYNPBEJ9",
    "type": "article",
    "abstract": "Visual Language Models (VLMs) have rapidly progressed with the recent success of large language models. However, there have been few attempts to incorporate efficient linear Recurrent Neural Networks (RNNs) architectures into VLMs. In this study, we introduce VisualRWKV, the first application of a linear RNN model to multimodal learning tasks, leveraging the pre-trained RWKV language model. We propose a data-dependent recurrence and sandwich prompts to enhance our modeling capabilities, along with a 2D image scanning mechanism to enrich the processing of visual sequences. Extensive experiments demonstrate that VisualRWKV achieves competitive performance compared to Transformer-based models like LLaVA-1.5 on various benchmarks. To facilitate further research and analysis, we have made the checkpoints and the associated code publicly accessible at the following GitHub repository: \\href{https://github.com/howard-hou/VisualRWKV}{https://github.com/howard-hou/VisualRWKV}.",
    "DOI": "10.48550/arXiv.2406.13362",
    "language": "en-US",
    "note": "arXiv:2406.13362 [cs]",
    "number": "arXiv:2406.13362",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "VisualRWKV: Exploring Recurrent Neural Networks for Visual Language Models",
    "title-short": "VisualRWKV",
    "URL": "http://arxiv.org/abs/2406.13362",
    "author": [
      {
        "family": "Hou",
        "given": "Haowen"
      },
      {
        "family": "Zeng",
        "given": "Peigen"
      },
      {
        "family": "Ma",
        "given": "Fei"
      },
      {
        "family": "Yu",
        "given": "Fei Richard"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 7, 23]]
    },
    "issued": {
      "date-parts": [["2024", 6, 19]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/3LUSJCN3",
    "type": "article",
    "abstract": "This paper tackles a key issue in the interpretation of scientific figures: the fine-grained alignment of text and figures. It advances beyond prior research that primarily dealt with straightforward, data-driven visualizations such as bar and pie charts and only offered a basic understanding of diagrams through captioning and classification. We introduce a novel task, Figure Integrity Verification, designed to evaluate the precision of technologies in aligning textual knowledge with visual elements in scientific figures. To support this, we develop a semi-automated method for constructing a large-scale dataset, Figure-seg, specifically designed for this task. Additionally, we propose an innovative framework, Every Part Matters (EPM), which leverages Multimodal Large Language Models (MLLMs) to not only incrementally improve the alignment and verification of text-figure integrity but also enhance integrity through analogical reasoning. Our comprehensive experiments show that these innovations substantially improve upon existing methods, allowing for more precise and thorough analysis of complex scientific figures. This progress not only enhances our understanding of multimodal technologies but also stimulates further research and practical applications across fields requiring the accurate interpretation of complex visual data.",
    "DOI": "10.48550/arXiv.2407.18626",
    "language": "en-US",
    "note": "arXiv:2407.18626 [cs]",
    "number": "arXiv:2407.18626",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Every Part Matters: Integrity Verification of Scientific Figures Based on Multimodal Large Language Models",
    "title-short": "Every Part Matters",
    "URL": "http://arxiv.org/abs/2407.18626",
    "author": [
      {
        "family": "Shi",
        "given": "Xiang"
      },
      {
        "family": "Liu",
        "given": "Jiawei"
      },
      {
        "family": "Liu",
        "given": "Yinpeng"
      },
      {
        "family": "Cheng",
        "given": "Qikai"
      },
      {
        "family": "Lu",
        "given": "Wei"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 5]]
    },
    "issued": {
      "date-parts": [["2024", 7, 26]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/A3XD7TFY",
    "type": "article",
    "abstract": "In the past year, Multimodal Large Language Models (MLLMs) have demonstrated remarkable performance in tasks such as visual question answering, visual understanding and reasoning. However, the extensive model size and high training and inference costs have hindered the widespread application of MLLMs in academia and industry. Thus, studying efficient and lightweight MLLMs has enormous potential, especially in edge computing scenarios. In this survey, we provide a comprehensive and systematic review of the current state of efficient MLLMs. Specifically, we summarize the timeline of representative efficient MLLMs, research state of efficient structures and strategies, and the applications. Finally, we discuss the limitations of current efficient MLLM research and promising future directions. Please refer to our GitHub repository for more details: https://github.com/lijiannuist/Efficient-Multimodal-LLMs-Survey.",
    "DOI": "10.48550/arXiv.2405.10739",
    "language": "en-US",
    "note": "arXiv:2405.10739 [cs]",
    "number": "arXiv:2405.10739",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Efficient Multimodal Large Language Models: A Survey",
    "title-short": "Efficient Multimodal Large Language Models",
    "URL": "http://arxiv.org/abs/2405.10739",
    "author": [
      {
        "family": "Jin",
        "given": "Yizhang"
      },
      {
        "family": "Li",
        "given": "Jian"
      },
      {
        "family": "Liu",
        "given": "Yexin"
      },
      {
        "family": "Gu",
        "given": "Tianjun"
      },
      {
        "family": "Wu",
        "given": "Kai"
      },
      {
        "family": "Jiang",
        "given": "Zhengkai"
      },
      {
        "family": "He",
        "given": "Muyang"
      },
      {
        "family": "Zhao",
        "given": "Bo"
      },
      {
        "family": "Tan",
        "given": "Xin"
      },
      {
        "family": "Gan",
        "given": "Zhenye"
      },
      {
        "family": "Wang",
        "given": "Yabiao"
      },
      {
        "family": "Wang",
        "given": "Chengjie"
      },
      {
        "family": "Ma",
        "given": "Lizhuang"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 5]]
    },
    "issued": {
      "date-parts": [["2024", 5, 17]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/CEZAVLHS",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
    "language": "en",
    "page": "13969-13979",
    "source": "openaccess.thecvf.com",
    "title": "CoG-DQA: Chain-of-Guiding Learning with Large Language Models for Diagram Question Answering",
    "title-short": "CoG-DQA",
    "URL": "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_CoG-DQA_Chain-of-Guiding_Learning_with_Large_Language_Models_for_Diagram_Question_CVPR_2024_paper.html",
    "author": [
      {
        "family": "Wang",
        "given": "Shaowei"
      },
      {
        "family": "Zhang",
        "given": "Lingling"
      },
      {
        "family": "Zhu",
        "given": "Longji"
      },
      {
        "family": "Qin",
        "given": "Tao"
      },
      {
        "family": "Yap",
        "given": "Kim-Hui"
      },
      {
        "family": "Zhang",
        "given": "Xinyu"
      },
      {
        "family": "Liu",
        "given": "Jun"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 5]]
    },
    "issued": {
      "date-parts": [["2024"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/VE8C2WLE",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
    "language": "en",
    "page": "27218-27227",
    "source": "openaccess.thecvf.com",
    "title": "VTQA: Visual Text Question Answering via Entity Alignment and Cross-Media Reasoning",
    "title-short": "VTQA",
    "URL": "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_VTQA_Visual_Text_Question_Answering_via_Entity_Alignment_and_Cross-Media_CVPR_2024_paper.html",
    "author": [
      {
        "family": "Chen",
        "given": "Kang"
      },
      {
        "family": "Wu",
        "given": "Xiangqian"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 5]]
    },
    "issued": {
      "date-parts": [["2024"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/PXRUJWXM",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
    "language": "en",
    "page": "13861-13871",
    "source": "openaccess.thecvf.com",
    "title": "Question Aware Vision Transformer for Multimodal Reasoning",
    "URL": "https://openaccess.thecvf.com/content/CVPR2024/html/Ganz_Question_Aware_Vision_Transformer_for_Multimodal_Reasoning_CVPR_2024_paper.html",
    "author": [
      {
        "family": "Ganz",
        "given": "Roy"
      },
      {
        "family": "Kittenplon",
        "given": "Yair"
      },
      {
        "family": "Aberdam",
        "given": "Aviad"
      },
      {
        "family": "Ben Avraham",
        "given": "Elad"
      },
      {
        "family": "Nuriel",
        "given": "Oren"
      },
      {
        "family": "Mazor",
        "given": "Shai"
      },
      {
        "family": "Litman",
        "given": "Ron"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 5]]
    },
    "issued": {
      "date-parts": [["2024"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/9LBHQQL3",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
    "language": "en",
    "page": "26374-26383",
    "source": "openaccess.thecvf.com",
    "title": "PixelLM: Pixel Reasoning with Large Multimodal Model",
    "title-short": "PixelLM",
    "URL": "https://openaccess.thecvf.com/content/CVPR2024/html/Ren_PixelLM_Pixel_Reasoning_with_Large_Multimodal_Model_CVPR_2024_paper.html",
    "author": [
      {
        "family": "Ren",
        "given": "Zhongwei"
      },
      {
        "family": "Huang",
        "given": "Zhicheng"
      },
      {
        "family": "Wei",
        "given": "Yunchao"
      },
      {
        "family": "Zhao",
        "given": "Yao"
      },
      {
        "family": "Fu",
        "given": "Dongmei"
      },
      {
        "family": "Feng",
        "given": "Jiashi"
      },
      {
        "family": "Jin",
        "given": "Xiaojie"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 5]]
    },
    "issued": {
      "date-parts": [["2024"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/HL5JGZDD",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
    "language": "en",
    "page": "13428-13437",
    "source": "openaccess.thecvf.com",
    "title": "Learning by Correction: Efficient Tuning Task for Zero-Shot Generative Vision-Language Reasoning",
    "title-short": "Learning by Correction",
    "URL": "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Learning_by_Correction_Efficient_Tuning_Task_for_Zero-Shot_Generative_Vision-Language_CVPR_2024_paper.html",
    "author": [
      {
        "family": "Li",
        "given": "Rongjie"
      },
      {
        "family": "Wu",
        "given": "Yu"
      },
      {
        "family": "He",
        "given": "Xuming"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 5]]
    },
    "issued": {
      "date-parts": [["2024"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/Y9RUUY3U",
    "type": "paper-conference",
    "abstract": "Table-based reasoning with large language models (LLMs) is a promising direction to tackle many table understanding tasks, such as table-based question answering and fact verification. Compared with generic reasoning, table-based reasoning requires the extraction of underlying semantics from both free-form questions and semi-structured tabular data. Chain-of-Thought and its similar approaches incorporate the reasoning chain in the form of textual context, but it is still an open question how to effectively leverage tabular data in the reasoning chain. We propose the Chain-of-Table framework, where tabular data is explicitly used in the reasoning chain as a proxy for intermediate thoughts. Specifically, we guide LLMs using in-context learning to iteratively generate operations and update the table to represent a tabular reasoning chain. LLMs can therefore dynamically plan the next operation based on the results of the previous ones. This continuous evolution of the table forms a chain, showing the reasoning process for a given tabular problem. The chain carries structured information of the intermediate results, enabling more accurate and reliable predictions. Chain-of-Table achieves new state-of-the-art performance on WikiTQ, FeTaQA, and TabFact benchmarks across multiple LLM choices.",
    "event-title": "The Twelfth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding",
    "title-short": "Chain-of-Table",
    "URL": "https://openreview.net/forum?id=4L0xnS4GQM",
    "author": [
      {
        "family": "Wang",
        "given": "Zilong"
      },
      {
        "family": "Zhang",
        "given": "Hao"
      },
      {
        "family": "Li",
        "given": "Chun-Liang"
      },
      {
        "family": "Eisenschlos",
        "given": "Julian Martin"
      },
      {
        "family": "Perot",
        "given": "Vincent"
      },
      {
        "family": "Wang",
        "given": "Zifeng"
      },
      {
        "family": "Miculicich",
        "given": "Lesly"
      },
      {
        "family": "Fujii",
        "given": "Yasuhisa"
      },
      {
        "family": "Shang",
        "given": "Jingbo"
      },
      {
        "family": "Lee",
        "given": "Chen-Yu"
      },
      {
        "family": "Pfister",
        "given": "Tomas"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 5]]
    },
    "issued": {
      "date-parts": [["2023", 10, 13]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/S69499AP",
    "type": "paper-conference",
    "abstract": "An increasing number of vision-language tasks can be handled with little to no training, i.e., in a zero and few-shot manner, by marrying large language models (LLMs) to vision encoders, resulting in large vision-language models (LVLMs). While this has huge upsides, such as not requiring training data or custom architectures, how an input is presented to an LVLM can have a major impact on zero-shot model performance. In particular, inputs phrased in an underspecified way can result in incorrect answers due to factors like missing visual information, complex implicit reasoning, or linguistic ambiguity. Therefore, adding visually-grounded information to the input as a preemptive clarification should improve model performance by reducing underspecification, e.g., by localizing objects and disambiguating references. Similarly, in the VQA setting, changing the way questions are framed can make them easier for models to answer. To this end, we present **Rep**hrase, **A**ugment and **Re**ason (RepARe), a gradient-free framework that extracts salient details about the image using the underlying LVLM as a captioner and reasoner, in order to propose modifications to the original question. We then use the LVLM’s confidence over a generated answer as an unsupervised scoring function to select the rephrased question most likely to improve zero-shot performance. Focusing on three visual question answering tasks, we show that RepARe can result in a 3.85% (absolute) increase in zero-shot accuracy on VQAv2, 6.41%, and 7.94% points increase on A-OKVQA, and VizWiz respectively. Additionally, we find that using gold answers for oracle question candidate selection achieves a substantial gain in VQA accuracy by up to 14.41%. Through extensive analysis, we demonstrate that outputs from RepARe increase syntactic complexity, and effectively utilize vision-language interaction and the frozen LLM.",
    "event-title": "The Twelfth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "Rephrase, Augment, Reason: Visual Grounding of Questions for Vision-Language Models",
    "title-short": "Rephrase, Augment, Reason",
    "URL": "https://openreview.net/forum?id=L4nOxziGf9",
    "author": [
      {
        "family": "Prasad",
        "given": "Archiki"
      },
      {
        "family": "Stengel-Eskin",
        "given": "Elias"
      },
      {
        "family": "Bansal",
        "given": "Mohit"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 5]]
    },
    "issued": {
      "date-parts": [["2023", 10, 13]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/KUEGGFIQ",
    "type": "article",
    "abstract": "The rapid development of large language models (LLMs) has been witnessed in recent years. Based on the powerful LLMs, multi-modal LLMs (MLLMs) extend the modality from text to a broader spectrum of domains, attracting widespread attention due to the broader range of application scenarios. As LLMs and MLLMs rely on vast amounts of model parameters and data to achieve emergent capabilities, the importance of data is receiving increasingly widespread attention and recognition. Tracing and analyzing recent data-oriented works for MLLMs, we find that the development of models and data is not two separate paths but rather interconnected. On the one hand, vaster and higher-quality data contribute to better performance of MLLMs, on the other hand, MLLMs can facilitate the development of data. The co-development of multi-modal data and MLLMs requires a clear view of 1) at which development stage of MLLMs can specific data-centric approaches be employed to enhance which capabilities, and 2) by utilizing which capabilities and acting as which roles can models contribute to multi-modal data. To promote the data-model co-development for MLLM community, we systematically review existing works related to MLLMs from the data-model co-development perspective. A regularly maintained project associated with this survey is accessible at https://github.com/modelscope/data-juicer/blob/main/docs/awesome_llm_data.md.",
    "DOI": "10.48550/arXiv.2407.08583",
    "language": "en-US",
    "note": "arXiv:2407.08583 [cs]",
    "number": "arXiv:2407.08583",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective",
    "title-short": "The Synergy between Data and Multi-Modal Large Language Models",
    "URL": "http://arxiv.org/abs/2407.08583",
    "author": [
      {
        "family": "Qin",
        "given": "Zhen"
      },
      {
        "family": "Chen",
        "given": "Daoyuan"
      },
      {
        "family": "Zhang",
        "given": "Wenhao"
      },
      {
        "family": "Yao",
        "given": "Liuyi"
      },
      {
        "family": "Huang",
        "given": "Yilun"
      },
      {
        "family": "Ding",
        "given": "Bolin"
      },
      {
        "family": "Li",
        "given": "Yaliang"
      },
      {
        "family": "Deng",
        "given": "Shuiguang"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 5]]
    },
    "issued": {
      "date-parts": [["2024", 7, 11]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/9JT9NL6B",
    "type": "article",
    "abstract": "Current Multimodal Large Language Models (MLLMs) typically integrate a pre-trained LLM with another pre-trained vision transformer through a connector, such as an MLP, endowing the LLM with visual capabilities. However, the misalignment between two embedding strategies in MLLMs -- the structural textual embeddings based on an embedding look-up table and the continuous embeddings generated directly by the vision encoder -- makes challenges for a more seamless fusion of visual and textual information. We propose Ovis, a novel MLLM architecture designed to structurally align visual and textual embeddings. Ovis integrates an additional learnable visual embedding table into the visual encoder's process. To capture rich visual semantics, each image patch indexes the visual embedding table multiple times, resulting in a final visual embedding that is a probabilistic combination of the indexed embeddings. This structural approach mirrors the method used for generating textual embeddings. Empirical evaluations on various multimodal benchmarks show that Ovis outperforms open-source MLLMs of similar parameter scales and even surpasses the proprietary model Qwen-VL-Plus overall. These results highlight the potential of Ovis' structured visual representation for advancing MLLM architectural design and promoting more effective multimodal learning. Code, datasets, and models are available at https://github.com/AIDC-AI/Ovis.",
    "DOI": "10.48550/arXiv.2405.20797",
    "language": "en-US",
    "note": "arXiv:2405.20797 [cs]",
    "number": "arXiv:2405.20797",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Ovis: Structural Embedding Alignment for Multimodal Large Language Model",
    "title-short": "Ovis",
    "URL": "http://arxiv.org/abs/2405.20797",
    "author": [
      {
        "family": "Lu",
        "given": "Shiyin"
      },
      {
        "family": "Li",
        "given": "Yang"
      },
      {
        "family": "Chen",
        "given": "Qing-Guo"
      },
      {
        "family": "Xu",
        "given": "Zhao"
      },
      {
        "family": "Luo",
        "given": "Weihua"
      },
      {
        "family": "Zhang",
        "given": "Kaifu"
      },
      {
        "family": "Ye",
        "given": "Han-Jia"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 5]]
    },
    "issued": {
      "date-parts": [["2024", 6, 17]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/DM4W3EC3",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF International Conference on Computer Vision",
    "language": "en",
    "page": "11975-11986",
    "source": "openaccess.thecvf.com",
    "title": "Sigmoid Loss for Language Image Pre-Training",
    "URL": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_Sigmoid_Loss_for_Language_Image_Pre-Training_ICCV_2023_paper.html",
    "author": [
      {
        "family": "Zhai",
        "given": "Xiaohua"
      },
      {
        "family": "Mustafa",
        "given": "Basil"
      },
      {
        "family": "Kolesnikov",
        "given": "Alexander"
      },
      {
        "family": "Beyer",
        "given": "Lucas"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 5]]
    },
    "issued": {
      "date-parts": [["2023"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/7GSGIE3E",
    "type": "article",
    "abstract": "Modern LVLMs still struggle to achieve fine-grained document understanding, such as OCR/translation/caption for regions of interest to the user, tasks that require the context of the entire page, or even multiple pages. Accordingly, this paper proposes Fox, an effective pipeline, hybrid data, and tuning strategy, that catalyzes LVLMs to focus anywhere on single/multi-page documents. We introduce a novel task to boost the document understanding by making LVLMs focus attention on the document-level region, such as redefining full-page OCR as foreground focus. We employ multiple vision vocabularies to extract visual hybrid knowledge for interleaved document pages (e.g., a page containing a photo). Meanwhile, we render cross-vocabulary vision data as the catalyzer to achieve a full reaction of multiple visual vocabularies and in-document figure understanding. Further, without modifying the weights of multiple vision vocabularies, the above catalyzed fine-grained understanding capabilities can be efficiently tuned to multi-page documents, enabling the model to focus anywhere in both format-free and page-free manners. Besides, we build a benchmark including 9 fine-grained sub-tasks (e.g., region-level OCR/summary, color-guided OCR) to promote document analysis in the community. The experimental results verify the superiority of our model.",
    "DOI": "10.48550/arXiv.2405.14295",
    "note": "arXiv:2405.14295 [cs]",
    "number": "arXiv:2405.14295",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Focus Anywhere for Fine-grained Multi-page Document Understanding",
    "URL": "http://arxiv.org/abs/2405.14295",
    "author": [
      {
        "family": "Liu",
        "given": "Chenglong"
      },
      {
        "family": "Wei",
        "given": "Haoran"
      },
      {
        "family": "Chen",
        "given": "Jinyue"
      },
      {
        "family": "Kong",
        "given": "Lingyu"
      },
      {
        "family": "Ge",
        "given": "Zheng"
      },
      {
        "family": "Zhu",
        "given": "Zining"
      },
      {
        "family": "Zhao",
        "given": "Liang"
      },
      {
        "family": "Sun",
        "given": "Jianjian"
      },
      {
        "family": "Han",
        "given": "Chunrui"
      },
      {
        "family": "Zhang",
        "given": "Xiangyu"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 5]]
    },
    "issued": {
      "date-parts": [["2024", 5, 23]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/TV77R6EE",
    "type": "article",
    "abstract": "Modern Large Vision-Language Models (LVLMs) enjoy the same vision vocabulary -- CLIP, which can cover most common vision tasks. However, for some special vision task that needs dense and fine-grained vision perception, e.g., document-level OCR or chart understanding, especially in non-English scenarios, the CLIP-style vocabulary may encounter low efficiency in tokenizing the vision knowledge and even suffer out-of-vocabulary problem. Accordingly, we propose Vary, an efficient and effective method to scale up the vision vocabulary of LVLMs. The procedures of Vary are naturally divided into two folds: the generation and integration of a new vision vocabulary. In the first phase, we devise a vocabulary network along with a tiny decoder-only transformer to produce the desired vocabulary via autoregression. In the next, we scale up the vanilla vision vocabulary by merging the new one with the original one (CLIP), enabling the LVLMs can quickly garner new features. Compared to the popular BLIP-2, MiniGPT4, and LLaVA, Vary can maintain its vanilla capabilities while enjoying more excellent fine-grained perception and understanding ability. Specifically, Vary is competent in new document parsing features (OCR or markdown conversion) while achieving 78.2% ANLS in DocVQA and 36.2% in MMVet. Our code will be publicly available on the homepage.",
    "DOI": "10.48550/ARXIV.2312.06109",
    "language": "en-US",
    "license": "Creative Commons Attribution 4.0 International",
    "note": "version: 1",
    "publisher": "arXiv",
    "source": "DOI.org (Datacite)",
    "title": "Vary: Scaling up the Vision Vocabulary for Large Vision-Language Models",
    "title-short": "Vary",
    "URL": "https://arxiv.org/abs/2312.06109",
    "author": [
      {
        "family": "Wei",
        "given": "Haoran"
      },
      {
        "family": "Kong",
        "given": "Lingyu"
      },
      {
        "family": "Chen",
        "given": "Jinyue"
      },
      {
        "family": "Zhao",
        "given": "Liang"
      },
      {
        "family": "Ge",
        "given": "Zheng"
      },
      {
        "family": "Yang",
        "given": "Jinrong"
      },
      {
        "family": "Sun",
        "given": "Jianjian"
      },
      {
        "family": "Han",
        "given": "Chunrui"
      },
      {
        "family": "Zhang",
        "given": "Xiangyu"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 5]]
    },
    "issued": {
      "date-parts": [["2023"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/TMNHUALL",
    "type": "article",
    "abstract": "Recently, interpreting complex charts with logical reasoning has emerged as challenges due to the development of vision-language models. A prior state-of-the-art (SOTA) model has presented an end-to-end method that leverages the vision-language model to convert charts into table format utilizing Large Language Model (LLM) for reasoning. However, unlike natural images, charts contain a mix of essential and irrelevant information required for chart reasoning, and we discover that this characteristic can lower the performance of chart-to-table extraction. In this paper, we introduce SIMPLOT, a method designed to extract only the elements necessary for chart reasoning. The proposed method involves two steps: 1) training to mimic a simple plot that contains only the essential information from a complex chart for table extraction, followed by 2) performing reasoning based on the table. Our model enables accurate chart reasoning without the need for additional annotations or datasets, and its effectiveness is demonstrated through various experiments. Furthermore, we propose a novel prompt mimicking how human interpret charts for more accurate reasoning. Our source code is available at https://github.com/sangwu99/Simplot.",
    "DOI": "10.48550/arXiv.2405.00021",
    "language": "en-US",
    "note": "arXiv:2405.00021 [cs]",
    "number": "arXiv:2405.00021",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "SIMPLOT: Enhancing Chart Question Answering by Distilling Essentials",
    "title-short": "SIMPLOT",
    "URL": "http://arxiv.org/abs/2405.00021",
    "author": [
      {
        "family": "Kim",
        "given": "Wonjoong"
      },
      {
        "family": "Park",
        "given": "Sangwu"
      },
      {
        "family": "In",
        "given": "Yeonjun"
      },
      {
        "family": "Han",
        "given": "Seokwon"
      },
      {
        "family": "Park",
        "given": "Chanyoung"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 6]]
    },
    "issued": {
      "date-parts": [["2024", 6, 17]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/FIDC9I87",
    "type": "article",
    "abstract": "We introduce a new benchmark, ChartMimic, aimed at assessing the visually-grounded code generation capabilities of large multimodal models (LMMs). ChartMimic utilizes information-intensive visual charts and textual instructions as inputs, requiring LMMs to generate the corresponding code for chart rendering. ChartMimic includes 1,000 human-curated (figure, instruction, code) triplets, which represent the authentic chart use cases found in scientific papers across various domains(e.g., Physics, Computer Science, Economics, etc). These charts span 18 regular types and 4 advanced types, diversifying into 191 subcategories. Furthermore, we propose multi-level evaluation metrics to provide an automatic and thorough assessment of the output code and the rendered charts. Unlike existing code generation benchmarks, ChartMimic places emphasis on evaluating LMMs' capacity to harmonize a blend of cognitive capabilities, encompassing visual understanding, code generation, and cross-modal reasoning. The evaluation of 3 proprietary models and 11 open-weight models highlights the substantial challenges posed by ChartMimic. Even the advanced GPT-4V, Claude-3-opus only achieve an average score of 73.2 and 53.7, respectively, indicating significant room for improvement. We anticipate that ChartMimic will inspire the development of LMMs, advancing the pursuit of artificial general intelligence.",
    "DOI": "10.48550/arXiv.2406.09961",
    "language": "en-US",
    "note": "arXiv:2406.09961 [cs]",
    "number": "arXiv:2406.09961",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "ChartMimic: Evaluating LMM's Cross-Modal Reasoning Capability via Chart-to-Code Generation",
    "title-short": "ChartMimic",
    "URL": "http://arxiv.org/abs/2406.09961",
    "author": [
      {
        "family": "Shi",
        "given": "Chufan"
      },
      {
        "family": "Yang",
        "given": "Cheng"
      },
      {
        "family": "Liu",
        "given": "Yaxin"
      },
      {
        "family": "Shui",
        "given": "Bo"
      },
      {
        "family": "Wang",
        "given": "Junjie"
      },
      {
        "family": "Jing",
        "given": "Mohan"
      },
      {
        "family": "Xu",
        "given": "Linran"
      },
      {
        "family": "Zhu",
        "given": "Xinyu"
      },
      {
        "family": "Li",
        "given": "Siheng"
      },
      {
        "family": "Zhang",
        "given": "Yuxiang"
      },
      {
        "family": "Liu",
        "given": "Gongye"
      },
      {
        "family": "Nie",
        "given": "Xiaomei"
      },
      {
        "family": "Cai",
        "given": "Deng"
      },
      {
        "family": "Yang",
        "given": "Yujiu"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 6]]
    },
    "issued": {
      "date-parts": [["2024", 6, 14]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/6SC6TCKP",
    "type": "article",
    "abstract": "Large vision-language models (LVLMs) excel across diverse tasks involving concrete images from natural scenes. However, their ability to interpret abstract figures, such as geometry shapes and scientific plots, remains limited due to a scarcity of training datasets in scientific domains. To fill this gap, we introduce Multimodal ArXiv, consisting of ArXivCap and ArXivQA, for enhancing LVLMs scientific comprehension. ArXivCap is a figure-caption dataset comprising 6.4M images and 3.9M captions, sourced from 572K ArXiv papers spanning various scientific domains. Drawing from ArXivCap, we introduce ArXivQA, a question-answering dataset generated by prompting GPT-4V based on scientific figures. ArXivQA greatly enhances open-sourced LVLMs' mathematical reasoning capabilities, achieving a 10.4\\% absolute accuracy gain on a multimodal mathematical reasoning benchmark. Furthermore, employing ArXivCap, we devise four vision-to-text tasks for benchmarking LVLMs. Evaluation results with state-of-the-art LVLMs underscore their struggle with the nuanced semantics of academic figures, while domain-specific training yields substantial performance gains. Our error analysis uncovers misinterpretations of visual context, recognition errors, and the production of overly simplified captions by current LVLMs, shedding light on future improvements.",
    "DOI": "10.48550/arXiv.2403.00231",
    "language": "en-US",
    "note": "arXiv:2403.00231 [cs]",
    "number": "arXiv:2403.00231",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of Large Vision-Language Models",
    "title-short": "Multimodal ArXiv",
    "URL": "http://arxiv.org/abs/2403.00231",
    "author": [
      {
        "family": "Li",
        "given": "Lei"
      },
      {
        "family": "Wang",
        "given": "Yuqi"
      },
      {
        "family": "Xu",
        "given": "Runxin"
      },
      {
        "family": "Wang",
        "given": "Peiyi"
      },
      {
        "family": "Feng",
        "given": "Xiachong"
      },
      {
        "family": "Kong",
        "given": "Lingpeng"
      },
      {
        "family": "Liu",
        "given": "Qi"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 6]]
    },
    "issued": {
      "date-parts": [["2024", 6, 2]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/AQBXEAMQ",
    "type": "article",
    "abstract": "In this work, we present SciGraphQA, a synthetic multi-turn question-answer dataset related to academic graphs. SciGraphQA is 13 times larger than ChartVQA, the previously largest chart-visual question-answering dataset. It is also the largest open-sourced chart VQA dataset with non-synthetic charts. To build our dataset, we selected 290,000 Computer Science or Machine Learning ArXiv papers published between 2010 and 2020, and then used Palm-2 to generate 295K samples of open-vocabulary multi-turn question-answering dialogues about the graphs. As context, we provided the text-only Palm-2 with paper title, abstract, paragraph mentioning the graph, and rich text contextual data from the graph itself, obtaining dialogues with an average 2.23 question-answer turns for each graph. We asked GPT-4 to assess the matching quality of our question-answer turns given the paper's context, obtaining an average rating of 8.7/10 on our 3K test set. We evaluated the 0-shot capability of the most popular MLLM models such as LLaVa, mPLUGowl, BLIP-2, and openFlamingo's on our dataset, finding LLaVA-13B being the most performant with a CIDEr score of 0.08. We further enriched the question prompts for LLAVA by including the serialized data tables extracted from the graphs using the DePlot model, boosting LLaVA's 0-shot CIDEr to 0.15. To verify the validity of our dataset, we also fine-tuned LLaVa using our dataset, reaching a substantially higher CIDEr score of 0.26. We anticipate further accuracy improvement by including segmentation mask tokens and leveraging larger LLM backbones coupled with emergent prompting techniques. Our code and data are open-sourced.",
    "DOI": "10.48550/arXiv.2308.03349",
    "language": "en-US",
    "note": "arXiv:2308.03349 [cs]",
    "number": "arXiv:2308.03349",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "SciGraphQA: A Large-Scale Synthetic Multi-Turn Question-Answering Dataset for Scientific Graphs",
    "title-short": "SciGraphQA",
    "URL": "http://arxiv.org/abs/2308.03349",
    "author": [
      {
        "family": "Li",
        "given": "Shengzhi"
      },
      {
        "family": "Tajbakhsh",
        "given": "Nima"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 6]]
    },
    "issued": {
      "date-parts": [["2023", 8, 7]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/CU5NZZXG",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF International Conference on Computer Vision",
    "language": "en",
    "page": "22202-22213",
    "source": "openaccess.thecvf.com",
    "title": "ChartReader: A Unified Framework for Chart Derendering and Comprehension without Heuristic Rules",
    "title-short": "ChartReader",
    "URL": "https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_ChartReader_A_Unified_Framework_for_Chart_Derendering_and_Comprehension_without_ICCV_2023_paper.html",
    "author": [
      {
        "family": "Cheng",
        "given": "Zhi-Qi"
      },
      {
        "family": "Dai",
        "given": "Qi"
      },
      {
        "family": "Hauptmann",
        "given": "Alexander G."
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 6]]
    },
    "issued": {
      "date-parts": [["2023"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/9KTG9P6T",
    "type": "article",
    "abstract": "Recently, the strong text creation ability of Large Language Models(LLMs) has given rise to many tools for assisting paper reading or even writing. However, the weak diagram analysis abilities of LLMs or Multimodal LLMs greatly limit their application scenarios, especially for scientific academic paper writing. In this work, towards a more versatile copilot for academic paper writing, we mainly focus on strengthening the multi-modal diagram analysis ability of Multimodal LLMs. By parsing Latex source files of high-quality papers, we carefully build a multi-modal diagram understanding dataset M-Paper. By aligning diagrams in the paper with related paragraphs, we construct professional diagram analysis samples for training and evaluation. M-Paper is the first dataset to support joint comprehension of multiple scientific diagrams, including figures and tables in the format of images or Latex codes. Besides, to better align the copilot with the user's intention, we introduce the `outline' as the control signal, which could be directly given by the user or revised based on auto-generated ones. Comprehensive experiments with a state-of-the-art Mumtimodal LLM demonstrate that training on our dataset shows stronger scientific diagram understanding performance, including diagram captioning, diagram analysis, and outline recommendation. The dataset, code, and model are available at https://github.com/X-PLUG/mPLUG-DocOwl/tree/main/PaperOwl.",
    "DOI": "10.48550/arXiv.2311.18248",
    "note": "arXiv:2311.18248 [cs]",
    "number": "arXiv:2311.18248",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "mPLUG-PaperOwl: Scientific Diagram Analysis with the Multimodal Large Language Model",
    "title-short": "mPLUG-PaperOwl",
    "URL": "http://arxiv.org/abs/2311.18248",
    "author": [
      {
        "family": "Hu",
        "given": "Anwen"
      },
      {
        "family": "Shi",
        "given": "Yaya"
      },
      {
        "family": "Xu",
        "given": "Haiyang"
      },
      {
        "family": "Ye",
        "given": "Jiabo"
      },
      {
        "family": "Ye",
        "given": "Qinghao"
      },
      {
        "family": "Yan",
        "given": "Ming"
      },
      {
        "family": "Li",
        "given": "Chenliang"
      },
      {
        "family": "Qian",
        "given": "Qi"
      },
      {
        "family": "Zhang",
        "given": "Ji"
      },
      {
        "family": "Huang",
        "given": "Fei"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 8]]
    },
    "issued": {
      "date-parts": [["2024", 1, 9]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/X8D6UFCS",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
    "language": "en",
    "page": "13040-13051",
    "source": "openaccess.thecvf.com",
    "title": "mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with Modality Collaboration",
    "title-short": "mPLUG-Owl2",
    "URL": "https://openaccess.thecvf.com/content/CVPR2024/html/Ye_mPLUG-Owl2_Revolutionizing_Multi-modal_Large_Language_Model_with_Modality_Collaboration_CVPR_2024_paper.html",
    "author": [
      {
        "family": "Ye",
        "given": "Qinghao"
      },
      {
        "family": "Xu",
        "given": "Haiyang"
      },
      {
        "family": "Ye",
        "given": "Jiabo"
      },
      {
        "family": "Yan",
        "given": "Ming"
      },
      {
        "family": "Hu",
        "given": "Anwen"
      },
      {
        "family": "Liu",
        "given": "Haowei"
      },
      {
        "family": "Qian",
        "given": "Qi"
      },
      {
        "family": "Zhang",
        "given": "Ji"
      },
      {
        "family": "Huang",
        "given": "Fei"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 8]]
    },
    "issued": {
      "date-parts": [["2024"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/DKFV462Z",
    "type": "article",
    "abstract": "Natural language is a powerful complementary modality of communication for data visualizations, such as bar and line charts. To facilitate chart-based reasoning using natural language, various downstream tasks have been introduced recently such as chart question answering, chart summarization, and fact-checking with charts. These tasks pose a unique challenge, demanding both vision-language reasoning and a nuanced understanding of chart data tables, visual encodings, and natural language prompts. Despite the recent success of Large Language Models (LLMs) across diverse NLP tasks, their abilities and limitations in the realm of data visualization remain under-explored, possibly due to their lack of multi-modal capabilities. To bridge the gap, this paper presents the first comprehensive evaluation of the recently developed large vision language models (LVLMs) for chart understanding and reasoning tasks. Our evaluation includes a comprehensive assessment of LVLMs, including GPT-4V and Gemini, across four major chart reasoning tasks. Furthermore, we perform a qualitative evaluation of LVLMs' performance on a diverse range of charts, aiming to provide a thorough analysis of their strengths and weaknesses. Our findings reveal that LVLMs demonstrate impressive abilities in generating fluent texts covering high-level data insights while also encountering common problems like hallucinations, factual errors, and data bias. We highlight the key strengths and limitations of chart comprehension tasks, offering insights for future research.",
    "DOI": "10.48550/arXiv.2406.00257",
    "language": "en-US",
    "note": "arXiv:2406.00257 [cs]",
    "number": "arXiv:2406.00257",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning? An Extensive Investigation into the Capabilities and Limitations of LVLMs",
    "title-short": "Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning?",
    "URL": "http://arxiv.org/abs/2406.00257",
    "author": [
      {
        "family": "Islam",
        "given": "Mohammed Saidul"
      },
      {
        "family": "Rahman",
        "given": "Raian"
      },
      {
        "family": "Masry",
        "given": "Ahmed"
      },
      {
        "family": "Laskar",
        "given": "Md Tahmid Rahman"
      },
      {
        "family": "Nayeem",
        "given": "Mir Tafseer"
      },
      {
        "family": "Hoque",
        "given": "Enamul"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 8]]
    },
    "issued": {
      "date-parts": [["2024", 5, 31]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/PCRN45VG",
    "type": "article",
    "abstract": "Emerging multimodal large language models (MLLMs) exhibit great potential for chart question answering (CQA). Recent efforts primarily focus on scaling up training datasets (i.e., charts, data tables, and question-answer (QA) pairs) through data collection and synthesis. However, our empirical study on existing MLLMs and CQA datasets reveals notable gaps. First, current data collection and synthesis focus on data volume and lack consideration of fine-grained visual encodings and QA tasks, resulting in unbalanced data distribution divergent from practical CQA scenarios. Second, existing work follows the training recipe of the base MLLMs initially designed for natural images, under-exploring the adaptation to unique chart characteristics, such as rich text elements. To fill the gap, we propose a visualization-referenced instruction tuning approach to guide the training dataset enhancement and model development. Specifically, we propose a novel data engine to effectively filter diverse and high-quality data from existing datasets and subsequently refine and augment the data using LLM-based generation techniques to better align with practical QA tasks and visual encodings. Then, to facilitate the adaptation to chart characteristics, we utilize the enriched data to train an MLLM by unfreezing the vision encoder and incorporating a mixture-of-resolution adaptation strategy for enhanced fine-grained recognition. Experimental results validate the effectiveness of our approach. Even with fewer training examples, our model consistently outperforms state-of-the-art CQA models on established benchmarks. We also contribute a dataset split as a benchmark for future research. Source codes and datasets of this paper are available at https://github.com/zengxingchen/ChartQA-MLLM.",
    "DOI": "10.48550/arXiv.2407.20174",
    "language": "en-US",
    "note": "arXiv:2407.20174 [cs]",
    "number": "arXiv:2407.20174",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning",
    "URL": "http://arxiv.org/abs/2407.20174",
    "author": [
      {
        "family": "Zeng",
        "given": "Xingchen"
      },
      {
        "family": "Lin",
        "given": "Haichuan"
      },
      {
        "family": "Ye",
        "given": "Yilin"
      },
      {
        "family": "Zeng",
        "given": "Wei"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 8]]
    },
    "issued": {
      "date-parts": [["2024", 7, 29]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/RREWJXJ4",
    "type": "article",
    "abstract": "Following the recent popularity of Large Language Models (LLMs), several attempts have been made to extend them to the visual domain. From having a visual assistant that could guide us through unfamiliar environments to generative models that produce images using only a high-level text description, the vision-language model (VLM) applications will significantly impact our relationship with technology. However, there are many challenges that need to be addressed to improve the reliability of those models. While language is discrete, vision evolves in a much higher dimensional space in which concepts cannot always be easily discretized. To better understand the mechanics behind mapping vision to language, we present this introduction to VLMs which we hope will help anyone who would like to enter the field. First, we introduce what VLMs are, how they work, and how to train them. Then, we present and discuss approaches to evaluate VLMs. Although this work primarily focuses on mapping images to language, we also discuss extending VLMs to videos.",
    "DOI": "10.48550/arXiv.2405.17247",
    "language": "en-US",
    "note": "arXiv:2405.17247 [cs]",
    "number": "arXiv:2405.17247",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "An Introduction to Vision-Language Modeling",
    "URL": "http://arxiv.org/abs/2405.17247",
    "author": [
      {
        "family": "Bordes",
        "given": "Florian"
      },
      {
        "family": "Pang",
        "given": "Richard Yuanzhe"
      },
      {
        "family": "Ajay",
        "given": "Anurag"
      },
      {
        "family": "Li",
        "given": "Alexander C."
      },
      {
        "family": "Bardes",
        "given": "Adrien"
      },
      {
        "family": "Petryk",
        "given": "Suzanne"
      },
      {
        "family": "Mañas",
        "given": "Oscar"
      },
      {
        "family": "Lin",
        "given": "Zhiqiu"
      },
      {
        "family": "Mahmoud",
        "given": "Anas"
      },
      {
        "family": "Jayaraman",
        "given": "Bargav"
      },
      {
        "family": "Ibrahim",
        "given": "Mark"
      },
      {
        "family": "Hall",
        "given": "Melissa"
      },
      {
        "family": "Xiong",
        "given": "Yunyang"
      },
      {
        "family": "Lebensold",
        "given": "Jonathan"
      },
      {
        "family": "Ross",
        "given": "Candace"
      },
      {
        "family": "Jayakumar",
        "given": "Srihari"
      },
      {
        "family": "Guo",
        "given": "Chuan"
      },
      {
        "family": "Bouchacourt",
        "given": "Diane"
      },
      {
        "family": "Al-Tahan",
        "given": "Haider"
      },
      {
        "family": "Padthe",
        "given": "Karthik"
      },
      {
        "family": "Sharma",
        "given": "Vasu"
      },
      {
        "family": "Xu",
        "given": "Hu"
      },
      {
        "family": "Tan",
        "given": "Xiaoqing Ellen"
      },
      {
        "family": "Richards",
        "given": "Megan"
      },
      {
        "family": "Lavoie",
        "given": "Samuel"
      },
      {
        "family": "Astolfi",
        "given": "Pietro"
      },
      {
        "family": "Hemmat",
        "given": "Reyhane Askari"
      },
      {
        "family": "Chen",
        "given": "Jun"
      },
      {
        "family": "Tirumala",
        "given": "Kushal"
      },
      {
        "family": "Assouel",
        "given": "Rim"
      },
      {
        "family": "Moayeri",
        "given": "Mazda"
      },
      {
        "family": "Talattof",
        "given": "Arjang"
      },
      {
        "family": "Chaudhuri",
        "given": "Kamalika"
      },
      {
        "family": "Liu",
        "given": "Zechun"
      },
      {
        "family": "Chen",
        "given": "Xilun"
      },
      {
        "family": "Garrido",
        "given": "Quentin"
      },
      {
        "family": "Ullrich",
        "given": "Karen"
      },
      {
        "family": "Agrawal",
        "given": "Aishwarya"
      },
      {
        "family": "Saenko",
        "given": "Kate"
      },
      {
        "family": "Celikyilmaz",
        "given": "Asli"
      },
      {
        "family": "Chandra",
        "given": "Vikas"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 8]]
    },
    "issued": {
      "date-parts": [["2024", 5, 27]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/FZ56ZLC9",
    "type": "article",
    "abstract": "Chart comprehension presents significant challenges for machine learning models due to the diverse and intricate shapes of charts. Existing multimodal methods often overlook these visual features or fail to integrate them effectively for chart question answering (ChartQA). To address this, we introduce Chartformer, a unified framework that enhances chart component recognition by accurately identifying and classifying components such as bars, lines, pies, titles, legends, and axes. Additionally, we propose a novel Question-guided Deformable Co-Attention (QDCAt) mechanism, which fuses chart features encoded by Chartformer with the given question, leveraging the question's guidance to ground the correct answer. Extensive experiments demonstrate that the proposed approaches significantly outperform baseline models in chart component recognition and ChartQA tasks, achieving improvements of 3.2% in mAP and 15.4% in accuracy, respectively. These results underscore the robustness of our solution for detailed visual data interpretation across various applications.",
    "DOI": "10.48550/arXiv.2407.21038",
    "language": "en-US",
    "note": "arXiv:2407.21038 [cs]",
    "number": "arXiv:2407.21038",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Advancing Chart Question Answering with Robust Chart Component Recognition",
    "URL": "http://arxiv.org/abs/2407.21038",
    "author": [
      {
        "family": "Zheng",
        "given": "Hanwen"
      },
      {
        "family": "Wang",
        "given": "Sijia"
      },
      {
        "family": "Thomas",
        "given": "Chris"
      },
      {
        "family": "Huang",
        "given": "Lifu"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 11]]
    },
    "issued": {
      "date-parts": [["2024", 7, 19]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/Y9KHXXE5",
    "type": "article",
    "abstract": "We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.",
    "DOI": "10.48550/arXiv.2303.08774",
    "language": "en-US",
    "note": "arXiv:2303.08774 [cs]",
    "number": "arXiv:2303.08774",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "GPT-4 Technical Report",
    "URL": "http://arxiv.org/abs/2303.08774",
    "author": [
      {
        "family": "OpenAI",
        "given": ""
      },
      {
        "family": "Achiam",
        "given": "Josh"
      },
      {
        "family": "Adler",
        "given": "Steven"
      },
      {
        "family": "Agarwal",
        "given": "Sandhini"
      },
      {
        "family": "Ahmad",
        "given": "Lama"
      },
      {
        "family": "Akkaya",
        "given": "Ilge"
      },
      {
        "family": "Aleman",
        "given": "Florencia Leoni"
      },
      {
        "family": "Almeida",
        "given": "Diogo"
      },
      {
        "family": "Altenschmidt",
        "given": "Janko"
      },
      {
        "family": "Altman",
        "given": "Sam"
      },
      {
        "family": "Anadkat",
        "given": "Shyamal"
      },
      {
        "family": "Avila",
        "given": "Red"
      },
      {
        "family": "Babuschkin",
        "given": "Igor"
      },
      {
        "family": "Balaji",
        "given": "Suchir"
      },
      {
        "family": "Balcom",
        "given": "Valerie"
      },
      {
        "family": "Baltescu",
        "given": "Paul"
      },
      {
        "family": "Bao",
        "given": "Haiming"
      },
      {
        "family": "Bavarian",
        "given": "Mohammad"
      },
      {
        "family": "Belgum",
        "given": "Jeff"
      },
      {
        "family": "Bello",
        "given": "Irwan"
      },
      {
        "family": "Berdine",
        "given": "Jake"
      },
      {
        "family": "Bernadett-Shapiro",
        "given": "Gabriel"
      },
      {
        "family": "Berner",
        "given": "Christopher"
      },
      {
        "family": "Bogdonoff",
        "given": "Lenny"
      },
      {
        "family": "Boiko",
        "given": "Oleg"
      },
      {
        "family": "Boyd",
        "given": "Madelaine"
      },
      {
        "family": "Brakman",
        "given": "Anna-Luisa"
      },
      {
        "family": "Brockman",
        "given": "Greg"
      },
      {
        "family": "Brooks",
        "given": "Tim"
      },
      {
        "family": "Brundage",
        "given": "Miles"
      },
      {
        "family": "Button",
        "given": "Kevin"
      },
      {
        "family": "Cai",
        "given": "Trevor"
      },
      {
        "family": "Campbell",
        "given": "Rosie"
      },
      {
        "family": "Cann",
        "given": "Andrew"
      },
      {
        "family": "Carey",
        "given": "Brittany"
      },
      {
        "family": "Carlson",
        "given": "Chelsea"
      },
      {
        "family": "Carmichael",
        "given": "Rory"
      },
      {
        "family": "Chan",
        "given": "Brooke"
      },
      {
        "family": "Chang",
        "given": "Che"
      },
      {
        "family": "Chantzis",
        "given": "Fotis"
      },
      {
        "family": "Chen",
        "given": "Derek"
      },
      {
        "family": "Chen",
        "given": "Sully"
      },
      {
        "family": "Chen",
        "given": "Ruby"
      },
      {
        "family": "Chen",
        "given": "Jason"
      },
      {
        "family": "Chen",
        "given": "Mark"
      },
      {
        "family": "Chess",
        "given": "Ben"
      },
      {
        "family": "Cho",
        "given": "Chester"
      },
      {
        "family": "Chu",
        "given": "Casey"
      },
      {
        "family": "Chung",
        "given": "Hyung Won"
      },
      {
        "family": "Cummings",
        "given": "Dave"
      },
      {
        "family": "Currier",
        "given": "Jeremiah"
      },
      {
        "family": "Dai",
        "given": "Yunxing"
      },
      {
        "family": "Decareaux",
        "given": "Cory"
      },
      {
        "family": "Degry",
        "given": "Thomas"
      },
      {
        "family": "Deutsch",
        "given": "Noah"
      },
      {
        "family": "Deville",
        "given": "Damien"
      },
      {
        "family": "Dhar",
        "given": "Arka"
      },
      {
        "family": "Dohan",
        "given": "David"
      },
      {
        "family": "Dowling",
        "given": "Steve"
      },
      {
        "family": "Dunning",
        "given": "Sheila"
      },
      {
        "family": "Ecoffet",
        "given": "Adrien"
      },
      {
        "family": "Eleti",
        "given": "Atty"
      },
      {
        "family": "Eloundou",
        "given": "Tyna"
      },
      {
        "family": "Farhi",
        "given": "David"
      },
      {
        "family": "Fedus",
        "given": "Liam"
      },
      {
        "family": "Felix",
        "given": "Niko"
      },
      {
        "family": "Fishman",
        "given": "Simón Posada"
      },
      {
        "family": "Forte",
        "given": "Juston"
      },
      {
        "family": "Fulford",
        "given": "Isabella"
      },
      {
        "family": "Gao",
        "given": "Leo"
      },
      {
        "family": "Georges",
        "given": "Elie"
      },
      {
        "family": "Gibson",
        "given": "Christian"
      },
      {
        "family": "Goel",
        "given": "Vik"
      },
      {
        "family": "Gogineni",
        "given": "Tarun"
      },
      {
        "family": "Goh",
        "given": "Gabriel"
      },
      {
        "family": "Gontijo-Lopes",
        "given": "Rapha"
      },
      {
        "family": "Gordon",
        "given": "Jonathan"
      },
      {
        "family": "Grafstein",
        "given": "Morgan"
      },
      {
        "family": "Gray",
        "given": "Scott"
      },
      {
        "family": "Greene",
        "given": "Ryan"
      },
      {
        "family": "Gross",
        "given": "Joshua"
      },
      {
        "family": "Gu",
        "given": "Shixiang Shane"
      },
      {
        "family": "Guo",
        "given": "Yufei"
      },
      {
        "family": "Hallacy",
        "given": "Chris"
      },
      {
        "family": "Han",
        "given": "Jesse"
      },
      {
        "family": "Harris",
        "given": "Jeff"
      },
      {
        "family": "He",
        "given": "Yuchen"
      },
      {
        "family": "Heaton",
        "given": "Mike"
      },
      {
        "family": "Heidecke",
        "given": "Johannes"
      },
      {
        "family": "Hesse",
        "given": "Chris"
      },
      {
        "family": "Hickey",
        "given": "Alan"
      },
      {
        "family": "Hickey",
        "given": "Wade"
      },
      {
        "family": "Hoeschele",
        "given": "Peter"
      },
      {
        "family": "Houghton",
        "given": "Brandon"
      },
      {
        "family": "Hsu",
        "given": "Kenny"
      },
      {
        "family": "Hu",
        "given": "Shengli"
      },
      {
        "family": "Hu",
        "given": "Xin"
      },
      {
        "family": "Huizinga",
        "given": "Joost"
      },
      {
        "family": "Jain",
        "given": "Shantanu"
      },
      {
        "family": "Jain",
        "given": "Shawn"
      },
      {
        "family": "Jang",
        "given": "Joanne"
      },
      {
        "family": "Jiang",
        "given": "Angela"
      },
      {
        "family": "Jiang",
        "given": "Roger"
      },
      {
        "family": "Jin",
        "given": "Haozhun"
      },
      {
        "family": "Jin",
        "given": "Denny"
      },
      {
        "family": "Jomoto",
        "given": "Shino"
      },
      {
        "family": "Jonn",
        "given": "Billie"
      },
      {
        "family": "Jun",
        "given": "Heewoo"
      },
      {
        "family": "Kaftan",
        "given": "Tomer"
      },
      {
        "family": "Kaiser",
        "given": "Łukasz"
      },
      {
        "family": "Kamali",
        "given": "Ali"
      },
      {
        "family": "Kanitscheider",
        "given": "Ingmar"
      },
      {
        "family": "Keskar",
        "given": "Nitish Shirish"
      },
      {
        "family": "Khan",
        "given": "Tabarak"
      },
      {
        "family": "Kilpatrick",
        "given": "Logan"
      },
      {
        "family": "Kim",
        "given": "Jong Wook"
      },
      {
        "family": "Kim",
        "given": "Christina"
      },
      {
        "family": "Kim",
        "given": "Yongjik"
      },
      {
        "family": "Kirchner",
        "given": "Jan Hendrik"
      },
      {
        "family": "Kiros",
        "given": "Jamie"
      },
      {
        "family": "Knight",
        "given": "Matt"
      },
      {
        "family": "Kokotajlo",
        "given": "Daniel"
      },
      {
        "family": "Kondraciuk",
        "given": "Łukasz"
      },
      {
        "family": "Kondrich",
        "given": "Andrew"
      },
      {
        "family": "Konstantinidis",
        "given": "Aris"
      },
      {
        "family": "Kosic",
        "given": "Kyle"
      },
      {
        "family": "Krueger",
        "given": "Gretchen"
      },
      {
        "family": "Kuo",
        "given": "Vishal"
      },
      {
        "family": "Lampe",
        "given": "Michael"
      },
      {
        "family": "Lan",
        "given": "Ikai"
      },
      {
        "family": "Lee",
        "given": "Teddy"
      },
      {
        "family": "Leike",
        "given": "Jan"
      },
      {
        "family": "Leung",
        "given": "Jade"
      },
      {
        "family": "Levy",
        "given": "Daniel"
      },
      {
        "family": "Li",
        "given": "Chak Ming"
      },
      {
        "family": "Lim",
        "given": "Rachel"
      },
      {
        "family": "Lin",
        "given": "Molly"
      },
      {
        "family": "Lin",
        "given": "Stephanie"
      },
      {
        "family": "Litwin",
        "given": "Mateusz"
      },
      {
        "family": "Lopez",
        "given": "Theresa"
      },
      {
        "family": "Lowe",
        "given": "Ryan"
      },
      {
        "family": "Lue",
        "given": "Patricia"
      },
      {
        "family": "Makanju",
        "given": "Anna"
      },
      {
        "family": "Malfacini",
        "given": "Kim"
      },
      {
        "family": "Manning",
        "given": "Sam"
      },
      {
        "family": "Markov",
        "given": "Todor"
      },
      {
        "family": "Markovski",
        "given": "Yaniv"
      },
      {
        "family": "Martin",
        "given": "Bianca"
      },
      {
        "family": "Mayer",
        "given": "Katie"
      },
      {
        "family": "Mayne",
        "given": "Andrew"
      },
      {
        "family": "McGrew",
        "given": "Bob"
      },
      {
        "family": "McKinney",
        "given": "Scott Mayer"
      },
      {
        "family": "McLeavey",
        "given": "Christine"
      },
      {
        "family": "McMillan",
        "given": "Paul"
      },
      {
        "family": "McNeil",
        "given": "Jake"
      },
      {
        "family": "Medina",
        "given": "David"
      },
      {
        "family": "Mehta",
        "given": "Aalok"
      },
      {
        "family": "Menick",
        "given": "Jacob"
      },
      {
        "family": "Metz",
        "given": "Luke"
      },
      {
        "family": "Mishchenko",
        "given": "Andrey"
      },
      {
        "family": "Mishkin",
        "given": "Pamela"
      },
      {
        "family": "Monaco",
        "given": "Vinnie"
      },
      {
        "family": "Morikawa",
        "given": "Evan"
      },
      {
        "family": "Mossing",
        "given": "Daniel"
      },
      {
        "family": "Mu",
        "given": "Tong"
      },
      {
        "family": "Murati",
        "given": "Mira"
      },
      {
        "family": "Murk",
        "given": "Oleg"
      },
      {
        "family": "Mély",
        "given": "David"
      },
      {
        "family": "Nair",
        "given": "Ashvin"
      },
      {
        "family": "Nakano",
        "given": "Reiichiro"
      },
      {
        "family": "Nayak",
        "given": "Rajeev"
      },
      {
        "family": "Neelakantan",
        "given": "Arvind"
      },
      {
        "family": "Ngo",
        "given": "Richard"
      },
      {
        "family": "Noh",
        "given": "Hyeonwoo"
      },
      {
        "family": "Ouyang",
        "given": "Long"
      },
      {
        "family": "O'Keefe",
        "given": "Cullen"
      },
      {
        "family": "Pachocki",
        "given": "Jakub"
      },
      {
        "family": "Paino",
        "given": "Alex"
      },
      {
        "family": "Palermo",
        "given": "Joe"
      },
      {
        "family": "Pantuliano",
        "given": "Ashley"
      },
      {
        "family": "Parascandolo",
        "given": "Giambattista"
      },
      {
        "family": "Parish",
        "given": "Joel"
      },
      {
        "family": "Parparita",
        "given": "Emy"
      },
      {
        "family": "Passos",
        "given": "Alex"
      },
      {
        "family": "Pavlov",
        "given": "Mikhail"
      },
      {
        "family": "Peng",
        "given": "Andrew"
      },
      {
        "family": "Perelman",
        "given": "Adam"
      },
      {
        "family": "Peres",
        "given": "Filipe de Avila Belbute"
      },
      {
        "family": "Petrov",
        "given": "Michael"
      },
      {
        "family": "Pinto",
        "given": "Henrique Ponde de Oliveira"
      },
      {
        "family": "Michael",
        "given": ""
      },
      {
        "family": "Pokorny",
        "given": ""
      },
      {
        "family": "Pokrass",
        "given": "Michelle"
      },
      {
        "family": "Pong",
        "given": "Vitchyr H."
      },
      {
        "family": "Powell",
        "given": "Tolly"
      },
      {
        "family": "Power",
        "given": "Alethea"
      },
      {
        "family": "Power",
        "given": "Boris"
      },
      {
        "family": "Proehl",
        "given": "Elizabeth"
      },
      {
        "family": "Puri",
        "given": "Raul"
      },
      {
        "family": "Radford",
        "given": "Alec"
      },
      {
        "family": "Rae",
        "given": "Jack"
      },
      {
        "family": "Ramesh",
        "given": "Aditya"
      },
      {
        "family": "Raymond",
        "given": "Cameron"
      },
      {
        "family": "Real",
        "given": "Francis"
      },
      {
        "family": "Rimbach",
        "given": "Kendra"
      },
      {
        "family": "Ross",
        "given": "Carl"
      },
      {
        "family": "Rotsted",
        "given": "Bob"
      },
      {
        "family": "Roussez",
        "given": "Henri"
      },
      {
        "family": "Ryder",
        "given": "Nick"
      },
      {
        "family": "Saltarelli",
        "given": "Mario"
      },
      {
        "family": "Sanders",
        "given": "Ted"
      },
      {
        "family": "Santurkar",
        "given": "Shibani"
      },
      {
        "family": "Sastry",
        "given": "Girish"
      },
      {
        "family": "Schmidt",
        "given": "Heather"
      },
      {
        "family": "Schnurr",
        "given": "David"
      },
      {
        "family": "Schulman",
        "given": "John"
      },
      {
        "family": "Selsam",
        "given": "Daniel"
      },
      {
        "family": "Sheppard",
        "given": "Kyla"
      },
      {
        "family": "Sherbakov",
        "given": "Toki"
      },
      {
        "family": "Shieh",
        "given": "Jessica"
      },
      {
        "family": "Shoker",
        "given": "Sarah"
      },
      {
        "family": "Shyam",
        "given": "Pranav"
      },
      {
        "family": "Sidor",
        "given": "Szymon"
      },
      {
        "family": "Sigler",
        "given": "Eric"
      },
      {
        "family": "Simens",
        "given": "Maddie"
      },
      {
        "family": "Sitkin",
        "given": "Jordan"
      },
      {
        "family": "Slama",
        "given": "Katarina"
      },
      {
        "family": "Sohl",
        "given": "Ian"
      },
      {
        "family": "Sokolowsky",
        "given": "Benjamin"
      },
      {
        "family": "Song",
        "given": "Yang"
      },
      {
        "family": "Staudacher",
        "given": "Natalie"
      },
      {
        "family": "Such",
        "given": "Felipe Petroski"
      },
      {
        "family": "Summers",
        "given": "Natalie"
      },
      {
        "family": "Sutskever",
        "given": "Ilya"
      },
      {
        "family": "Tang",
        "given": "Jie"
      },
      {
        "family": "Tezak",
        "given": "Nikolas"
      },
      {
        "family": "Thompson",
        "given": "Madeleine B."
      },
      {
        "family": "Tillet",
        "given": "Phil"
      },
      {
        "family": "Tootoonchian",
        "given": "Amin"
      },
      {
        "family": "Tseng",
        "given": "Elizabeth"
      },
      {
        "family": "Tuggle",
        "given": "Preston"
      },
      {
        "family": "Turley",
        "given": "Nick"
      },
      {
        "family": "Tworek",
        "given": "Jerry"
      },
      {
        "family": "Uribe",
        "given": "Juan Felipe Cerón"
      },
      {
        "family": "Vallone",
        "given": "Andrea"
      },
      {
        "family": "Vijayvergiya",
        "given": "Arun"
      },
      {
        "family": "Voss",
        "given": "Chelsea"
      },
      {
        "family": "Wainwright",
        "given": "Carroll"
      },
      {
        "family": "Wang",
        "given": "Justin Jay"
      },
      {
        "family": "Wang",
        "given": "Alvin"
      },
      {
        "family": "Wang",
        "given": "Ben"
      },
      {
        "family": "Ward",
        "given": "Jonathan"
      },
      {
        "family": "Wei",
        "given": "Jason"
      },
      {
        "family": "Weinmann",
        "given": "C. J."
      },
      {
        "family": "Welihinda",
        "given": "Akila"
      },
      {
        "family": "Welinder",
        "given": "Peter"
      },
      {
        "family": "Weng",
        "given": "Jiayi"
      },
      {
        "family": "Weng",
        "given": "Lilian"
      },
      {
        "family": "Wiethoff",
        "given": "Matt"
      },
      {
        "family": "Willner",
        "given": "Dave"
      },
      {
        "family": "Winter",
        "given": "Clemens"
      },
      {
        "family": "Wolrich",
        "given": "Samuel"
      },
      {
        "family": "Wong",
        "given": "Hannah"
      },
      {
        "family": "Workman",
        "given": "Lauren"
      },
      {
        "family": "Wu",
        "given": "Sherwin"
      },
      {
        "family": "Wu",
        "given": "Jeff"
      },
      {
        "family": "Wu",
        "given": "Michael"
      },
      {
        "family": "Xiao",
        "given": "Kai"
      },
      {
        "family": "Xu",
        "given": "Tao"
      },
      {
        "family": "Yoo",
        "given": "Sarah"
      },
      {
        "family": "Yu",
        "given": "Kevin"
      },
      {
        "family": "Yuan",
        "given": "Qiming"
      },
      {
        "family": "Zaremba",
        "given": "Wojciech"
      },
      {
        "family": "Zellers",
        "given": "Rowan"
      },
      {
        "family": "Zhang",
        "given": "Chong"
      },
      {
        "family": "Zhang",
        "given": "Marvin"
      },
      {
        "family": "Zhao",
        "given": "Shengjia"
      },
      {
        "family": "Zheng",
        "given": "Tianhao"
      },
      {
        "family": "Zhuang",
        "given": "Juntang"
      },
      {
        "family": "Zhuk",
        "given": "William"
      },
      {
        "family": "Zoph",
        "given": "Barret"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 14]]
    },
    "issued": {
      "date-parts": [["2024", 3, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/Y93LRX5E",
    "type": "article",
    "abstract": "Modern artificial intelligence (AI) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development.",
    "DOI": "10.48550/arXiv.2407.21783",
    "language": "en-US",
    "note": "arXiv:2407.21783 [cs]\nTLDR: It is found that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks, and performs competitively with the state-of-the-art on image, video, and speech recognition tasks.",
    "number": "arXiv:2407.21783",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "The Llama 3 Herd of Models",
    "URL": "http://arxiv.org/abs/2407.21783",
    "author": [
      {
        "family": "Dubey",
        "given": "Abhimanyu"
      },
      {
        "family": "Jauhri",
        "given": "Abhinav"
      },
      {
        "family": "Pandey",
        "given": "Abhinav"
      },
      {
        "family": "Kadian",
        "given": "Abhishek"
      },
      {
        "family": "Al-Dahle",
        "given": "Ahmad"
      },
      {
        "family": "Letman",
        "given": "Aiesha"
      },
      {
        "family": "Mathur",
        "given": "Akhil"
      },
      {
        "family": "Schelten",
        "given": "Alan"
      },
      {
        "family": "Yang",
        "given": "Amy"
      },
      {
        "family": "Fan",
        "given": "Angela"
      },
      {
        "family": "Goyal",
        "given": "Anirudh"
      },
      {
        "family": "Hartshorn",
        "given": "Anthony"
      },
      {
        "family": "Yang",
        "given": "Aobo"
      },
      {
        "family": "Mitra",
        "given": "Archi"
      },
      {
        "family": "Sravankumar",
        "given": "Archie"
      },
      {
        "family": "Korenev",
        "given": "Artem"
      },
      {
        "family": "Hinsvark",
        "given": "Arthur"
      },
      {
        "family": "Rao",
        "given": "Arun"
      },
      {
        "family": "Zhang",
        "given": "Aston"
      },
      {
        "family": "Rodriguez",
        "given": "Aurelien"
      },
      {
        "family": "Gregerson",
        "given": "Austen"
      },
      {
        "family": "Spataru",
        "given": "Ava"
      },
      {
        "family": "Roziere",
        "given": "Baptiste"
      },
      {
        "family": "Biron",
        "given": "Bethany"
      },
      {
        "family": "Tang",
        "given": "Binh"
      },
      {
        "family": "Chern",
        "given": "Bobbie"
      },
      {
        "family": "Caucheteux",
        "given": "Charlotte"
      },
      {
        "family": "Nayak",
        "given": "Chaya"
      },
      {
        "family": "Bi",
        "given": "Chloe"
      },
      {
        "family": "Marra",
        "given": "Chris"
      },
      {
        "family": "McConnell",
        "given": "Chris"
      },
      {
        "family": "Keller",
        "given": "Christian"
      },
      {
        "family": "Touret",
        "given": "Christophe"
      },
      {
        "family": "Wu",
        "given": "Chunyang"
      },
      {
        "family": "Wong",
        "given": "Corinne"
      },
      {
        "family": "Ferrer",
        "given": "Cristian Canton"
      },
      {
        "family": "Nikolaidis",
        "given": "Cyrus"
      },
      {
        "family": "Allonsius",
        "given": "Damien"
      },
      {
        "family": "Song",
        "given": "Daniel"
      },
      {
        "family": "Pintz",
        "given": "Danielle"
      },
      {
        "family": "Livshits",
        "given": "Danny"
      },
      {
        "family": "Esiobu",
        "given": "David"
      },
      {
        "family": "Choudhary",
        "given": "Dhruv"
      },
      {
        "family": "Mahajan",
        "given": "Dhruv"
      },
      {
        "family": "Garcia-Olano",
        "given": "Diego"
      },
      {
        "family": "Perino",
        "given": "Diego"
      },
      {
        "family": "Hupkes",
        "given": "Dieuwke"
      },
      {
        "family": "Lakomkin",
        "given": "Egor"
      },
      {
        "family": "AlBadawy",
        "given": "Ehab"
      },
      {
        "family": "Lobanova",
        "given": "Elina"
      },
      {
        "family": "Dinan",
        "given": "Emily"
      },
      {
        "family": "Smith",
        "given": "Eric Michael"
      },
      {
        "family": "Radenovic",
        "given": "Filip"
      },
      {
        "family": "Zhang",
        "given": "Frank"
      },
      {
        "family": "Synnaeve",
        "given": "Gabriel"
      },
      {
        "family": "Lee",
        "given": "Gabrielle"
      },
      {
        "family": "Anderson",
        "given": "Georgia Lewis"
      },
      {
        "family": "Nail",
        "given": "Graeme"
      },
      {
        "family": "Mialon",
        "given": "Gregoire"
      },
      {
        "family": "Pang",
        "given": "Guan"
      },
      {
        "family": "Cucurell",
        "given": "Guillem"
      },
      {
        "family": "Nguyen",
        "given": "Hailey"
      },
      {
        "family": "Korevaar",
        "given": "Hannah"
      },
      {
        "family": "Xu",
        "given": "Hu"
      },
      {
        "family": "Touvron",
        "given": "Hugo"
      },
      {
        "family": "Zarov",
        "given": "Iliyan"
      },
      {
        "family": "Ibarra",
        "given": "Imanol Arrieta"
      },
      {
        "family": "Kloumann",
        "given": "Isabel"
      },
      {
        "family": "Misra",
        "given": "Ishan"
      },
      {
        "family": "Evtimov",
        "given": "Ivan"
      },
      {
        "family": "Copet",
        "given": "Jade"
      },
      {
        "family": "Lee",
        "given": "Jaewon"
      },
      {
        "family": "Geffert",
        "given": "Jan"
      },
      {
        "family": "Vranes",
        "given": "Jana"
      },
      {
        "family": "Park",
        "given": "Jason"
      },
      {
        "family": "Mahadeokar",
        "given": "Jay"
      },
      {
        "family": "Shah",
        "given": "Jeet"
      },
      {
        "family": "Linde",
        "given": "Jelmer",
        "non-dropping-particle": "van der"
      },
      {
        "family": "Billock",
        "given": "Jennifer"
      },
      {
        "family": "Hong",
        "given": "Jenny"
      },
      {
        "family": "Lee",
        "given": "Jenya"
      },
      {
        "family": "Fu",
        "given": "Jeremy"
      },
      {
        "family": "Chi",
        "given": "Jianfeng"
      },
      {
        "family": "Huang",
        "given": "Jianyu"
      },
      {
        "family": "Liu",
        "given": "Jiawen"
      },
      {
        "family": "Wang",
        "given": "Jie"
      },
      {
        "family": "Yu",
        "given": "Jiecao"
      },
      {
        "family": "Bitton",
        "given": "Joanna"
      },
      {
        "family": "Spisak",
        "given": "Joe"
      },
      {
        "family": "Park",
        "given": "Jongsoo"
      },
      {
        "family": "Rocca",
        "given": "Joseph"
      },
      {
        "family": "Johnstun",
        "given": "Joshua"
      },
      {
        "family": "Saxe",
        "given": "Joshua"
      },
      {
        "family": "Jia",
        "given": "Junteng"
      },
      {
        "family": "Alwala",
        "given": "Kalyan Vasuden"
      },
      {
        "family": "Upasani",
        "given": "Kartikeya"
      },
      {
        "family": "Plawiak",
        "given": "Kate"
      },
      {
        "family": "Li",
        "given": "Ke"
      },
      {
        "family": "Heafield",
        "given": "Kenneth"
      },
      {
        "family": "Stone",
        "given": "Kevin"
      },
      {
        "family": "El-Arini",
        "given": "Khalid"
      },
      {
        "family": "Iyer",
        "given": "Krithika"
      },
      {
        "family": "Malik",
        "given": "Kshitiz"
      },
      {
        "family": "Chiu",
        "given": "Kuenley"
      },
      {
        "family": "Bhalla",
        "given": "Kunal"
      },
      {
        "family": "Rantala-Yeary",
        "given": "Lauren"
      },
      {
        "family": "Maaten",
        "given": "Laurens",
        "non-dropping-particle": "van der"
      },
      {
        "family": "Chen",
        "given": "Lawrence"
      },
      {
        "family": "Tan",
        "given": "Liang"
      },
      {
        "family": "Jenkins",
        "given": "Liz"
      },
      {
        "family": "Martin",
        "given": "Louis"
      },
      {
        "family": "Madaan",
        "given": "Lovish"
      },
      {
        "family": "Malo",
        "given": "Lubo"
      },
      {
        "family": "Blecher",
        "given": "Lukas"
      },
      {
        "family": "Landzaat",
        "given": "Lukas"
      },
      {
        "family": "Oliveira",
        "given": "Luke",
        "non-dropping-particle": "de"
      },
      {
        "family": "Muzzi",
        "given": "Madeline"
      },
      {
        "family": "Pasupuleti",
        "given": "Mahesh"
      },
      {
        "family": "Singh",
        "given": "Mannat"
      },
      {
        "family": "Paluri",
        "given": "Manohar"
      },
      {
        "family": "Kardas",
        "given": "Marcin"
      },
      {
        "family": "Oldham",
        "given": "Mathew"
      },
      {
        "family": "Rita",
        "given": "Mathieu"
      },
      {
        "family": "Pavlova",
        "given": "Maya"
      },
      {
        "family": "Kambadur",
        "given": "Melanie"
      },
      {
        "family": "Lewis",
        "given": "Mike"
      },
      {
        "family": "Si",
        "given": "Min"
      },
      {
        "family": "Singh",
        "given": "Mitesh Kumar"
      },
      {
        "family": "Hassan",
        "given": "Mona"
      },
      {
        "family": "Goyal",
        "given": "Naman"
      },
      {
        "family": "Torabi",
        "given": "Narjes"
      },
      {
        "family": "Bashlykov",
        "given": "Nikolay"
      },
      {
        "family": "Bogoychev",
        "given": "Nikolay"
      },
      {
        "family": "Chatterji",
        "given": "Niladri"
      },
      {
        "family": "Duchenne",
        "given": "Olivier"
      },
      {
        "family": "Çelebi",
        "given": "Onur"
      },
      {
        "family": "Alrassy",
        "given": "Patrick"
      },
      {
        "family": "Zhang",
        "given": "Pengchuan"
      },
      {
        "family": "Li",
        "given": "Pengwei"
      },
      {
        "family": "Vasic",
        "given": "Petar"
      },
      {
        "family": "Weng",
        "given": "Peter"
      },
      {
        "family": "Bhargava",
        "given": "Prajjwal"
      },
      {
        "family": "Dubal",
        "given": "Pratik"
      },
      {
        "family": "Krishnan",
        "given": "Praveen"
      },
      {
        "family": "Koura",
        "given": "Punit Singh"
      },
      {
        "family": "Xu",
        "given": "Puxin"
      },
      {
        "family": "He",
        "given": "Qing"
      },
      {
        "family": "Dong",
        "given": "Qingxiao"
      },
      {
        "family": "Srinivasan",
        "given": "Ragavan"
      },
      {
        "family": "Ganapathy",
        "given": "Raj"
      },
      {
        "family": "Calderer",
        "given": "Ramon"
      },
      {
        "family": "Cabral",
        "given": "Ricardo Silveira"
      },
      {
        "family": "Stojnic",
        "given": "Robert"
      },
      {
        "family": "Raileanu",
        "given": "Roberta"
      },
      {
        "family": "Girdhar",
        "given": "Rohit"
      },
      {
        "family": "Patel",
        "given": "Rohit"
      },
      {
        "family": "Sauvestre",
        "given": "Romain"
      },
      {
        "family": "Polidoro",
        "given": "Ronnie"
      },
      {
        "family": "Sumbaly",
        "given": "Roshan"
      },
      {
        "family": "Taylor",
        "given": "Ross"
      },
      {
        "family": "Silva",
        "given": "Ruan"
      },
      {
        "family": "Hou",
        "given": "Rui"
      },
      {
        "family": "Wang",
        "given": "Rui"
      },
      {
        "family": "Hosseini",
        "given": "Saghar"
      },
      {
        "family": "Chennabasappa",
        "given": "Sahana"
      },
      {
        "family": "Singh",
        "given": "Sanjay"
      },
      {
        "family": "Bell",
        "given": "Sean"
      },
      {
        "family": "Kim",
        "given": "Seohyun Sonia"
      },
      {
        "family": "Edunov",
        "given": "Sergey"
      },
      {
        "family": "Nie",
        "given": "Shaoliang"
      },
      {
        "family": "Narang",
        "given": "Sharan"
      },
      {
        "family": "Raparthy",
        "given": "Sharath"
      },
      {
        "family": "Shen",
        "given": "Sheng"
      },
      {
        "family": "Wan",
        "given": "Shengye"
      },
      {
        "family": "Bhosale",
        "given": "Shruti"
      },
      {
        "family": "Zhang",
        "given": "Shun"
      },
      {
        "family": "Vandenhende",
        "given": "Simon"
      },
      {
        "family": "Batra",
        "given": "Soumya"
      },
      {
        "family": "Whitman",
        "given": "Spencer"
      },
      {
        "family": "Sootla",
        "given": "Sten"
      },
      {
        "family": "Collot",
        "given": "Stephane"
      },
      {
        "family": "Gururangan",
        "given": "Suchin"
      },
      {
        "family": "Borodinsky",
        "given": "Sydney"
      },
      {
        "family": "Herman",
        "given": "Tamar"
      },
      {
        "family": "Fowler",
        "given": "Tara"
      },
      {
        "family": "Sheasha",
        "given": "Tarek"
      },
      {
        "family": "Georgiou",
        "given": "Thomas"
      },
      {
        "family": "Scialom",
        "given": "Thomas"
      },
      {
        "family": "Speckbacher",
        "given": "Tobias"
      },
      {
        "family": "Mihaylov",
        "given": "Todor"
      },
      {
        "family": "Xiao",
        "given": "Tong"
      },
      {
        "family": "Karn",
        "given": "Ujjwal"
      },
      {
        "family": "Goswami",
        "given": "Vedanuj"
      },
      {
        "family": "Gupta",
        "given": "Vibhor"
      },
      {
        "family": "Ramanathan",
        "given": "Vignesh"
      },
      {
        "family": "Kerkez",
        "given": "Viktor"
      },
      {
        "family": "Gonguet",
        "given": "Vincent"
      },
      {
        "family": "Do",
        "given": "Virginie"
      },
      {
        "family": "Vogeti",
        "given": "Vish"
      },
      {
        "family": "Petrovic",
        "given": "Vladan"
      },
      {
        "family": "Chu",
        "given": "Weiwei"
      },
      {
        "family": "Xiong",
        "given": "Wenhan"
      },
      {
        "family": "Fu",
        "given": "Wenyin"
      },
      {
        "family": "Meers",
        "given": "Whitney"
      },
      {
        "family": "Martinet",
        "given": "Xavier"
      },
      {
        "family": "Wang",
        "given": "Xiaodong"
      },
      {
        "family": "Tan",
        "given": "Xiaoqing Ellen"
      },
      {
        "family": "Xie",
        "given": "Xinfeng"
      },
      {
        "family": "Jia",
        "given": "Xuchao"
      },
      {
        "family": "Wang",
        "given": "Xuewei"
      },
      {
        "family": "Goldschlag",
        "given": "Yaelle"
      },
      {
        "family": "Gaur",
        "given": "Yashesh"
      },
      {
        "family": "Babaei",
        "given": "Yasmine"
      },
      {
        "family": "Wen",
        "given": "Yi"
      },
      {
        "family": "Song",
        "given": "Yiwen"
      },
      {
        "family": "Zhang",
        "given": "Yuchen"
      },
      {
        "family": "Li",
        "given": "Yue"
      },
      {
        "family": "Mao",
        "given": "Yuning"
      },
      {
        "family": "Coudert",
        "given": "Zacharie Delpierre"
      },
      {
        "family": "Yan",
        "given": "Zheng"
      },
      {
        "family": "Chen",
        "given": "Zhengxing"
      },
      {
        "family": "Papakipos",
        "given": "Zoe"
      },
      {
        "family": "Singh",
        "given": "Aaditya"
      },
      {
        "family": "Grattafiori",
        "given": "Aaron"
      },
      {
        "family": "Jain",
        "given": "Abha"
      },
      {
        "family": "Kelsey",
        "given": "Adam"
      },
      {
        "family": "Shajnfeld",
        "given": "Adam"
      },
      {
        "family": "Gangidi",
        "given": "Adithya"
      },
      {
        "family": "Victoria",
        "given": "Adolfo"
      },
      {
        "family": "Goldstand",
        "given": "Ahuva"
      },
      {
        "family": "Menon",
        "given": "Ajay"
      },
      {
        "family": "Sharma",
        "given": "Ajay"
      },
      {
        "family": "Boesenberg",
        "given": "Alex"
      },
      {
        "family": "Vaughan",
        "given": "Alex"
      },
      {
        "family": "Baevski",
        "given": "Alexei"
      },
      {
        "family": "Feinstein",
        "given": "Allie"
      },
      {
        "family": "Kallet",
        "given": "Amanda"
      },
      {
        "family": "Sangani",
        "given": "Amit"
      },
      {
        "family": "Yunus",
        "given": "Anam"
      },
      {
        "family": "Lupu",
        "given": "Andrei"
      },
      {
        "family": "Alvarado",
        "given": "Andres"
      },
      {
        "family": "Caples",
        "given": "Andrew"
      },
      {
        "family": "Gu",
        "given": "Andrew"
      },
      {
        "family": "Ho",
        "given": "Andrew"
      },
      {
        "family": "Poulton",
        "given": "Andrew"
      },
      {
        "family": "Ryan",
        "given": "Andrew"
      },
      {
        "family": "Ramchandani",
        "given": "Ankit"
      },
      {
        "family": "Franco",
        "given": "Annie"
      },
      {
        "family": "Saraf",
        "given": "Aparajita"
      },
      {
        "family": "Chowdhury",
        "given": "Arkabandhu"
      },
      {
        "family": "Gabriel",
        "given": "Ashley"
      },
      {
        "family": "Bharambe",
        "given": "Ashwin"
      },
      {
        "family": "Eisenman",
        "given": "Assaf"
      },
      {
        "family": "Yazdan",
        "given": "Azadeh"
      },
      {
        "family": "James",
        "given": "Beau"
      },
      {
        "family": "Maurer",
        "given": "Ben"
      },
      {
        "family": "Leonhardi",
        "given": "Benjamin"
      },
      {
        "family": "Huang",
        "given": "Bernie"
      },
      {
        "family": "Loyd",
        "given": "Beth"
      },
      {
        "family": "De Paola",
        "given": "Beto"
      },
      {
        "family": "Paranjape",
        "given": "Bhargavi"
      },
      {
        "family": "Liu",
        "given": "Bing"
      },
      {
        "family": "Wu",
        "given": "Bo"
      },
      {
        "family": "Ni",
        "given": "Boyu"
      },
      {
        "family": "Hancock",
        "given": "Braden"
      },
      {
        "family": "Wasti",
        "given": "Bram"
      },
      {
        "family": "Spence",
        "given": "Brandon"
      },
      {
        "family": "Stojkovic",
        "given": "Brani"
      },
      {
        "family": "Gamido",
        "given": "Brian"
      },
      {
        "family": "Montalvo",
        "given": "Britt"
      },
      {
        "family": "Parker",
        "given": "Carl"
      },
      {
        "family": "Burton",
        "given": "Carly"
      },
      {
        "family": "Mejia",
        "given": "Catalina"
      },
      {
        "family": "Wang",
        "given": "Changhan"
      },
      {
        "family": "Kim",
        "given": "Changkyu"
      },
      {
        "family": "Zhou",
        "given": "Chao"
      },
      {
        "family": "Hu",
        "given": "Chester"
      },
      {
        "family": "Chu",
        "given": "Ching-Hsiang"
      },
      {
        "family": "Cai",
        "given": "Chris"
      },
      {
        "family": "Tindal",
        "given": "Chris"
      },
      {
        "family": "Feichtenhofer",
        "given": "Christoph"
      },
      {
        "family": "Civin",
        "given": "Damon"
      },
      {
        "family": "Beaty",
        "given": "Dana"
      },
      {
        "family": "Kreymer",
        "given": "Daniel"
      },
      {
        "family": "Li",
        "given": "Daniel"
      },
      {
        "family": "Wyatt",
        "given": "Danny"
      },
      {
        "family": "Adkins",
        "given": "David"
      },
      {
        "family": "Xu",
        "given": "David"
      },
      {
        "family": "Testuggine",
        "given": "Davide"
      },
      {
        "family": "David",
        "given": "Delia"
      },
      {
        "family": "Parikh",
        "given": "Devi"
      },
      {
        "family": "Liskovich",
        "given": "Diana"
      },
      {
        "family": "Foss",
        "given": "Didem"
      },
      {
        "family": "Wang",
        "given": "Dingkang"
      },
      {
        "family": "Le",
        "given": "Duc"
      },
      {
        "family": "Holland",
        "given": "Dustin"
      },
      {
        "family": "Dowling",
        "given": "Edward"
      },
      {
        "family": "Jamil",
        "given": "Eissa"
      },
      {
        "family": "Montgomery",
        "given": "Elaine"
      },
      {
        "family": "Presani",
        "given": "Eleonora"
      },
      {
        "family": "Hahn",
        "given": "Emily"
      },
      {
        "family": "Wood",
        "given": "Emily"
      },
      {
        "family": "Brinkman",
        "given": "Erik"
      },
      {
        "family": "Arcaute",
        "given": "Esteban"
      },
      {
        "family": "Dunbar",
        "given": "Evan"
      },
      {
        "family": "Smothers",
        "given": "Evan"
      },
      {
        "family": "Sun",
        "given": "Fei"
      },
      {
        "family": "Kreuk",
        "given": "Felix"
      },
      {
        "family": "Tian",
        "given": "Feng"
      },
      {
        "family": "Ozgenel",
        "given": "Firat"
      },
      {
        "family": "Caggioni",
        "given": "Francesco"
      },
      {
        "family": "Guzmán",
        "given": "Francisco"
      },
      {
        "family": "Kanayet",
        "given": "Frank"
      },
      {
        "family": "Seide",
        "given": "Frank"
      },
      {
        "family": "Florez",
        "given": "Gabriela Medina"
      },
      {
        "family": "Schwarz",
        "given": "Gabriella"
      },
      {
        "family": "Badeer",
        "given": "Gada"
      },
      {
        "family": "Swee",
        "given": "Georgia"
      },
      {
        "family": "Halpern",
        "given": "Gil"
      },
      {
        "family": "Thattai",
        "given": "Govind"
      },
      {
        "family": "Herman",
        "given": "Grant"
      },
      {
        "family": "Sizov",
        "given": "Grigory"
      },
      {
        "family": "Guangyi",
        "given": ""
      },
      {
        "family": "Zhang",
        "given": ""
      },
      {
        "family": "Lakshminarayanan",
        "given": "Guna"
      },
      {
        "family": "Shojanazeri",
        "given": "Hamid"
      },
      {
        "family": "Zou",
        "given": "Han"
      },
      {
        "family": "Wang",
        "given": "Hannah"
      },
      {
        "family": "Zha",
        "given": "Hanwen"
      },
      {
        "family": "Habeeb",
        "given": "Haroun"
      },
      {
        "family": "Rudolph",
        "given": "Harrison"
      },
      {
        "family": "Suk",
        "given": "Helen"
      },
      {
        "family": "Aspegren",
        "given": "Henry"
      },
      {
        "family": "Goldman",
        "given": "Hunter"
      },
      {
        "family": "Molybog",
        "given": "Igor"
      },
      {
        "family": "Tufanov",
        "given": "Igor"
      },
      {
        "family": "Veliche",
        "given": "Irina-Elena"
      },
      {
        "family": "Gat",
        "given": "Itai"
      },
      {
        "family": "Weissman",
        "given": "Jake"
      },
      {
        "family": "Geboski",
        "given": "James"
      },
      {
        "family": "Kohli",
        "given": "James"
      },
      {
        "family": "Asher",
        "given": "Japhet"
      },
      {
        "family": "Gaya",
        "given": "Jean-Baptiste"
      },
      {
        "family": "Marcus",
        "given": "Jeff"
      },
      {
        "family": "Tang",
        "given": "Jeff"
      },
      {
        "family": "Chan",
        "given": "Jennifer"
      },
      {
        "family": "Zhen",
        "given": "Jenny"
      },
      {
        "family": "Reizenstein",
        "given": "Jeremy"
      },
      {
        "family": "Teboul",
        "given": "Jeremy"
      },
      {
        "family": "Zhong",
        "given": "Jessica"
      },
      {
        "family": "Jin",
        "given": "Jian"
      },
      {
        "family": "Yang",
        "given": "Jingyi"
      },
      {
        "family": "Cummings",
        "given": "Joe"
      },
      {
        "family": "Carvill",
        "given": "Jon"
      },
      {
        "family": "Shepard",
        "given": "Jon"
      },
      {
        "family": "McPhie",
        "given": "Jonathan"
      },
      {
        "family": "Torres",
        "given": "Jonathan"
      },
      {
        "family": "Ginsburg",
        "given": "Josh"
      },
      {
        "family": "Wang",
        "given": "Junjie"
      },
      {
        "family": "Wu",
        "given": "Kai"
      },
      {
        "family": "U",
        "given": "Kam Hou"
      },
      {
        "family": "Saxena",
        "given": "Karan"
      },
      {
        "family": "Prasad",
        "given": "Karthik"
      },
      {
        "family": "Khandelwal",
        "given": "Kartikay"
      },
      {
        "family": "Zand",
        "given": "Katayoun"
      },
      {
        "family": "Matosich",
        "given": "Kathy"
      },
      {
        "family": "Veeraraghavan",
        "given": "Kaushik"
      },
      {
        "family": "Michelena",
        "given": "Kelly"
      },
      {
        "family": "Li",
        "given": "Keqian"
      },
      {
        "family": "Huang",
        "given": "Kun"
      },
      {
        "family": "Chawla",
        "given": "Kunal"
      },
      {
        "family": "Lakhotia",
        "given": "Kushal"
      },
      {
        "family": "Huang",
        "given": "Kyle"
      },
      {
        "family": "Chen",
        "given": "Lailin"
      },
      {
        "family": "Garg",
        "given": "Lakshya"
      },
      {
        "family": "A",
        "given": "Lavender"
      },
      {
        "family": "Silva",
        "given": "Leandro"
      },
      {
        "family": "Bell",
        "given": "Lee"
      },
      {
        "family": "Zhang",
        "given": "Lei"
      },
      {
        "family": "Guo",
        "given": "Liangpeng"
      },
      {
        "family": "Yu",
        "given": "Licheng"
      },
      {
        "family": "Moshkovich",
        "given": "Liron"
      },
      {
        "family": "Wehrstedt",
        "given": "Luca"
      },
      {
        "family": "Khabsa",
        "given": "Madian"
      },
      {
        "family": "Avalani",
        "given": "Manav"
      },
      {
        "family": "Bhatt",
        "given": "Manish"
      },
      {
        "family": "Tsimpoukelli",
        "given": "Maria"
      },
      {
        "family": "Mankus",
        "given": "Martynas"
      },
      {
        "family": "Hasson",
        "given": "Matan"
      },
      {
        "family": "Lennie",
        "given": "Matthew"
      },
      {
        "family": "Reso",
        "given": "Matthias"
      },
      {
        "family": "Groshev",
        "given": "Maxim"
      },
      {
        "family": "Naumov",
        "given": "Maxim"
      },
      {
        "family": "Lathi",
        "given": "Maya"
      },
      {
        "family": "Keneally",
        "given": "Meghan"
      },
      {
        "family": "Seltzer",
        "given": "Michael L."
      },
      {
        "family": "Valko",
        "given": "Michal"
      },
      {
        "family": "Restrepo",
        "given": "Michelle"
      },
      {
        "family": "Patel",
        "given": "Mihir"
      },
      {
        "family": "Vyatskov",
        "given": "Mik"
      },
      {
        "family": "Samvelyan",
        "given": "Mikayel"
      },
      {
        "family": "Clark",
        "given": "Mike"
      },
      {
        "family": "Macey",
        "given": "Mike"
      },
      {
        "family": "Wang",
        "given": "Mike"
      },
      {
        "family": "Hermoso",
        "given": "Miquel Jubert"
      },
      {
        "family": "Metanat",
        "given": "Mo"
      },
      {
        "family": "Rastegari",
        "given": "Mohammad"
      },
      {
        "family": "Bansal",
        "given": "Munish"
      },
      {
        "family": "Santhanam",
        "given": "Nandhini"
      },
      {
        "family": "Parks",
        "given": "Natascha"
      },
      {
        "family": "White",
        "given": "Natasha"
      },
      {
        "family": "Bawa",
        "given": "Navyata"
      },
      {
        "family": "Singhal",
        "given": "Nayan"
      },
      {
        "family": "Egebo",
        "given": "Nick"
      },
      {
        "family": "Usunier",
        "given": "Nicolas"
      },
      {
        "family": "Laptev",
        "given": "Nikolay Pavlovich"
      },
      {
        "family": "Dong",
        "given": "Ning"
      },
      {
        "family": "Zhang",
        "given": "Ning"
      },
      {
        "family": "Cheng",
        "given": "Norman"
      },
      {
        "family": "Chernoguz",
        "given": "Oleg"
      },
      {
        "family": "Hart",
        "given": "Olivia"
      },
      {
        "family": "Salpekar",
        "given": "Omkar"
      },
      {
        "family": "Kalinli",
        "given": "Ozlem"
      },
      {
        "family": "Kent",
        "given": "Parkin"
      },
      {
        "family": "Parekh",
        "given": "Parth"
      },
      {
        "family": "Saab",
        "given": "Paul"
      },
      {
        "family": "Balaji",
        "given": "Pavan"
      },
      {
        "family": "Rittner",
        "given": "Pedro"
      },
      {
        "family": "Bontrager",
        "given": "Philip"
      },
      {
        "family": "Roux",
        "given": "Pierre"
      },
      {
        "family": "Dollar",
        "given": "Piotr"
      },
      {
        "family": "Zvyagina",
        "given": "Polina"
      },
      {
        "family": "Ratanchandani",
        "given": "Prashant"
      },
      {
        "family": "Yuvraj",
        "given": "Pritish"
      },
      {
        "family": "Liang",
        "given": "Qian"
      },
      {
        "family": "Alao",
        "given": "Rachad"
      },
      {
        "family": "Rodriguez",
        "given": "Rachel"
      },
      {
        "family": "Ayub",
        "given": "Rafi"
      },
      {
        "family": "Murthy",
        "given": "Raghotham"
      },
      {
        "family": "Nayani",
        "given": "Raghu"
      },
      {
        "family": "Mitra",
        "given": "Rahul"
      },
      {
        "family": "Li",
        "given": "Raymond"
      },
      {
        "family": "Hogan",
        "given": "Rebekkah"
      },
      {
        "family": "Battey",
        "given": "Robin"
      },
      {
        "family": "Wang",
        "given": "Rocky"
      },
      {
        "family": "Maheswari",
        "given": "Rohan"
      },
      {
        "family": "Howes",
        "given": "Russ"
      },
      {
        "family": "Rinott",
        "given": "Ruty"
      },
      {
        "family": "Bondu",
        "given": "Sai Jayesh"
      },
      {
        "family": "Datta",
        "given": "Samyak"
      },
      {
        "family": "Chugh",
        "given": "Sara"
      },
      {
        "family": "Hunt",
        "given": "Sara"
      },
      {
        "family": "Dhillon",
        "given": "Sargun"
      },
      {
        "family": "Sidorov",
        "given": "Sasha"
      },
      {
        "family": "Pan",
        "given": "Satadru"
      },
      {
        "family": "Verma",
        "given": "Saurabh"
      },
      {
        "family": "Yamamoto",
        "given": "Seiji"
      },
      {
        "family": "Ramaswamy",
        "given": "Sharadh"
      },
      {
        "family": "Lindsay",
        "given": "Shaun"
      },
      {
        "family": "Lindsay",
        "given": "Shaun"
      },
      {
        "family": "Feng",
        "given": "Sheng"
      },
      {
        "family": "Lin",
        "given": "Shenghao"
      },
      {
        "family": "Zha",
        "given": "Shengxin Cindy"
      },
      {
        "family": "Shankar",
        "given": "Shiva"
      },
      {
        "family": "Zhang",
        "given": "Shuqiang"
      },
      {
        "family": "Zhang",
        "given": "Shuqiang"
      },
      {
        "family": "Wang",
        "given": "Sinong"
      },
      {
        "family": "Agarwal",
        "given": "Sneha"
      },
      {
        "family": "Sajuyigbe",
        "given": "Soji"
      },
      {
        "family": "Chintala",
        "given": "Soumith"
      },
      {
        "family": "Max",
        "given": "Stephanie"
      },
      {
        "family": "Chen",
        "given": "Stephen"
      },
      {
        "family": "Kehoe",
        "given": "Steve"
      },
      {
        "family": "Satterfield",
        "given": "Steve"
      },
      {
        "family": "Govindaprasad",
        "given": "Sudarshan"
      },
      {
        "family": "Gupta",
        "given": "Sumit"
      },
      {
        "family": "Cho",
        "given": "Sungmin"
      },
      {
        "family": "Virk",
        "given": "Sunny"
      },
      {
        "family": "Subramanian",
        "given": "Suraj"
      },
      {
        "family": "Choudhury",
        "given": "Sy"
      },
      {
        "family": "Goldman",
        "given": "Sydney"
      },
      {
        "family": "Remez",
        "given": "Tal"
      },
      {
        "family": "Glaser",
        "given": "Tamar"
      },
      {
        "family": "Best",
        "given": "Tamara"
      },
      {
        "family": "Kohler",
        "given": "Thilo"
      },
      {
        "family": "Robinson",
        "given": "Thomas"
      },
      {
        "family": "Li",
        "given": "Tianhe"
      },
      {
        "family": "Zhang",
        "given": "Tianjun"
      },
      {
        "family": "Matthews",
        "given": "Tim"
      },
      {
        "family": "Chou",
        "given": "Timothy"
      },
      {
        "family": "Shaked",
        "given": "Tzook"
      },
      {
        "family": "Vontimitta",
        "given": "Varun"
      },
      {
        "family": "Ajayi",
        "given": "Victoria"
      },
      {
        "family": "Montanez",
        "given": "Victoria"
      },
      {
        "family": "Mohan",
        "given": "Vijai"
      },
      {
        "family": "Kumar",
        "given": "Vinay Satish"
      },
      {
        "family": "Mangla",
        "given": "Vishal"
      },
      {
        "family": "Ionescu",
        "given": "Vlad"
      },
      {
        "family": "Poenaru",
        "given": "Vlad"
      },
      {
        "family": "Mihailescu",
        "given": "Vlad Tiberiu"
      },
      {
        "family": "Ivanov",
        "given": "Vladimir"
      },
      {
        "family": "Li",
        "given": "Wei"
      },
      {
        "family": "Wang",
        "given": "Wenchen"
      },
      {
        "family": "Jiang",
        "given": "Wenwen"
      },
      {
        "family": "Bouaziz",
        "given": "Wes"
      },
      {
        "family": "Constable",
        "given": "Will"
      },
      {
        "family": "Tang",
        "given": "Xiaocheng"
      },
      {
        "family": "Wang",
        "given": "Xiaofang"
      },
      {
        "family": "Wu",
        "given": "Xiaojian"
      },
      {
        "family": "Wang",
        "given": "Xiaolan"
      },
      {
        "family": "Xia",
        "given": "Xide"
      },
      {
        "family": "Wu",
        "given": "Xilun"
      },
      {
        "family": "Gao",
        "given": "Xinbo"
      },
      {
        "family": "Chen",
        "given": "Yanjun"
      },
      {
        "family": "Hu",
        "given": "Ye"
      },
      {
        "family": "Jia",
        "given": "Ye"
      },
      {
        "family": "Qi",
        "given": "Ye"
      },
      {
        "family": "Li",
        "given": "Yenda"
      },
      {
        "family": "Zhang",
        "given": "Yilin"
      },
      {
        "family": "Zhang",
        "given": "Ying"
      },
      {
        "family": "Adi",
        "given": "Yossi"
      },
      {
        "family": "Nam",
        "given": "Youngjin"
      },
      {
        "family": "Yu",
        "given": ""
      },
      {
        "family": "Wang",
        "given": ""
      },
      {
        "family": "Hao",
        "given": "Yuchen"
      },
      {
        "family": "Qian",
        "given": "Yundi"
      },
      {
        "family": "He",
        "given": "Yuzi"
      },
      {
        "family": "Rait",
        "given": "Zach"
      },
      {
        "family": "DeVito",
        "given": "Zachary"
      },
      {
        "family": "Rosnbrick",
        "given": "Zef"
      },
      {
        "family": "Wen",
        "given": "Zhaoduo"
      },
      {
        "family": "Yang",
        "given": "Zhenyu"
      },
      {
        "family": "Zhao",
        "given": "Zhiwei"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 14]]
    },
    "issued": {
      "date-parts": [["2024", 7, 31]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/75QVLR5D",
    "type": "article",
    "abstract": "Large language models (LLMs) have revolutionized the field of artificial intelligence, enabling natural language processing tasks that were previously thought to be exclusive to humans. In this work, we introduce Qwen, the first installment of our large language model series. Qwen is a comprehensive language model series that encompasses distinct models with varying parameter counts. It includes Qwen, the base pretrained language models, and Qwen-Chat, the chat models finetuned with human alignment techniques. The base language models consistently demonstrate superior performance across a multitude of downstream tasks, and the chat models, particularly those trained using Reinforcement Learning from Human Feedback (RLHF), are highly competitive. The chat models possess advanced tool-use and planning capabilities for creating agent applications, showcasing impressive performance even when compared to bigger models on complex tasks like utilizing a code interpreter. Furthermore, we have developed coding-specialized models, Code-Qwen and Code-Qwen-Chat, as well as mathematics-focused models, Math-Qwen-Chat, which are built upon base language models. These models demonstrate significantly improved performance in comparison with open-source models, and slightly fall behind the proprietary models.",
    "DOI": "10.48550/arXiv.2309.16609",
    "note": "arXiv:2309.16609 [cs]",
    "number": "arXiv:2309.16609",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Qwen Technical Report",
    "URL": "http://arxiv.org/abs/2309.16609",
    "author": [
      {
        "family": "Bai",
        "given": "Jinze"
      },
      {
        "family": "Bai",
        "given": "Shuai"
      },
      {
        "family": "Chu",
        "given": "Yunfei"
      },
      {
        "family": "Cui",
        "given": "Zeyu"
      },
      {
        "family": "Dang",
        "given": "Kai"
      },
      {
        "family": "Deng",
        "given": "Xiaodong"
      },
      {
        "family": "Fan",
        "given": "Yang"
      },
      {
        "family": "Ge",
        "given": "Wenbin"
      },
      {
        "family": "Han",
        "given": "Yu"
      },
      {
        "family": "Huang",
        "given": "Fei"
      },
      {
        "family": "Hui",
        "given": "Binyuan"
      },
      {
        "family": "Ji",
        "given": "Luo"
      },
      {
        "family": "Li",
        "given": "Mei"
      },
      {
        "family": "Lin",
        "given": "Junyang"
      },
      {
        "family": "Lin",
        "given": "Runji"
      },
      {
        "family": "Liu",
        "given": "Dayiheng"
      },
      {
        "family": "Liu",
        "given": "Gao"
      },
      {
        "family": "Lu",
        "given": "Chengqiang"
      },
      {
        "family": "Lu",
        "given": "Keming"
      },
      {
        "family": "Ma",
        "given": "Jianxin"
      },
      {
        "family": "Men",
        "given": "Rui"
      },
      {
        "family": "Ren",
        "given": "Xingzhang"
      },
      {
        "family": "Ren",
        "given": "Xuancheng"
      },
      {
        "family": "Tan",
        "given": "Chuanqi"
      },
      {
        "family": "Tan",
        "given": "Sinan"
      },
      {
        "family": "Tu",
        "given": "Jianhong"
      },
      {
        "family": "Wang",
        "given": "Peng"
      },
      {
        "family": "Wang",
        "given": "Shijie"
      },
      {
        "family": "Wang",
        "given": "Wei"
      },
      {
        "family": "Wu",
        "given": "Shengguang"
      },
      {
        "family": "Xu",
        "given": "Benfeng"
      },
      {
        "family": "Xu",
        "given": "Jin"
      },
      {
        "family": "Yang",
        "given": "An"
      },
      {
        "family": "Yang",
        "given": "Hao"
      },
      {
        "family": "Yang",
        "given": "Jian"
      },
      {
        "family": "Yang",
        "given": "Shusheng"
      },
      {
        "family": "Yao",
        "given": "Yang"
      },
      {
        "family": "Yu",
        "given": "Bowen"
      },
      {
        "family": "Yuan",
        "given": "Hongyi"
      },
      {
        "family": "Yuan",
        "given": "Zheng"
      },
      {
        "family": "Zhang",
        "given": "Jianwei"
      },
      {
        "family": "Zhang",
        "given": "Xingxuan"
      },
      {
        "family": "Zhang",
        "given": "Yichang"
      },
      {
        "family": "Zhang",
        "given": "Zhenru"
      },
      {
        "family": "Zhou",
        "given": "Chang"
      },
      {
        "family": "Zhou",
        "given": "Jingren"
      },
      {
        "family": "Zhou",
        "given": "Xiaohuan"
      },
      {
        "family": "Zhu",
        "given": "Tianhang"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 14]]
    },
    "issued": {
      "date-parts": [["2023", 9, 28]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/HS6296SQ",
    "type": "article",
    "abstract": "This report introduces the Qwen2 series, the latest addition to our large language models and large multimodal models. We release a comprehensive suite of foundational and instruction-tuned language models, encompassing a parameter range from 0.5 to 72 billion, featuring dense models and a Mixture-of-Experts model. Qwen2 surpasses most prior open-weight models, including its predecessor Qwen1.5, and exhibits competitive performance relative to proprietary models across diverse benchmarks on language understanding, generation, multilingual proficiency, coding, mathematics, and reasoning. The flagship model, Qwen2-72B, showcases remarkable performance: 84.2 on MMLU, 37.9 on GPQA, 64.6 on HumanEval, 89.5 on GSM8K, and 82.4 on BBH as a base language model. The instruction-tuned variant, Qwen2-72B-Instruct, attains 9.1 on MT-Bench, 48.1 on Arena-Hard, and 35.7 on LiveCodeBench. Moreover, Qwen2 demonstrates robust multilingual capabilities, proficient in approximately 30 languages, spanning English, Chinese, Spanish, French, German, Arabic, Russian, Korean, Japanese, Thai, Vietnamese, and more, underscoring its versatility and global reach. To foster community innovation and accessibility, we have made the Qwen2 model weights openly available on Hugging Face and ModelScope, and the supplementary materials including example code on GitHub. These platforms also include resources for quantization, fine-tuning, and deployment, facilitating a wide range of applications and research endeavors.",
    "DOI": "10.48550/arXiv.2407.10671",
    "language": "en-US",
    "note": "arXiv:2407.10671 [cs]\nTLDR: A comprehensive suite of foundational and instruction-tuned language models, encompassing a parameter range from 0.5 to 72 billion, featuring dense models and a Mixture-of-Experts model, which surpasses most prior open-weight models and demonstrates robust multilingual capabilities.",
    "number": "arXiv:2407.10671",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Qwen2 Technical Report",
    "URL": "http://arxiv.org/abs/2407.10671",
    "author": [
      {
        "family": "Yang",
        "given": "An"
      },
      {
        "family": "Yang",
        "given": "Baosong"
      },
      {
        "family": "Hui",
        "given": "Binyuan"
      },
      {
        "family": "Zheng",
        "given": "Bo"
      },
      {
        "family": "Yu",
        "given": "Bowen"
      },
      {
        "family": "Zhou",
        "given": "Chang"
      },
      {
        "family": "Li",
        "given": "Chengpeng"
      },
      {
        "family": "Li",
        "given": "Chengyuan"
      },
      {
        "family": "Liu",
        "given": "Dayiheng"
      },
      {
        "family": "Huang",
        "given": "Fei"
      },
      {
        "family": "Dong",
        "given": "Guanting"
      },
      {
        "family": "Wei",
        "given": "Haoran"
      },
      {
        "family": "Lin",
        "given": "Huan"
      },
      {
        "family": "Tang",
        "given": "Jialong"
      },
      {
        "family": "Wang",
        "given": "Jialin"
      },
      {
        "family": "Yang",
        "given": "Jian"
      },
      {
        "family": "Tu",
        "given": "Jianhong"
      },
      {
        "family": "Zhang",
        "given": "Jianwei"
      },
      {
        "family": "Ma",
        "given": "Jianxin"
      },
      {
        "family": "Yang",
        "given": "Jianxin"
      },
      {
        "family": "Xu",
        "given": "Jin"
      },
      {
        "family": "Zhou",
        "given": "Jingren"
      },
      {
        "family": "Bai",
        "given": "Jinze"
      },
      {
        "family": "He",
        "given": "Jinzheng"
      },
      {
        "family": "Lin",
        "given": "Junyang"
      },
      {
        "family": "Dang",
        "given": "Kai"
      },
      {
        "family": "Lu",
        "given": "Keming"
      },
      {
        "family": "Chen",
        "given": "Keqin"
      },
      {
        "family": "Yang",
        "given": "Kexin"
      },
      {
        "family": "Li",
        "given": "Mei"
      },
      {
        "family": "Xue",
        "given": "Mingfeng"
      },
      {
        "family": "Ni",
        "given": "Na"
      },
      {
        "family": "Zhang",
        "given": "Pei"
      },
      {
        "family": "Wang",
        "given": "Peng"
      },
      {
        "family": "Peng",
        "given": "Ru"
      },
      {
        "family": "Men",
        "given": "Rui"
      },
      {
        "family": "Gao",
        "given": "Ruize"
      },
      {
        "family": "Lin",
        "given": "Runji"
      },
      {
        "family": "Wang",
        "given": "Shijie"
      },
      {
        "family": "Bai",
        "given": "Shuai"
      },
      {
        "family": "Tan",
        "given": "Sinan"
      },
      {
        "family": "Zhu",
        "given": "Tianhang"
      },
      {
        "family": "Li",
        "given": "Tianhao"
      },
      {
        "family": "Liu",
        "given": "Tianyu"
      },
      {
        "family": "Ge",
        "given": "Wenbin"
      },
      {
        "family": "Deng",
        "given": "Xiaodong"
      },
      {
        "family": "Zhou",
        "given": "Xiaohuan"
      },
      {
        "family": "Ren",
        "given": "Xingzhang"
      },
      {
        "family": "Zhang",
        "given": "Xinyu"
      },
      {
        "family": "Wei",
        "given": "Xipin"
      },
      {
        "family": "Ren",
        "given": "Xuancheng"
      },
      {
        "family": "Liu",
        "given": "Xuejing"
      },
      {
        "family": "Fan",
        "given": "Yang"
      },
      {
        "family": "Yao",
        "given": "Yang"
      },
      {
        "family": "Zhang",
        "given": "Yichang"
      },
      {
        "family": "Wan",
        "given": "Yu"
      },
      {
        "family": "Chu",
        "given": "Yunfei"
      },
      {
        "family": "Liu",
        "given": "Yuqiong"
      },
      {
        "family": "Cui",
        "given": "Zeyu"
      },
      {
        "family": "Zhang",
        "given": "Zhenru"
      },
      {
        "family": "Guo",
        "given": "Zhifang"
      },
      {
        "family": "Fan",
        "given": "Zhihao"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 14]]
    },
    "issued": {
      "date-parts": [["2024", 7, 17]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/5KM3V9LR",
    "type": "article",
    "abstract": "Large Language Models (LLMs) have demonstrated exceptional natural language understanding abilities and have excelled in a variety of natural language processing (NLP)tasks in recent years. Despite the fact that most LLMs are trained predominantly in English, multiple studies have demonstrated their comparative performance in many other languages. However, fundamental questions persist regarding how LLMs acquire their multi-lingual abilities and how performance varies across different languages. These inquiries are crucial for the study of LLMs since users and researchers often come from diverse language backgrounds, potentially influencing their utilization and interpretation of LLMs' results. In this work, we propose a systematic way of qualifying the performance disparities of LLMs under multilingual settings. We investigate the phenomenon of across-language generalizations in LLMs, wherein insufficient multi-lingual training data leads to advanced multi-lingual capabilities. To accomplish this, we employ a novel back-translation-based prompting method. The results show that GPT exhibits highly translating-like behaviour in multilingual settings.",
    "DOI": "10.48550/arXiv.2305.16339",
    "language": "en-US",
    "note": "arXiv:2305.16339 [cs]",
    "number": "arXiv:2305.16339",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Don't Trust ChatGPT when Your Question is not in English: A Study of Multilingual Abilities and Types of LLMs",
    "title-short": "Don't Trust ChatGPT when Your Question is not in English",
    "URL": "http://arxiv.org/abs/2305.16339",
    "author": [
      {
        "family": "Zhang",
        "given": "Xiang"
      },
      {
        "family": "Li",
        "given": "Senyu"
      },
      {
        "family": "Hauer",
        "given": "Bradley"
      },
      {
        "family": "Shi",
        "given": "Ning"
      },
      {
        "family": "Kondrak",
        "given": "Grzegorz"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 24]]
    },
    "issued": {
      "date-parts": [["2023", 10, 24]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/FSGEAQRR",
    "type": "article",
    "abstract": "Multilingual Language Models (MLLMs) exhibit robust cross-lingual transfer capabilities, or the ability to leverage information acquired in a source language and apply it to a target language. These capabilities find practical applications in well-established Natural Language Processing (NLP) tasks such as Named Entity Recognition (NER). This study aims to investigate the effectiveness of a source language when applied to a target language, particularly in the context of perturbing the input test set. We evaluate on 13 pairs of languages, each including one high-resource language (HRL) and one low-resource language (LRL) with a geographic, genetic, or borrowing relationship. We evaluate two well-known MLLMs--MBERT and XLM-R--on these pairs, in native LRL and cross-lingual transfer settings, in two tasks, under a set of different perturbations. Our findings indicate that NER cross-lingual transfer depends largely on the overlap of entity chunks. If a source and target language have more entities in common, the transfer ability is stronger. Models using cross-lingual transfer also appear to be somewhat more robust to certain perturbations of the input, perhaps indicating an ability to leverage stronger representations derived from the HRL. Our research provides valuable insights into cross-lingual transfer and its implications for NLP applications, and underscores the need to consider linguistic nuances and potential limitations when employing MLLMs across distinct languages.",
    "DOI": "10.48550/arXiv.2403.20056",
    "language": "en-US",
    "note": "arXiv:2403.20056 [cs]",
    "number": "arXiv:2403.20056",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Cross-Lingual Transfer Robustness to Lower-Resource Languages on Adversarial Datasets",
    "URL": "http://arxiv.org/abs/2403.20056",
    "author": [
      {
        "family": "Manafi",
        "given": "Shadi"
      },
      {
        "family": "Krishnaswamy",
        "given": "Nikhil"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 24]]
    },
    "issued": {
      "date-parts": [["2024", 3, 29]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/8VMKYS3J",
    "type": "article",
    "abstract": "Large language models (LLMs) have demonstrated multilingual capabilities; yet, they are mostly English-centric due to the imbalanced training corpora. Existing works leverage this phenomenon to improve their multilingual performances through translation, primarily on natural language processing (NLP) tasks. This work extends the evaluation from NLP tasks to real user queries and from English-centric LLMs to non-English-centric LLMs. While translation into English can help improve the performance of multilingual NLP tasks for English-centric LLMs, it may not be optimal for all scenarios. For culture-related tasks that need deep language understanding, prompting in the native language tends to be more promising as it better captures the nuances of culture and language. Our experiments reveal varied behaviors among different LLMs and tasks in the multilingual context. Therefore, we advocate for more comprehensive multilingual evaluation and more efforts toward developing multilingual LLMs beyond English-centric ones.",
    "DOI": "10.48550/arXiv.2403.10258",
    "language": "en-US",
    "note": "arXiv:2403.10258 [cs]\nTLDR: This work extends the evaluation from NLP tasks to real user queries and from English-centric LLMs to non-English-centric LLMs, revealing varied behaviors among different LLMs and tasks in the multilingual context.",
    "number": "arXiv:2403.10258",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Is Translation All You Need? A Study on Solving Multilingual Tasks with Large Language Models",
    "title-short": "Is Translation All You Need?",
    "URL": "http://arxiv.org/abs/2403.10258",
    "author": [
      {
        "family": "Liu",
        "given": "Chaoqun"
      },
      {
        "family": "Zhang",
        "given": "Wenxuan"
      },
      {
        "family": "Zhao",
        "given": "Yiran"
      },
      {
        "family": "Luu",
        "given": "Anh Tuan"
      },
      {
        "family": "Bing",
        "given": "Lidong"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 8, 24]]
    },
    "issued": {
      "date-parts": [["2024", 6, 20]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/W7WPFN3A",
    "type": "article",
    "abstract": "The rapid development of Large Language Models (LLMs) demonstrates remarkable multilingual capabilities in natural language processing, attracting global attention in both academia and industry. To mitigate potential discrimination and enhance the overall usability and accessibility for diverse language user groups, it is important for the development of language-fair technology. Despite the breakthroughs of LLMs, the investigation into the multilingual scenario remains insufficient, where a comprehensive survey to summarize recent approaches, developments, limitations, and potential solutions is desirable. To this end, we provide a survey with multiple perspectives on the utilization of LLMs in the multilingual scenario. We first rethink the transitions between previous and current research on pre-trained language models. Then we introduce several perspectives on the multilingualism of LLMs, including training and inference methods, model security, multi-domain with language culture, and usage of datasets. We also discuss the major challenges that arise in these aspects, along with possible solutions. Besides, we highlight future research directions that aim at further enhancing LLMs with multilingualism. The survey aims to help the research community address multilingual problems and provide a comprehensive understanding of the core concepts, key techniques, and latest developments in multilingual natural language processing based on LLMs.",
    "DOI": "10.48550/arXiv.2405.10936",
    "language": "en-US",
    "note": "arXiv:2405.10936 [cs]",
    "number": "arXiv:2405.10936",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "A Survey on Large Language Models with Multilingualism: Recent Advances and New Frontiers",
    "title-short": "A Survey on Large Language Models with Multilingualism",
    "URL": "http://arxiv.org/abs/2405.10936",
    "author": [
      {
        "family": "Huang",
        "given": "Kaiyu"
      },
      {
        "family": "Mo",
        "given": "Fengran"
      },
      {
        "family": "Li",
        "given": "Hongliang"
      },
      {
        "family": "Li",
        "given": "You"
      },
      {
        "family": "Zhang",
        "given": "Yuanchi"
      },
      {
        "family": "Yi",
        "given": "Weijian"
      },
      {
        "family": "Mao",
        "given": "Yulong"
      },
      {
        "family": "Liu",
        "given": "Jinchen"
      },
      {
        "family": "Xu",
        "given": "Yuzhuang"
      },
      {
        "family": "Xu",
        "given": "Jinan"
      },
      {
        "family": "Nie",
        "given": "Jian-Yun"
      },
      {
        "family": "Liu",
        "given": "Yang"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 10]]
    },
    "issued": {
      "date-parts": [["2024", 5, 17]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/VM22ACIW",
    "type": "article",
    "abstract": "Multilingual Large Language Models are capable of using powerful Large Language Models to handle and respond to queries in multiple languages, which achieves remarkable success in multilingual natural language processing tasks. Despite these breakthroughs, there still remains a lack of a comprehensive survey to summarize existing approaches and recent developments in this field. To this end, in this paper, we present a thorough review and provide a unified perspective to summarize the recent progress as well as emerging trends in multilingual large language models (MLLMs) literature. The contributions of this paper can be summarized: (1) First survey: to our knowledge, we take the first step and present a thorough review in MLLMs research field according to multi-lingual alignment; (2) New taxonomy: we offer a new and unified perspective to summarize the current progress of MLLMs; (3) New frontiers: we highlight several emerging frontiers and discuss the corresponding challenges; (4) Abundant resources: we collect abundant open-source resources, including relevant papers, data corpora, and leaderboards. We hope our work can provide the community with quick access and spur breakthrough research in MLLMs.",
    "DOI": "10.48550/arXiv.2404.04925",
    "note": "arXiv:2404.04925 [cs]",
    "number": "arXiv:2404.04925",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Multilingual Large Language Model: A Survey of Resources, Taxonomy and Frontiers",
    "title-short": "Multilingual Large Language Model",
    "URL": "http://arxiv.org/abs/2404.04925",
    "author": [
      {
        "family": "Qin",
        "given": "Libo"
      },
      {
        "family": "Chen",
        "given": "Qiguang"
      },
      {
        "family": "Zhou",
        "given": "Yuhang"
      },
      {
        "family": "Chen",
        "given": "Zhi"
      },
      {
        "family": "Li",
        "given": "Yinghui"
      },
      {
        "family": "Liao",
        "given": "Lizi"
      },
      {
        "family": "Li",
        "given": "Min"
      },
      {
        "family": "Che",
        "given": "Wanxiang"
      },
      {
        "family": "Yu",
        "given": "Philip S."
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 10]]
    },
    "issued": {
      "date-parts": [["2024", 4, 7]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/QLH8VR9W",
    "type": "article",
    "abstract": "The widespread adoption of cloud-based proprietary large language models (LLMs) has introduced significant challenges, including operational dependencies, privacy concerns, and the necessity of continuous internet connectivity. In this work, we introduce an LLMOps pipeline, \"LlamaDuo\", for the seamless migration of knowledge and abilities from service-oriented LLMs to smaller, locally manageable models. This pipeline is crucial for ensuring service continuity in the presence of operational failures, strict privacy policies, or offline requirements. Our LlamaDuo involves fine-tuning a small language model against the service LLM using a synthetic dataset generated by the latter. If the performance of the fine-tuned model falls short of expectations, it is enhanced by further fine-tuning with additional similar data created by the service LLM. This iterative process guarantees that the smaller model can eventually match or even surpass the service LLM's capabilities in specific downstream tasks, offering a practical and scalable solution for managing AI deployments in constrained environments. Extensive experiments with leading edge LLMs are conducted to demonstrate the effectiveness, adaptability, and affordability of LlamaDuo across various downstream tasks. Our pipeline implementation is available at https://github.com/deep-diver/llamaduo.",
    "DOI": "10.48550/arXiv.2408.13467",
    "language": "en-US",
    "note": "arXiv:2408.13467 [cs]\nTLDR: This work introduces an LLMOps pipeline,\"LlamaDuo\", for the seamless migration of knowledge and abilities from service-oriented LLMs to smaller, locally manageable models, offering a practical and scalable solution for managing AI deployments in constrained environments.",
    "number": "arXiv:2408.13467",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "LlamaDuo: LLMOps Pipeline for Seamless Migration from Service LLMs to Small-Scale Local LLMs",
    "title-short": "LlamaDuo",
    "URL": "http://arxiv.org/abs/2408.13467",
    "author": [
      {
        "family": "Park",
        "given": "Chansung"
      },
      {
        "family": "Jiang",
        "given": "Juyong"
      },
      {
        "family": "Wang",
        "given": "Fan"
      },
      {
        "family": "Paul",
        "given": "Sayak"
      },
      {
        "family": "Tang",
        "given": "Jing"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 11]]
    },
    "issued": {
      "date-parts": [["2024", 8, 28]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/7WSX57TP",
    "type": "article-journal",
    "container-title": "Advances in Neural Information Processing Systems",
    "journalAbbreviation": "Adv. Neur. In.",
    "language": "en",
    "page": "46595-46623",
    "source": "proceedings.neurips.cc",
    "title": "Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena",
    "URL": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html",
    "volume": "36",
    "author": [
      {
        "family": "Zheng",
        "given": "Lianmin"
      },
      {
        "family": "Chiang",
        "given": "Wei-Lin"
      },
      {
        "family": "Sheng",
        "given": "Ying"
      },
      {
        "family": "Zhuang",
        "given": "Siyuan"
      },
      {
        "family": "Wu",
        "given": "Zhanghao"
      },
      {
        "family": "Zhuang",
        "given": "Yonghao"
      },
      {
        "family": "Lin",
        "given": "Zi"
      },
      {
        "family": "Li",
        "given": "Zhuohan"
      },
      {
        "family": "Li",
        "given": "Dacheng"
      },
      {
        "family": "Xing",
        "given": "Eric"
      },
      {
        "family": "Zhang",
        "given": "Hao"
      },
      {
        "family": "Gonzalez",
        "given": "Joseph E."
      },
      {
        "family": "Stoica",
        "given": "Ion"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 11]]
    },
    "issued": {
      "date-parts": [["2023", 12, 15]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/LL73L7N4",
    "type": "article",
    "abstract": "Model-based evaluation is at the heart of successful model development -- as a reward model for training, and as a replacement for human evaluation. To train such evaluators, the standard approach is to collect a large amount of human preference judgments over model responses, which is costly and the data becomes stale as models improve. In this work, we present an approach that aims to im-prove evaluators without human annotations, using synthetic training data only. Starting from unlabeled instructions, our iterative self-improvement scheme generates contrasting model outputs and trains an LLM-as-a-Judge to produce reasoning traces and final judgments, repeating this training at each new iteration using the improved predictions. Without any labeled preference data, our Self-Taught Evaluator can improve a strong LLM (Llama3-70B-Instruct) from 75.4 to 88.3 (88.7 with majority vote) on RewardBench. This outperforms commonly used LLM judges such as GPT-4 and matches the performance of the top-performing reward models trained with labeled examples.",
    "DOI": "10.48550/arXiv.2408.02666",
    "language": "en-US",
    "note": "arXiv:2408.02666 [cs]\nTLDR: This work presents an approach that aims to prove evaluators without human annotations, using synthetic training data only, and can improve a strong LLM from 75.4 to 88.3 (88.7 with majority vote) on RewardBench.",
    "number": "arXiv:2408.02666",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Self-Taught Evaluators",
    "URL": "http://arxiv.org/abs/2408.02666",
    "author": [
      {
        "family": "Wang",
        "given": "Tianlu"
      },
      {
        "family": "Kulikov",
        "given": "Ilia"
      },
      {
        "family": "Golovneva",
        "given": "Olga"
      },
      {
        "family": "Yu",
        "given": "Ping"
      },
      {
        "family": "Yuan",
        "given": "Weizhe"
      },
      {
        "family": "Dwivedi-Yu",
        "given": "Jane"
      },
      {
        "family": "Pang",
        "given": "Richard Yuanzhe"
      },
      {
        "family": "Fazel-Zarandi",
        "given": "Maryam"
      },
      {
        "family": "Weston",
        "given": "Jason"
      },
      {
        "family": "Li",
        "given": "Xian"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 12]]
    },
    "issued": {
      "date-parts": [["2024", 8, 8]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/3ISVHCIA",
    "type": "article",
    "abstract": "Text data augmentation is an effective strategy for overcoming the challenge of limited sample sizes in many natural language processing (NLP) tasks. This challenge is especially prominent in the few-shot learning scenario, where the data in the target domain is generally much scarcer and of lowered quality. A natural and widely-used strategy to mitigate such challenges is to perform data augmentation to better capture the data invariance and increase the sample size. However, current text data augmentation methods either can't ensure the correct labeling of the generated data (lacking faithfulness) or can't ensure sufficient diversity in the generated data (lacking compactness), or both. Inspired by the recent success of large language models, especially the development of ChatGPT, which demonstrated improved language comprehension abilities, in this work, we propose a text data augmentation approach based on ChatGPT (named AugGPT). AugGPT rephrases each sentence in the training samples into multiple conceptually similar but semantically different samples. The augmented samples can then be used in downstream model training. Experiment results on few-shot learning text classification tasks show the superior performance of the proposed AugGPT approach over state-of-the-art text data augmentation methods in terms of testing accuracy and distribution of the augmented samples.",
    "DOI": "10.48550/arXiv.2302.13007",
    "language": "en-US",
    "note": "arXiv:2302.13007 [cs]\n<AI Smry>: Experimental results on few-shot learning text classiﬁcation tasks show the superior performance of the proposed ChatAug approach over state-of-the-art text data augmentation methods in terms of testing accuracy and distribution of the augmented samples.\nabstractTranslation: 文本数据增强是克服许多自然语言处理 （NLP） 任务中样本量有限的挑战的有效策略。这一挑战在小样本学习场景中尤为突出，因为目标域中的数据通常要稀缺得多，质量也较低。缓解此类挑战的一种自然且广泛使用的策略是执行数据增强以更好地捕获数据不变性并增加样本量。但是，当前的文本数据增强方法要么无法确保生成数据的正确标记（缺乏忠实度），要么无法确保生成数据具有足够的多样性（缺乏紧凑性），或者两者兼而有之。受最近大型语言模型成功的启发，特别是 ChatGPT 的发展，它展示了改进的语言理解能力，在这项工作中，我们提出了一种基于 ChatGPT 的文本数据增强方法（名为 AugGPT）。AugGPT 将训练样本中的每个句子改写为多个概念相似但语义不同的样本。然后，增强样本可用于下游模型训练。小样本学习文本分类任务的实验结果表明，在测试准确性和增强样本的分布方面，所提出的 AugGPT 方法的性能优于最先进的文本数据增强方法。\nTLDR: Experimental results on few-shot learning text classiﬁcation tasks show the superior performance of the proposed ChatAug approach over state-of-the-art text data augmentation methods in terms of testing accuracy and distribution of the augmented samples.",
    "number": "arXiv:2302.13007",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "AugGPT: Leveraging ChatGPT for Text Data Augmentation",
    "title-short": "AugGPT",
    "URL": "http://arxiv.org/abs/2302.13007",
    "author": [
      {
        "family": "Dai",
        "given": "Haixing"
      },
      {
        "family": "Liu",
        "given": "Zhengliang"
      },
      {
        "family": "Liao",
        "given": "Wenxiong"
      },
      {
        "family": "Huang",
        "given": "Xiaoke"
      },
      {
        "family": "Cao",
        "given": "Yihan"
      },
      {
        "family": "Wu",
        "given": "Zihao"
      },
      {
        "family": "Zhao",
        "given": "Lin"
      },
      {
        "family": "Xu",
        "given": "Shaochen"
      },
      {
        "family": "Liu",
        "given": "Wei"
      },
      {
        "family": "Liu",
        "given": "Ninghao"
      },
      {
        "family": "Li",
        "given": "Sheng"
      },
      {
        "family": "Zhu",
        "given": "Dajiang"
      },
      {
        "family": "Cai",
        "given": "Hongmin"
      },
      {
        "family": "Sun",
        "given": "Lichao"
      },
      {
        "family": "Li",
        "given": "Quanzheng"
      },
      {
        "family": "Shen",
        "given": "Dinggang"
      },
      {
        "family": "Liu",
        "given": "Tianming"
      },
      {
        "family": "Li",
        "given": "Xiang"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 12]]
    },
    "issued": {
      "date-parts": [["2023", 3, 20]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/46J2HNTW",
    "type": "article",
    "abstract": "*Data Synthesis* is a promising way to train a small model with very little labeled data. One approach for data synthesis is to leverage the rich knowledge from large language models to synthesize pseudo training examples for small models, making it possible to achieve both data and compute efficiency at the same time. However, a key challenge in data synthesis is that the synthesized dataset often suffers from a large distributional discrepancy from the *real task* data distribution. Thus, in this paper, we propose *Synthesis Step by Step* (**S3**), a data synthesis framework that shrinks this distribution gap by iteratively extrapolating the errors made by a small model trained on the synthesized dataset on a small real-world validation dataset using a large language model. Extensive experiments on multiple NLP tasks show that our approach improves the performance of a small model by reducing the gap between the synthetic dataset and the real data, resulting in significant improvement compared to several baselines: 9.48% improvement compared to ZeroGen and 2.73% compared to GoldGen, and at most 15.17% improvement compared to the small model trained on human-annotated data.",
    "DOI": "10.48550/arXiv.2310.13671",
    "language": "en-US",
    "note": "arXiv:2310.13671 [cs]\n<AI Smry>: This paper proposes *Synthesis Step by Step* (**S3**), a data synthesis framework that shrinks this distribution gap by iteratively extrapolating the errors made by a small model trained on the synthesized dataset on a small real-world validation dataset using a large language model.\nTLDR: This paper proposes *Synthesis Step by Step* (**S3**), a data synthesis framework that shrinks this distribution gap by iteratively extrapolating the errors made by a small model trained on the synthesized dataset on a small real-world validation dataset using a large language model.",
    "number": "arXiv:2310.13671",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Let's Synthesize Step by Step: Iterative Dataset Synthesis with Large Language Models by Extrapolating Errors from Small Models",
    "title-short": "Let's Synthesize Step by Step",
    "URL": "http://arxiv.org/abs/2310.13671",
    "author": [
      {
        "family": "Wang",
        "given": "Ruida"
      },
      {
        "family": "Zhou",
        "given": "Wangchunshu"
      },
      {
        "family": "Sachan",
        "given": "Mrinmaya"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 12]]
    },
    "issued": {
      "date-parts": [["2023", 10, 20]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/JNKNZ8GU",
    "type": "webpage",
    "abstract": "The success of AI models relies on the availability of large, diverse, and high-quality datasets, which can be challenging to obtain due to data scarcity, privacy concerns, and high costs. Synthetic data has emerged as a promising solution by generating artificial data that mimics real-world patterns. This paper provides an overview of synthetic data research, discussing its applications, challenges, and future directions. We present empirical evidence from prior art to demonstrate its effectiveness and highlight the importance of ensuring its factuality, fidelity, and unbiasedness. We emphasize the need for responsible use of synthetic data to build more powerful, inclusive, and trustworthy language models.",
    "container-title": "arXiv.org",
    "language": "en",
    "title": "Best Practices and Lessons Learned on Synthetic Data",
    "URL": "https://arxiv.org/abs/2404.07503v2",
    "author": [
      {
        "family": "Liu",
        "given": "Ruibo"
      },
      {
        "family": "Wei",
        "given": "Jerry"
      },
      {
        "family": "Liu",
        "given": "Fangyu"
      },
      {
        "family": "Si",
        "given": "Chenglei"
      },
      {
        "family": "Zhang",
        "given": "Yanzhe"
      },
      {
        "family": "Rao",
        "given": "Jinmeng"
      },
      {
        "family": "Zheng",
        "given": "Steven"
      },
      {
        "family": "Peng",
        "given": "Daiyi"
      },
      {
        "family": "Yang",
        "given": "Diyi"
      },
      {
        "family": "Zhou",
        "given": "Denny"
      },
      {
        "family": "Dai",
        "given": "Andrew M."
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 12]]
    },
    "issued": {
      "date-parts": [["2024", 4, 11]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/I7LYWAS6",
    "type": "article-journal",
    "container-title": "Advances in Neural Information Processing Systems",
    "journalAbbreviation": "Adv. Neur. In.",
    "language": "en",
    "page": "55006-55021",
    "source": "proceedings.neurips.cc",
    "title": "LIMA: Less Is More for Alignment",
    "title-short": "LIMA",
    "URL": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/ac662d74829e4407ce1d126477f4a03a-Abstract-Conference.html",
    "volume": "36",
    "author": [
      {
        "family": "Zhou",
        "given": "Chunting"
      },
      {
        "family": "Liu",
        "given": "Pengfei"
      },
      {
        "family": "Xu",
        "given": "Puxin"
      },
      {
        "family": "Iyer",
        "given": "Srinivasan"
      },
      {
        "family": "Sun",
        "given": "Jiao"
      },
      {
        "family": "Mao",
        "given": "Yuning"
      },
      {
        "family": "Ma",
        "given": "Xuezhe"
      },
      {
        "family": "Efrat",
        "given": "Avia"
      },
      {
        "family": "Yu",
        "given": "Ping"
      },
      {
        "family": "Yu",
        "given": "Lili"
      },
      {
        "family": "Zhang",
        "given": "Susan"
      },
      {
        "family": "Ghosh",
        "given": "Gargi"
      },
      {
        "family": "Lewis",
        "given": "Mike"
      },
      {
        "family": "Zettlemoyer",
        "given": "Luke"
      },
      {
        "family": "Levy",
        "given": "Omer"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 13]]
    },
    "issued": {
      "date-parts": [["2023", 12, 15]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/3T3DP369",
    "type": "article",
    "abstract": "In the realm of Large Language Models (LLMs), the balance between instruction data quality and quantity is a focal point. Recognizing this, we introduce a self-guided methodology for LLMs to autonomously discern and select cherry samples from open-source datasets, effectively minimizing manual curation and potential cost for instruction tuning an LLM. Our key innovation, the Instruction-Following Difficulty (IFD) metric, emerges as a pivotal metric to identify discrepancies between a model's expected responses and its intrinsic generation capability. Through the application of IFD, cherry samples can be pinpointed, leading to a marked uptick in model training efficiency. Empirical validations on datasets like Alpaca and WizardLM underpin our findings; with a mere $10\\%$ of original data input, our strategy showcases improved results. This synthesis of self-guided cherry-picking and the IFD metric signifies a transformative leap in the instruction tuning of LLMs, promising both efficiency and resource-conscious advancements. Codes, data, and models are available: https://github.com/tianyi-lab/Cherry_LLM",
    "DOI": "10.48550/arXiv.2308.12032",
    "language": "en-US",
    "note": "arXiv:2308.12032 [cs]\n<AI Smry>: This work introduces a self-guided methodology for LLMs to autonomously discern and select cherry samples from open-source datasets, effectively minimizing manual curation and potential cost for instruction tuning an LLM.\nTLDR: This work introduces a self-guided methodology for LLMs to autonomously discern and select cherry samples from open-source datasets, effectively minimizing manual curation and potential cost for instruction tuning an LLM.",
    "number": "arXiv:2308.12032",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning",
    "title-short": "From Quantity to Quality",
    "URL": "http://arxiv.org/abs/2308.12032",
    "author": [
      {
        "family": "Li",
        "given": "Ming"
      },
      {
        "family": "Zhang",
        "given": "Yong"
      },
      {
        "family": "Li",
        "given": "Zhitao"
      },
      {
        "family": "Chen",
        "given": "Jiuhai"
      },
      {
        "family": "Chen",
        "given": "Lichang"
      },
      {
        "family": "Cheng",
        "given": "Ning"
      },
      {
        "family": "Wang",
        "given": "Jianzong"
      },
      {
        "family": "Zhou",
        "given": "Tianyi"
      },
      {
        "family": "Xiao",
        "given": "Jing"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 13]]
    },
    "issued": {
      "date-parts": [["2024", 4, 5]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/8MLYTPCQ",
    "type": "article",
    "abstract": "Pretrained large language models (LLMs) are currently state-of-the-art for solving the vast majority of natural language processing tasks. While many real-world applications still require fine-tuning to reach satisfactory levels of performance, many of them are in the low-data regime, making fine-tuning challenging. To address this, we propose LLM2LLM, a targeted and iterative data augmentation strategy that uses a teacher LLM to enhance a small seed dataset by augmenting additional data that can be used for fine-tuning on a specific task. LLM2LLM (1) fine-tunes a baseline student LLM on the initial seed data, (2) evaluates and extracts data points that the model gets wrong, and (3) uses a teacher LLM to generate synthetic data based on these incorrect data points, which are then added back into the training data. This approach amplifies the signal from incorrectly predicted data points by the LLM during training and reintegrates them into the dataset to focus on more challenging examples for the LLM. Our results show that LLM2LLM significantly enhances the performance of LLMs in the low-data regime, outperforming both traditional fine-tuning and other data augmentation baselines. LLM2LLM reduces the dependence on labor-intensive data curation and paves the way for more scalable and performant LLM solutions, allowing us to tackle data-constrained domains and tasks. We achieve improvements up to 24.2% on the GSM8K dataset, 32.6% on CaseHOLD, 32.0% on SNIPS, 52.6% on TREC and 39.8% on SST-2 over regular fine-tuning in the low-data regime using a Llama-2-7B student model. Our code is available at https://github.com/SqueezeAILab/LLM2LLM .",
    "DOI": "10.48550/arXiv.2403.15042",
    "language": "en-US",
    "note": "arXiv:2403.15042 [cs]\n<AI Smry>: This work proposes LLM2LLM, a targeted and iterative data augmentation strategy that uses a teacher LLM to enhance a small seed dataset by augmenting additional data that can be used for fine-tuning on a specific task.\nTLDR: 这项工作提出了 LLM2LLM，这是一种有针对性的迭代数据增强策略，它使用教师 LLM 通过增强可用于微调特定任务的额外数据来增强小型种子数据集。",
    "number": "arXiv:2403.15042",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "LLM2LLM: Boosting LLMs with Novel Iterative Data Enhancement",
    "title-short": "LLM2LLM",
    "URL": "http://arxiv.org/abs/2403.15042",
    "author": [
      {
        "family": "Lee",
        "given": "Nicholas"
      },
      {
        "family": "Wattanawong",
        "given": "Thanakul"
      },
      {
        "family": "Kim",
        "given": "Sehoon"
      },
      {
        "family": "Mangalam",
        "given": "Karttikeya"
      },
      {
        "family": "Shen",
        "given": "Sheng"
      },
      {
        "family": "Anumanchipalli",
        "given": "Gopala"
      },
      {
        "family": "Mahoney",
        "given": "Michael W."
      },
      {
        "family": "Keutzer",
        "given": "Kurt"
      },
      {
        "family": "Gholami",
        "given": "Amir"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 16]]
    },
    "issued": {
      "date-parts": [["2024", 7, 13]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/HLQC3XED",
    "type": "article",
    "abstract": "Large Language Models (LLMs) have achieved significant advancements, however, the common learning paradigm treats LLMs as passive information repositories, neglecting their potential for active learning and alignment. Some approaches train LLMs using their own generated synthetic data, exploring the possibility of active alignment. However, there is still a huge gap between these one-time alignment methods and the continuous automatic alignment of humans. In this paper, we introduce \\textbf{I-SHEEP}, an \\textbf{I}terative \\textbf{S}elf-En\\textbf{H}anc\\textbf{E}m\\textbf{E}nt \\textbf{P}aradigm.This human-like paradigm enables LLMs to \\textbf{continuously self-align from scratch with nothing}. Compared to the one-time alignment method Dromedary \\cite{sun2023principledriven}, which refers to the first iteration in this paper, I-SHEEP can significantly enhance capacities on both Qwen and Llama models. I-SHEEP achieves a maximum relative improvement of 78.2\\% in the Alpaca Eval, 24.0\\% in the MT Bench, and an absolute increase of 8.88\\% in the IFEval accuracy over subsequent iterations in Qwen-1.5 72B model. Additionally, I-SHEEP surpasses the base model in various standard benchmark generation tasks, achieving an average improvement of 24.77\\% in code generation tasks, 12.04\\% in TrivialQA, and 20.29\\% in SQuAD. We also provide new insights based on the experiment results. Our codes, datasets, and models are available at \\textbf{https://anonymous.4open.science/r/I-SHEEP}.",
    "DOI": "10.48550/arXiv.2408.08072",
    "language": "en-US",
    "note": "arXiv:2408.08072 [cs]\nTLDR: Compared to the one-time alignment method Dromedary, which refers to the first iteration in this paper, I-SHEEP can significantly enhance capacities on both Qwen and Llama models and surpasses the base model in various standard benchmark generation tasks.",
    "number": "arXiv:2408.08072",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "I-SHEEP: Self-Alignment of LLM from Scratch through an Iterative Self-Enhancement Paradigm",
    "title-short": "I-SHEEP",
    "URL": "http://arxiv.org/abs/2408.08072",
    "author": [
      {
        "family": "Liang",
        "given": "Yiming"
      },
      {
        "family": "Zhang",
        "given": "Ge"
      },
      {
        "family": "Qu",
        "given": "Xingwei"
      },
      {
        "family": "Zheng",
        "given": "Tianyu"
      },
      {
        "family": "Guo",
        "given": "Jiawei"
      },
      {
        "family": "Du",
        "given": "Xinrun"
      },
      {
        "family": "Yang",
        "given": "Zhenzhu"
      },
      {
        "family": "Liu",
        "given": "Jiaheng"
      },
      {
        "family": "Lin",
        "given": "Chenghua"
      },
      {
        "family": "Ma",
        "given": "Lei"
      },
      {
        "family": "Huang",
        "given": "Wenhao"
      },
      {
        "family": "Zhang",
        "given": "Jiajun"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 16]]
    },
    "issued": {
      "date-parts": [["2024", 8, 27]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/4V69ZTQX",
    "type": "article",
    "abstract": "Fine-tuning on instruction data has been widely validated as an effective practice for implementing chat language models like ChatGPT. Scaling the diversity and quality of such data, although straightforward, stands a great chance of leading to improved performance. This paper aims to improve the upper bound of open-source models further. We first provide a systematically designed, diverse, informative, large-scale dataset of instructional conversations, UltraChat, which does not involve human queries. Our objective is to capture the breadth of interactions that a human might have with an AI assistant and employs a comprehensive framework to generate multi-turn conversation iteratively. UltraChat contains 1.5 million high-quality multi-turn dialogues and covers a wide range of topics and instructions. Our statistical analysis of UltraChat reveals its superiority in various key metrics, including scale, average length, diversity, coherence, etc., solidifying its position as a leading open-source dataset. Building upon UltraChat, we fine-tune a LLaMA model to create a powerful conversational model, UltraLLaMA. Our evaluations indicate that UltraLLaMA consistently outperforms other open-source models, including Vicuna, the previously recognized state-of-the-art open-source model. The dataset and the model will be publicly released\\footnote{\\url{https://github.com/thunlp/UltraChat}}.",
    "DOI": "10.48550/arXiv.2305.14233",
    "language": "en-US",
    "note": "arXiv:2305.14233 [cs]\nTLDR: This paper provides a systematically designed, diverse, informative, large-scale dataset of instructional conversations, UltraChat, and fine-tune a LLaMA model to create a powerful conversational model, UltraLLaMA, which consistently outperforms other open-source models, including Vicuna.",
    "number": "arXiv:2305.14233",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Enhancing Chat Language Models by Scaling High-quality Instructional Conversations",
    "URL": "http://arxiv.org/abs/2305.14233",
    "author": [
      {
        "family": "Ding",
        "given": "Ning"
      },
      {
        "family": "Chen",
        "given": "Yulin"
      },
      {
        "family": "Xu",
        "given": "Bokai"
      },
      {
        "family": "Qin",
        "given": "Yujia"
      },
      {
        "family": "Zheng",
        "given": "Zhi"
      },
      {
        "family": "Hu",
        "given": "Shengding"
      },
      {
        "family": "Liu",
        "given": "Zhiyuan"
      },
      {
        "family": "Sun",
        "given": "Maosong"
      },
      {
        "family": "Zhou",
        "given": "Bowen"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 16]]
    },
    "issued": {
      "date-parts": [["2023", 5, 23]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/QEUX8YXA",
    "type": "article",
    "abstract": "The prominent progress in generative models has significantly improved the reality of generated faces, bringing serious concerns to society. Since recent GAN-generated faces are in high realism, the forgery traces have become more imperceptible, increasing the forensics challenge. To combat GAN-generated faces, many countermeasures based on Convolutional Neural Networks (CNNs) have been spawned due to their strong learning ability. In this paper, we rethink this problem and explore a new approach based on forest models instead of CNNs. Specifically, we describe a simple and effective forest-based method set called {\\em ForensicsForest Family} to detect GAN-generate faces. The proposed ForensicsForest family is composed of three variants, which are {\\em ForensicsForest}, {\\em Hybrid ForensicsForest} and {\\em Divide-and-Conquer ForensicsForest} respectively. ForenscisForest is a newly proposed Multi-scale Hierarchical Cascade Forest, which takes semantic, frequency and biology features as input, hierarchically cascades different levels of features for authenticity prediction, and then employs a multi-scale ensemble scheme that can comprehensively consider different levels of information to improve the performance further. Based on ForensicsForest, we develop Hybrid ForensicsForest, an extended version that integrates the CNN layers into models, to further refine the effectiveness of augmented features. Moreover, to reduce the memory cost in training, we propose Divide-and-Conquer ForensicsForest, which can construct a forest model using only a portion of training samplings. In the training stage, we train several candidate forest models using the subsets of training samples. Then a ForensicsForest is assembled by picking the suitable components from these candidate forest models...",
    "DOI": "10.48550/arXiv.2308.00964",
    "language": "en-US",
    "note": "arXiv:2308.00964 [cs]",
    "number": "arXiv:2308.00964",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "ForensicsForest Family: A Series of Multi-scale Hierarchical Cascade Forests for Detecting GAN-generated Faces",
    "title-short": "ForensicsForest Family",
    "URL": "http://arxiv.org/abs/2308.00964",
    "author": [
      {
        "family": "Lu",
        "given": "Jiucui"
      },
      {
        "family": "Zhou",
        "given": "Jiaran"
      },
      {
        "family": "Dong",
        "given": "Junyu"
      },
      {
        "family": "Li",
        "given": "Bin"
      },
      {
        "family": "Lyu",
        "given": "Siwei"
      },
      {
        "family": "Li",
        "given": "Yuezun"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 18]]
    },
    "issued": {
      "date-parts": [["2024", 4, 26]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/LEDL2YQB",
    "type": "paper-conference",
    "event-title": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
    "language": "en",
    "page": "12105-12114",
    "source": "openaccess.thecvf.com",
    "title": "Learning on Gradients: Generalized Artifacts Representation for GAN-Generated Images Detection",
    "title-short": "Learning on Gradients",
    "URL": "https://openaccess.thecvf.com/content/CVPR2023/html/Tan_Learning_on_Gradients_Generalized_Artifacts_Representation_for_GAN-Generated_Images_Detection_CVPR_2023_paper.html",
    "author": [
      {
        "family": "Tan",
        "given": "Chuangchuang"
      },
      {
        "family": "Zhao",
        "given": "Yao"
      },
      {
        "family": "Wei",
        "given": "Shikui"
      },
      {
        "family": "Gu",
        "given": "Guanghua"
      },
      {
        "family": "Wei",
        "given": "Yunchao"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 18]]
    },
    "issued": {
      "date-parts": [["2023"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/ALRKN3CW",
    "type": "article",
    "abstract": "We introduce jina-embeddings-v3, a novel text embedding model with 570 million parameters, achieves state-of-the-art performance on multilingual data and long-context retrieval tasks, supporting context lengths of up to 8192 tokens. The model includes a set of task-specific Low-Rank Adaptation (LoRA) adapters to generate high-quality embeddings for query-document retrieval, clustering, classification, and text matching. Additionally, Matryoshka Representation Learning is integrated into the training process, allowing flexible truncation of embedding dimensions without compromising performance. Evaluation on the MTEB benchmark shows that jina-embeddings-v3 outperforms the latest proprietary embeddings from OpenAI and Cohere on English tasks, while achieving superior performance compared to multilingual-e5-large-instruct across all multilingual tasks.",
    "DOI": "10.48550/arXiv.2409.10173",
    "language": "en-US",
    "note": "arXiv:2409.10173 [cs]\nversion: 1",
    "number": "arXiv:2409.10173",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "jina-embeddings-v3: Multilingual Embeddings With Task LoRA",
    "title-short": "jina-embeddings-v3",
    "URL": "http://arxiv.org/abs/2409.10173",
    "author": [
      {
        "family": "Sturua",
        "given": "Saba"
      },
      {
        "family": "Mohr",
        "given": "Isabelle"
      },
      {
        "family": "Akram",
        "given": "Mohammad Kalim"
      },
      {
        "family": "Günther",
        "given": "Michael"
      },
      {
        "family": "Wang",
        "given": "Bo"
      },
      {
        "family": "Krimmel",
        "given": "Markus"
      },
      {
        "family": "Wang",
        "given": "Feng"
      },
      {
        "family": "Mastrapas",
        "given": "Georgios"
      },
      {
        "family": "Koukounas",
        "given": "Andreas"
      },
      {
        "family": "Koukounas",
        "given": "Andreas"
      },
      {
        "family": "Wang",
        "given": "Nan"
      },
      {
        "family": "Xiao",
        "given": "Han"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 19]]
    },
    "issued": {
      "date-parts": [["2024", 9, 16]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/YJCH4LMU",
    "type": "article",
    "abstract": "Selecting the best code solution from multiple generated ones is an essential task in code generation, which can be achieved by using some reliable validators (e.g., developer-written test cases) for assistance. Since reliable test cases are not always available and can be expensive to build in practice, researchers propose to automatically generate test cases to assess code solutions. However, when both code solutions and test cases are plausible and not reliable, selecting the best solution becomes challenging. Although some heuristic strategies have been proposed to tackle this problem, they lack a strong theoretical guarantee and it is still an open question whether an optimal selection strategy exists. Our work contributes in two ways. First, we show that within a Bayesian framework, the optimal selection strategy can be defined based on the posterior probability of the observed passing states between solutions and tests. The problem of identifying the best solution is then framed as an integer programming problem. Second, we propose an efficient approach for approximating this optimal (yet uncomputable) strategy, where the approximation error is bounded by the correctness of prior knowledge. We then incorporate effective prior knowledge to tailor code generation tasks. Both theoretical and empirical studies confirm that existing heuristics are limited in selecting the best solutions with plausible test cases. Our proposed approximated optimal strategy B4 significantly surpasses existing heuristics in selecting code solutions generated by large language models (LLMs) with LLM-generated tests, achieving a relative performance improvement by up to 50% over the strongest heuristic and 246% over the random selection in the most challenging scenarios. Our code is publicly available at https://github.com/ZJU-CTAG/B4.",
    "DOI": "10.48550/arXiv.2409.08692",
    "note": "arXiv:2409.08692 [cs]\nversion: 1",
    "number": "arXiv:2409.08692",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "B4: Towards Optimal Assessment of Plausible Code Solutions with Plausible Tests",
    "title-short": "B4",
    "URL": "http://arxiv.org/abs/2409.08692",
    "author": [
      {
        "family": "Chen",
        "given": "Mouxiang"
      },
      {
        "family": "Liu",
        "given": "Zhongxin"
      },
      {
        "family": "Tao",
        "given": "He"
      },
      {
        "family": "Hong",
        "given": "Yusu"
      },
      {
        "family": "Lo",
        "given": "David"
      },
      {
        "family": "Xia",
        "given": "Xin"
      },
      {
        "family": "Sun",
        "given": "Jianling"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 25]]
    },
    "issued": {
      "date-parts": [["2024", 9, 13]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/8EVTZBMQ",
    "type": "article",
    "abstract": "Fine-tuning is arguably the most straightforward way to tailor a pre-trained model (e.g., a foundation model) to downstream applications, but it also comes with the risk of losing valuable knowledge the model had learned in pre-training. For example, fine-tuning a pre-trained classifier capable of recognizing a large number of classes to master a subset of classes at hand is shown to drastically degrade the model's accuracy in the other classes it had previously learned. As such, it is hard to further use the fine-tuned model when it encounters classes beyond the fine-tuning data. In this paper, we systematically dissect the issue, aiming to answer the fundamental question, ''What has been damaged in the fine-tuned model?'' To our surprise, we find that the fine-tuned model neither forgets the relationship among the other classes nor degrades the features to recognize these classes. Instead, the fine-tuned model often produces more discriminative features for these other classes, even if they were missing during fine-tuning! {What really hurts the accuracy is the discrepant logit scales between the fine-tuning classes and the other classes}, implying that a simple post-processing calibration would bring back the pre-trained model's capability and at the same time unveil the feature improvement over all classes. We conduct an extensive empirical study to demonstrate the robustness of our findings and provide preliminary explanations underlying them, suggesting new directions for future theoretical analysis. Our code is available at https://github.com/OSU-MLB/Fine-Tuning-Is-Fine-If-Calibrated.",
    "DOI": "10.48550/arXiv.2409.16223",
    "note": "arXiv:2409.16223 [cs]",
    "number": "arXiv:2409.16223",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Fine-Tuning is Fine, if Calibrated",
    "URL": "http://arxiv.org/abs/2409.16223",
    "author": [
      {
        "family": "Mai",
        "given": "Zheda"
      },
      {
        "family": "Chowdhury",
        "given": "Arpita"
      },
      {
        "family": "Zhang",
        "given": "Ping"
      },
      {
        "family": "Tu",
        "given": "Cheng-Hao"
      },
      {
        "family": "Chen",
        "given": "Hong-You"
      },
      {
        "family": "Pahuja",
        "given": "Vardaan"
      },
      {
        "family": "Berger-Wolf",
        "given": "Tanya"
      },
      {
        "family": "Gao",
        "given": "Song"
      },
      {
        "family": "Stewart",
        "given": "Charles"
      },
      {
        "family": "Su",
        "given": "Yu"
      },
      {
        "family": "Chao",
        "given": "Wei-Lun"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 25]]
    },
    "issued": {
      "date-parts": [["2024", 9, 24]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/KZRH7FCY",
    "type": "article",
    "abstract": "Fine-tuning is arguably the most straightforward way to tailor a pre-trained model (e.g., a foundation model) to downstream applications, but it also comes with the risk of losing valuable knowledge the model had learned in pre-training. For example, fine-tuning a pre-trained classifier capable of recognizing a large number of classes to master a subset of classes at hand is shown to drastically degrade the model's accuracy in the other classes it had previously learned. As such, it is hard to further use the fine-tuned model when it encounters classes beyond the fine-tuning data. In this paper, we systematically dissect the issue, aiming to answer the fundamental question, ''What has been damaged in the fine-tuned model?'' To our surprise, we find that the fine-tuned model neither forgets the relationship among the other classes nor degrades the features to recognize these classes. Instead, the fine-tuned model often produces more discriminative features for these other classes, even if they were missing during fine-tuning! {What really hurts the accuracy is the discrepant logit scales between the fine-tuning classes and the other classes}, implying that a simple post-processing calibration would bring back the pre-trained model's capability and at the same time unveil the feature improvement over all classes. We conduct an extensive empirical study to demonstrate the robustness of our findings and provide preliminary explanations underlying them, suggesting new directions for future theoretical analysis. Our code is available at https://github.com/OSU-MLB/Fine-Tuning-Is-Fine-If-Calibrated.",
    "DOI": "10.48550/arXiv.2409.16223",
    "note": "arXiv:2409.16223 [cs]",
    "number": "arXiv:2409.16223",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Fine-Tuning is Fine, if Calibrated",
    "URL": "http://arxiv.org/abs/2409.16223",
    "author": [
      {
        "family": "Mai",
        "given": "Zheda"
      },
      {
        "family": "Chowdhury",
        "given": "Arpita"
      },
      {
        "family": "Zhang",
        "given": "Ping"
      },
      {
        "family": "Tu",
        "given": "Cheng-Hao"
      },
      {
        "family": "Chen",
        "given": "Hong-You"
      },
      {
        "family": "Pahuja",
        "given": "Vardaan"
      },
      {
        "family": "Berger-Wolf",
        "given": "Tanya"
      },
      {
        "family": "Gao",
        "given": "Song"
      },
      {
        "family": "Stewart",
        "given": "Charles"
      },
      {
        "family": "Su",
        "given": "Yu"
      },
      {
        "family": "Chao",
        "given": "Wei-Lun"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 25]]
    },
    "issued": {
      "date-parts": [["2024", 9, 24]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/ZX595C5W",
    "type": "article",
    "abstract": "Large language models (LLMs) have limitations in handling tasks that require real-time access to external APIs. While several benchmarks like ToolBench and APIGen have been developed to assess LLMs' API-use capabilities, they often suffer from issues such as lack of generalizability, limited multi-step reasoning coverage, and instability due to real-time API fluctuations. In this paper, we introduce SEAL, an end-to-end testbed designed to evaluate LLMs in real-world API usage. SEAL standardizes existing benchmarks, integrates an agent system for testing API retrieval and planning, and addresses the instability of real-time APIs by introducing a GPT-4-powered API simulator with caching for deterministic evaluations. Our testbed provides a comprehensive evaluation pipeline that covers API retrieval, API calls, and final responses, offering a reliable framework for structured performance comparison in diverse real-world scenarios. SEAL is publicly available, with ongoing updates for new benchmarks.",
    "DOI": "10.48550/arXiv.2409.15523",
    "language": "en-US",
    "note": "arXiv:2409.15523 [cs]",
    "number": "arXiv:2409.15523",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "SEAL: Suite for Evaluating API-use of LLMs",
    "title-short": "SEAL",
    "URL": "http://arxiv.org/abs/2409.15523",
    "author": [
      {
        "family": "Kim",
        "given": "Woojeong"
      },
      {
        "family": "Jagmohan",
        "given": "Ashish"
      },
      {
        "family": "Vempaty",
        "given": "Aditya"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 25]]
    },
    "issued": {
      "date-parts": [["2024", 9, 23]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/G7S3CPGT",
    "type": "article",
    "abstract": "Selecting the best code solution from multiple generated ones is an essential task in code generation, which can be achieved by using some reliable validators (e.g., developer-written test cases) for assistance. Since reliable test cases are not always available and can be expensive to build in practice, researchers propose to automatically generate test cases to assess code solutions. However, when both code solutions and test cases are plausible and not reliable, selecting the best solution becomes challenging. Although some heuristic strategies have been proposed to tackle this problem, they lack a strong theoretical guarantee and it is still an open question whether an optimal selection strategy exists. Our work contributes in two ways. First, we show that within a Bayesian framework, the optimal selection strategy can be defined based on the posterior probability of the observed passing states between solutions and tests. The problem of identifying the best solution is then framed as an integer programming problem. Second, we propose an efficient approach for approximating this optimal (yet uncomputable) strategy, where the approximation error is bounded by the correctness of prior knowledge. We then incorporate effective prior knowledge to tailor code generation tasks. Both theoretical and empirical studies confirm that existing heuristics are limited in selecting the best solutions with plausible test cases. Our proposed approximated optimal strategy B4 significantly surpasses existing heuristics in selecting code solutions generated by large language models (LLMs) with LLM-generated tests, achieving a relative performance improvement by up to 50% over the strongest heuristic and 246% over the random selection in the most challenging scenarios. Our code is publicly available at https://github.com/ZJU-CTAG/B4.",
    "DOI": "10.48550/arXiv.2409.08692",
    "language": "en-US",
    "note": "arXiv:2409.08692 [cs]\nTLDR: The proposed approximated optimal strategy B4 significantly surpasses existing heuristics in selecting code solutions generated by large language models with LLM-generated tests, achieving a relative performance improvement by up to 50% over the strongest heuristic and 246% over the random selection in the most challenging scenarios.",
    "number": "arXiv:2409.08692",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "B4: Towards Optimal Assessment of Plausible Code Solutions with Plausible Tests",
    "title-short": "B4",
    "URL": "http://arxiv.org/abs/2409.08692",
    "author": [
      {
        "family": "Chen",
        "given": "Mouxiang"
      },
      {
        "family": "Liu",
        "given": "Zhongxin"
      },
      {
        "family": "Tao",
        "given": "He"
      },
      {
        "family": "Hong",
        "given": "Yusu"
      },
      {
        "family": "Lo",
        "given": "David"
      },
      {
        "family": "Xia",
        "given": "Xin"
      },
      {
        "family": "Sun",
        "given": "Jianling"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 25]]
    },
    "issued": {
      "date-parts": [["2024", 9, 13]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/SLVLX7S5",
    "type": "article",
    "abstract": "Fine-tuning is arguably the most straightforward way to tailor a pre-trained model (e.g., a foundation model) to downstream applications, but it also comes with the risk of losing valuable knowledge the model had learned in pre-training. For example, fine-tuning a pre-trained classifier capable of recognizing a large number of classes to master a subset of classes at hand is shown to drastically degrade the model's accuracy in the other classes it had previously learned. As such, it is hard to further use the fine-tuned model when it encounters classes beyond the fine-tuning data. In this paper, we systematically dissect the issue, aiming to answer the fundamental question, ''What has been damaged in the fine-tuned model?'' To our surprise, we find that the fine-tuned model neither forgets the relationship among the other classes nor degrades the features to recognize these classes. Instead, the fine-tuned model often produces more discriminative features for these other classes, even if they were missing during fine-tuning! {What really hurts the accuracy is the discrepant logit scales between the fine-tuning classes and the other classes}, implying that a simple post-processing calibration would bring back the pre-trained model's capability and at the same time unveil the feature improvement over all classes. We conduct an extensive empirical study to demonstrate the robustness of our findings and provide preliminary explanations underlying them, suggesting new directions for future theoretical analysis. Our code is available at https://github.com/OSU-MLB/Fine-Tuning-Is-Fine-If-Calibrated.",
    "DOI": "10.48550/arXiv.2409.16223",
    "language": "en-US",
    "note": "arXiv:2409.16223 [cs]",
    "number": "arXiv:2409.16223",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Fine-Tuning is Fine, if Calibrated",
    "URL": "http://arxiv.org/abs/2409.16223",
    "author": [
      {
        "family": "Mai",
        "given": "Zheda"
      },
      {
        "family": "Chowdhury",
        "given": "Arpita"
      },
      {
        "family": "Zhang",
        "given": "Ping"
      },
      {
        "family": "Tu",
        "given": "Cheng-Hao"
      },
      {
        "family": "Chen",
        "given": "Hong-You"
      },
      {
        "family": "Pahuja",
        "given": "Vardaan"
      },
      {
        "family": "Berger-Wolf",
        "given": "Tanya"
      },
      {
        "family": "Gao",
        "given": "Song"
      },
      {
        "family": "Stewart",
        "given": "Charles"
      },
      {
        "family": "Su",
        "given": "Yu"
      },
      {
        "family": "Chao",
        "given": "Wei-Lun"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 25]]
    },
    "issued": {
      "date-parts": [["2024", 9, 24]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/ETXM4VDW",
    "type": "article",
    "abstract": "Data selection is of great significance in pre-training large language models, given the variation in quality within the large-scale available training corpora. To achieve this, researchers are currently investigating the use of data influence to measure the importance of data instances, $i.e.,$ a high influence score indicates that incorporating this instance to the training set is likely to enhance the model performance. Consequently, they select the top-$k$ instances with the highest scores. However, this approach has several limitations. (1) Computing the influence of all available data is time-consuming. (2) The selected data instances are not diverse enough, which may hinder the pre-trained model's ability to generalize effectively to various downstream tasks. In this paper, we introduce \\texttt{Quad}, a data selection approach that considers both quality and diversity by using data influence to achieve state-of-the-art pre-training results. In particular, noting that attention layers capture extensive semantic details, we have adapted the accelerated $iHVP$ computation methods for attention layers, enhancing our ability to evaluate the influence of data, $i.e.,$ its quality. For the diversity, \\texttt{Quad} clusters the dataset into similar data instances within each cluster and diverse instances across different clusters. For each cluster, if we opt to select data from it, we take some samples to evaluate the influence to prevent processing all instances. To determine which clusters to select, we utilize the classic Multi-Armed Bandit method, treating each cluster as an arm. This approach favors clusters with highly influential instances (ensuring high quality) or clusters that have been selected less frequently (ensuring diversity), thereby well balancing between quality and diversity.",
    "DOI": "10.48550/arXiv.2409.16986",
    "language": "en-US",
    "note": "arXiv:2409.16986 [cs]\nTLDR: A data selection approach that considers both quality and diversity by using data influence to achieve state-of-the-art pre-training results and adapted the accelerated iHVP computation methods for attention layers, enhancing the ability to evaluate the influence of data.",
    "number": "arXiv:2409.16986",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Harnessing Diversity for Important Data Selection in Pretraining Large Language Models",
    "URL": "http://arxiv.org/abs/2409.16986",
    "author": [
      {
        "family": "Zhang",
        "given": "Chi"
      },
      {
        "family": "Zhong",
        "given": "Huaping"
      },
      {
        "family": "Zhang",
        "given": "Kuan"
      },
      {
        "family": "Chai",
        "given": "Chengliang"
      },
      {
        "family": "Wang",
        "given": "Rui"
      },
      {
        "family": "Zhuang",
        "given": "Xinlin"
      },
      {
        "family": "Bai",
        "given": "Tianyi"
      },
      {
        "family": "Qiu",
        "given": "Jiantao"
      },
      {
        "family": "Cao",
        "given": "Lei"
      },
      {
        "family": "Yuan",
        "given": "Ye"
      },
      {
        "family": "Wang",
        "given": "Guoren"
      },
      {
        "family": "He",
        "given": "Conghui"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 26]]
    },
    "issued": {
      "date-parts": [["2024", 9, 25]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/N5A3IKRL",
    "type": "article",
    "abstract": "Instruction tuning is a vital step of training large language models (LLM), so how to enhance the effect of instruction tuning has received increased attention. Existing works indicate that the quality of the dataset is more crucial than the quantity during instruction tuning of LLM. Therefore, recently a lot of studies focus on exploring the methods of selecting high-quality subset from instruction datasets, aiming to reduce training costs and enhance the instruction-following capabilities of LLMs. This paper presents a comprehensive survey on data selection for LLM instruction tuning. Firstly, we introduce the wildly used instruction datasets. Then, we propose a new taxonomy of the data selection methods and provide a detailed introduction of recent advances,and the evaluation strategies and results of data selection methods are also elaborated in detail. Finally, we emphasize the open challenges and present new frontiers of this task.",
    "DOI": "10.48550/arXiv.2402.05123",
    "language": "en-US",
    "note": "arXiv:2402.05123 [cs]\nTLDR: A new taxonomy of the data selection methods is proposed and a detailed introduction of recent advances is provided, and the evaluation strategies and results of data selection methods are also elaborated in detail.",
    "number": "arXiv:2402.05123",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "A Survey on Data Selection for LLM Instruction Tuning",
    "URL": "http://arxiv.org/abs/2402.05123",
    "author": [
      {
        "family": "Wang",
        "given": "Jiahao"
      },
      {
        "family": "Zhang",
        "given": "Bolin"
      },
      {
        "family": "Du",
        "given": "Qianlong"
      },
      {
        "family": "Zhang",
        "given": "Jiajun"
      },
      {
        "family": "Chu",
        "given": "Dianhui"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 29]]
    },
    "issued": {
      "date-parts": [["2024", 2, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/7UWGGNPJ",
    "type": "article",
    "abstract": "Training large language models (LLMs) with open-domain instruction following data brings colossal success. However, manually creating such instruction data is very time-consuming and labor-intensive. Moreover, humans may struggle to produce high-complexity instructions. In this paper, we show an avenue for creating large amounts of instruction data with varying levels of complexity using LLM instead of humans. Starting with an initial set of instructions, we use our proposed Evol-Instruct to rewrite them step by step into more complex instructions. Then, we mix all generated instruction data to fine-tune LLaMA. We call the resulting model WizardLM. Human evaluations on a complexity-balanced test bed and Vicuna's testset show that instructions from Evol-Instruct are superior to human-created ones. By analyzing the human evaluation results of the high complexity part, we demonstrate that outputs from our WizardLM are preferred to outputs from OpenAI ChatGPT. In GPT-4 automatic evaluation, WizardLM achieves more than 90\\% capacity of ChatGPT on 17 out of 29 skills. Even though WizardLM still lags behind ChatGPT in some aspects, our findings suggest that fine-tuning with AI-evolved instructions is a promising direction for enhancing LLMs. Our code and data are public at https://github.com/nlpxucan/WizardLM",
    "DOI": "10.48550/arXiv.2304.12244",
    "language": "en-US",
    "note": "arXiv:2304.12244 [cs]\nTLDR: The findings suggest that fine-tuning with AI-evolved instructions is a promising direction for enhancing LLMs, and it is demonstrated that outputs from the authors' WizardLM are preferred to outputs from OpenAI ChatGPT.",
    "number": "arXiv:2304.12244",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "WizardLM: Empowering Large Language Models to Follow Complex Instructions",
    "title-short": "WizardLM",
    "URL": "http://arxiv.org/abs/2304.12244",
    "author": [
      {
        "family": "Xu",
        "given": "Can"
      },
      {
        "family": "Sun",
        "given": "Qingfeng"
      },
      {
        "family": "Zheng",
        "given": "Kai"
      },
      {
        "family": "Geng",
        "given": "Xiubo"
      },
      {
        "family": "Zhao",
        "given": "Pu"
      },
      {
        "family": "Feng",
        "given": "Jiazhan"
      },
      {
        "family": "Tao",
        "given": "Chongyang"
      },
      {
        "family": "Jiang",
        "given": "Daxin"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 29]]
    },
    "issued": {
      "date-parts": [["2023", 6, 10]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/5NTCZKU3",
    "type": "webpage",
    "abstract": "Large language models (LLMs) are initially pretrained for broad capabilities and then finetuned with instruction-following datasets to improve their performance in interacting with humans. Despite advances in finetuning, a standardized guideline for selecting high-quality datasets to optimize this process remains elusive. In this paper, we first propose InstructMining, an innovative method designed for automatically selecting premium instruction-following data for finetuning LLMs. Specifically, InstructMining utilizes natural language indicators as a measure of data quality, applying them to evaluate unseen datasets. During experimentation, we discover that double descent phenomenon exists in large language model finetuning. Based on this observation, we further leverage BlendSearch to help find the best subset among the entire dataset (i.e., 2,532 out of 100,000). Experiment results show that InstructMining-7B achieves state-of-the-art performance on two of the most popular benchmarks: LLM-as-a-judge and Huggingface OpenLLM leaderboard.",
    "container-title": "arXiv.org",
    "language": "en",
    "title": "Instruction Mining: Instruction Data Selection for Tuning Large Language Models",
    "title-short": "Instruction Mining",
    "URL": "https://arxiv.org/abs/2307.06290v3",
    "author": [
      {
        "family": "Cao",
        "given": "Yihan"
      },
      {
        "family": "Kang",
        "given": "Yanbin"
      },
      {
        "family": "Wang",
        "given": "Chi"
      },
      {
        "family": "Sun",
        "given": "Lichao"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 29]]
    },
    "issued": {
      "date-parts": [["2023", 7, 12]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/IGT2M8GV",
    "type": "article",
    "abstract": "Currently, the rapid development of computer vision and deep learning has enabled the creation or manipulation of high-fidelity facial images and videos via deep generative approaches. This technology, also known as deepfake, has achieved dramatic progress and become increasingly popular in social media. However, the technology can generate threats to personal privacy and national security by spreading misinformation. To diminish the risks of deepfake, it is desirable to develop powerful forgery detection methods to distinguish fake faces from real faces. This paper presents a comprehensive survey of recent deep learning-based approaches for facial forgery detection. We attempt to provide the reader with a deeper understanding of the current advances as well as the major challenges for deepfake detection based on deep learning. We present an overview of deepfake techniques and analyse the characteristics of various deepfake datasets. We then provide a systematic review of different categories of deepfake detection and state-of-the-art deepfake detection methods. The drawbacks of existing detection methods are analyzed, and future research directions are discussed to address the challenges in improving both the performance and generalization of deepfake detection.",
    "DOI": "10.48550/arXiv.2409.14289",
    "language": "en-US",
    "note": "arXiv:2409.14289 [cs]",
    "number": "arXiv:2409.14289",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Deep Learning Technology for Face Forgery Detection: A Survey",
    "title-short": "Deep Learning Technology for Face Forgery Detection",
    "URL": "http://arxiv.org/abs/2409.14289",
    "author": [
      {
        "family": "Ma",
        "given": "Lixia"
      },
      {
        "family": "Yang",
        "given": "Puning"
      },
      {
        "family": "Xu",
        "given": "Yuting"
      },
      {
        "family": "Yang",
        "given": "Ziming"
      },
      {
        "family": "Li",
        "given": "Peipei"
      },
      {
        "family": "Huang",
        "given": "Huaibo"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 29]]
    },
    "issued": {
      "date-parts": [["2024", 9, 23]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/F923JP94",
    "type": "article",
    "abstract": "With the rapid development of AI-generated content (AIGC) technology, the production of realistic fake facial images and videos that deceive human visual perception has become possible. Consequently, various face forgery detection techniques have been proposed to identify such fake facial content. However, evaluating the effectiveness and generalizability of these detection techniques remains a significant challenge. To address this, we have constructed a large-scale evaluation benchmark called DeepFaceGen, aimed at quantitatively assessing the effectiveness of face forgery detection and facilitating the iterative development of forgery detection technology. DeepFaceGen consists of 776,990 real face image/video samples and 773,812 face forgery image/video samples, generated using 34 mainstream face generation techniques. During the construction process, we carefully consider important factors such as content diversity, fairness across ethnicities, and availability of comprehensive labels, in order to ensure the versatility and convenience of DeepFaceGen. Subsequently, DeepFaceGen is employed in this study to evaluate and analyze the performance of 13 mainstream face forgery detection techniques from various perspectives. Through extensive experimental analysis, we derive significant findings and propose potential directions for future research. The code and dataset for DeepFaceGen are available at https://github.com/HengruiLou/DeepFaceGen.",
    "DOI": "10.48550/arXiv.2406.09181",
    "language": "en-US",
    "note": "arXiv:2406.09181 [cs]\nTLDR: A large-scale evaluation benchmark, aimed at quantitatively assessing the effectiveness of face forgery detection and facilitating the iterative development of forgery detection technology, is constructed, and DeepFaceGen is employed in this study to evaluate and analyze the performance of 13 mainstream face forgery detection techniques.",
    "number": "arXiv:2406.09181",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "A Large-scale Universal Evaluation Benchmark For Face Forgery Detection",
    "URL": "http://arxiv.org/abs/2406.09181",
    "author": [
      {
        "family": "Bei",
        "given": "Yijun"
      },
      {
        "family": "Lou",
        "given": "Hengrui"
      },
      {
        "family": "Geng",
        "given": "Jinsong"
      },
      {
        "family": "Liu",
        "given": "Erteng"
      },
      {
        "family": "Cheng",
        "given": "Lechao"
      },
      {
        "family": "Song",
        "given": "Jie"
      },
      {
        "family": "Song",
        "given": "Mingli"
      },
      {
        "family": "Feng",
        "given": "Zunlei"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 29]]
    },
    "issued": {
      "date-parts": [["2024", 6, 13]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/YLSBG8BI",
    "type": "article",
    "abstract": "This research addresses the challenge of developing a universal deepfake detector that can effectively identify unseen deepfake images despite limited training data. Existing frequency-based paradigms have relied on frequency-level artifacts introduced during the up-sampling in GAN pipelines to detect forgeries. However, the rapid advancements in synthesis technology have led to specific artifacts for each generation model. Consequently, these detectors have exhibited a lack of proficiency in learning the frequency domain and tend to overfit to the artifacts present in the training data, leading to suboptimal performance on unseen sources. To address this issue, we introduce a novel frequency-aware approach called FreqNet, centered around frequency domain learning, specifically designed to enhance the generalizability of deepfake detectors. Our method forces the detector to continuously focus on high-frequency information, exploiting high-frequency representation of features across spatial and channel dimensions. Additionally, we incorporate a straightforward frequency domain learning module to learn source-agnostic features. It involves convolutional layers applied to both the phase spectrum and amplitude spectrum between the Fast Fourier Transform (FFT) and Inverse Fast Fourier Transform (iFFT). Extensive experimentation involving 17 GANs demonstrates the effectiveness of our proposed method, showcasing state-of-the-art performance (+9.8\\%) while requiring fewer parameters. The code is available at {\\cred \\url{https://github.com/chuangchuangtan/FreqNet-DeepfakeDetection}}.",
    "DOI": "10.48550/arXiv.2403.07240",
    "language": "en-US",
    "note": "arXiv:2403.07240 [cs]\nTLDR: This research addresses the challenge of developing a universal deepfake detector that can effectively identify unseen deepfake images despite limited training data by introducing a novel frequency-aware approach called FreqNet, centered around frequency domain learning, specifically designed to enhance the generalizability of deepfake detectors.",
    "number": "arXiv:2403.07240",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Frequency-Aware Deepfake Detection: Improving Generalizability through Frequency Space Learning",
    "title-short": "Frequency-Aware Deepfake Detection",
    "URL": "http://arxiv.org/abs/2403.07240",
    "author": [
      {
        "family": "Tan",
        "given": "Chuangchuang"
      },
      {
        "family": "Zhao",
        "given": "Yao"
      },
      {
        "family": "Wei",
        "given": "Shikui"
      },
      {
        "family": "Gu",
        "given": "Guanghua"
      },
      {
        "family": "Liu",
        "given": "Ping"
      },
      {
        "family": "Wei",
        "given": "Yunchao"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 9, 29]]
    },
    "issued": {
      "date-parts": [["2024", 3, 11]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/IE27BAS8",
    "type": "webpage",
    "abstract": "An emerging method to cheaply improve a weaker language model is to finetune it on outputs from a stronger model, such as a proprietary system like ChatGPT (e.g., Alpaca, Self-Instruct, and others). This approach looks to cheaply imitate the proprietary model's capabilities using a weaker open-source model. In this work, we critically analyze this approach. We first finetune a series of LMs that imitate ChatGPT using varying base model sizes (1.5B--13B), data sources, and imitation data amounts (0.3M--150M tokens). We then evaluate the models using crowd raters and canonical NLP benchmarks. Initially, we were surprised by the output quality of our imitation models -- they appear far better at following instructions, and crowd workers rate their outputs as competitive with ChatGPT. However, when conducting more targeted automatic evaluations, we find that imitation models close little to none of the gap from the base LM to ChatGPT on tasks that are not heavily supported in the imitation data. We show that these performance discrepancies may slip past human raters because imitation models are adept at mimicking ChatGPT's style but not its factuality. Overall, we conclude that model imitation is a false promise: there exists a substantial capabilities gap between open and closed LMs that, with current methods, can only be bridged using an unwieldy amount of imitation data or by using more capable base LMs. In turn, we argue that the highest leverage action for improving open-source models is to tackle the difficult challenge of developing better base LMs, rather than taking the shortcut of imitating proprietary systems.",
    "container-title": "arXiv.org",
    "language": "en",
    "title": "The False Promise of Imitating Proprietary LLMs",
    "URL": "https://arxiv.org/abs/2305.15717v1",
    "author": [
      {
        "family": "Gudibande",
        "given": "Arnav"
      },
      {
        "family": "Wallace",
        "given": "Eric"
      },
      {
        "family": "Snell",
        "given": "Charlie"
      },
      {
        "family": "Geng",
        "given": "Xinyang"
      },
      {
        "family": "Liu",
        "given": "Hao"
      },
      {
        "family": "Abbeel",
        "given": "Pieter"
      },
      {
        "family": "Levine",
        "given": "Sergey"
      },
      {
        "family": "Song",
        "given": "Dawn"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 10, 9]]
    },
    "issued": {
      "date-parts": [["2023", 5, 25]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/BK7Q5X2J",
    "type": "webpage",
    "abstract": "To induce desired behaviors in large language models (LLMs) for interaction-driven tasks, the instruction-tuning stage typically trains LLMs on instruction-response pairs using the next-token prediction (NTP) loss. Previous work aiming to improve instruction-tuning performance often emphasizes the need for higher-quality supervised fine-tuning (SFT) datasets, which typically involves expensive data filtering with proprietary LLMs or labor-intensive data generation by human annotators. However, these approaches do not fully leverage the datasets' intrinsic properties, resulting in high computational and labor costs, thereby limiting scalability and performance gains. In this paper, we propose SFTMix, a novel recipe that elevates instruction-tuning performance beyond the conventional NTP paradigm, without the need for well-curated datasets. Observing that LLMs exhibit uneven confidence across the semantic representation space, we argue that examples with different confidence levels should play distinct roles during the instruction-tuning process. Based on this insight, SFTMix leverages training dynamics to identify examples with varying confidence levels, then applies a Mixup-based regularization to mitigate overfitting on confident examples while propagating supervision signals to improve learning on relatively unconfident ones. This approach enables SFTMix to significantly outperform NTP across a wide range of instruction-following and healthcare domain-specific SFT tasks, demonstrating its adaptability to diverse LLM families and scalability to datasets of any size. Comprehensive ablation studies further verify the robustness of SFTMix's design choices, underscoring its versatility in consistently enhancing performance across different LLMs and datasets in broader natural language processing applications.",
    "container-title": "arXiv.org",
    "language": "en",
    "title": "SFTMix: Elevating Language Model Instruction Tuning with Mixup Recipe",
    "title-short": "SFTMix",
    "URL": "https://arxiv.org/abs/2410.05248v1",
    "author": [
      {
        "family": "Xiao",
        "given": "Yuxin"
      },
      {
        "family": "Zhang",
        "given": "Shujian"
      },
      {
        "family": "Zhou",
        "given": "Wenxuan"
      },
      {
        "family": "Ghassemi",
        "given": "Marzyeh"
      },
      {
        "family": "Zhao",
        "given": "Sanqiang"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 10, 9]]
    },
    "issued": {
      "date-parts": [["2024", 10, 7]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/ACDX83CB",
    "type": "article",
    "abstract": "With significant efforts in recent studies, LLM-as-a-Judge has become a cost-effective alternative to human evaluation for assessing the text generation quality in a wide range of tasks. However, there still remains a reliability gap between LLM-as-a-Judge and human evaluation. One important reason is the lack of guided oracles in the evaluation process. Motivated by the role of reference pervasively used in classic text evaluation, we introduce RevisEval, a novel text generation evaluation paradigm via the response-adapted references. RevisEval is driven by the key observation that an ideal reference should maintain the necessary relevance to the response to be evaluated. Specifically, RevisEval leverages the text revision capabilities of large language models (LLMs) to adaptively revise the response, then treat the revised text as the reference (response-adapted reference) for the subsequent evaluation. Extensive experiments demonstrate that RevisEval outperforms traditional reference-free and reference-based evaluation paradigms that use LLM-as-a-Judge across NLG tasks and open-ended instruction-following tasks. More importantly, our response-adapted references can further boost the classical text metrics, e.g., BLEU and BERTScore, compared to traditional references and even rival the LLM-as-a-Judge. A detailed analysis is also conducted to confirm RevisEval's effectiveness in bias reduction, the impact of inference cost, and reference relevance.",
    "DOI": "10.48550/arXiv.2410.05193",
    "language": "en-US",
    "note": "arXiv:2410.05193 \nversion: 1\nTLDR: RevisEval is a novel text generation evaluation paradigm via the response-adapted references that outperforms traditional reference-free and reference-based evaluation paradigms that use LLM-as-a-Judge across NLG tasks and open-ended instruction-following tasks.",
    "number": "arXiv:2410.05193",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "RevisEval: Improving LLM-as-a-Judge via Response-Adapted References",
    "title-short": "RevisEval",
    "URL": "http://arxiv.org/abs/2410.05193",
    "author": [
      {
        "family": "Zhang",
        "given": "Qiyuan"
      },
      {
        "family": "Wang",
        "given": "Yufei"
      },
      {
        "family": "YU",
        "given": "Tiezheng"
      },
      {
        "family": "Jiang",
        "given": "Yuxin"
      },
      {
        "family": "Wu",
        "given": "Chuhan"
      },
      {
        "family": "Li",
        "given": "Liangyou"
      },
      {
        "family": "Wang",
        "given": "Yasheng"
      },
      {
        "family": "Jiang",
        "given": "Xin"
      },
      {
        "family": "Shang",
        "given": "Lifeng"
      },
      {
        "family": "Tang",
        "given": "Ruiming"
      },
      {
        "family": "Lyu",
        "given": "Fuyuan"
      },
      {
        "family": "Ma",
        "given": "Chen"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 10, 10]]
    },
    "issued": {
      "date-parts": [["2024", 10, 7]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/MXB7GKHK",
    "type": "article",
    "abstract": "Large \"instruction-tuned\" language models (i.e., finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks. Nevertheless, they depend heavily on human-written instruction data that is often limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model. We introduce Self-Instruct, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own generations. Our pipeline generates instructions, input, and output samples from a language model, then filters invalid or similar ones before using them to finetune the original model. Applying our method to the vanilla GPT3, we demonstrate a 33% absolute improvement over the original model on Super-NaturalInstructions, on par with the performance of InstructGPT-001, which was trained with private user data and human annotations. For further evaluation, we curate a set of expert-written instructions for novel tasks, and show through human evaluation that tuning GPT3 with Self-Instruct outperforms using existing public instruction datasets by a large margin, leaving only a 5% absolute gap behind InstructGPT-001. Self-Instruct provides an almost annotation-free method for aligning pre-trained language models with instructions, and we release our large synthetic dataset to facilitate future studies on instruction tuning. Our code and data are available at https://github.com/yizhongw/self-instruct.",
    "DOI": "10.48550/arXiv.2212.10560",
    "language": "en-US",
    "note": "arXiv:2212.10560\nTLDR: Self-Instruct is introduced, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own generations by generating instructions, input, and output samples from a language model, then filters invalid or similar ones before using them to finetune the original model.",
    "number": "arXiv:2212.10560",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
    "title-short": "Self-Instruct",
    "URL": "http://arxiv.org/abs/2212.10560",
    "author": [
      {
        "family": "Wang",
        "given": "Yizhong"
      },
      {
        "family": "Kordi",
        "given": "Yeganeh"
      },
      {
        "family": "Mishra",
        "given": "Swaroop"
      },
      {
        "family": "Liu",
        "given": "Alisa"
      },
      {
        "family": "Smith",
        "given": "Noah A."
      },
      {
        "family": "Khashabi",
        "given": "Daniel"
      },
      {
        "family": "Hajishirzi",
        "given": "Hannaneh"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 10, 10]]
    },
    "issued": {
      "date-parts": [["2023", 5, 25]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/BAXFCIKR",
    "type": "article",
    "abstract": "Data is a crucial element in large language model (LLM) alignment. Recent studies have explored using LLMs for efficient data collection. However, LLM-generated data often suffers from quality issues, with underrepresented or absent aspects and low-quality datapoints. To address these problems, we propose Data Advisor, an enhanced LLM-based method for generating data that takes into account the characteristics of the desired dataset. Starting from a set of pre-defined principles in hand, Data Advisor monitors the status of the generated data, identifies weaknesses in the current dataset, and advises the next iteration of data generation accordingly. Data Advisor can be easily integrated into existing data generation methods to enhance data quality and coverage. Experiments on safety alignment of three representative LLMs (i.e., Mistral, Llama2, and Falcon) demonstrate the effectiveness of Data Advisor in enhancing model safety against various fine-grained safety issues without sacrificing model utility.",
    "DOI": "10.48550/arXiv.2410.05269",
    "language": "en-US",
    "note": "arXiv:2410.05269\nTLDR: Data Advisor is proposed, an enhanced LLM-based method for generating data that takes into account the characteristics of the desired dataset and demonstrates the effectiveness of Data Advisor in enhancing model safety against various fine-grained safety issues without sacrificing model utility.",
    "number": "arXiv:2410.05269",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Data Advisor: Dynamic Data Curation for Safety Alignment of Large Language Models",
    "title-short": "Data Advisor",
    "URL": "http://arxiv.org/abs/2410.05269",
    "author": [
      {
        "family": "Wang",
        "given": "Fei"
      },
      {
        "family": "Mehrabi",
        "given": "Ninareh"
      },
      {
        "family": "Goyal",
        "given": "Palash"
      },
      {
        "family": "Gupta",
        "given": "Rahul"
      },
      {
        "family": "Chang",
        "given": "Kai-Wei"
      },
      {
        "family": "Galstyan",
        "given": "Aram"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 10, 10]]
    },
    "issued": {
      "date-parts": [["2024", 10, 7]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/44AZ6S64",
    "type": "article",
    "abstract": "Large language models (LLMs) have exhibited complex reasoning abilities by generating question rationales and demonstrated exceptional performance in natural language processing (NLP) tasks. However, these reasoning capabilities generally emerge in models with tens of billions of parameters, creating significant computational challenges for real-world deployment. Recent research has concentrated on improving open-source smaller models through knowledge distillation (KD) from commercial LLMs. Nevertheless, most of these studies rely solely on the responses from one single LLM as the gold rationale for training. In this paper, we introduce a novel Mistake-Aware Peer-Review Distillation (MAPD) approach: 1) Instead of merely obtaining gold rationales from teachers, our method asks teachers to identify and explain the student's mistakes, providing customized instruction learning data. 2) We design a simulated peer-review process between teacher LLMs, which selects only the generated rationales above the acceptance threshold. This reduces the chance of teachers guessing correctly with flawed rationale, improving instructional data quality. Comprehensive experiments and analysis on mathematical, commonsense, and logical reasoning tasks demonstrate the effectiveness of our method.",
    "DOI": "10.48550/arXiv.2410.03663",
    "language": "en-US",
    "note": "arXiv:2410.03663",
    "number": "arXiv:2410.03663",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Enhance Reasoning by Learning from Mistakes: Peer-Review Knowledge Distillation from Multiple Large Language Models",
    "title-short": "Enhance Reasoning by Learning from Mistakes",
    "URL": "http://arxiv.org/abs/2410.03663",
    "author": [
      {
        "family": "Li",
        "given": "Zhuochun"
      },
      {
        "family": "Ji",
        "given": "Yuelyu"
      },
      {
        "family": "Meng",
        "given": "Rui"
      },
      {
        "family": "He",
        "given": "Daqing"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 10, 10]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/VKTEYDRU",
    "type": "article",
    "abstract": "Understanding and accurately following instructions is critical for large language models (LLMs) to be effective across diverse tasks. In this work, we rigorously examine the key factors that enable models to generalize to unseen instructions, providing insights to guide the collection of data for instruction-tuning. Through controlled experiments, inspired by the Turing-complete Markov algorithm, we demonstrate that such generalization $\\textbf{only emerges}$ when training data is diversified enough across semantic domains. Our findings also reveal that merely diversifying within limited domains fails to ensure robust generalization. In contrast, cross-domain data diversification, even under constrained data budgets, significantly enhances a model's adaptability. We further extend our analysis to real-world scenarios, including fine-tuning of $\\textit{$\\textbf{specialist}$}$ and $\\textit{$\\textbf{generalist}$}$ models. In both cases, we demonstrate that 1) better performance can be achieved by increasing the diversity of an established dataset while keeping the data size constant, and 2) when scaling up the data, diversifying the semantics of instructions is more effective than simply increasing the quantity of similar data. Our research provides important insights for dataset collation, particularly when optimizing model performance by expanding training data for both specialist and generalist scenarios. We show that careful consideration of data diversification is key: training specialist models with data extending beyond their core domain leads to significant performance improvements, while generalist models benefit from diverse data mixtures that enhance their overall instruction-following capabilities across a wide range of applications. Our results highlight the critical role of strategic diversification and offer clear guidelines for improving data quality.",
    "DOI": "10.48550/arXiv.2410.04717",
    "language": "en-US",
    "note": "arXiv:2410.04717 \nversion: 1\nTLDR: It is shown that careful consideration of data diversification is key: training specialist models with data extending beyond their core domain leads to significant performance improvements, while generalist models benefit from diverse data mixtures that enhance their overall instruction- following capabilities across a wide range of applications.",
    "number": "arXiv:2410.04717",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "$\\textbf{Only-IF}$:Revealing the Decisive Effect of Instruction Diversity on Generalization",
    "title-short": "$\\textbf{Only-IF}$",
    "URL": "http://arxiv.org/abs/2410.04717",
    "author": [
      {
        "family": "Zhang",
        "given": "Dylan"
      },
      {
        "family": "Wang",
        "given": "Justin"
      },
      {
        "family": "Charton",
        "given": "Francois"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 10, 10]]
    },
    "issued": {
      "date-parts": [["2024", 10, 7]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/8Z2H6FRH",
    "type": "article",
    "abstract": "Transformer tends to overallocate attention to irrelevant context. In this work, we introduce Diff Transformer, which amplifies attention to the relevant context while canceling noise. Specifically, the differential attention mechanism calculates attention scores as the difference between two separate softmax attention maps. The subtraction cancels noise, promoting the emergence of sparse attention patterns. Experimental results on language modeling show that Diff Transformer outperforms Transformer in various settings of scaling up model size and training tokens. More intriguingly, it offers notable advantages in practical applications, such as long-context modeling, key information retrieval, hallucination mitigation, in-context learning, and reduction of activation outliers. By being less distracted by irrelevant context, Diff Transformer can mitigate hallucination in question answering and text summarization. For in-context learning, Diff Transformer not only enhances accuracy but is also more robust to order permutation, which was considered as a chronic robustness issue. The results position Diff Transformer as a highly effective and promising architecture to advance large language models.",
    "DOI": "10.48550/arXiv.2410.05258",
    "language": "en-US",
    "note": "arXiv:2410.05258 \nversion: 1",
    "number": "arXiv:2410.05258",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Differential Transformer",
    "URL": "http://arxiv.org/abs/2410.05258",
    "author": [
      {
        "family": "Ye",
        "given": "Tianzhu"
      },
      {
        "family": "Dong",
        "given": "Li"
      },
      {
        "family": "Xia",
        "given": "Yuqing"
      },
      {
        "family": "Sun",
        "given": "Yutao"
      },
      {
        "family": "Zhu",
        "given": "Yi"
      },
      {
        "family": "Huang",
        "given": "Gao"
      },
      {
        "family": "Wei",
        "given": "Furu"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 10, 10]]
    },
    "issued": {
      "date-parts": [["2024", 10, 7]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/6XQHQ3K4",
    "type": "article",
    "abstract": "This work investigates the selection of high-quality pre-training data from massive corpora to enhance LMs' capabilities for downstream usage. We formulate data selection as a generalized Optimal Control problem, which can be solved theoretically by Pontryagin's Maximum Principle (PMP), yielding a set of necessary conditions that characterize the relationship between optimal data selection and LM training dynamics. Based on these theoretical results, we introduce PMP-based Data Selection (PDS), a framework that approximates optimal data selection by solving the PMP conditions. In our experiments, we adopt PDS to select data from CommmonCrawl and show that the PDS-selected corpus accelerates the learning of LMs and constantly boosts their performance on a wide range of downstream tasks across various model sizes. Moreover, the benefits of PDS extend to ~400B models trained on ~10T tokens, as evidenced by the extrapolation of the test loss curves according to the Scaling Laws. PDS also improves data utilization when the pre-training data is limited, by reducing the data demand by 1.8 times, which mitigates the quick exhaustion of available web-crawled corpora. Our code, data, and model checkpoints can be found in https://github.com/microsoft/LMOps/tree/main/data_selection.",
    "DOI": "10.48550/arXiv.2410.07064",
    "language": "en-US",
    "note": "arXiv:2410.07064\nTLDR: This work introduces PMP-based Data Selection (PDS), a framework that approximates optimal data selection by solving the PMP conditions and shows that the PDS-selected corpus accelerates the learning of LMs and constantly boosts their performance on a wide range of downstream tasks across various model sizes.",
    "number": "arXiv:2410.07064",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Data Selection via Optimal Control for Language Models",
    "URL": "http://arxiv.org/abs/2410.07064",
    "author": [
      {
        "family": "Gu",
        "given": "Yuxian"
      },
      {
        "family": "Dong",
        "given": "Li"
      },
      {
        "family": "Wang",
        "given": "Hongning"
      },
      {
        "family": "Hao",
        "given": "Yaru"
      },
      {
        "family": "Dong",
        "given": "Qingxiu"
      },
      {
        "family": "Wei",
        "given": "Furu"
      },
      {
        "family": "Huang",
        "given": "Minlie"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 10, 11]]
    },
    "issued": {
      "date-parts": [["2024", 10, 9]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/8WVJDGQP",
    "type": "article",
    "abstract": "Various visual foundation models have distinct strengths and weaknesses, both of which can be improved through heterogeneous multi-teacher knowledge distillation without labels, termed \"agglomerative models.\" We build upon this body of work by studying the effect of the teachers' activation statistics, particularly the impact of the loss function on the resulting student model quality. We explore a standard toolkit of statistical normalization techniques to better align the different distributions and assess their effects. Further, we examine the impact on downstream teacher-matching metrics, which motivates the use of Hadamard matrices. With these matrices, we demonstrate useful properties, showing how they can be used for isotropic standardization, where each dimension of a multivariate distribution is standardized using the same scale. We call this technique \"PHI Standardization\" (PHI-S) and empirically demonstrate that it produces the best student model across the suite of methods studied.",
    "DOI": "10.48550/arXiv.2410.01680",
    "language": "en-US",
    "note": "arXiv:2410.01680",
    "number": "arXiv:2410.01680",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "PHI-S: Distribution Balancing for Label-Free Multi-Teacher Distillation",
    "title-short": "PHI-S",
    "URL": "http://arxiv.org/abs/2410.01680",
    "author": [
      {
        "family": "Ranzinger",
        "given": "Mike"
      },
      {
        "family": "Barker",
        "given": "Jon"
      },
      {
        "family": "Heinrich",
        "given": "Greg"
      },
      {
        "family": "Molchanov",
        "given": "Pavlo"
      },
      {
        "family": "Catanzaro",
        "given": "Bryan"
      },
      {
        "family": "Tao",
        "given": "Andrew"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 10, 11]]
    },
    "issued": {
      "date-parts": [["2024", 10, 2]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/J63PNUVB",
    "type": "article",
    "abstract": "Recently, the proliferation of highly realistic synthetic images, facilitated through a variety of GANs and Diffusions, has significantly heightened the susceptibility to misuse. While the primary focus of deepfake detection has traditionally centered on the design of detection algorithms, an investigative inquiry into the generator architectures has remained conspicuously absent in recent years. This paper contributes to this lacuna by rethinking the architectures of CNN-based generators, thereby establishing a generalized representation of synthetic artifacts. Our findings illuminate that the up-sampling operator can, beyond frequency-based artifacts, produce generalized forgery artifacts. In particular, the local interdependence among image pixels caused by upsampling operators is significantly demonstrated in synthetic images generated by GAN or diffusion. Building upon this observation, we introduce the concept of Neighboring Pixel Relationships(NPR) as a means to capture and characterize the generalized structural artifacts stemming from up-sampling operations. A comprehensive analysis is conducted on an open-world dataset, comprising samples generated by \\tft{28 distinct generative models}. This analysis culminates in the establishment of a novel state-of-the-art performance, showcasing a remarkable \\tft{11.6\\%} improvement over existing methods. The code is available at https://github.com/chuangchuangtan/NPR-DeepfakeDetection.",
    "DOI": "10.48550/arXiv.2312.10461",
    "language": "en-US",
    "note": "arXiv:2312.10461\nTLDR: It is illuminated that the up-sampling operator can, beyond frequency-based artifacts, produce generalized forgery artifacts, and the concept of Neighboring Pixel Relationships is introduced as a means to capture and characterize the generalized structural artifacts stemming from up-sampling operations.",
    "number": "arXiv:2312.10461",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Rethinking the Up-Sampling Operations in CNN-based Generative Network for Generalizable Deepfake Detection",
    "URL": "http://arxiv.org/abs/2312.10461",
    "author": [
      {
        "family": "Tan",
        "given": "Chuangchuang"
      },
      {
        "family": "Liu",
        "given": "Huan"
      },
      {
        "family": "Zhao",
        "given": "Yao"
      },
      {
        "family": "Wei",
        "given": "Shikui"
      },
      {
        "family": "Gu",
        "given": "Guanghua"
      },
      {
        "family": "Liu",
        "given": "Ping"
      },
      {
        "family": "Wei",
        "given": "Yunchao"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 10, 11]]
    },
    "issued": {
      "date-parts": [["2023", 12, 20]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/G2T5GJGX",
    "type": "article",
    "abstract": "Supervised fine-tuning (SFT) is crucial for aligning Large Language Models (LLMs) with human instructions. The primary goal during SFT is to select a small yet representative subset of training data from the larger pool, such that fine-tuning with this subset achieves results comparable to or even exceeding those obtained using the entire dataset. However, most existing data selection techniques are designed for small-scale data pools, which fail to meet the demands of real-world SFT scenarios. In this paper, we replicated several self-scoring methods those that do not rely on external model assistance on two million scale datasets, and found that nearly all methods struggled to significantly outperform random selection when dealing with such large-scale data pools. Moreover, our comparisons suggest that, during SFT, diversity in data selection is more critical than simply focusing on high quality data. We also analyzed the limitations of several current approaches, explaining why they perform poorly on large-scale datasets and why they are unsuitable for such contexts. Finally, we found that filtering data by token length offers a stable and efficient method for improving results. This approach, particularly when training on long text data, proves highly beneficial for relatively weaker base models, such as Llama3.",
    "DOI": "10.48550/arXiv.2410.09335",
    "language": "en-US",
    "note": "arXiv:2410.09335\nTLDR: This paper replicated several self-scoring methods those that do not rely on external model assistance on two million scale datasets and found that nearly all methods struggled to significantly outperform random selection when dealing with such large-scale data pools.",
    "number": "arXiv:2410.09335",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Rethinking Data Selection at Scale: Random Selection is Almost All You Need",
    "title-short": "Rethinking Data Selection at Scale",
    "URL": "http://arxiv.org/abs/2410.09335",
    "author": [
      {
        "family": "Xia",
        "given": "Tingyu"
      },
      {
        "family": "Yu",
        "given": "Bowen"
      },
      {
        "family": "Dang",
        "given": "Kai"
      },
      {
        "family": "Yang",
        "given": "An"
      },
      {
        "family": "Wu",
        "given": "Yuan"
      },
      {
        "family": "Tian",
        "given": "Yuan"
      },
      {
        "family": "Chang",
        "given": "Yi"
      },
      {
        "family": "Lin",
        "given": "Junyang"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 10, 17]]
    },
    "issued": {
      "date-parts": [["2024", 10, 12]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/IJLXMGAF",
    "type": "article",
    "abstract": "Within the scaling laws paradigm, which underpins the training of large neural networks like ChatGPT and Llama, we consider a supervised regression setting and establish the existance of a strong form of the model collapse phenomenon, a critical performance degradation due to synthetic data in the training corpus. Our results show that even the smallest fraction of synthetic data (e.g., as little as 1\\% of the total training dataset) can still lead to model collapse: larger and larger training sets do not enhance performance. We further investigate whether increasing model size, an approach aligned with current trends in training large language models, exacerbates or mitigates model collapse. In a simplified regime where neural networks are approximated via random projections of tunable size, we both theoretically and empirically show that larger models can amplify model collapse. Interestingly, our theory also indicates that, beyond the interpolation threshold (which can be extremely high for very large datasets), larger models may mitigate the collapse, although they do not entirely prevent it. Our theoretical findings are empirically verified through experiments on language models and feed-forward neural networks for images.",
    "DOI": "10.48550/arXiv.2410.04840",
    "language": "en-US",
    "note": "arXiv:2410.04840\nTLDR: This work considers a supervised regression setting and establishes the existance of a strong form of the model collapse phenomenon, a critical performance degradation due to synthetic data in the training corpus, and theoretically and empirically shows that larger models can amplify model collapse.",
    "number": "arXiv:2410.04840",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Strong Model Collapse",
    "URL": "http://arxiv.org/abs/2410.04840",
    "author": [
      {
        "family": "Dohmatob",
        "given": "Elvis"
      },
      {
        "family": "Feng",
        "given": "Yunzhen"
      },
      {
        "family": "Subramonian",
        "given": "Arjun"
      },
      {
        "family": "Kempe",
        "given": "Julia"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 10, 17]]
    },
    "issued": {
      "date-parts": [["2024", 10, 8]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/4RAPS4AK",
    "type": "article",
    "abstract": "Current AI alignment methodologies rely on human-provided demonstrations or judgments, and the learned capabilities of AI systems would be upper-bounded by human capabilities as a result. This raises a challenging research question: How can we keep improving the systems when their capabilities have surpassed the levels of humans? This paper answers this question in the context of tackling hard reasoning tasks (e.g., level 4-5 MATH problems) via learning from human annotations on easier tasks (e.g., level 1-3 MATH problems), which we term as \\textit{easy-to-hard generalization}. Our key insight is that an evaluator (reward model) trained on supervisions for easier tasks can be effectively used for scoring candidate solutions of harder tasks and hence facilitating easy-to-hard generalization over different levels of tasks. Based on this insight, we propose a novel approach to scalable alignment, which firstly trains the process-supervised reward models on easy problems (e.g., level 1-3), and then uses them to evaluate the performance of policy models on hard problems. We show that such \\textit{easy-to-hard generalization from evaluators} can enable \\textit{easy-to-hard generalizations in generators} either through re-ranking or reinforcement learning (RL). Notably, our process-supervised 7b RL model achieves an accuracy of 34.0\\% on MATH500, despite only using human supervision on easy problems. Our approach suggests a promising path toward AI systems that advance beyond the frontier of human supervision.",
    "DOI": "10.48550/arXiv.2403.09472",
    "language": "en-US",
    "note": "arXiv:2403.09472\nTLDR: A novel approach to scalable alignment is proposed, which firstly trains the process-supervised reward models on easy problems, and then uses them to evaluate the performance of policy models on hard problems, and suggests a promising path toward AI systems that advance beyond the frontier of human supervision.",
    "number": "arXiv:2403.09472",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Easy-to-Hard Generalization: Scalable Alignment Beyond Human Supervision",
    "title-short": "Easy-to-Hard Generalization",
    "URL": "http://arxiv.org/abs/2403.09472",
    "author": [
      {
        "family": "Sun",
        "given": "Zhiqing"
      },
      {
        "family": "Yu",
        "given": "Longhui"
      },
      {
        "family": "Shen",
        "given": "Yikang"
      },
      {
        "family": "Liu",
        "given": "Weiyang"
      },
      {
        "family": "Yang",
        "given": "Yiming"
      },
      {
        "family": "Welleck",
        "given": "Sean"
      },
      {
        "family": "Gan",
        "given": "Chuang"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 10, 17]]
    },
    "issued": {
      "date-parts": [["2024", 3, 14]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/PK26USTA",
    "type": "article",
    "abstract": "How can we train models to perform well on hard test data when hard training data is by definition difficult to label correctly? This question has been termed the scalable oversight problem and has drawn increasing attention as language models have continually improved. In this paper, we present the surprising conclusion that current pretrained language models often generalize relatively well from easy to hard data, even performing as well as oracle models finetuned on hard data. We demonstrate this kind of easy-to-hard generalization using simple finetuning methods like in-context learning, linear classifier heads, and QLoRA for seven different measures of datapoint hardness, including six empirically diverse human hardness measures (like grade level) and one model-based measure (loss-based). Furthermore, we show that even if one cares most about model performance on hard data, it can be better to collect easy data rather than hard data for finetuning, since hard data is generally noisier and costlier to collect. Our experiments use open models up to 70b in size and four publicly available question-answering datasets with questions ranging in difficulty from 3rd grade science questions to college level STEM questions and general-knowledge trivia. We conclude that easy-to-hard generalization in LMs is surprisingly strong for the tasks studied. Our code is available at: https://github.com/allenai/easy-to-hard-generalization",
    "DOI": "10.48550/arXiv.2401.06751",
    "language": "en-US",
    "note": "arXiv:2401.06751\nTLDR: The surprising conclusion is presented that current pretrained language models often generalize relatively well from easy to hard data, even performing as well as oracle models finetuned on hard data.",
    "number": "arXiv:2401.06751",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "The Unreasonable Effectiveness of Easy Training Data for Hard Tasks",
    "URL": "http://arxiv.org/abs/2401.06751",
    "author": [
      {
        "family": "Hase",
        "given": "Peter"
      },
      {
        "family": "Bansal",
        "given": "Mohit"
      },
      {
        "family": "Clark",
        "given": "Peter"
      },
      {
        "family": "Wiegreffe",
        "given": "Sarah"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 10, 17]]
    },
    "issued": {
      "date-parts": [["2024", 6, 5]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/YS3SGAHC",
    "type": "article",
    "abstract": "Alignment with human preference prevents large language models (LLMs) from generating misleading or toxic content while requiring high-cost human feedback. Assuming resources of human annotation are limited, there are two different ways of allocating considered: more diverse PROMPTS or more diverse RESPONSES to be labeled. Nonetheless, a straightforward comparison between their impact is absent. In this work, we first control the diversity of both sides according to the number of samples for fine-tuning, which can directly reflect their influence. We find that instead of numerous prompts, more responses but fewer prompts better trigger LLMs for human alignment. Additionally, the concept of diversity for prompts can be more complex than responses that are typically quantified by single digits. Consequently, a new formulation of prompt diversity is proposed, further implying a linear correlation with the final performance of LLMs after fine-tuning. We also leverage it on data augmentation and conduct experiments to show its effect on different algorithms.",
    "DOI": "10.48550/arXiv.2403.11124",
    "language": "en-US",
    "note": "arXiv:2403.11124\nTLDR: This work finds that instead of numerous prompts, more responses but fewer prompts better trigger LLMs for human alignment, further implying a linear correlation with the final performance of LLMs after fine-tuning.",
    "number": "arXiv:2403.11124",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Scaling Data Diversity for Fine-Tuning Language Models in Human Alignment",
    "URL": "http://arxiv.org/abs/2403.11124",
    "author": [
      {
        "family": "Song",
        "given": "Feifan"
      },
      {
        "family": "Yu",
        "given": "Bowen"
      },
      {
        "family": "Lang",
        "given": "Hao"
      },
      {
        "family": "Yu",
        "given": "Haiyang"
      },
      {
        "family": "Huang",
        "given": "Fei"
      },
      {
        "family": "Wang",
        "given": "Houfeng"
      },
      {
        "family": "Li",
        "given": "Yongbin"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 10, 17]]
    },
    "issued": {
      "date-parts": [["2024", 3, 30]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/5UXL76T6",
    "type": "article",
    "abstract": "Enhancing the instruction-following ability of Large Language Models (LLMs) primarily demands substantial instruction-tuning datasets. However, the sheer volume of these imposes a considerable computational burden and annotation cost. To investigate a label-efficient instruction tuning method that allows the model itself to actively sample subsets that are equally or even more effective, we introduce a self-evolving mechanism DiverseEvol. In this process, a model iteratively augments its training subset to refine its own performance, without requiring any intervention from humans or more advanced LLMs. The key to our data sampling technique lies in the enhancement of diversity in the chosen subsets, as the model selects new data points most distinct from any existing ones according to its current embedding space. Extensive experiments across three datasets and benchmarks demonstrate the effectiveness of DiverseEvol. Our models, trained on less than 8% of the original dataset, maintain or improve performance compared with finetuning on full data. We also provide empirical evidence to analyze the importance of diversity in instruction data and the iterative scheme as opposed to one-time sampling. Our code is publicly available at https://github.com/OFA-Sys/DiverseEvol.git.",
    "DOI": "10.48550/arXiv.2311.08182",
    "language": "en-US",
    "note": "arXiv:2311.08182\nTLDR: This work introduces a self-evolving mechanism DiverseEvol, a label-efficient instruction tuning method that allows the model itself to actively sample subsets that are equally or even more effective, and provides empirical evidence to analyze the importance of diversity in instruction data and the iterative scheme as opposed to one-time sampling.",
    "number": "arXiv:2311.08182",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Self-Evolved Diverse Data Sampling for Efficient Instruction Tuning",
    "URL": "http://arxiv.org/abs/2311.08182",
    "author": [
      {
        "family": "Wu",
        "given": "Shengguang"
      },
      {
        "family": "Lu",
        "given": "Keming"
      },
      {
        "family": "Xu",
        "given": "Benfeng"
      },
      {
        "family": "Lin",
        "given": "Junyang"
      },
      {
        "family": "Su",
        "given": "Qi"
      },
      {
        "family": "Zhou",
        "given": "Chang"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 10, 17]]
    },
    "issued": {
      "date-parts": [["2023", 11, 14]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/3ZJ9E3SU",
    "type": "article",
    "abstract": "Supervised Fine-Tuning (SFT) serves as a crucial phase in aligning Large Language Models (LLMs) to specific task prerequisites. The selection of fine-tuning data profoundly influences the model's performance, whose principle is traditionally grounded in data quality and distribution. In this paper, we introduce a new dimension in SFT data selection: learnability. This new dimension is motivated by the intuition that SFT unlocks capabilities acquired by a LLM during the pretraining phase. Given that different pretrained models have disparate capabilities, the SFT data appropriate for one may not suit another. Thus, we introduce the term learnability to define the suitability of data for effective learning by the model. We present the Loss Based SFT Data Selection (LoBaSS) method, utilizing data learnability as the principal criterion for the selection SFT data. This method provides a nuanced approach, allowing the alignment of data selection with inherent model capabilities, ensuring optimal compatibility and learning efficiency. In experimental comparisons involving 7B and 13B models, our LoBaSS method is able to surpass full-data fine-tuning at merely 6% of the total training data. When employing 16.7% of the data, LoBaSS harmonizes the model's capabilities across conversational and mathematical domains, proving its efficacy and adaptability.",
    "DOI": "10.48550/arXiv.2310.13008",
    "language": "en-US",
    "note": "arXiv:2310.13008\nTLDR: The Loss Based SFT Data Selection (LoBaSS) method is presented, utilizing data learnability as the principal criterion for the selection SFT data, allowing the alignment of data selection with inherent model capabilities, ensuring optimal compatibility and learning efficiency.",
    "number": "arXiv:2310.13008",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "LoBaSS: Gauging Learnability in Supervised Fine-tuning Data",
    "title-short": "LoBaSS",
    "URL": "http://arxiv.org/abs/2310.13008",
    "author": [
      {
        "family": "Zhou",
        "given": "Haotian"
      },
      {
        "family": "Liu",
        "given": "Tingkai"
      },
      {
        "family": "Ma",
        "given": "Qianli"
      },
      {
        "family": "Yuan",
        "given": "Jianbo"
      },
      {
        "family": "Liu",
        "given": "Pengfei"
      },
      {
        "family": "You",
        "given": "Yang"
      },
      {
        "family": "Yang",
        "given": "Hongxia"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 10, 18]]
    },
    "issued": {
      "date-parts": [["2023", 10, 16]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/4JLZLG47",
    "type": "article",
    "abstract": "Instruction tuning, a specialized technique to enhance large language model (LLM) performance via instruction datasets, relies heavily on the quality of employed data. Existing quality improvement methods alter instruction data through dataset expansion or curation. However, the expansion method risks data redundancy, potentially compromising LLM performance, while the curation approach confines the LLM's potential to the original dataset. Our aim is to surpass the original data quality without encountering these shortcomings. To achieve this, we propose LIFT (LLM Instruction Fusion Transfer), a novel and versatile paradigm designed to elevate the instruction quality to new heights. LIFT strategically broadens data distribution to encompass more high-quality subspaces and eliminates redundancy, concentrating on high-quality segments across overall data subspaces. Experimental results demonstrate that, even with a limited quantity of high-quality instruction data selected by our paradigm, LLMs not only consistently uphold robust performance across various tasks but also surpass some state-of-the-art results, highlighting the significant improvement in instruction quality achieved by our paradigm.",
    "DOI": "10.48550/arXiv.2312.11508",
    "language": "en-US",
    "note": "arXiv:2312.11508\nTLDR: LIFT (LLM Instruction Fusion Transfer), a novel and versatile paradigm designed to elevate the instruction quality to new heights, is proposed, which strategically broadens data distribution to encompass more high-quality subspaces and eliminates redundancy, concentrating on high-quality segments across overall data subspaces.",
    "number": "arXiv:2312.11508",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Rethinking the Instruction Quality: LIFT is What You Need",
    "title-short": "Rethinking the Instruction Quality",
    "URL": "http://arxiv.org/abs/2312.11508",
    "author": [
      {
        "family": "Xu",
        "given": "Yang"
      },
      {
        "family": "Yao",
        "given": "Yongqiang"
      },
      {
        "family": "Huang",
        "given": "Yufan"
      },
      {
        "family": "Qi",
        "given": "Mengnan"
      },
      {
        "family": "Wang",
        "given": "Maoquan"
      },
      {
        "family": "Gu",
        "given": "Bin"
      },
      {
        "family": "Sundaresan",
        "given": "Neel"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 10, 18]]
    },
    "issued": {
      "date-parts": [["2023", 12, 27]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/XV864B4R",
    "type": "paper-conference",
    "abstract": "The increasing prevalence of AI-generated content on the internet raises a critical and timely question: What happens when generative machine learning models are pretrained on web-scale datasets containing data created by earlier models? Previous work prophesied _model collapse_, a phenomenon whereby model-generated synthetic data degrades performance with each additional model-fitting and sampling iteration, with newer models becoming more and more useless. In this work, we clarify and unify the fractured literature on the perils and promises of synthetic data in model-data feedback loops to better forecast likely futures of large-scale deep generative models. First, previous work claimed that model collapse is caused by replacing all past data with fresh synthetic data at each model-fitting iteration and that collapse is avoided by instead accumulating data across model-fitting iterations; we test this claim on three prominent generative modeling settings, and find both claims hold in all three settings. Second, we study a middle-ground in which the available data pool contains increasing amounts of synthetic data, but each model is fit using a fixed compute budget; we demonstrate that model test loss on real data increases more quickly, but still plateaus unlike when data are replaced en masse. Third, we investigate whether the cardinality or proportion of real data matters more for avoiding model collapse. Surprisingly, we find a non-trivial interaction between real and synthetic data, where the value of synthetic data for reducing model test loss depends on the absolute quantity of real data. Our insights are particularly important when forecasting whether future deep generative models will collapse or thrive, and our results open avenues for empirically and mathematically studying the context-dependent value of synthetic data.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "Collapse or Thrive? Perils and Promises of Synthetic Data in a Self-Generating World",
    "title-short": "Collapse or Thrive?",
    "URL": "https://openreview.net/forum?id=Xr5iINA3zU",
    "accessed": {
      "date-parts": [["2024", 10, 23]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/WPCQT2QK",
    "type": "article",
    "abstract": "In this report, we introduce the Qwen2.5-Coder series, a significant upgrade from its predecessor, CodeQwen1.5. This series includes two models: Qwen2.5-Coder-1.5B and Qwen2.5-Coder-7B. As a code-specific model, Qwen2.5-Coder is built upon the Qwen2.5 architecture and continues pretrained on a vast corpus of over 5.5 trillion tokens. Through meticulous data cleaning, scalable synthetic data generation, and balanced data mixing, Qwen2.5-Coder demonstrates impressive code generation capabilities while retaining general versatility. The model has been evaluated on a wide range of code-related tasks, achieving state-of-the-art (SOTA) performance across more than 10 benchmarks, including code generation, completion, reasoning, and repair, consistently outperforming larger models of the same model size. We believe that the release of the Qwen2.5-Coder series will not only push the boundaries of research in code intelligence but also, through its permissive licensing, encourage broader adoption by developers in real-world applications.",
    "DOI": "10.48550/arXiv.2409.12186",
    "language": "en-US",
    "note": "arXiv:2409.12186\nTLDR: The Qwen2.5-Coder series is introduced, a significant upgrade from its predecessor, CodeQwen1.5, which achieved state-of-the-art (SOTA) performance across more than 10 benchmarks, including code generation, completion, reasoning, and repair, consistently outperforming larger models of the same model size.",
    "number": "arXiv:2409.12186",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Qwen2.5-Coder Technical Report",
    "URL": "http://arxiv.org/abs/2409.12186",
    "author": [
      {
        "family": "Hui",
        "given": "Binyuan"
      },
      {
        "family": "Yang",
        "given": "Jian"
      },
      {
        "family": "Cui",
        "given": "Zeyu"
      },
      {
        "family": "Yang",
        "given": "Jiaxi"
      },
      {
        "family": "Liu",
        "given": "Dayiheng"
      },
      {
        "family": "Zhang",
        "given": "Lei"
      },
      {
        "family": "Liu",
        "given": "Tianyu"
      },
      {
        "family": "Zhang",
        "given": "Jiajun"
      },
      {
        "family": "Yu",
        "given": "Bowen"
      },
      {
        "family": "Dang",
        "given": "Kai"
      },
      {
        "family": "Yang",
        "given": "An"
      },
      {
        "family": "Men",
        "given": "Rui"
      },
      {
        "family": "Huang",
        "given": "Fei"
      },
      {
        "family": "Ren",
        "given": "Xingzhang"
      },
      {
        "family": "Ren",
        "given": "Xuancheng"
      },
      {
        "family": "Zhou",
        "given": "Jingren"
      },
      {
        "family": "Lin",
        "given": "Junyang"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 10, 24]]
    },
    "issued": {
      "date-parts": [["2024", 9, 18]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/PS4DZVWZ",
    "type": "article",
    "abstract": "This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. In addition to being one of the largest corpora available for the task of NLI, at 433k examples, this corpus improves upon available resources in its coverage: it offers data from ten distinct genres of written and spoken English--making it possible to evaluate systems on nearly the full complexity of the language--and it offers an explicit setting for the evaluation of cross-genre domain adaptation.",
    "DOI": "10.48550/arXiv.1704.05426",
    "language": "en-US",
    "note": "arXiv:1704.05426",
    "number": "arXiv:1704.05426",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
    "URL": "http://arxiv.org/abs/1704.05426",
    "author": [
      {
        "family": "Williams",
        "given": "Adina"
      },
      {
        "family": "Nangia",
        "given": "Nikita"
      },
      {
        "family": "Bowman",
        "given": "Samuel R."
      }
    ],
    "accessed": {
      "date-parts": [["2024", 11, 14]]
    },
    "issued": {
      "date-parts": [["2018", 2, 19]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/TS4RYAGU",
    "type": "paper-conference",
    "abstract": "The paper introduces the Hungarian Language Understanding (HuLU) benchmark, a comprehensive assessment framework designed to evaluate the performance of neural language models on Hungarian language tasks. Inspired by the renowned GLUE and SuperGLUE benchmarks, HuLU aims to address the challenges specific to Hungarian language processing. The benchmark consists of various datasets, each representing different linguistic phenomena and task complexities. Moreover, the paper presents a web service developed for HuLU, offering a user-friendly interface for model evaluation. This platform not only ensures consistent assessment but also fosters transparency by maintaining a leaderboard showcasing model performances. Preliminary evaluations of various LMMs on HuLU datasets indicate that while Hungarian models show promise, there's room for improvement to match the proficiency of English-centric models in their native language.",
    "container-title": "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    "event-place": "Torino, Italia",
    "event-title": "LREC-COLING 2024",
    "language": "en-US",
    "page": "8360–8371",
    "publisher": "ELRA and ICCL",
    "publisher-place": "Torino, Italia",
    "source": "ACLWeb",
    "title": "HuLU: Hungarian Language Understanding Benchmark Kit",
    "title-short": "HuLU",
    "URL": "https://aclanthology.org/2024.lrec-main.733",
    "author": [
      {
        "family": "Ligeti-Nagy",
        "given": "Noémi"
      },
      {
        "family": "Ferenczi",
        "given": "Gerg\\Ho"
      },
      {
        "family": "Héja",
        "given": "Enik\\Ho"
      },
      {
        "family": "Laki",
        "given": "László János"
      },
      {
        "family": "Vadász",
        "given": "Noémi"
      },
      {
        "family": "Yang",
        "given": "Zijian Gy\\Hoz\\Ho"
      },
      {
        "family": "Váradi",
        "given": "Tamás"
      }
    ],
    "editor": [
      {
        "family": "Calzolari",
        "given": "Nicoletta"
      },
      {
        "family": "Kan",
        "given": "Min-Yen"
      },
      {
        "family": "Hoste",
        "given": "Veronique"
      },
      {
        "family": "Lenci",
        "given": "Alessandro"
      },
      {
        "family": "Sakti",
        "given": "Sakriani"
      },
      {
        "family": "Xue",
        "given": "Nianwen"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 11, 14]]
    },
    "issued": {
      "date-parts": [["2024", 5]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/HUXSIAAX",
    "type": "article",
    "abstract": "Understanding entailment and contradiction is fundamental to understanding natural language, and inference about entailment and contradiction is a valuable testing ground for the development of semantic representations. However, machine learning research in this area has been dramatically limited by the lack of large-scale resources. To address this, we introduce the Stanford Natural Language Inference corpus, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. At 570K pairs, it is two orders of magnitude larger than all other resources of its type. This increase in scale allows lexicalized classifiers to outperform some sophisticated existing entailment models, and it allows a neural network-based model to perform competitively on natural language inference benchmarks for the first time.",
    "DOI": "10.48550/arXiv.1508.05326",
    "language": "en-US",
    "note": "arXiv:1508.05326",
    "number": "arXiv:1508.05326",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "A large annotated corpus for learning natural language inference",
    "URL": "http://arxiv.org/abs/1508.05326",
    "author": [
      {
        "family": "Bowman",
        "given": "Samuel R."
      },
      {
        "family": "Angeli",
        "given": "Gabor"
      },
      {
        "family": "Potts",
        "given": "Christopher"
      },
      {
        "family": "Manning",
        "given": "Christopher D."
      }
    ],
    "accessed": {
      "date-parts": [["2024", 11, 14]]
    },
    "issued": {
      "date-parts": [["2015", 8, 21]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/TKYIHZ2Z",
    "type": "article",
    "abstract": "For natural language understanding (NLU) technology to be maximally useful, both practically and as a scientific object of study, it must be general: it must be able to process language in a way that is not exclusively tailored to any one specific task or dataset. In pursuit of this objective, we introduce the General Language Understanding Evaluation benchmark (GLUE), a tool for evaluating and analyzing the performance of models across a diverse range of existing NLU tasks. GLUE is model-agnostic, but it incentivizes sharing knowledge across tasks because certain tasks have very limited training data. We further provide a hand-crafted diagnostic test suite that enables detailed linguistic analysis of NLU models. We evaluate baselines based on current methods for multi-task and transfer learning and find that they do not immediately give substantial improvements over the aggregate performance of training a separate model per task, indicating room for improvement in developing general and robust NLU systems.",
    "DOI": "10.48550/arXiv.1804.07461",
    "language": "en-US",
    "note": "arXiv:1804.07461",
    "number": "arXiv:1804.07461",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
    "title-short": "GLUE",
    "URL": "http://arxiv.org/abs/1804.07461",
    "author": [
      {
        "family": "Wang",
        "given": "Alex"
      },
      {
        "family": "Singh",
        "given": "Amanpreet"
      },
      {
        "family": "Michael",
        "given": "Julian"
      },
      {
        "family": "Hill",
        "given": "Felix"
      },
      {
        "family": "Levy",
        "given": "Omer"
      },
      {
        "family": "Bowman",
        "given": "Samuel R."
      }
    ],
    "accessed": {
      "date-parts": [["2024", 11, 14]]
    },
    "issued": {
      "date-parts": [["2019", 2, 22]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/XCGTBWWZ",
    "type": "article",
    "abstract": "Extractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuAD 2.0, the latest version of the Stanford Question Answering Dataset (SQuAD). SQuAD 2.0 combines existing SQuAD data with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuAD 2.0, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuAD 2.0 is a challenging natural language understanding task for existing models: a strong neural system that gets 86% F1 on SQuAD 1.1 achieves only 66% F1 on SQuAD 2.0.",
    "DOI": "10.48550/arXiv.1806.03822",
    "language": "en-US",
    "note": "arXiv:1806.03822",
    "number": "arXiv:1806.03822",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Know What You Don't Know: Unanswerable Questions for SQuAD",
    "title-short": "Know What You Don't Know",
    "URL": "http://arxiv.org/abs/1806.03822",
    "author": [
      {
        "family": "Rajpurkar",
        "given": "Pranav"
      },
      {
        "family": "Jia",
        "given": "Robin"
      },
      {
        "family": "Liang",
        "given": "Percy"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 11, 14]]
    },
    "issued": {
      "date-parts": [["2018", 6, 11]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/VV89E4SU",
    "type": "paper-conference",
    "abstract": "Shared and internationally recognized benchmarks are fundamental for the development of any computational system. We aim to help the research community working on compositional distributional semantic models (CDSMs) by providing SICK (Sentences Involving Compositional Knowldedge), a large size English benchmark tailored for them. SICK consists of about 10,000 English sentence pairs that include many examples of the lexical, syntactic and semantic phenomena that CDSMs are expected to account for, but do not require dealing with other aspects of existing sentential data sets (idiomatic multiword expressions, named entities, telegraphic language) that are not within the scope of CDSMs. By means of crowdsourcing techniques, each pair was annotated for two crucial semantic tasks: relatedness in meaning (with a 5-point rating scale as gold score) and entailment relation between the two elements (with three possible gold labels: entailment, contradiction, and neutral). The SICK data set was used in SemEval-2014 Task 1, and it freely available for research purposes.",
    "container-title": "Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC'14)",
    "event-place": "Reykjavik, Iceland",
    "event-title": "LREC 2014",
    "language": "en-US",
    "page": "216–223",
    "publisher": "European Language Resources Association (ELRA)",
    "publisher-place": "Reykjavik, Iceland",
    "source": "ACLWeb",
    "title": "A SICK cure for the evaluation of compositional distributional semantic models",
    "URL": "http://www.lrec-conf.org/proceedings/lrec2014/pdf/363_Paper.pdf",
    "author": [
      {
        "family": "Marelli",
        "given": "Marco"
      },
      {
        "family": "Menini",
        "given": "Stefano"
      },
      {
        "family": "Baroni",
        "given": "Marco"
      },
      {
        "family": "Bentivogli",
        "given": "Luisa"
      },
      {
        "family": "Bernardi",
        "given": "Raffaella"
      },
      {
        "family": "Zamparelli",
        "given": "Roberto"
      }
    ],
    "editor": [
      {
        "family": "Calzolari",
        "given": "Nicoletta"
      },
      {
        "family": "Choukri",
        "given": "Khalid"
      },
      {
        "family": "Declerck",
        "given": "Thierry"
      },
      {
        "family": "Loftsson",
        "given": "Hrafn"
      },
      {
        "family": "Maegaard",
        "given": "Bente"
      },
      {
        "family": "Mariani",
        "given": "Joseph"
      },
      {
        "family": "Moreno",
        "given": "Asuncion"
      },
      {
        "family": "Odijk",
        "given": "Jan"
      },
      {
        "family": "Piperidis",
        "given": "Stelios"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 11, 14]]
    },
    "issued": {
      "date-parts": [["2014", 5]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/R4CSYU7X",
    "type": "article",
    "abstract": "We introduce a new large-scale NLI benchmark dataset, collected via an iterative, adversarial human-and-model-in-the-loop procedure. We show that training models on this new dataset leads to state-of-the-art performance on a variety of popular NLI benchmarks, while posing a more difficult challenge with its new test set. Our analysis sheds light on the shortcomings of current state-of-the-art models, and shows that non-expert annotators are successful at finding their weaknesses. The data collection method can be applied in a never-ending learning scenario, becoming a moving target for NLU, rather than a static benchmark that will quickly saturate.",
    "DOI": "10.48550/arXiv.1910.14599",
    "language": "en-US",
    "note": "arXiv:1910.14599",
    "number": "arXiv:1910.14599",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Adversarial NLI: A New Benchmark for Natural Language Understanding",
    "title-short": "Adversarial NLI",
    "URL": "http://arxiv.org/abs/1910.14599",
    "author": [
      {
        "family": "Nie",
        "given": "Yixin"
      },
      {
        "family": "Williams",
        "given": "Adina"
      },
      {
        "family": "Dinan",
        "given": "Emily"
      },
      {
        "family": "Bansal",
        "given": "Mohit"
      },
      {
        "family": "Weston",
        "given": "Jason"
      },
      {
        "family": "Kiela",
        "given": "Douwe"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 11, 14]]
    },
    "issued": {
      "date-parts": [["2020", 5, 6]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/R4967GZK",
    "type": "paper-conference",
    "abstract": "In order for machine learning to garner widespread public adoption, models must be able to provide interpretable and robust explanations for their decisions, as well as learn from human-provided explanations at train time. In this work, we extend the Stanford Natural Language Inference dataset with an additional layer of human-annotated natural language explanations of the entailment relations. We further implement models that incorporate these explanations into their training process and output them at test time. We show how our corpus of explanations, which we call e-SNLI, can be used for various goals, such as obtaining full sentence justifications of a model’s decisions, improving universal sentence representations and transferring to out-of-domain NLI datasets. Our dataset thus opens up a range of research directions for using natural language explanations, both for improving models and for asserting their trust",
    "container-title": "Advances in Neural Information Processing Systems",
    "language": "en-US",
    "publisher": "Curran Associates, Inc.",
    "source": "Neural Information Processing Systems",
    "title": "e-SNLI: Natural Language Inference with Natural Language Explanations",
    "title-short": "e-SNLI",
    "URL": "https://proceedings.neurips.cc/paper/2018/hash/4c7a167bb329bd92580a99ce422d6fa6-Abstract.html",
    "volume": "31",
    "author": [
      {
        "family": "Camburu",
        "given": "Oana-Maria"
      },
      {
        "family": "Rocktäschel",
        "given": "Tim"
      },
      {
        "family": "Lukasiewicz",
        "given": "Thomas"
      },
      {
        "family": "Blunsom",
        "given": "Phil"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 11, 14]]
    },
    "issued": {
      "date-parts": [["2018"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/RIWAKDS5",
    "type": "article",
    "abstract": "As language models grow ever larger, so do their vocabularies. This has shifted the memory footprint of LLMs during training disproportionately to one single layer: the cross-entropy in the loss computation. Cross-entropy builds up a logit matrix with entries for each pair of input tokens and vocabulary items and, for small models, consumes an order of magnitude more memory than the rest of the LLM combined. We propose Cut Cross-Entropy (CCE), a method that computes the cross-entropy loss without materializing the logits for all tokens into global memory. Rather, CCE only computes the logit for the correct token and evaluates the log-sum-exp over all logits on the fly. We implement a custom kernel that performs the matrix multiplications and the log-sum-exp reduction over the vocabulary in flash memory, making global memory consumption for the cross-entropy computation negligible. This has a dramatic effect. Taking the Gemma 2 (2B) model as an example, CCE reduces the memory footprint of the loss computation from 24 GB to 1 MB, and the total training-time memory consumption of the classifier head from 28 GB to 1 GB. To improve the throughput of CCE, we leverage the inherent sparsity of softmax and propose to skip elements of the gradient computation that have a negligible (i.e., below numerical precision) contribution to the gradient. Experiments demonstrate that the dramatic reduction in memory consumption is accomplished without sacrificing training speed or convergence.",
    "DOI": "10.48550/arXiv.2411.09009",
    "language": "en-US",
    "note": "arXiv:2411.09009 \nversion: 1",
    "number": "arXiv:2411.09009",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Cut Your Losses in Large-Vocabulary Language Models",
    "URL": "http://arxiv.org/abs/2411.09009",
    "author": [
      {
        "family": "Wijmans",
        "given": "Erik"
      },
      {
        "family": "Huval",
        "given": "Brody"
      },
      {
        "family": "Hertzberg",
        "given": "Alexander"
      },
      {
        "family": "Koltun",
        "given": "Vladlen"
      },
      {
        "family": "Krähenbühl",
        "given": "Philipp"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 11, 20]]
    },
    "issued": {
      "date-parts": [["2024", 11, 13]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/VMZJUSWJ",
    "type": "article",
    "abstract": "Instruction tuning has been widely adopted to ensure large language models (LLMs) follow user instructions effectively. The resulting instruction-following capabilities of LLMs heavily rely on the instruction datasets used for tuning. Recently, synthetic instruction datasets have emerged as an economically viable solution to provide LLMs diverse and high-quality instructions. However, existing approaches typically assume that larger or stronger models are stronger teachers for instruction tuning, and hence simply adopt these models as response generators to the synthetic instructions. In this paper, we challenge this commonly-adopted assumption. Our extensive experiments across five base models and twenty response generators reveal that larger and stronger models are not necessarily stronger teachers of smaller models. We refer to this phenomenon as the Larger Models' Paradox. We observe that existing metrics cannot precisely predict the effectiveness of response generators since they ignore the compatibility between teachers and base models being fine-tuned. We thus develop a novel metric, named as Compatibility-Adjusted Reward (CAR) to measure the effectiveness of response generators. Our experiments across five base models demonstrate that CAR outperforms almost all baselines.",
    "DOI": "10.48550/arXiv.2411.07133",
    "language": "en-US",
    "note": "arXiv:2411.07133 \nversion: 2\nTLDR: A novel metric, named as Compatibility-Adjusted Reward (CAR) is developed to measure the effectiveness of response generators since existing metrics cannot precisely predict the effectiveness of response generators since they ignore the compatibility between teachers and base models being fine-tuned.",
    "number": "arXiv:2411.07133",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Stronger Models are NOT Stronger Teachers for Instruction Tuning",
    "URL": "http://arxiv.org/abs/2411.07133",
    "author": [
      {
        "family": "Xu",
        "given": "Zhangchen"
      },
      {
        "family": "Jiang",
        "given": "Fengqing"
      },
      {
        "family": "Niu",
        "given": "Luyao"
      },
      {
        "family": "Lin",
        "given": "Bill Yuchen"
      },
      {
        "family": "Poovendran",
        "given": "Radha"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 11, 20]]
    },
    "issued": {
      "date-parts": [["2024", 11, 12]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/GJLVTK5V",
    "type": "paper-conference",
    "abstract": "The paper reports on the development of the Hungarian Gigaword Corpus (HGC), an extended new edition of the Hungarian National Corpus, with upgraded and redesigned linguistic annotation and an increased size of 1.5 billion tokens. Issues concerning the standard steps of corpus collection and preparation are discussed with special emphasis on linguistic analysis and annotation due to Hungarian having some challenging characteristics with respect to computational processing. As the HGC is designed to serve as a resource for a wide range of linguistic research as well as for the interested public, a number of issues had to be resolved which were raised by trying to find a balance between the above two application areas. The following main objectives have been defined for the development of the HGC, focusing on the pivotal concept of increase in: - size: extending the corpus to minimum 1 billion words, - quality: using new technology for development and analysis, - coverage and representativity: taking new samples of language use and including further variants (transcribed spoken language data and user generated content (social media) from the internet in particular).",
    "container-title": "Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC'14)",
    "event-place": "Reykjavik, Iceland",
    "event-title": "LREC 2014",
    "language": "en-US",
    "page": "1719–1723",
    "publisher": "European Language Resources Association (ELRA)",
    "publisher-place": "Reykjavik, Iceland",
    "source": "ACLWeb",
    "title": "The Hungarian Gigaword Corpus",
    "URL": "http://www.lrec-conf.org/proceedings/lrec2014/pdf/681_Paper.pdf",
    "author": [
      {
        "family": "Oravecz",
        "given": "Csaba"
      },
      {
        "family": "Váradi",
        "given": "Tamás"
      },
      {
        "family": "Sass",
        "given": "Bálint"
      }
    ],
    "editor": [
      {
        "family": "Calzolari",
        "given": "Nicoletta"
      },
      {
        "family": "Choukri",
        "given": "Khalid"
      },
      {
        "family": "Declerck",
        "given": "Thierry"
      },
      {
        "family": "Loftsson",
        "given": "Hrafn"
      },
      {
        "family": "Maegaard",
        "given": "Bente"
      },
      {
        "family": "Mariani",
        "given": "Joseph"
      },
      {
        "family": "Moreno",
        "given": "Asuncion"
      },
      {
        "family": "Odijk",
        "given": "Jan"
      },
      {
        "family": "Piperidis",
        "given": "Stelios"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 11, 21]]
    },
    "issued": {
      "date-parts": [["2014", 5]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/KVSL85XP",
    "type": "article",
    "abstract": "While scaling laws provide a reliable methodology for predicting train loss across compute scales for a single data distribution, less is known about how these predictions should change as we change the distribution. In this paper, we derive a strategy for predicting one loss from another and apply it to predict across different pre-training datasets and from pre-training data to downstream task data. Our predictions extrapolate well even at 20x the largest FLOP budget used to fit the curves. More precisely, we find that there are simple shifted power law relationships between (1) the train losses of two models trained on two separate datasets when the models are paired by training compute (train-to-train), (2) the train loss and the test loss on any downstream distribution for a single model (train-to-test), and (3) the test losses of two models trained on two separate train datasets (test-to-test). The results hold up for pre-training datasets that differ substantially (some are entirely code and others have no code at all) and across a variety of downstream tasks. Finally, we find that in some settings these shifted power law relationships can yield more accurate predictions than extrapolating single-dataset scaling laws.",
    "DOI": "10.48550/arXiv.2411.12925",
    "language": "en-US",
    "note": "arXiv:2411.12925",
    "number": "arXiv:2411.12925",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Loss-to-Loss Prediction: Scaling Laws for All Datasets",
    "title-short": "Loss-to-Loss Prediction",
    "URL": "http://arxiv.org/abs/2411.12925",
    "author": [
      {
        "family": "Brandfonbrener",
        "given": "David"
      },
      {
        "family": "Anand",
        "given": "Nikhil"
      },
      {
        "family": "Vyas",
        "given": "Nikhil"
      },
      {
        "family": "Malach",
        "given": "Eran"
      },
      {
        "family": "Kakade",
        "given": "Sham"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 11, 21]]
    },
    "issued": {
      "date-parts": [["2024", 11, 19]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/V8WB4I9E",
    "type": "article",
    "abstract": "LLMs have performed well on several reasoning benchmarks, including ones that test analogical reasoning abilities. However, there is debate on the extent to which they are performing general abstract reasoning versus employing non-robust processes, e.g., that overly rely on similarity to pre-training data. Here we investigate the robustness of analogy-making abilities previously claimed for LLMs on three of four domains studied by Webb, Holyoak, and Lu (2023): letter-string analogies, digit matrices, and story analogies. For each domain we test humans and GPT models on robustness to variants of the original analogy problems that test the same abstract reasoning abilities but are likely dissimilar from tasks in the pre-training data. The performance of a system that uses robust abstract reasoning should not decline substantially on these variants. On simple letter-string analogies, we find that while the performance of humans remains high for two types of variants we tested, the GPT models' performance declines sharply. This pattern is less pronounced as the complexity of these problems is increased, as both humans and GPT models perform poorly on both the original and variant problems requiring more complex analogies. On digit-matrix problems, we find a similar pattern but only on one out of the two types of variants we tested. On story-based analogy problems, we find that, unlike humans, the performance of GPT models are susceptible to answer-order effects, and that GPT models also may be more sensitive than humans to paraphrasing. This work provides evidence that LLMs often lack the robustness of zero-shot human analogy-making, exhibiting brittleness on most of the variations we tested. More generally, this work points to the importance of carefully evaluating AI systems not only for accuracy but also robustness when testing their cognitive capabilities.",
    "DOI": "10.48550/arXiv.2411.14215",
    "language": "en-US",
    "note": "arXiv:2411.14215",
    "number": "arXiv:2411.14215",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Evaluating the Robustness of Analogical Reasoning in Large Language Models",
    "URL": "http://arxiv.org/abs/2411.14215",
    "author": [
      {
        "family": "Lewis",
        "given": "Martha"
      },
      {
        "family": "Mitchell",
        "given": "Melanie"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 11, 23]]
    },
    "issued": {
      "date-parts": [["2024", 11, 21]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/TV3W23VV",
    "type": "article",
    "abstract": "It has been well-known that Chain-of-Thought can remarkably enhance LLMs' performance on complex tasks. However, because it also introduces slower inference speeds and higher computational costs, many researches have attempted to use implicit CoT, which does not need LLMs to explicitly generate the intermediate steps. But there is still gap between their efficacy and typical explicit CoT methods. This leaves us a doubt that, does implicit CoT really equal to explicit CoT? Therefore, in this study, we address this question through experiments. We probe the information of intermediate steps from the model's hidden states when it is performing implicit CoT. The results surprisingly indicate that LLMs hardly think about intermediate steps, suggesting they may just rely on experience rather than strict step-by-step reasoning. Moreover, we find LLMs' implicit reasoning capabilities are susceptible and unstable, reaffirming the necessity of explicit CoT to effectively support complex tasks.",
    "DOI": "10.48550/arXiv.2411.15862",
    "language": "en-US",
    "note": "arXiv:2411.15862\nTLDR: The results surprisingly indicate that LLMs hardly think about intermediate steps, suggesting they may just rely on experience rather than strict step-by-step reasoning, and reaffirming the necessity of explicit CoT to effectively support complex tasks.",
    "number": "arXiv:2411.15862",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "LLMs Do Not Think Step-by-step In Implicit Reasoning",
    "URL": "http://arxiv.org/abs/2411.15862",
    "author": [
      {
        "family": "Yu",
        "given": "Yijiong"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 11, 26]]
    },
    "issued": {
      "date-parts": [["2024", 11, 24]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/MSELTP3V",
    "type": "article",
    "abstract": "The process of creating training data to teach models is currently driven by humans, who manually analyze model weaknesses and plan how to create data that improves a student model. Recent approaches using LLMs as annotators reduce human effort, but still require humans to interpret feedback from evaluations and control the LLM to produce data the student needs. Automating this labor-intensive process by creating autonomous data generation agents - or teachers - is desirable, but requires environments that can simulate the feedback-driven, iterative, closed loop of data creation. To enable rapid and scalable testing for such agents and their modules, we introduce DataEnvGym, a testbed of teacher environments for data generation agents. DataEnvGym frames data generation as a sequential decision-making task, involving an agent consisting of a data generation policy (which generates a plan for creating training data) and a data generation engine (which transforms the plan into data), inside an environment that provides student feedback. The agent's goal is to improve student performance. Students are iteratively trained and evaluated on generated data, with their feedback (in the form of errors or weak skills) being reported to the agent after each iteration. DataEnvGym includes multiple teacher environment instantiations across 3 levels of structure in the state representation and action space. More structured environments are based on inferred skills and offer more interpretability and curriculum control. We support 3 diverse tasks (math, code, and VQA) and test multiple students and teachers. Example agents in our teaching environments can iteratively improve students across tasks and settings. Moreover, we show that environments teach different skill levels and test variants of key modules, pointing to future work in improving data generation agents, engines, and feedback mechanisms.",
    "DOI": "10.48550/arXiv.2410.06215",
    "language": "en-US",
    "note": "arXiv:2410.06215\nTLDR: DataEnvGym is introduced, a testbed of teacher environments for data generation agents and their modules, and shows that environments teach different skill levels and test variants of key modules, pointing to future work in improving data generation agents, engines, and feedback mechanisms.",
    "number": "arXiv:2410.06215",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "DataEnvGym: Data Generation Agents in Teacher Environments with Student Feedback",
    "title-short": "DataEnvGym",
    "URL": "http://arxiv.org/abs/2410.06215",
    "author": [
      {
        "family": "Khan",
        "given": "Zaid"
      },
      {
        "family": "Stengel-Eskin",
        "given": "Elias"
      },
      {
        "family": "Cho",
        "given": "Jaemin"
      },
      {
        "family": "Bansal",
        "given": "Mohit"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 11, 27]]
    },
    "issued": {
      "date-parts": [["2024", 10, 8]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/5N9GMGLY",
    "type": "paper-conference",
    "abstract": "Supervised learning has become a cornerstone of modern machine learning, yet a comprehensive theory explaining its effectiveness remains elusive. Empirical phenomena, such as neural analogy-making and the linear representation hypothesis, suggest that supervised models can learn interpretable factors of variation in a linear fashion. Recent advances in self-supervised learning, particularly nonlinear Independent Component Analysis, have shown that these methods can recover latent structures by inverting the data generating process. We extend these identifiability results to parametric instance discrimination, then show how insights transfer to the ubiquitous setting of supervised learning with cross-entropy minimization. We prove that even in standard classification tasks, models learn representations of ground-truth factors of variation up to a linear transformation under a certain DGP. We corroborate our theoretical contribution with a series of empirical studies. First, using simulated data matching our theoretical assumptions, we demonstrate successful disentanglement of latent factors. Second, we show that on DisLib, a widely-used disentanglement benchmark, simple classification tasks recover latent structures up to linear transformations. Finally, we reveal that models trained on ImageNet encode representations that permit linear decoding of proxy factors of variation. Together, our theoretical findings and experiments offer a compelling explanation for recent observations of linear representations, such as superposition in neural networks. This work takes a significant step toward a cohesive theory that accounts for the unreasonable effectiveness of supervised learning.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "Cross-Entropy Is All You Need To Invert the Data Generating Process",
    "URL": "https://openreview.net/forum?id=hrqNOxpItr",
    "accessed": {
      "date-parts": [["2024", 11, 28]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/7ZTFDUFK",
    "type": "paper-conference",
    "abstract": "Synthetic data augmentation via large language models (LLMs) allows researchers to leverage additional training data, thus enhancing the performance of downstream tasks, especially when real-world data is scarce. However, the generated data can deviate from the real-world data, and this misalignment can bring deficient outcomes while applying the trained model to applications. Therefore, we proposed efficient weighted-loss approaches to align synthetic data with real-world distribution by emphasizing high-quality and diversified data generated by LLMs with using merely a little real-world data. We empirically assessed the effectiveness of our method on multiple text classification tasks, and the results showed leveraging our approaches on a BERT-level model robustly outperformed standard cross-entropy and other data weighting approaches, providing potential solutions to effectively leveraging synthetic data from any suitable data generator for model training.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "Not All LLM-Generated Data Are Equal: Rethinking Data Weighting in Text Classification",
    "title-short": "Not All LLM-Generated Data Are Equal",
    "URL": "https://openreview.net/forum?id=oI5tZaWkF9",
    "accessed": {
      "date-parts": [["2024", 11, 28]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/XGZLXTB9",
    "type": "paper-conference",
    "abstract": "Traditional data influence estimation methods, like influence function, assume that learning algorithms are permutation-invariant with respect to training data. However, modern training paradigms—especially for foundation models using stochastic algorithms and non-convergent, multi-stage curricula—are sensitive to data ordering, thus violating this assumption. This mismatch renders influence functions inadequate for answering some critical questions in current machine learning: How can we differentiate the influence of the same data contributing at different stages of training? More generally, how can we capture the dependence of data influence on the optimization trajectory during training? To address this gap, we formalize the concept of \\emph{trajectory-specific leave-one-out (LOO) influence}, which quantifies the impact of removing a data point from a specific iteration during training, accounting for the exact sequence of data encountered and the model's optimization trajectory. However, exactly evaluating the trajectory-specific LOO presents a significant computational challenge. To address this, we propose \\emph{data value embedding}, a novel technique enabling efficient approximation of trajectory-specific LOO. Specifically, we compute a training data embedding that encapsulates the cumulative interactions between data and the evolving model parameters. The LOO can then be efficiently approximated through a simple dot-product between the data value embedding and the gradient of the given test data. As data value embedding captures training data ordering, it offers valuable insights into model training dynamics. In particular, we uncover distinct phases of data influence, revealing that data points in the early and late stages of training exert a greater impact on the final model. These insights translate into actionable strategies for managing the computational overhead of data selection by strategically timing the selection process, potentially opening new avenues in data curation research.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "Capturing the Temporal Dependence of Training Data Influence",
    "URL": "https://openreview.net/forum?id=uHLgDEgiS5",
    "accessed": {
      "date-parts": [["2024", 11, 29]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/7MM2KNWU",
    "type": "article",
    "abstract": "Recent work in language modeling has raised the possibility of self-improvement, where a language models evaluates and refines its own generations to achieve higher performance without external feedback. It is impossible for this self-improvement to create information that is not already in the model, so why should we expect that this will lead to improved capabilities? We offer a new perspective on the capabilities of self-improvement through a lens we refer to as sharpening. Motivated by the observation that language models are often better at verifying response quality than they are at generating correct responses, we formalize self-improvement as using the model itself as a verifier during post-training in order to ``sharpen'' the model to one placing large mass on high-quality sequences, thereby amortizing the expensive inference-time computation of generating good sequences. We begin by introducing a new statistical framework for sharpening in which the learner aims to sharpen a pre-trained base policy via sample access, and establish fundamental limits. Then we analyze two natural families of self-improvement algorithms based on SFT and RLHF.",
    "DOI": "10.48550/arXiv.2412.01951",
    "language": "en-US",
    "note": "arXiv:2412.01951 [cs]\nTLDR: A new perspective on the capabilities of self-improvement through a lens the authors refer to as sharpening is offered, which formalizes self-improvement as using the model itself as a verifier during post-training in order to ``sharpen'' the model to one placing large mass on high-quality sequences, thereby amortizing the expensive inference-time computation of generating good sequences.",
    "number": "arXiv:2412.01951",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Self-Improvement in Language Models: The Sharpening Mechanism",
    "title-short": "Self-Improvement in Language Models",
    "URL": "http://arxiv.org/abs/2412.01951",
    "author": [
      {
        "family": "Huang",
        "given": "Audrey"
      },
      {
        "family": "Block",
        "given": "Adam"
      },
      {
        "family": "Foster",
        "given": "Dylan J."
      },
      {
        "family": "Rohatgi",
        "given": "Dhruv"
      },
      {
        "family": "Zhang",
        "given": "Cyril"
      },
      {
        "family": "Simchowitz",
        "given": "Max"
      },
      {
        "family": "Ash",
        "given": "Jordan T."
      },
      {
        "family": "Krishnamurthy",
        "given": "Akshay"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 12, 4]]
    },
    "issued": {
      "date-parts": [["2024", 12, 2]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/ZCFRBFY6",
    "type": "article",
    "abstract": "Synthetic data generation with Large Language Models is a promising paradigm for augmenting natural data over a nearly infinite range of tasks. Given this variety, direct comparisons among synthetic data generation algorithms are scarce, making it difficult to understand where improvement comes from and what bottlenecks exist. We propose to evaluate algorithms via the makeup of synthetic data generated by each algorithm in terms of data quality, diversity, and complexity. We choose these three characteristics for their significance in open-ended processes and the impact each has on the capabilities of downstream models. We find quality to be essential for in-distribution model generalization, diversity to be essential for out-of-distribution generalization, and complexity to be beneficial for both. Further, we emphasize the existence of Quality-Diversity trade-offs in training data and the downstream effects on model performance. We then examine the effect of various components in the synthetic data pipeline on each data characteristic. This examination allows us to taxonomize and compare synthetic data generation algorithms through the components they utilize and the resulting effects on data QDC composition. This analysis extends into a discussion on the importance of balancing QDC in synthetic data for efficient reinforcement learning and self-improvement algorithms. Analogous to the QD trade-offs in training data, often there exist trade-offs between model output quality and output diversity which impact the composition of synthetic data. We observe that many models are currently evaluated and optimized only for output quality, thereby limiting output diversity and the potential for self-improvement. We argue that balancing these trade-offs is essential to the development of future self-improvement algorithms and highlight a number of works making progress in this direction.",
    "DOI": "10.48550/arXiv.2412.02980",
    "language": "en-US",
    "note": "arXiv:2412.02980 [cs]\nTLDR: It is argued that balancing these trade-offs is essential to the development of future self-improvement algorithms and highlight a number of works making progress in this direction.",
    "number": "arXiv:2412.02980",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Surveying the Effects of Quality, Diversity, and Complexity in Synthetic Data From Large Language Models",
    "URL": "http://arxiv.org/abs/2412.02980",
    "author": [
      {
        "family": "Havrilla",
        "given": "Alex"
      },
      {
        "family": "Dai",
        "given": "Andrew"
      },
      {
        "family": "O'Mahony",
        "given": "Laura"
      },
      {
        "family": "Oostermeijer",
        "given": "Koen"
      },
      {
        "family": "Zisler",
        "given": "Vera"
      },
      {
        "family": "Albalak",
        "given": "Alon"
      },
      {
        "family": "Milo",
        "given": "Fabrizio"
      },
      {
        "family": "Raparthy",
        "given": "Sharath Chandra"
      },
      {
        "family": "Gandhi",
        "given": "Kanishk"
      },
      {
        "family": "Abbasi",
        "given": "Baber"
      },
      {
        "family": "Phung",
        "given": "Duy"
      },
      {
        "family": "Iyer",
        "given": "Maia"
      },
      {
        "family": "Mahan",
        "given": "Dakota"
      },
      {
        "family": "Blagden",
        "given": "Chase"
      },
      {
        "family": "Gureja",
        "given": "Srishti"
      },
      {
        "family": "Hamdy",
        "given": "Mohammed"
      },
      {
        "family": "Li",
        "given": "Wen-Ding"
      },
      {
        "family": "Paolini",
        "given": "Giovanni"
      },
      {
        "family": "Ammanamanchi",
        "given": "Pawan Sasanka"
      },
      {
        "family": "Meyerson",
        "given": "Elliot"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 12, 5]]
    },
    "issued": {
      "date-parts": [["2024", 12, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/NWADZKWG",
    "type": "article",
    "abstract": "Different from its counterpart outcome reward models (ORMs), which evaluate the entire responses, a process reward model (PRM) scores a reasoning trajectory step by step, providing denser and more fine grained rewards. However, training a PRM requires labels annotated at every intermediate step, presenting significant challenges for both manual and automatic data collection. This paper aims to address this challenge. Both theoretically and empirically, we show that an \\textit{implicit PRM} can be obtained at no additional cost, by simply training an ORM on the cheaper response-level labels. The only assumption is to parameterize the outcome reward as the log-likelihood ratios of the policy and reference models, which can be optimized regardless of the specific choice of loss objectives. In experiments, we instantiate our implicit PRMs with various objectives and evaluate their performance on MATH. We show that our implicit PRM outperforms a strong MCTS-based baseline \\textit{\\'a la} Math-Shepherd using less than $1/38$ of the training data. Its performance can be further improved with majority voting. We further find that scaling up instructions and responses benefits our implicit PRM, and the latter brings a larger gain. Particularly, we find that our implicit PRM, when instantiated with the cross-entropy (CE) loss, is more data-efficient and can keep improving generation models even when trained with only one response per instruction, the setup that suffers from extreme data scarcity and imbalance. Further, instructions should be relevant to downstream tasks while the diversity of responses does not bring gains. Surprisingly, training on extra Math-Shepherd step labels brings no further improvements to our implicit PRM trained on only outcome data. We hope that our work will encourage a rethinking of PRM training approaches and contribute to making training PRMs more accessible.",
    "DOI": "10.48550/arXiv.2412.01981",
    "language": "en-US",
    "note": "arXiv:2412.01981 [cs]\nTLDR: The implicit PRM, when instantiated with the cross-entropy (CE) loss, is more data-efficient and can keep improving generation models even when trained with only one response per instruction, the setup that suffers from extreme data scarcity and imbalance.",
    "number": "arXiv:2412.01981",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Free Process Rewards without Process Labels",
    "URL": "http://arxiv.org/abs/2412.01981",
    "author": [
      {
        "family": "Yuan",
        "given": "Lifan"
      },
      {
        "family": "Li",
        "given": "Wendi"
      },
      {
        "family": "Chen",
        "given": "Huayu"
      },
      {
        "family": "Cui",
        "given": "Ganqu"
      },
      {
        "family": "Ding",
        "given": "Ning"
      },
      {
        "family": "Zhang",
        "given": "Kaiyan"
      },
      {
        "family": "Zhou",
        "given": "Bowen"
      },
      {
        "family": "Liu",
        "given": "Zhiyuan"
      },
      {
        "family": "Peng",
        "given": "Hao"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 12, 5]]
    },
    "issued": {
      "date-parts": [["2024", 12, 2]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/T47LDGY9",
    "type": "article",
    "abstract": "Given the increasing use of synthetic data in language model (LM) post-training, an LM's ability to generate high-quality data has become nearly as crucial as its ability to solve problems directly. While prior works have focused on developing effective data generation methods, they lack systematic comparison of different LMs as data generators in a unified setting. To address this gap, we propose AgoraBench, a benchmark that provides standardized settings and metrics to evaluate LMs' data generation abilities. Through synthesizing 1.26 million training instances using 6 LMs and training 99 student models, we uncover key insights about LMs' data generation capabilities. First, we observe that LMs exhibit distinct strengths. For instance, GPT-4o excels at generating new problems, while Claude-3.5-Sonnet performs better at enhancing existing ones. Furthermore, our analysis reveals that an LM's data generation ability doesn't necessarily correlate with its problem-solving ability. Instead, multiple intrinsic features of data quality-including response quality, perplexity, and instruction difficulty-collectively serve as better indicators. Finally, we demonstrate that strategic choices in output format and cost-conscious model selection significantly impact data generation effectiveness.",
    "DOI": "10.48550/arXiv.2412.03679",
    "language": "en-US",
    "note": "arXiv:2412.03679 [cs]\nTLDR: This work proposes AgoraBench, a benchmark that provides standardized settings and metrics to evaluate LMs' data generation abilities and reveals that multiple intrinsic features of data quality-including response quality, perplexity, and instruction difficulty-collectively serve as better indicators.",
    "number": "arXiv:2412.03679",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Evaluating Language Models as Synthetic Data Generators",
    "URL": "http://arxiv.org/abs/2412.03679",
    "author": [
      {
        "family": "Kim",
        "given": "Seungone"
      },
      {
        "family": "Suk",
        "given": "Juyoung"
      },
      {
        "family": "Yue",
        "given": "Xiang"
      },
      {
        "family": "Viswanathan",
        "given": "Vijay"
      },
      {
        "family": "Lee",
        "given": "Seongyun"
      },
      {
        "family": "Wang",
        "given": "Yizhong"
      },
      {
        "family": "Gashteovski",
        "given": "Kiril"
      },
      {
        "family": "Lawrence",
        "given": "Carolin"
      },
      {
        "family": "Welleck",
        "given": "Sean"
      },
      {
        "family": "Neubig",
        "given": "Graham"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 12, 6]]
    },
    "issued": {
      "date-parts": [["2024", 12, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/78UX924C",
    "type": "article",
    "abstract": "Recent research has focused on enhancing the capability of smaller models through imitation learning, drawing on the outputs generated by large foundation models (LFMs). A number of issues impact the quality of these models, ranging from limited imitation signals from shallow LFM outputs; small scale homogeneous training data; and most notably a lack of rigorous evaluation resulting in overestimating the small model's capability as they tend to learn to imitate the style, but not the reasoning process of LFMs. To address these challenges, we develop Orca (We are working with our legal team to publicly release a diff of the model weights in accordance with LLaMA's release policy to be published at https://aka.ms/orca-lm), a 13-billion parameter model that learns to imitate the reasoning process of LFMs. Orca learns from rich signals from GPT-4 including explanation traces; step-by-step thought processes; and other complex instructions, guided by teacher assistance from ChatGPT. To promote this progressive learning, we tap into large-scale and diverse imitation data with judicious sampling and selection. Orca surpasses conventional state-of-the-art instruction-tuned models such as Vicuna-13B by more than 100% in complex zero-shot reasoning benchmarks like Big-Bench Hard (BBH) and 42% on AGIEval. Moreover, Orca reaches parity with ChatGPT on the BBH benchmark and shows competitive performance (4 pts gap with optimized system message) in professional and academic examinations like the SAT, LSAT, GRE, and GMAT, both in zero-shot settings without CoT; while trailing behind GPT-4. Our research indicates that learning from step-by-step explanations, whether these are generated by humans or more advanced AI models, is a promising direction to improve model capabilities and skills.",
    "DOI": "10.48550/arXiv.2306.02707",
    "language": "en-US",
    "note": "arXiv:2306.02707 [cs]\nTLDR: Orca is developed, a 13-billion parameter model that learns to imitate the reasoning process of LFMs, indicating that learning from step-by-step explanations, whether these are generated by humans or more advanced AI models, is a promising direction to improve model capabilities and skills.",
    "number": "arXiv:2306.02707",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Orca: Progressive Learning from Complex Explanation Traces of GPT-4",
    "title-short": "Orca",
    "URL": "http://arxiv.org/abs/2306.02707",
    "author": [
      {
        "family": "Mukherjee",
        "given": "Subhabrata"
      },
      {
        "family": "Mitra",
        "given": "Arindam"
      },
      {
        "family": "Jawahar",
        "given": "Ganesh"
      },
      {
        "family": "Agarwal",
        "given": "Sahaj"
      },
      {
        "family": "Palangi",
        "given": "Hamid"
      },
      {
        "family": "Awadallah",
        "given": "Ahmed"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 12, 11]]
    },
    "issued": {
      "date-parts": [["2023", 6, 5]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/GH3FKUTJ",
    "type": "article",
    "abstract": "We introduce phi-1, a new large language model for code, with significantly smaller size than competing models: phi-1 is a Transformer-based model with 1.3B parameters, trained for 4 days on 8 A100s, using a selection of ``textbook quality\" data from the web (6B tokens) and synthetically generated textbooks and exercises with GPT-3.5 (1B tokens). Despite this small scale, phi-1 attains pass@1 accuracy 50.6% on HumanEval and 55.5% on MBPP. It also displays surprising emergent properties compared to phi-1-base, our model before our finetuning stage on a dataset of coding exercises, and phi-1-small, a smaller model with 350M parameters trained with the same pipeline as phi-1 that still achieves 45% on HumanEval.",
    "DOI": "10.48550/arXiv.2306.11644",
    "language": "en-US",
    "note": "arXiv:2306.11644 [cs]",
    "number": "arXiv:2306.11644",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Textbooks Are All You Need",
    "URL": "http://arxiv.org/abs/2306.11644",
    "author": [
      {
        "family": "Gunasekar",
        "given": "Suriya"
      },
      {
        "family": "Zhang",
        "given": "Yi"
      },
      {
        "family": "Aneja",
        "given": "Jyoti"
      },
      {
        "family": "Mendes",
        "given": "Caio César Teodoro"
      },
      {
        "family": "Giorno",
        "given": "Allie Del"
      },
      {
        "family": "Gopi",
        "given": "Sivakanth"
      },
      {
        "family": "Javaheripi",
        "given": "Mojan"
      },
      {
        "family": "Kauffmann",
        "given": "Piero"
      },
      {
        "family": "Rosa",
        "given": "Gustavo",
        "dropping-particle": "de"
      },
      {
        "family": "Saarikivi",
        "given": "Olli"
      },
      {
        "family": "Salim",
        "given": "Adil"
      },
      {
        "family": "Shah",
        "given": "Shital"
      },
      {
        "family": "Behl",
        "given": "Harkirat Singh"
      },
      {
        "family": "Wang",
        "given": "Xin"
      },
      {
        "family": "Bubeck",
        "given": "Sébastien"
      },
      {
        "family": "Eldan",
        "given": "Ronen"
      },
      {
        "family": "Kalai",
        "given": "Adam Tauman"
      },
      {
        "family": "Lee",
        "given": "Yin Tat"
      },
      {
        "family": "Li",
        "given": "Yuanzhi"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 12, 11]]
    },
    "issued": {
      "date-parts": [["2023", 10, 2]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/CVYYT8ZR",
    "type": "article",
    "abstract": "How well can NLP models generalize to a variety of unseen tasks when provided with task instructions? To address this question, we first introduce Super-NaturalInstructions, a benchmark of 1,616 diverse NLP tasks and their expert-written instructions. Our collection covers 76 distinct task types, including but not limited to classification, extraction, infilling, sequence tagging, text rewriting, and text composition. This large and diverse collection of tasks enables rigorous benchmarking of cross-task generalization under instructions -- training models to follow instructions on a subset of tasks and evaluating them on the remaining unseen ones. Furthermore, we build Tk-Instruct, a transformer model trained to follow a variety of in-context instructions (plain language task definitions or k-shot examples). Our experiments show that Tk-Instruct outperforms existing instruction-following models such as InstructGPT by over 9% on our benchmark despite being an order of magnitude smaller. We further analyze generalization as a function of various scaling parameters, such as the number of observed tasks, the number of instances per task, and model sizes. We hope our dataset and model facilitate future progress towards more general-purpose NLP models.",
    "DOI": "10.48550/arXiv.2204.07705",
    "language": "en-US",
    "note": "arXiv:2204.07705 [cs]",
    "number": "arXiv:2204.07705",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks",
    "title-short": "Super-NaturalInstructions",
    "URL": "http://arxiv.org/abs/2204.07705",
    "author": [
      {
        "family": "Wang",
        "given": "Yizhong"
      },
      {
        "family": "Mishra",
        "given": "Swaroop"
      },
      {
        "family": "Alipoormolabashi",
        "given": "Pegah"
      },
      {
        "family": "Kordi",
        "given": "Yeganeh"
      },
      {
        "family": "Mirzaei",
        "given": "Amirreza"
      },
      {
        "family": "Arunkumar",
        "given": "Anjana"
      },
      {
        "family": "Ashok",
        "given": "Arjun"
      },
      {
        "family": "Dhanasekaran",
        "given": "Arut Selvan"
      },
      {
        "family": "Naik",
        "given": "Atharva"
      },
      {
        "family": "Stap",
        "given": "David"
      },
      {
        "family": "Pathak",
        "given": "Eshaan"
      },
      {
        "family": "Karamanolakis",
        "given": "Giannis"
      },
      {
        "family": "Lai",
        "given": "Haizhi Gary"
      },
      {
        "family": "Purohit",
        "given": "Ishan"
      },
      {
        "family": "Mondal",
        "given": "Ishani"
      },
      {
        "family": "Anderson",
        "given": "Jacob"
      },
      {
        "family": "Kuznia",
        "given": "Kirby"
      },
      {
        "family": "Doshi",
        "given": "Krima"
      },
      {
        "family": "Patel",
        "given": "Maitreya"
      },
      {
        "family": "Pal",
        "given": "Kuntal Kumar"
      },
      {
        "family": "Moradshahi",
        "given": "Mehrad"
      },
      {
        "family": "Parmar",
        "given": "Mihir"
      },
      {
        "family": "Purohit",
        "given": "Mirali"
      },
      {
        "family": "Varshney",
        "given": "Neeraj"
      },
      {
        "family": "Kaza",
        "given": "Phani Rohitha"
      },
      {
        "family": "Verma",
        "given": "Pulkit"
      },
      {
        "family": "Puri",
        "given": "Ravsehaj Singh"
      },
      {
        "family": "Karia",
        "given": "Rushang"
      },
      {
        "family": "Sampat",
        "given": "Shailaja Keyur"
      },
      {
        "family": "Doshi",
        "given": "Savan"
      },
      {
        "family": "Mishra",
        "given": "Siddhartha"
      },
      {
        "family": "Reddy",
        "given": "Sujan"
      },
      {
        "family": "Patro",
        "given": "Sumanta"
      },
      {
        "family": "Dixit",
        "given": "Tanay"
      },
      {
        "family": "Shen",
        "given": "Xudong"
      },
      {
        "family": "Baral",
        "given": "Chitta"
      },
      {
        "family": "Choi",
        "given": "Yejin"
      },
      {
        "family": "Smith",
        "given": "Noah A."
      },
      {
        "family": "Hajishirzi",
        "given": "Hannaneh"
      },
      {
        "family": "Khashabi",
        "given": "Daniel"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 12, 11]]
    },
    "issued": {
      "date-parts": [["2022", 10, 24]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/GGUI9QGC",
    "type": "article",
    "abstract": "Instruction tuning has been widely used to unleash the complete potential of large language models. Notably, complex and diverse instructions are of significant importance as they can effectively align models with various downstream tasks. However, current approaches to constructing large-scale instructions predominantly favour powerful models such as GPT-4 or those with over 70 billion parameters, under the empirical presumption that such larger language models (LLMs) inherently possess enhanced capabilities. In this study, we question this prevalent assumption and conduct an in-depth exploration into the potential of smaller language models (SLMs) in the context of instruction evolution. Extensive experiments across three scenarios of instruction evolution reveal that smaller language models (SLMs) can synthesize more effective instructions than LLMs. Further analysis demonstrates that SLMs possess a broader output space during instruction evolution, resulting in more complex and diverse variants. We also observe that the existing metrics fail to focus on the impact of the instructions. Thus, we propose Instruction Complex-Aware IFD (IC-IFD), which introduces instruction complexity in the original IFD score to evaluate the effectiveness of instruction data more accurately. Our source code is available at: \\href{https://github.com/HypherX/Evolution-Analysis}{https://github.com/HypherX/Evolution-Analysis}",
    "DOI": "10.48550/arXiv.2412.11231",
    "language": "en-US",
    "note": "arXiv:2412.11231 [cs]\nversion: 1\nTLDR: This study proposes Instruction Complex-Aware IFD (IC-IFD), which introduces instruction complexity in the original IFD score to evaluate the effectiveness of instruction data more accurately and demonstrates that smaller language models (SLMs) can synthesize more effective instructions than LLMs.",
    "number": "arXiv:2412.11231",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Smaller Language Models Are Better Instruction Evolvers",
    "URL": "http://arxiv.org/abs/2412.11231",
    "author": [
      {
        "family": "Hui",
        "given": "Tingfeng"
      },
      {
        "family": "Zhao",
        "given": "Lulu"
      },
      {
        "family": "Dong",
        "given": "Guanting"
      },
      {
        "family": "Zhang",
        "given": "Yaqi"
      },
      {
        "family": "Zhou",
        "given": "Hua"
      },
      {
        "family": "Su",
        "given": "Sen"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 12, 20]]
    },
    "issued": {
      "date-parts": [["2024", 12, 15]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/F26M95ZE",
    "type": "article",
    "abstract": "In this report, we introduce Qwen2.5, a comprehensive series of large language models (LLMs) designed to meet diverse needs. Compared to previous iterations, Qwen 2.5 has been significantly improved during both the pre-training and post-training stages. In terms of pre-training, we have scaled the high-quality pre-training datasets from the previous 7 trillion tokens to 18 trillion tokens. This provides a strong foundation for common sense, expert knowledge, and reasoning capabilities. In terms of post-training, we implement intricate supervised finetuning with over 1 million samples, as well as multistage reinforcement learning. Post-training techniques enhance human preference, and notably improve long text generation, structural data analysis, and instruction following. To handle diverse and varied use cases effectively, we present Qwen2.5 LLM series in rich sizes. Open-weight offerings include base and instruction-tuned models, with quantized versions available. In addition, for hosted solutions, the proprietary models currently include two mixture-of-experts (MoE) variants: Qwen2.5-Turbo and Qwen2.5-Plus, both available from Alibaba Cloud Model Studio. Qwen2.5 has demonstrated top-tier performance on a wide range of benchmarks evaluating language understanding, reasoning, mathematics, coding, human preference alignment, etc. Specifically, the open-weight flagship Qwen2.5-72B-Instruct outperforms a number of open and proprietary models and demonstrates competitive performance to the state-of-the-art open-weight model, Llama-3-405B-Instruct, which is around 5 times larger. Qwen2.5-Turbo and Qwen2.5-Plus offer superior cost-effectiveness while performing competitively against GPT-4o-mini and GPT-4o respectively. Additionally, as the foundation, Qwen2.5 models have been instrumental in training specialized models such as Qwen2.5-Math, Qwen2.5-Coder, QwQ, and multimodal models.",
    "DOI": "10.48550/arXiv.2412.15115",
    "language": "en-US",
    "note": "arXiv:2412.15115 [cs]",
    "number": "arXiv:2412.15115",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Qwen2.5 Technical Report",
    "URL": "http://arxiv.org/abs/2412.15115",
    "author": [
      {
        "family": "Qwen",
        "given": ""
      },
      {
        "family": "Yang",
        "given": "An"
      },
      {
        "family": "Yang",
        "given": "Baosong"
      },
      {
        "family": "Zhang",
        "given": "Beichen"
      },
      {
        "family": "Hui",
        "given": "Binyuan"
      },
      {
        "family": "Zheng",
        "given": "Bo"
      },
      {
        "family": "Yu",
        "given": "Bowen"
      },
      {
        "family": "Li",
        "given": "Chengyuan"
      },
      {
        "family": "Liu",
        "given": "Dayiheng"
      },
      {
        "family": "Huang",
        "given": "Fei"
      },
      {
        "family": "Wei",
        "given": "Haoran"
      },
      {
        "family": "Lin",
        "given": "Huan"
      },
      {
        "family": "Yang",
        "given": "Jian"
      },
      {
        "family": "Tu",
        "given": "Jianhong"
      },
      {
        "family": "Zhang",
        "given": "Jianwei"
      },
      {
        "family": "Yang",
        "given": "Jianxin"
      },
      {
        "family": "Yang",
        "given": "Jiaxi"
      },
      {
        "family": "Zhou",
        "given": "Jingren"
      },
      {
        "family": "Lin",
        "given": "Junyang"
      },
      {
        "family": "Dang",
        "given": "Kai"
      },
      {
        "family": "Lu",
        "given": "Keming"
      },
      {
        "family": "Bao",
        "given": "Keqin"
      },
      {
        "family": "Yang",
        "given": "Kexin"
      },
      {
        "family": "Yu",
        "given": "Le"
      },
      {
        "family": "Li",
        "given": "Mei"
      },
      {
        "family": "Xue",
        "given": "Mingfeng"
      },
      {
        "family": "Zhang",
        "given": "Pei"
      },
      {
        "family": "Zhu",
        "given": "Qin"
      },
      {
        "family": "Men",
        "given": "Rui"
      },
      {
        "family": "Lin",
        "given": "Runji"
      },
      {
        "family": "Li",
        "given": "Tianhao"
      },
      {
        "family": "Xia",
        "given": "Tingyu"
      },
      {
        "family": "Ren",
        "given": "Xingzhang"
      },
      {
        "family": "Ren",
        "given": "Xuancheng"
      },
      {
        "family": "Fan",
        "given": "Yang"
      },
      {
        "family": "Su",
        "given": "Yang"
      },
      {
        "family": "Zhang",
        "given": "Yichang"
      },
      {
        "family": "Wan",
        "given": "Yu"
      },
      {
        "family": "Liu",
        "given": "Yuqiong"
      },
      {
        "family": "Cui",
        "given": "Zeyu"
      },
      {
        "family": "Zhang",
        "given": "Zhenru"
      },
      {
        "family": "Qiu",
        "given": "Zihan"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 12, 20]]
    },
    "issued": {
      "date-parts": [["2024", 12, 19]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/TA5FKHA2",
    "type": "paper-conference",
    "abstract": "Fine-tuning large pre-trained language models with Evol-Instruct has achieved encouraging results across a wide range of tasks. However, designing effective evolving methods for instruction evolution requires substantial human expertise. This paper proposes Auto Evol-Instruct, an end-to-end framework that evolves instruction datasets using large language models without any human effort. The framework automatically analyzes and summarizes suitable evolutionary strategies for the given instruction data and iteratively improves the evolving method based on issues exposed during the instruction evolution process. Our extensive experiments demonstrate that the best method optimized by Auto Evol-Instruct outperforms human-designed methods on various benchmarks, including MT-Bench, AlpacaEval, GSM8K, and HumanEval.",
    "container-title": "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    "DOI": "10.18653/v1/2024.emnlp-main.397",
    "event-place": "Miami, Florida, USA",
    "event-title": "EMNLP 2024",
    "language": "en-US",
    "page": "6998–7018",
    "publisher": "Association for Computational Linguistics",
    "publisher-place": "Miami, Florida, USA",
    "source": "ACLWeb",
    "title": "Automatic Instruction Evolving for Large Language Models",
    "URL": "https://aclanthology.org/2024.emnlp-main.397",
    "author": [
      {
        "family": "Zeng",
        "given": "Weihao"
      },
      {
        "family": "Xu",
        "given": "Can"
      },
      {
        "family": "Zhao",
        "given": "Yingxiu"
      },
      {
        "family": "Lou",
        "given": "Jian-Guang"
      },
      {
        "family": "Chen",
        "given": "Weizhu"
      }
    ],
    "editor": [
      {
        "family": "Al-Onaizan",
        "given": "Yaser"
      },
      {
        "family": "Bansal",
        "given": "Mohit"
      },
      {
        "family": "Chen",
        "given": "Yun-Nung"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 12, 25]]
    },
    "issued": {
      "date-parts": [["2024", 11]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/EQCXKSDR",
    "type": "article",
    "abstract": "Datasets nowadays are generally constructed from multiple sources and using different synthetic techniques, making data de-noising and de-duplication crucial before being used for post-training. In this work, we propose to perform instruction tuning by iterative data selection (\\ApproachName{}). We measure the quality of a sample from complexity and diversity simultaneously. Instead of calculating the complexity score once for all before fine-tuning, we highlight the importance of updating this model-specific score during fine-tuning to accurately accommodate the dynamic changes of the model. On the other hand, the diversity score is defined on top of the samples' responses under the consideration of their informativeness. IterIT integrates the strengths of both worlds by iteratively updating the complexity score for the top-ranked samples and greedily selecting the ones with the highest complexity-diversity score. Experiments on multiple instruction-tuning data demonstrate consistent improvements of IterIT over strong baselines. Moreover, our approach also generalizes well to domain-specific scenarios and different backbone models. All resources will be available at https://github.com/JiaQiSJTU/IterIT.",
    "DOI": "10.48550/arXiv.2412.17365",
    "language": "en-US",
    "note": "arXiv:2412.17365 [cs]\nTLDR: This work proposes to perform instruction tuning by iterative data selection by iteratively updating the complexity score for the top-ranked samples and greedily selecting the ones with the highest complexity-diversity score.",
    "number": "arXiv:2412.17365",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Boosting LLM via Learning from Data Iteratively and Selectively",
    "URL": "http://arxiv.org/abs/2412.17365",
    "author": [
      {
        "family": "Jia",
        "given": "Qi"
      },
      {
        "family": "Ren",
        "given": "Siyu"
      },
      {
        "family": "Qin",
        "given": "Ziheng"
      },
      {
        "family": "Xue",
        "given": "Fuzhao"
      },
      {
        "family": "Ni",
        "given": "Jinjie"
      },
      {
        "family": "You",
        "given": "Yang"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 12, 26]]
    },
    "issued": {
      "date-parts": [["2024", 12, 23]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/VNXK9PC4",
    "type": "article",
    "abstract": "We introduce DavIR, a model-based data selection method for post-training Large Language Models. DavIR generalizes Reducible Holdout Loss to core-set selection problem of causal language modeling, and quantifies the learnability of a given datum with respect to a pre-trained LLM based on relative reduction in loss during fine-tuning, a metric we show to be closely related to the implicit reward model described in Direct Preference Optimization (DPO). We show that 6% of Alpaca dataset selected with DavIR can steer both the LLaMA and Gemma model family to produce superior performance compared to the same models trained on the full 52K dataset. We also show that Alpaca dataset compressed with DavIR can be combined with GSM8K dataset to effectively balance open-domain freeform QA and mathematical reasoning capabilities. Finally, we apply the DavIR objective to DPO and develop a normalized DavIR-DPO objective which improves alignment performance of Zephyr-7B-SFT model by 8% (relative) on AlpacaEval, compared against training on vanilla DPO objective.",
    "DOI": "10.48550/arXiv.2310.13008",
    "language": "en-US",
    "note": "arXiv:2310.13008 [cs]\nversion: 2",
    "number": "arXiv:2310.13008",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "DavIR: Data Selection via Implicit Reward for Large Language Models",
    "title-short": "DavIR",
    "URL": "http://arxiv.org/abs/2310.13008",
    "author": [
      {
        "family": "Zhou",
        "given": "Haotian"
      },
      {
        "family": "Liu",
        "given": "Tingkai"
      },
      {
        "family": "Ma",
        "given": "Qianli"
      },
      {
        "family": "Zhang",
        "given": "Yufeng"
      },
      {
        "family": "Yuan",
        "given": "Jianbo"
      },
      {
        "family": "Liu",
        "given": "Pengfei"
      },
      {
        "family": "You",
        "given": "Yang"
      },
      {
        "family": "Yang",
        "given": "Hongxia"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 12, 26]]
    },
    "issued": {
      "date-parts": [["2024", 12, 19]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/T4ESXS3F",
    "type": "article",
    "abstract": "Instruction tuning is a standard technique employed to align large language models to end tasks and user preferences after the initial pretraining phase. Recent research indicates the critical role of data engineering in instruction tuning -- when appropriately selected, only limited data is necessary to achieve superior performance. However, we still lack a principled understanding of what makes good instruction tuning data for alignment, and how we should select data automatically and effectively. In this work, we delve deeply into automatic data selection strategies for alignment. We start with controlled studies to measure data across three dimensions: complexity, quality, and diversity, along which we examine existing methods and introduce novel techniques for enhanced data measurement. Subsequently, we propose a simple strategy to select data samples based on the measurement. We present deita (short for Data-Efficient Instruction Tuning for Alignment), a series of models fine-tuned from LLaMA and Mistral models using data samples automatically selected with our proposed approach. Empirically, deita performs better or on par with the state-of-the-art open-source alignment models with only 6K SFT training data samples -- over 10x less than the data used in the baselines. When further trained with direct preference optimization (DPO), deita-Mistral-7B + DPO trained with 6K SFT and 10K DPO samples achieve 7.55 MT-Bench and 90.06% AlpacaEval scores. We anticipate this work to provide tools on automatic data selection, facilitating data-efficient alignment. We release our models as well as the selected datasets for future researches to effectively align models more efficiently.",
    "DOI": "10.48550/arXiv.2312.15685",
    "language": "en-US",
    "note": "arXiv:2312.15685 [cs]\nTLDR: This work presents deita (short for Data-Efficient Instruction Tuning for Alignment), a series of models fine-tuned from LLaMA and Mistral models using data samples automatically selected with this proposed approach, and proposes a simple strategy to select data samples based on the measurement.",
    "number": "arXiv:2312.15685",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning",
    "title-short": "What Makes Good Data for Alignment?",
    "URL": "http://arxiv.org/abs/2312.15685",
    "author": [
      {
        "family": "Liu",
        "given": "Wei"
      },
      {
        "family": "Zeng",
        "given": "Weihao"
      },
      {
        "family": "He",
        "given": "Keqing"
      },
      {
        "family": "Jiang",
        "given": "Yong"
      },
      {
        "family": "He",
        "given": "Junxian"
      }
    ],
    "accessed": {
      "date-parts": [["2024", 12, 26]]
    },
    "issued": {
      "date-parts": [["2024", 4, 16]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/2PUC924V",
    "type": "article",
    "abstract": "Alignment has become a critical step for instruction-tuned Large Language Models (LLMs) to become helpful assistants. However, the effective evaluation of alignment for emerging Chinese LLMs is still largely unexplored. To fill in this gap, we introduce AlignBench, a comprehensive multi-dimensional benchmark for evaluating LLMs' alignment in Chinese. We design a human-in-the-loop data curation pipeline, containing eight main categories, 683 real-scenario rooted queries and corresponding human verified references. To ensure the correctness of references, each knowledge-intensive query is accompanied with evidences collected from reliable web sources (including URLs and quotations) by our annotators. For automatic evaluation, our benchmark employs a rule-calibrated multi-dimensional LLM-as-Judge~\\cite{zheng2023judging} approach with Chain-of-Thought to generate explanations and final ratings, ensuring high reliability and interpretability. All evaluation code, data, and LLM generations are available at \\url{https://github.com/THUDM/AlignBench}. Since its release, AlignBench has been adopted by top (Chinese) LLMs for evaluating their alignment capabilities in Chinese, including ChatGLM, Qwen, DeepSeek, Yi, Baichuan, and Abab.",
    "DOI": "10.48550/arXiv.2311.18743",
    "language": "en-US",
    "note": "arXiv:2311.18743 [cs]\nTLDR: AlignBench, a comprehensive multi-dimensional benchmark for evaluating LLMs' alignment in Chinese, is introduced, containing a human-in-the-loop data curation pipeline, containing eight main categories, 683 real-scenario rooted queries and corresponding human verified references.",
    "number": "arXiv:2311.18743",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "AlignBench: Benchmarking Chinese Alignment of Large Language Models",
    "title-short": "AlignBench",
    "URL": "http://arxiv.org/abs/2311.18743",
    "author": [
      {
        "family": "Liu",
        "given": "Xiao"
      },
      {
        "family": "Lei",
        "given": "Xuanyu"
      },
      {
        "family": "Wang",
        "given": "Shengyuan"
      },
      {
        "family": "Huang",
        "given": "Yue"
      },
      {
        "family": "Feng",
        "given": "Zhuoer"
      },
      {
        "family": "Wen",
        "given": "Bosi"
      },
      {
        "family": "Cheng",
        "given": "Jiale"
      },
      {
        "family": "Ke",
        "given": "Pei"
      },
      {
        "family": "Xu",
        "given": "Yifan"
      },
      {
        "family": "Tam",
        "given": "Weng Lam"
      },
      {
        "family": "Zhang",
        "given": "Xiaohan"
      },
      {
        "family": "Sun",
        "given": "Lichao"
      },
      {
        "family": "Gu",
        "given": "Xiaotao"
      },
      {
        "family": "Wang",
        "given": "Hongning"
      },
      {
        "family": "Zhang",
        "given": "Jing"
      },
      {
        "family": "Huang",
        "given": "Minlie"
      },
      {
        "family": "Dong",
        "given": "Yuxiao"
      },
      {
        "family": "Tang",
        "given": "Jie"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 1, 21]]
    },
    "issued": {
      "date-parts": [["2024", 8, 25]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/J7AN9ZJ5",
    "type": "article",
    "abstract": "LLM-based auto-annotators have become a key component of the LLM development process due to their cost-effectiveness and scalability compared to human-based evaluation. However, these auto-annotators can introduce complex biases that are hard to remove. Even simple, known confounders such as preference for longer outputs remain in existing automated evaluation metrics. We propose a simple regression analysis approach for controlling biases in auto-evaluations. As a real case study, we focus on reducing the length bias of AlpacaEval, a fast and affordable benchmark for chat LLMs that uses LLMs to estimate response quality. Despite being highly correlated with human preferences, AlpacaEval is known to favor models that generate longer outputs. We introduce a length-controlled AlpacaEval that aims to answer the counterfactual question: \"What would the preference be if the model's and baseline's output had the same length?\". To achieve this, we first fit a generalized linear model to predict the biased output of interest (auto-annotator preferences) based on the mediators we want to control for (length difference) and other relevant features. We then obtain length-controlled preferences by predicting preferences while conditioning the GLM with a zero difference in lengths. Length-controlling not only improves the robustness of the metric to manipulations in model verbosity, we also find that it increases the Spearman correlation with LMSYS' Chatbot Arena from 0.94 to 0.98. We release the code and leaderboard at https://tatsu-lab.github.io/alpaca_eval/ .",
    "DOI": "10.48550/arXiv.2404.04475",
    "language": "en-US",
    "note": "arXiv:2404.04475 [cs]",
    "number": "arXiv:2404.04475",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Length-Controlled AlpacaEval: A Simple Way to Debias Automatic Evaluators",
    "title-short": "Length-Controlled AlpacaEval",
    "URL": "http://arxiv.org/abs/2404.04475",
    "author": [
      {
        "family": "Dubois",
        "given": "Yann"
      },
      {
        "family": "Galambosi",
        "given": "Balázs"
      },
      {
        "family": "Liang",
        "given": "Percy"
      },
      {
        "family": "Hashimoto",
        "given": "Tatsunori B."
      }
    ],
    "accessed": {
      "date-parts": [["2025", 1, 22]]
    },
    "issued": {
      "date-parts": [["2024", 4, 6]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/3LH8A8UJ",
    "type": "article",
    "abstract": "The quality of Supervised Fine-Tuning (SFT) data plays a critical role in enhancing the conversational capabilities of Large Language Models (LLMs). However, as LLMs become more advanced, the availability of high-quality human-annotated SFT data has become a significant bottleneck, necessitating a greater reliance on synthetic training data. In this work, we introduce Condor, a novel two-stage synthetic data generation framework that incorporates World Knowledge Tree and Self-Reflection Refinement to produce high-quality SFT data at scale. Our experimental results demonstrate that a base model fine-tuned on only 20K Condor-generated samples achieves superior performance compared to counterparts. The additional refinement stage in Condor further enables iterative self-improvement for LLMs at various scales (up to 72B), validating the effectiveness of our approach. Furthermore, our investigation into the scaling for synthetic data in post-training reveals substantial unexplored potential for performance improvements, opening promising avenues for future research.",
    "DOI": "10.48550/arXiv.2501.12273",
    "language": "en-US",
    "note": "arXiv:2501.12273 [cs]",
    "number": "arXiv:2501.12273",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and Refinement",
    "title-short": "Condor",
    "URL": "http://arxiv.org/abs/2501.12273",
    "author": [
      {
        "family": "Cao",
        "given": "Maosong"
      },
      {
        "family": "Zhang",
        "given": "Taolin"
      },
      {
        "family": "Li",
        "given": "Mo"
      },
      {
        "family": "Zhang",
        "given": "Chuyu"
      },
      {
        "family": "Liu",
        "given": "Yunxin"
      },
      {
        "family": "Duan",
        "given": "Haodong"
      },
      {
        "family": "Zhang",
        "given": "Songyang"
      },
      {
        "family": "Chen",
        "given": "Kai"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 1, 22]]
    },
    "issued": {
      "date-parts": [["2025", 1, 21]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/HHTA4N7V",
    "type": "article",
    "abstract": "Recent work by Zellers et al. (2018) introduced a new task of commonsense natural language inference: given an event description such as \"A woman sits at a piano,\" a machine must select the most likely followup: \"She sets her fingers on the keys.\" With the introduction of BERT, near human-level performance was reached. Does this mean that machines can perform human level commonsense inference? In this paper, we show that commonsense inference still proves difficult for even state-of-the-art models, by presenting HellaSwag, a new challenge dataset. Though its questions are trivial for humans (>95% accuracy), state-of-the-art models struggle (<48%). We achieve this via Adversarial Filtering (AF), a data collection paradigm wherein a series of discriminators iteratively select an adversarial set of machine-generated wrong answers. AF proves to be surprisingly robust. The key insight is to scale up the length and complexity of the dataset examples towards a critical 'Goldilocks' zone wherein generated text is ridiculous to humans, yet often misclassified by state-of-the-art models. Our construction of HellaSwag, and its resulting difficulty, sheds light on the inner workings of deep pretrained models. More broadly, it suggests a new path forward for NLP research, in which benchmarks co-evolve with the evolving state-of-the-art in an adversarial way, so as to present ever-harder challenges.",
    "DOI": "10.48550/arXiv.1905.07830",
    "language": "en-US",
    "note": "arXiv:1905.07830 [cs]",
    "number": "arXiv:1905.07830",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "HellaSwag: Can a Machine Really Finish Your Sentence?",
    "title-short": "HellaSwag",
    "URL": "http://arxiv.org/abs/1905.07830",
    "author": [
      {
        "family": "Zellers",
        "given": "Rowan"
      },
      {
        "family": "Holtzman",
        "given": "Ari"
      },
      {
        "family": "Bisk",
        "given": "Yonatan"
      },
      {
        "family": "Farhadi",
        "given": "Ali"
      },
      {
        "family": "Choi",
        "given": "Yejin"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 1, 24]]
    },
    "issued": {
      "date-parts": [["2019", 5, 19]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/386U3ZB7",
    "type": "article",
    "abstract": "BIG-Bench (Srivastava et al., 2022) is a diverse evaluation suite that focuses on tasks believed to be beyond the capabilities of current language models. Language models have already made good progress on this benchmark, with the best model in the BIG-Bench paper outperforming average reported human-rater results on 65% of the BIG-Bench tasks via few-shot prompting. But on what tasks do language models fall short of average human-rater performance, and are those tasks actually unsolvable by current language models? In this work, we focus on a suite of 23 challenging BIG-Bench tasks which we call BIG-Bench Hard (BBH). These are the task for which prior language model evaluations did not outperform the average human-rater. We find that applying chain-of-thought (CoT) prompting to BBH tasks enables PaLM to surpass the average human-rater performance on 10 of the 23 tasks, and Codex (code-davinci-002) to surpass the average human-rater performance on 17 of the 23 tasks. Since many tasks in BBH require multi-step reasoning, few-shot prompting without CoT, as done in the BIG-Bench evaluations (Srivastava et al., 2022), substantially underestimates the best performance and capabilities of language models, which is better captured via CoT prompting. As further analysis, we explore the interaction between CoT and model scale on BBH, finding that CoT enables emergent task performance on several BBH tasks with otherwise flat scaling curves.",
    "DOI": "10.48550/arXiv.2210.09261",
    "language": "en-US",
    "note": "arXiv:2210.09261 [cs]\nTLDR: This work finds that applying chain-of-thought (CoT) prompting to BBH tasks enables PaLM to surpass the average human-rater performance on 10 of the 23 tasks, and Codex to surpass it on 17 of the23 tasks.",
    "number": "arXiv:2210.09261",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them",
    "URL": "http://arxiv.org/abs/2210.09261",
    "author": [
      {
        "family": "Suzgun",
        "given": "Mirac"
      },
      {
        "family": "Scales",
        "given": "Nathan"
      },
      {
        "family": "Schärli",
        "given": "Nathanael"
      },
      {
        "family": "Gehrmann",
        "given": "Sebastian"
      },
      {
        "family": "Tay",
        "given": "Yi"
      },
      {
        "family": "Chung",
        "given": "Hyung Won"
      },
      {
        "family": "Chowdhery",
        "given": "Aakanksha"
      },
      {
        "family": "Le",
        "given": "Quoc V."
      },
      {
        "family": "Chi",
        "given": "Ed H."
      },
      {
        "family": "Zhou",
        "given": "Denny"
      },
      {
        "family": "Wei",
        "given": "Jason"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 1, 24]]
    },
    "issued": {
      "date-parts": [["2022", 10, 17]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/FMQKUUPH",
    "type": "article",
    "abstract": "The abilities to form and abstract concepts is key to human intelligence, but such abilities remain lacking in state-of-the-art AI systems. There has been substantial research on conceptual abstraction in AI, particularly using idealized domains such as Raven's Progressive Matrices and Bongard problems, but even when AI systems succeed on such problems, the systems are rarely evaluated in depth to see if they have actually grasped the concepts they are meant to capture. In this paper we describe an in-depth evaluation benchmark for the Abstraction and Reasoning Corpus (ARC), a collection of few-shot abstraction and analogy problems developed by Chollet [2019]. In particular, we describe ConceptARC, a new, publicly available benchmark in the ARC domain that systematically assesses abstraction and generalization abilities on a number of basic spatial and semantic concepts. ConceptARC differs from the original ARC dataset in that it is specifically organized around \"concept groups\" -- sets of problems that focus on specific concepts and that are vary in complexity and level of abstraction. We report results on testing humans on this benchmark as well as three machine solvers: the top two programs from a 2021 ARC competition and OpenAI's GPT-4. Our results show that humans substantially outperform the machine solvers on this benchmark, showing abilities to abstract and generalize concepts that are not yet captured by AI systems. We believe that this benchmark will spur improvements in the development of AI systems for conceptual abstraction and in the effective evaluation of such systems.",
    "DOI": "10.48550/arXiv.2305.07141",
    "note": "arXiv:2305.07141 [cs]\nTLDR: ConceptARC is a new, publicly available benchmark in the ARC domain that systematically assesses abstraction and generalization abilities on a number of basic spatial and semantic concepts, showing abilities to abstract and generalize concepts that are not yet captured by AI systems.",
    "number": "arXiv:2305.07141",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "The ConceptARC Benchmark: Evaluating Understanding and Generalization in the ARC Domain",
    "title-short": "The ConceptARC Benchmark",
    "URL": "http://arxiv.org/abs/2305.07141",
    "author": [
      {
        "family": "Moskvichev",
        "given": "Arseny"
      },
      {
        "family": "Odouard",
        "given": "Victor Vikram"
      },
      {
        "family": "Mitchell",
        "given": "Melanie"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 1, 24]]
    },
    "issued": {
      "date-parts": [["2023", 5, 11]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/W4CNCDA9",
    "type": "article",
    "abstract": "We propose a benchmark to measure whether a language model is truthful in generating answers to questions. The benchmark comprises 817 questions that span 38 categories, including health, law, finance and politics. We crafted questions that some humans would answer falsely due to a false belief or misconception. To perform well, models must avoid generating false answers learned from imitating human texts. We tested GPT-3, GPT-Neo/J, GPT-2 and a T5-based model. The best model was truthful on 58% of questions, while human performance was 94%. Models generated many false answers that mimic popular misconceptions and have the potential to deceive humans. The largest models were generally the least truthful. This contrasts with other NLP tasks, where performance improves with model size. However, this result is expected if false answers are learned from the training distribution. We suggest that scaling up models alone is less promising for improving truthfulness than fine-tuning using training objectives other than imitation of text from the web.",
    "DOI": "10.48550/arXiv.2109.07958",
    "language": "en-US",
    "note": "arXiv:2109.07958 [cs]",
    "number": "arXiv:2109.07958",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods",
    "title-short": "TruthfulQA",
    "URL": "http://arxiv.org/abs/2109.07958",
    "author": [
      {
        "family": "Lin",
        "given": "Stephanie"
      },
      {
        "family": "Hilton",
        "given": "Jacob"
      },
      {
        "family": "Evans",
        "given": "Owain"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 1, 24]]
    },
    "issued": {
      "date-parts": [["2022", 5, 8]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/BJMADVIJ",
    "type": "article",
    "abstract": "Recent years have witnessed a surge in the popularity of Machine Learning (ML), applied across diverse domains. However, progress is impeded by the scarcity of training data due to expensive acquisition and privacy legislation. Synthetic data emerges as a solution, but the abundance of released models and limited overview literature pose challenges for decision-making. This work surveys 417 Synthetic Data Generation (SDG) models over the last decade, providing a comprehensive overview of model types, functionality, and improvements. Common attributes are identified, leading to a classification and trend analysis. The findings reveal increased model performance and complexity, with neural network-based approaches prevailing, except for privacy-preserving data generation. Computer vision dominates, with GANs as primary generative models, while diffusion models, transformers, and RNNs compete. Implications from our performance evaluation highlight the scarcity of common metrics and datasets, making comparisons challenging. Additionally, the neglect of training and computational costs in literature necessitates attention in future research. This work serves as a guide for SDG model selection and identifies crucial areas for future exploration.",
    "DOI": "10.48550/arXiv.2401.02524",
    "note": "arXiv:2401.02524 [cs]",
    "number": "arXiv:2401.02524",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Comprehensive Exploration of Synthetic Data Generation: A Survey",
    "title-short": "Comprehensive Exploration of Synthetic Data Generation",
    "URL": "http://arxiv.org/abs/2401.02524",
    "author": [
      {
        "family": "Bauer",
        "given": "André"
      },
      {
        "family": "Trapp",
        "given": "Simon"
      },
      {
        "family": "Stenger",
        "given": "Michael"
      },
      {
        "family": "Leppich",
        "given": "Robert"
      },
      {
        "family": "Kounev",
        "given": "Samuel"
      },
      {
        "family": "Leznik",
        "given": "Mark"
      },
      {
        "family": "Chard",
        "given": "Kyle"
      },
      {
        "family": "Foster",
        "given": "Ian"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 10]]
    },
    "issued": {
      "date-parts": [["2024", 2, 1]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/KI6RG956",
    "type": "article",
    "abstract": "Within the evolving landscape of deep learning, the dilemma of data quantity and quality has been a long-standing problem. The recent advent of Large Language Models (LLMs) offers a data-centric solution to alleviate the limitations of real-world data with synthetic data generation. However, current investigations into this field lack a unified framework and mostly stay on the surface. Therefore, this paper provides an organization of relevant studies based on a generic workflow of synthetic data generation. By doing so, we highlight the gaps within existing research and outline prospective avenues for future study. This work aims to shepherd the academic and industrial communities towards deeper, more methodical inquiries into the capabilities and applications of LLMs-driven synthetic data generation.",
    "DOI": "10.48550/arXiv.2406.15126",
    "note": "arXiv:2406.15126 [cs]",
    "number": "arXiv:2406.15126",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey",
    "title-short": "On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation",
    "URL": "http://arxiv.org/abs/2406.15126",
    "author": [
      {
        "family": "Long",
        "given": "Lin"
      },
      {
        "family": "Wang",
        "given": "Rui"
      },
      {
        "family": "Xiao",
        "given": "Ruixuan"
      },
      {
        "family": "Zhao",
        "given": "Junbo"
      },
      {
        "family": "Ding",
        "given": "Xiao"
      },
      {
        "family": "Chen",
        "given": "Gang"
      },
      {
        "family": "Wang",
        "given": "Haobo"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 10]]
    },
    "issued": {
      "date-parts": [["2024", 6, 14]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/K58ICFG9",
    "type": "article",
    "abstract": "The success of Large Language Models (LLMs) is inherently linked to the availability of vast, diverse, and high-quality data for training and evaluation. However, the growth rate of high-quality data is significantly outpaced by the expansion of training datasets, leading to a looming data exhaustion crisis. This underscores the urgent need to enhance data efficiency and explore new data sources. In this context, synthetic data has emerged as a promising solution. Currently, data generation primarily consists of two major approaches: data augmentation and synthesis. This paper comprehensively reviews and summarizes data generation techniques throughout the lifecycle of LLMs, including data preparation, pre-training, fine-tuning, instruction-tuning, preference alignment, and applications. Furthermore, We discuss the current constraints faced by these methods and investigate potential pathways for future development and research. Our aspiration is to equip researchers with a clear understanding of these methodologies, enabling them to swiftly identify appropriate data generation strategies in the construction of LLMs, while providing valuable insights for future exploration.",
    "DOI": "10.48550/arXiv.2410.12896",
    "note": "arXiv:2410.12896 [cs]",
    "number": "arXiv:2410.12896",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "A Survey on Data Synthesis and Augmentation for Large Language Models",
    "URL": "http://arxiv.org/abs/2410.12896",
    "author": [
      {
        "family": "Wang",
        "given": "Ke"
      },
      {
        "family": "Zhu",
        "given": "Jiahui"
      },
      {
        "family": "Ren",
        "given": "Minjie"
      },
      {
        "family": "Liu",
        "given": "Zeming"
      },
      {
        "family": "Li",
        "given": "Shiwei"
      },
      {
        "family": "Zhang",
        "given": "Zongye"
      },
      {
        "family": "Zhang",
        "given": "Chenkai"
      },
      {
        "family": "Wu",
        "given": "Xiaoyu"
      },
      {
        "family": "Zhan",
        "given": "Qiqi"
      },
      {
        "family": "Liu",
        "given": "Qingjie"
      },
      {
        "family": "Wang",
        "given": "Yunhong"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 10]]
    },
    "issued": {
      "date-parts": [["2024", 10, 16]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/KP6SXDSU",
    "type": "article",
    "abstract": "A major factor in the recent success of large language models is the use of enormous and ever-growing text datasets for unsupervised pre-training. However, naively training a model on all available data may not be optimal (or feasible), as the quality of available text data can vary. Filtering out data can also decrease the carbon footprint and financial costs of training models by reducing the amount of training required. Data selection methods aim to determine which candidate data points to include in the training dataset and how to appropriately sample from the selected data points. The promise of improved data selection methods has caused the volume of research in the area to rapidly expand. However, because deep learning is mostly driven by empirical evidence and experimentation on large-scale data is expensive, few organizations have the resources for extensive data selection research. Consequently, knowledge of effective data selection practices has become concentrated within a few organizations, many of which do not openly share their findings and methodologies. To narrow this gap in knowledge, we present a comprehensive review of existing literature on data selection methods and related research areas, providing a taxonomy of existing approaches. By describing the current landscape of research, this work aims to accelerate progress in data selection by establishing an entry point for new and established researchers. Additionally, throughout this review we draw attention to noticeable holes in the literature and conclude the paper by proposing promising avenues for future research.",
    "DOI": "10.48550/arXiv.2402.16827",
    "language": "en-US",
    "note": "arXiv:2402.16827 [cs]",
    "number": "arXiv:2402.16827",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "A Survey on Data Selection for Language Models",
    "URL": "http://arxiv.org/abs/2402.16827",
    "author": [
      {
        "family": "Albalak",
        "given": "Alon"
      },
      {
        "family": "Elazar",
        "given": "Yanai"
      },
      {
        "family": "Xie",
        "given": "Sang Michael"
      },
      {
        "family": "Longpre",
        "given": "Shayne"
      },
      {
        "family": "Lambert",
        "given": "Nathan"
      },
      {
        "family": "Wang",
        "given": "Xinyi"
      },
      {
        "family": "Muennighoff",
        "given": "Niklas"
      },
      {
        "family": "Hou",
        "given": "Bairu"
      },
      {
        "family": "Pan",
        "given": "Liangming"
      },
      {
        "family": "Jeong",
        "given": "Haewon"
      },
      {
        "family": "Raffel",
        "given": "Colin"
      },
      {
        "family": "Chang",
        "given": "Shiyu"
      },
      {
        "family": "Hashimoto",
        "given": "Tatsunori"
      },
      {
        "family": "Wang",
        "given": "William Yang"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 10]]
    },
    "issued": {
      "date-parts": [["2024", 8, 2]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/SJU4K69P",
    "type": "paper-conference",
    "abstract": "Instruction tuning is critical to large language models (LLMs) for achieving better instruction following and task adaptation capabilities but its success heavily relies on the training data quality. Many recent methods focus on improving the data quality but often overlook the compatibility of the data with the student model being finetuned. This paper introduces Selective Reflection-Tuning, a novel paradigm that synergizes a teacher LLM`s reflection and introspection for improving existing data quality with the data selection capability of the student LLM, to automatically refine existing instruction-tuning data. This teacher-student collaboration produces high-quality and student-compatible instruction-response pairs, resulting in sample-efficient instruction tuning and LLMs of superior performance. Selective Reflection-Tuning is a data augmentation and synthesis that generally improves LLM finetuning and self-improvement without collecting brand-new data. We apply our method to Alpaca and WizardLM data and achieve much stronger and top-tier 7B and 13B LLMs.",
    "container-title": "Findings of the Association for Computational Linguistics: ACL 2024",
    "DOI": "10.18653/v1/2024.findings-acl.958",
    "event-place": "Bangkok, Thailand",
    "event-title": "Findings 2024",
    "page": "16189–16211",
    "publisher": "Association for Computational Linguistics",
    "publisher-place": "Bangkok, Thailand",
    "source": "ACLWeb",
    "title": "Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning",
    "title-short": "Selective Reflection-Tuning",
    "URL": "https://aclanthology.org/2024.findings-acl.958/",
    "author": [
      {
        "family": "Li",
        "given": "Ming"
      },
      {
        "family": "Chen",
        "given": "Lichang"
      },
      {
        "family": "Chen",
        "given": "Jiuhai"
      },
      {
        "family": "He",
        "given": "Shwai"
      },
      {
        "family": "Gu",
        "given": "Jiuxiang"
      },
      {
        "family": "Zhou",
        "given": "Tianyi"
      }
    ],
    "editor": [
      {
        "family": "Ku",
        "given": "Lun-Wei"
      },
      {
        "family": "Martins",
        "given": "Andre"
      },
      {
        "family": "Srikumar",
        "given": "Vivek"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 11]]
    },
    "issued": {
      "date-parts": [["2024", 8]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/YKPHNF67",
    "type": "article-journal",
    "abstract": "The performance of large language models (LLMs) in natural language processing (NLP) tasks is significantly influenced by the quality and diversity of data used for supervised fine-tuning (SFT). Current data selection methods often focus solely on quality or diversity, leading to underperforming models due to suboptimal training data. In this paper, we introduce GraphFilter, a novel method that represents the dataset as a bipartite graph, linking sentences to their constituent n-grams. This representation effectively captures the relationships between sentences and linguistic patterns, facilitating the selection of sentences that enhance n-gram diversity. To balance quality and diversity during selection, we propose a priority function that combines the quality metric with the diversity metric in a multiplicative manner. GraphFilter iteratively selects high-priority sentences, updates the bipartite graph by removing covered n-grams, and re-calculates priorities to reflect the evolving data landscape. We conduct extensive experiments using three model backbones across six widely used benchmarks. The results demonstrate that GraphFilter outperforms all nine baseline approaches, achieving superior model performance and computational efficiency. Our analyses validate the effectiveness of our design choices, examine the subsets selected by GraphFilter and other methods, highlight the importance of instruction diversity, and explore the role of quality and diversity in relation to subset sizes. GraphFilter establishes a new foundation for effective data selection strategies, encouraging further research in data selection for LLMs.",
    "language": "en",
    "source": "openreview.net",
    "title": "The Best of Both Worlds: Bridging Quality and Diversity in Data Selection with Bipartite Graph",
    "title-short": "The Best of Both Worlds",
    "URL": "https://openreview.net/forum?id=V9oT5Jmxpu",
    "author": [
      {
        "family": "Wu",
        "given": "Minghao"
      },
      {
        "family": "Vu",
        "given": "Thuy-Trang"
      },
      {
        "family": "Qu",
        "given": "Lizhen"
      },
      {
        "family": "Haf",
        "given": "Reza"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 12]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/FL4533XH",
    "type": "article",
    "abstract": "Instruction tuning is critical to improve LLMs but usually suffers from low-quality and redundant data. Data filtering for instruction tuning has proved important in improving both the efficiency and performance of the tuning process. But it also leads to extra cost and computation due to the involvement of LLMs in this process. To reduce the filtering cost, we study Superfiltering: Can we use a smaller and weaker model to select data for finetuning a larger and stronger model? Despite the performance gap between weak and strong language models, we find their highly consistent capability to perceive instruction difficulty and data selection results. This enables us to use a much smaller and more efficient model to filter the instruction data used to train a larger language model. Not only does it largely speed up the data filtering, but the filtered-data-finetuned LLM achieves even better performance on standard benchmarks. Extensive experiments validate the efficacy and efficiency of our approach.",
    "DOI": "10.48550/arXiv.2402.00530",
    "note": "arXiv:2402.00530 [cs]",
    "number": "arXiv:2402.00530",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Superfiltering: Weak-to-Strong Data Filtering for Fast Instruction-Tuning",
    "title-short": "Superfiltering",
    "URL": "http://arxiv.org/abs/2402.00530",
    "author": [
      {
        "family": "Li",
        "given": "Ming"
      },
      {
        "family": "Zhang",
        "given": "Yong"
      },
      {
        "family": "He",
        "given": "Shwai"
      },
      {
        "family": "Li",
        "given": "Zhitao"
      },
      {
        "family": "Zhao",
        "given": "Hongyu"
      },
      {
        "family": "Wang",
        "given": "Jianzong"
      },
      {
        "family": "Cheng",
        "given": "Ning"
      },
      {
        "family": "Zhou",
        "given": "Tianyi"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 15]]
    },
    "issued": {
      "date-parts": [["2024", 6, 7]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/TAH6RGBY",
    "type": "article",
    "abstract": "There is a consensus that instruction fine-tuning of LLMs requires high-quality data, but what are they? LIMA (NeurIPS 2023) and AlpaGasus (ICLR 2024) are state-of-the-art methods for selecting such high-quality examples, either via manual curation or using GPT-3.5-Turbo as a quality scorer. We show that the extremely simple baseline of selecting the 1,000 instructions with longest responses -- that intuitively contain more learnable information and are harder to overfit -- from standard datasets can consistently outperform these sophisticated methods according to GPT-4 and PaLM-2 as judges, while remaining competitive on the Open LLM benchmarks that test factual knowledge. We demonstrate this for several LLMs (Llama-2-7B, Llama-2-13B, Mistral-7B-v0.1) and datasets (Alpaca-52k, Evol-Instruct-70k). In addition, a lightweight refinement of such long instructions can further improve the abilities of the fine-tuned LLMs, and allows us to obtain competitive results on MT-Bench and the 2nd highest-ranked Llama-2-7B-based model on AlpacaEval 2.0, while training on only 1,000 examples and no extra preference data. We also conduct a thorough analysis of our models to ensure that their enhanced performance is not simply due to GPT-4's preference for longer responses. Overall, our findings suggest that fine-tuning on the longest responses should be the default baseline for any work on instruction fine-tuning. We provide our code at https://github.com/tml-epfl/long-is-more-for-alignment.",
    "DOI": "10.48550/arXiv.2402.04833",
    "note": "arXiv:2402.04833 [cs]",
    "number": "arXiv:2402.04833",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Long Is More for Alignment: A Simple but Tough-to-Beat Baseline for Instruction Fine-Tuning",
    "title-short": "Long Is More for Alignment",
    "URL": "http://arxiv.org/abs/2402.04833",
    "author": [
      {
        "family": "Zhao",
        "given": "Hao"
      },
      {
        "family": "Andriushchenko",
        "given": "Maksym"
      },
      {
        "family": "Croce",
        "given": "Francesco"
      },
      {
        "family": "Flammarion",
        "given": "Nicolas"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 15]]
    },
    "issued": {
      "date-parts": [["2024", 6, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/JL3RILH6",
    "type": "article",
    "abstract": "Answering questions with Chain-of-Thought (CoT) has significantly enhanced the reasoning capabilities of Large Language Models (LLMs), yet its impact on Large Multimodal Models (LMMs) still lacks a systematic assessment and in-depth investigation. In this paper, we introduce MME-CoT, a specialized benchmark evaluating the CoT reasoning performance of LMMs, spanning six domains: math, science, OCR, logic, space-time, and general scenes. As the first comprehensive study in this area, we propose a thorough evaluation suite incorporating three novel metrics that assess the reasoning quality, robustness, and efficiency at a fine-grained level. Leveraging curated high-quality data and a unique evaluation strategy, we conduct an in-depth analysis of state-of-the-art LMMs, uncovering several key insights: 1) Models with reflection mechanism demonstrate a superior CoT quality, with Kimi k1.5 outperforming GPT-4o and demonstrating the highest quality results; 2) CoT prompting often degrades LMM performance on perception-heavy tasks, suggesting a potentially harmful overthinking behavior; and 3) Although the CoT quality is high, LMMs with reflection exhibit significant inefficiency in both normal response and self-correction phases. We hope MME-CoT serves as a foundation for advancing multimodal reasoning in LMMs. Project Page: https://mmecot.github.io/",
    "DOI": "10.48550/arXiv.2502.09621",
    "note": "arXiv:2502.09621 [cs]",
    "number": "arXiv:2502.09621",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "MME-CoT: Benchmarking Chain-of-Thought in Large Multimodal Models for Reasoning Quality, Robustness, and Efficiency",
    "title-short": "MME-CoT",
    "URL": "http://arxiv.org/abs/2502.09621",
    "author": [
      {
        "family": "Jiang",
        "given": "Dongzhi"
      },
      {
        "family": "Zhang",
        "given": "Renrui"
      },
      {
        "family": "Guo",
        "given": "Ziyu"
      },
      {
        "family": "Li",
        "given": "Yanwei"
      },
      {
        "family": "Qi",
        "given": "Yu"
      },
      {
        "family": "Chen",
        "given": "Xinyan"
      },
      {
        "family": "Wang",
        "given": "Liuhui"
      },
      {
        "family": "Jin",
        "given": "Jianhan"
      },
      {
        "family": "Guo",
        "given": "Claire"
      },
      {
        "family": "Yan",
        "given": "Shen"
      },
      {
        "family": "Zhang",
        "given": "Bo"
      },
      {
        "family": "Fu",
        "given": "Chaoyou"
      },
      {
        "family": "Gao",
        "given": "Peng"
      },
      {
        "family": "Li",
        "given": "Hongsheng"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 18]]
    },
    "issued": {
      "date-parts": [["2025", 2, 13]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/HJJK9737",
    "type": "article",
    "abstract": "Emojis have become an integral part of digital communication, enriching text by conveying emotions, tone, and intent. Existing emoji recommendation methods are primarily evaluated based on their ability to match the exact emoji a user chooses in the original text. However, they ignore the essence of users' behavior on social media in that each text can correspond to multiple reasonable emojis. To better assess a model's ability to align with such real-world emoji usage, we propose a new semantics preserving evaluation framework for emoji recommendation, which measures a model's ability to recommend emojis that maintain the semantic consistency with the user's text. To evaluate how well a model preserves semantics, we assess whether the predicted affective state, demographic profile, and attitudinal stance of the user remain unchanged. If these attributes are preserved, we consider the recommended emojis to have maintained the original semantics. The advanced abilities of Large Language Models (LLMs) in understanding and generating nuanced, contextually relevant output make them well-suited for handling the complexities of semantics preserving emoji recommendation. To this end, we construct a comprehensive benchmark to systematically assess the performance of six proprietary and open-source LLMs using different prompting techniques on our task. Our experiments demonstrate that GPT-4o outperforms other LLMs, achieving a semantics preservation score of 79.23%. Additionally, we conduct case studies to analyze model biases in downstream classification tasks and evaluate the diversity of the recommended emojis.",
    "DOI": "10.48550/arXiv.2409.10760",
    "note": "arXiv:2409.10760 [cs]",
    "number": "arXiv:2409.10760",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Semantics Preserving Emoji Recommendation with Large Language Models",
    "URL": "http://arxiv.org/abs/2409.10760",
    "author": [
      {
        "family": "Qiu",
        "given": "Zhongyi"
      },
      {
        "family": "Qiu",
        "given": "Kangyi"
      },
      {
        "family": "Lyu",
        "given": "Hanjia"
      },
      {
        "family": "Xiong",
        "given": "Wei"
      },
      {
        "family": "Luo",
        "given": "Jiebo"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 18]]
    },
    "issued": {
      "date-parts": [["2024", 9, 16]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/ID7NUL4A",
    "type": "article",
    "abstract": "The manipulation of the personality traits of large language models (LLMs) has emerged as a key area of research. Methods like prompt-based In-Context Knowledge Editing (IKE) and gradient-based Model Editor Networks (MEND) have been explored but show irregularity and variability; IKE depends on the prompt, leading to variability and sensitivity, while MEND yields inconsistent and gibberish outputs. To address this, we employed Opinion QA Based Parameter-Efficient Fine-Tuning (PEFT), specifically Quantized Low-Rank Adaptation (QLoRA), to manipulate the Big Five personality traits: Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism. After PEFT, models such as Mistral-7B-Instruct and LLaMA-2-7B-chat began generating emojis, even though no emojis were present in the PEFT data. For instance, LLaMA-2-7B-chat generated emojis in 99.5% of extraversion-related test instances, while Mistral-7B-Instruct did so in 92.5% of openness-related test instances. ICL Explainability analysis indicated that the LLMs used emojis intentionally to express these traits. Mechanistic Interpretability analysis showed that this latent behaviour of LLMs could be traced to specific neurons that became activated or amplified after PEFT. This paper provides a number of novel contributions. First, introducing an Opinion QA dataset for PEFT-driven personality manipulation; second, developing metric models to benchmark LLM personality traits; third, demonstrating PEFT's superiority over IKE in personality manipulation; and finally, analysing and validating emoji usage through explainability methods such as Mechanistic Interpretability and In-context learning Explainability methods.",
    "DOI": "10.48550/arXiv.2409.10245",
    "note": "arXiv:2409.10245 [cs]",
    "number": "arXiv:2409.10245",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "From Text to Emoji: How PEFT-Driven Personality Manipulation Unleashes the Emoji Potential in LLMs",
    "title-short": "From Text to Emoji",
    "URL": "http://arxiv.org/abs/2409.10245",
    "author": [
      {
        "family": "Jain",
        "given": "Navya"
      },
      {
        "family": "Wu",
        "given": "Zekun"
      },
      {
        "family": "Munoz",
        "given": "Cristian"
      },
      {
        "family": "Hilliard",
        "given": "Airlie"
      },
      {
        "family": "Guan",
        "given": "Xin"
      },
      {
        "family": "Koshiyama",
        "given": "Adriano"
      },
      {
        "family": "Kazim",
        "given": "Emre"
      },
      {
        "family": "Treleaven",
        "given": "Philip"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 18]]
    },
    "issued": {
      "date-parts": [["2025", 1, 23]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/KRZ529YN",
    "type": "paper-conference",
    "abstract": "Emojis have gained immense popularity on social platforms, serving as a common means to supplement or replace text. However, existing data mining approaches generally either completely ignore or simply treat emojis as ordinary Unicode characters, which may limit the model`s ability to grasp the rich semantic information in emojis and the interaction between emojis and texts. Thus, it is necessary to release the emoji`s power in social media data mining. To this end, we first construct a heterogeneous graph consisting of three types of nodes, i.e. post, word and emoji nodes to improve the representation of different elements in posts. The edges are also well-defined to model how these three elements interact with each other. To facilitate the sharing of information among post, word and emoji nodes, we propose a graph pre-train framework for text and emoji co-modeling, which contains two graph pre-training tasks: node-level graph contrastive learning and edge-level link reconstruction learning. Extensive experiments on the Xiaohongshu and Twitter datasets with two types of downstream tasks demonstrate that our approach proves significant improvement over previous strong baseline methods.",
    "container-title": "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    "DOI": "10.18653/v1/2024.emnlp-main.989",
    "event-place": "Miami, Florida, USA",
    "event-title": "EMNLP 2024",
    "page": "17851–17863",
    "publisher": "Association for Computational Linguistics",
    "publisher-place": "Miami, Florida, USA",
    "source": "ACLWeb",
    "title": "Unleashing the Power of Emojis in Texts via Self-supervised Graph Pre-Training",
    "URL": "https://aclanthology.org/2024.emnlp-main.989/",
    "author": [
      {
        "family": "Zhang",
        "given": "Zhou"
      },
      {
        "family": "Tan",
        "given": "Dongzeng"
      },
      {
        "family": "Wang",
        "given": "Jiaan"
      },
      {
        "family": "Chen",
        "given": "Yilong"
      },
      {
        "family": "Xu",
        "given": "Jiarong"
      }
    ],
    "editor": [
      {
        "family": "Al-Onaizan",
        "given": "Yaser"
      },
      {
        "family": "Bansal",
        "given": "Mohit"
      },
      {
        "family": "Chen",
        "given": "Yun-Nung"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 18]]
    },
    "issued": {
      "date-parts": [["2024", 11]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/3H2TRRLU",
    "type": "article",
    "abstract": "Emojis have become a universal language in online communication, often carrying nuanced and context-dependent meanings. Among these, irony poses a significant challenge for Large Language Models (LLMs) due to its inherent incongruity between appearance and intent. This study examines the ability of GPT-4o to interpret irony in emojis. By prompting GPT-4o to evaluate the likelihood of specific emojis being used to express irony on social media and comparing its interpretations with human perceptions, we aim to bridge the gap between machine and human understanding. Our findings reveal nuanced insights into GPT-4o's interpretive capabilities, highlighting areas of alignment with and divergence from human behavior. Additionally, this research underscores the importance of demographic factors, such as age and gender, in shaping emoji interpretation and evaluates how these factors influence GPT-4o's performance.",
    "DOI": "10.48550/arXiv.2501.11241",
    "note": "arXiv:2501.11241 [cs]",
    "number": "arXiv:2501.11241",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Irony in Emojis: A Comparative Study of Human and LLM Interpretation",
    "title-short": "Irony in Emojis",
    "URL": "http://arxiv.org/abs/2501.11241",
    "author": [
      {
        "family": "Zheng",
        "given": "Yawen"
      },
      {
        "family": "Lyu",
        "given": "Hanjia"
      },
      {
        "family": "Luo",
        "given": "Jiebo"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 18]]
    },
    "issued": {
      "date-parts": [["2025", 1, 20]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/JQKSY8CL",
    "type": "article",
    "abstract": "Emojis have become ubiquitous in online communication, serving as a universal medium to convey emotions and decorative elements. Their widespread use transcends language and cultural barriers, enhancing understanding and fostering more inclusive interactions. While existing work gained valuable insight into emojis understanding, exploring emojis' capability to serve as a universal sentiment indicator leveraging large language models (LLMs) has not been thoroughly examined. Our study aims to investigate the capacity of emojis to serve as reliable sentiment markers through LLMs across languages and cultures. We leveraged the multimodal capabilities of ChatGPT to explore the sentiments of various representations of emojis and evaluated how well emoji-conveyed sentiment aligned with text sentiment on a multi-lingual dataset collected from 32 countries. Our analysis reveals that the accuracy of LLM-based emoji-conveyed sentiment is 81.43%, underscoring emojis' significant potential to serve as a universal sentiment marker. We also found a consistent trend that the accuracy of sentiment conveyed by emojis increased as the number of emojis grew in text. The results reinforce the potential of emojis to serve as global sentiment indicators, offering insight into fields such as cross-lingual and cross-cultural sentiment analysis on social media platforms. Code: https://github.com/ResponsibleAILab/emoji-universal-sentiment.",
    "DOI": "10.48550/arXiv.2412.17255",
    "note": "arXiv:2412.17255 [cs]",
    "number": "arXiv:2412.17255",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Unlocking Cross-Lingual Sentiment Analysis through Emoji Interpretation: A Multimodal Generative AI Approach",
    "title-short": "Unlocking Cross-Lingual Sentiment Analysis through Emoji Interpretation",
    "URL": "http://arxiv.org/abs/2412.17255",
    "author": [
      {
        "family": "Jahan",
        "given": "Rafid Ishrak"
      },
      {
        "family": "Fan",
        "given": "Heng"
      },
      {
        "family": "Chen",
        "given": "Haihua"
      },
      {
        "family": "Feng",
        "given": "Yunhe"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 18]]
    },
    "issued": {
      "date-parts": [["2024", 12, 23]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/HIZR6KE9",
    "type": "article-journal",
    "abstract": "Vision and Language are two major modalities in Artificial Intelligence research. Bridging the gap between these modalities has long been a key focus in the multimodal community. Inspired by human cognition, we believe that if a model can see an image and directly associate it with its linguistic meaning, the model possesses high-level intelligence that spans vision and language. In our work, we focus on emojis in images, a widely-used \"cryptic symbol\", with a data form of both visual and linguistic features, i.e. emojis have the specific textual semantics while human understand the meaning from their visual information. Specifically, we first propose the novel task of translating emojis in images to corresponding idioms, thereby challenging Multimodal Large Language Models (MLLMs) to (1) understand the semantic correlation between language and emojis, and (2) reason the intricate linguistic meaning from the emojis in images. To facilitate the advancement of this task, we construct a high-quality benchmark (emoji2idiom) following the process of automatic model generation and human manual filtering. Based on our constructed emoji2idiom, we employ multiple advanced MLLMs to conduct extensive experiments and detailed analyses, demonstrating that existing MLLMs do not yet have enough capability to understand and reason the linguistic information from visual data. We believe our proposed benchmark and interesting discoveries will encourage the community to attach importance to the intelligence of MLLMs directly associating language from vision, to give MLLMs more comprehensive vision-language understanding ability.",
    "language": "en",
    "source": "openreview.net",
    "title": "🤔Emoji2Idiom: Benchmarking Cryptic Symbol Understanding of Multimodal Large Language Models",
    "title-short": "🤔Emoji2Idiom",
    "URL": "https://openreview.net/forum?id=YxOG4FjZLd",
    "author": [
      {
        "family": "Kuang",
        "given": "Jiayi"
      },
      {
        "family": "Li",
        "given": "Yinghui"
      },
      {
        "family": "Wang",
        "given": "Chen"
      },
      {
        "family": "Shen",
        "given": "Ying"
      },
      {
        "family": "Jiang",
        "given": "Wenhao"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 19]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/YJTCZZYY",
    "type": "article-journal",
    "abstract": "<p>An important function of emoji as communicative symbols is to convey emotional content from sender to receiver in computer-mediated communication, e. g., WhatsApp. However, compared with real faces, pictures or words, many emoji are ambiguous because they do not symbolize a discrete emotion or feeling state. Thus, their meaning relies on the context of the message in which they are embedded. Previous studies investigated affective judgments of pictures, faces, and words suggesting that these stimuli show a typical distribution along the big two emotion dimensions of valence and arousal. Also, emoji and emoticons have been investigated recently for their affective significance. The present study extends previous research by investigating affective ratings of emoji, emoticons and human faces and by direct comparison between them. In total, 60 stimuli have been rated by 83 participants (eight males, age: 18–49 years), using the non-verbal Self-Assessment Manikin Scales for valence and arousal. The emotionality of the stimuli was measured on a 9-point Likert scale. The results show significant main effects of the factors “stimulus category” and “discrete emotion” including emotionality, valence and arousal. Also, the interaction between these two main factors was significant. Emoji elicited highest arousal, whereas stimuli related to happiness were rated highest in valence across stimulus categories. Angry emoji were rated highest in emotionality. Also, the discrete emotion was best recognized in emoji, followed by human face stimuli and lastly emoticons.</p>",
    "container-title": "Frontiers in Psychology",
    "DOI": "10.3389/fpsyg.2021.645173",
    "ISSN": "1664-1078",
    "journalAbbreviation": "Front. Psychol.",
    "language": "English",
    "note": "publisher: Frontiers",
    "source": "Frontiers",
    "title": "Emoji as Affective Symbols: Affective Judgments of Emoji, Emoticons, and Human Faces Varying in Emotional Content",
    "title-short": "Emoji as Affective Symbols",
    "URL": "https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2021.645173/full",
    "volume": "12",
    "author": [
      {
        "family": "Fischer",
        "given": "Brigitte"
      },
      {
        "family": "Herbert",
        "given": "Cornelia"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 19]]
    },
    "issued": {
      "date-parts": [["2021", 4, 20]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/CIJ4II2J",
    "type": "article",
    "abstract": "Recently, there has been growing interest in leveraging large language models (LLMs) to generate symbolic world models from textual descriptions. Although LLMs have been extensively explored in the context of world modeling, prior studies encountered several challenges, including evaluation randomness, dependence on indirect metrics, and a limited domain scope. To address these limitations, we introduce a novel benchmark, Text2World, based on planning domain definition language (PDDL), featuring hundreds of diverse domains and employing multi-criteria, execution-based metrics for a more robust evaluation. We benchmark current LLMs using Text2World and find that reasoning models trained with large-scale reinforcement learning outperform others. However, even the best-performing model still demonstrates limited capabilities in world modeling. Building on these insights, we examine several promising strategies to enhance the world modeling capabilities of LLMs, including test-time scaling, agent training, and more. We hope that Text2World can serve as a crucial resource, laying the groundwork for future research in leveraging LLMs as world models. The project page is available at https://text-to-world.github.io/.",
    "DOI": "10.48550/arXiv.2502.13092",
    "language": "en-US",
    "note": "arXiv:2502.13092 [cs]",
    "number": "arXiv:2502.13092",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Text2World: Benchmarking Large Language Models for Symbolic World Model Generation",
    "title-short": "Text2World",
    "URL": "http://arxiv.org/abs/2502.13092",
    "author": [
      {
        "family": "Hu",
        "given": "Mengkang"
      },
      {
        "family": "Chen",
        "given": "Tianxing"
      },
      {
        "family": "Zou",
        "given": "Yude"
      },
      {
        "family": "Lei",
        "given": "Yuheng"
      },
      {
        "family": "Chen",
        "given": "Qiguang"
      },
      {
        "family": "Li",
        "given": "Ming"
      },
      {
        "family": "Zhang",
        "given": "Hongyuan"
      },
      {
        "family": "Shao",
        "given": "Wenqi"
      },
      {
        "family": "Luo",
        "given": "Ping"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 19]]
    },
    "issued": {
      "date-parts": [["2025", 2, 18]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/2XMWJ8UC",
    "type": "article",
    "abstract": "While Large Language Models (LLMs) adapt well to downstream tasks after fine-tuning, this adaptability often compromises prompt robustness, as even minor prompt variations can significantly degrade performance. To address this, we propose Prompt-Agnostic Fine-Tuning(PAFT), a simple yet effective approach that dynamically adjusts prompts during fine-tuning. This encourages the model to learn underlying task principles rather than overfitting to specific prompt formulations. PAFT operates in two stages: First, a diverse set of meaningful, synthetic candidate prompts is constructed. Second, during fine-tuning, prompts are randomly sampled from this set to create dynamic training inputs. Extensive experiments across diverse datasets and LLMs demonstrate that models trained with PAFT exhibit strong robustness and generalization across a wide range of prompts, including unseen ones. This enhanced robustness improves both model performance and inference speed while maintaining training efficiency. Ablation studies further confirm the effectiveness of PAFT.",
    "DOI": "10.48550/arXiv.2502.12859",
    "language": "en-US",
    "note": "arXiv:2502.12859 [cs]",
    "number": "arXiv:2502.12859",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "PAFT: Prompt-Agnostic Fine-Tuning",
    "title-short": "PAFT",
    "URL": "http://arxiv.org/abs/2502.12859",
    "author": [
      {
        "family": "Wei",
        "given": "Chenxing"
      },
      {
        "family": "Shu",
        "given": "Yao"
      },
      {
        "family": "Ou",
        "given": "Mingwen"
      },
      {
        "family": "He",
        "given": "Ying Tiffany"
      },
      {
        "family": "Yu",
        "given": "Fei Richard"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 19]]
    },
    "issued": {
      "date-parts": [["2025", 2, 18]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/ULT7LI56",
    "type": "article",
    "abstract": "Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models. To address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 450 authors across 132 institutions. Task topics are diverse, drawing problems from linguistics, childhood development, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI's GPT models, Google-internal dense transformer architectures, and Switch-style sparse transformers on BIG-bench, across model sizes spanning millions to hundreds of billions of parameters. In addition, a team of human expert raters performed all tasks in order to provide a strong baseline. Findings include: model performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); performance is remarkably similar across model classes, though with benefits from sparsity; tasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit \"breakthrough\" behavior at a critical scale often involve multiple steps or components, or brittle metrics; social bias typically increases with scale in settings with ambiguous context, but this can be improved with prompting.",
    "DOI": "10.48550/arXiv.2206.04615",
    "note": "arXiv:2206.04615 [cs]",
    "number": "arXiv:2206.04615",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models",
    "title-short": "Beyond the Imitation Game",
    "URL": "http://arxiv.org/abs/2206.04615",
    "author": [
      {
        "family": "Srivastava",
        "given": "Aarohi"
      },
      {
        "family": "Rastogi",
        "given": "Abhinav"
      },
      {
        "family": "Rao",
        "given": "Abhishek"
      },
      {
        "family": "Shoeb",
        "given": "Abu Awal Md"
      },
      {
        "family": "Abid",
        "given": "Abubakar"
      },
      {
        "family": "Fisch",
        "given": "Adam"
      },
      {
        "family": "Brown",
        "given": "Adam R."
      },
      {
        "family": "Santoro",
        "given": "Adam"
      },
      {
        "family": "Gupta",
        "given": "Aditya"
      },
      {
        "family": "Garriga-Alonso",
        "given": "Adrià"
      },
      {
        "family": "Kluska",
        "given": "Agnieszka"
      },
      {
        "family": "Lewkowycz",
        "given": "Aitor"
      },
      {
        "family": "Agarwal",
        "given": "Akshat"
      },
      {
        "family": "Power",
        "given": "Alethea"
      },
      {
        "family": "Ray",
        "given": "Alex"
      },
      {
        "family": "Warstadt",
        "given": "Alex"
      },
      {
        "family": "Kocurek",
        "given": "Alexander W."
      },
      {
        "family": "Safaya",
        "given": "Ali"
      },
      {
        "family": "Tazarv",
        "given": "Ali"
      },
      {
        "family": "Xiang",
        "given": "Alice"
      },
      {
        "family": "Parrish",
        "given": "Alicia"
      },
      {
        "family": "Nie",
        "given": "Allen"
      },
      {
        "family": "Hussain",
        "given": "Aman"
      },
      {
        "family": "Askell",
        "given": "Amanda"
      },
      {
        "family": "Dsouza",
        "given": "Amanda"
      },
      {
        "family": "Slone",
        "given": "Ambrose"
      },
      {
        "family": "Rahane",
        "given": "Ameet"
      },
      {
        "family": "Iyer",
        "given": "Anantharaman S."
      },
      {
        "family": "Andreassen",
        "given": "Anders"
      },
      {
        "family": "Madotto",
        "given": "Andrea"
      },
      {
        "family": "Santilli",
        "given": "Andrea"
      },
      {
        "family": "Stuhlmüller",
        "given": "Andreas"
      },
      {
        "family": "Dai",
        "given": "Andrew"
      },
      {
        "family": "La",
        "given": "Andrew"
      },
      {
        "family": "Lampinen",
        "given": "Andrew"
      },
      {
        "family": "Zou",
        "given": "Andy"
      },
      {
        "family": "Jiang",
        "given": "Angela"
      },
      {
        "family": "Chen",
        "given": "Angelica"
      },
      {
        "family": "Vuong",
        "given": "Anh"
      },
      {
        "family": "Gupta",
        "given": "Animesh"
      },
      {
        "family": "Gottardi",
        "given": "Anna"
      },
      {
        "family": "Norelli",
        "given": "Antonio"
      },
      {
        "family": "Venkatesh",
        "given": "Anu"
      },
      {
        "family": "Gholamidavoodi",
        "given": "Arash"
      },
      {
        "family": "Tabassum",
        "given": "Arfa"
      },
      {
        "family": "Menezes",
        "given": "Arul"
      },
      {
        "family": "Kirubarajan",
        "given": "Arun"
      },
      {
        "family": "Mullokandov",
        "given": "Asher"
      },
      {
        "family": "Sabharwal",
        "given": "Ashish"
      },
      {
        "family": "Herrick",
        "given": "Austin"
      },
      {
        "family": "Efrat",
        "given": "Avia"
      },
      {
        "family": "Erdem",
        "given": "Aykut"
      },
      {
        "family": "Karakaş",
        "given": "Ayla"
      },
      {
        "family": "Roberts",
        "given": "B. Ryan"
      },
      {
        "family": "Loe",
        "given": "Bao Sheng"
      },
      {
        "family": "Zoph",
        "given": "Barret"
      },
      {
        "family": "Bojanowski",
        "given": "Bartłomiej"
      },
      {
        "family": "Özyurt",
        "given": "Batuhan"
      },
      {
        "family": "Hedayatnia",
        "given": "Behnam"
      },
      {
        "family": "Neyshabur",
        "given": "Behnam"
      },
      {
        "family": "Inden",
        "given": "Benjamin"
      },
      {
        "family": "Stein",
        "given": "Benno"
      },
      {
        "family": "Ekmekci",
        "given": "Berk"
      },
      {
        "family": "Lin",
        "given": "Bill Yuchen"
      },
      {
        "family": "Howald",
        "given": "Blake"
      },
      {
        "family": "Orinion",
        "given": "Bryan"
      },
      {
        "family": "Diao",
        "given": "Cameron"
      },
      {
        "family": "Dour",
        "given": "Cameron"
      },
      {
        "family": "Stinson",
        "given": "Catherine"
      },
      {
        "family": "Argueta",
        "given": "Cedrick"
      },
      {
        "family": "Ramírez",
        "given": "César Ferri"
      },
      {
        "family": "Singh",
        "given": "Chandan"
      },
      {
        "family": "Rathkopf",
        "given": "Charles"
      },
      {
        "family": "Meng",
        "given": "Chenlin"
      },
      {
        "family": "Baral",
        "given": "Chitta"
      },
      {
        "family": "Wu",
        "given": "Chiyu"
      },
      {
        "family": "Callison-Burch",
        "given": "Chris"
      },
      {
        "family": "Waites",
        "given": "Chris"
      },
      {
        "family": "Voigt",
        "given": "Christian"
      },
      {
        "family": "Manning",
        "given": "Christopher D."
      },
      {
        "family": "Potts",
        "given": "Christopher"
      },
      {
        "family": "Ramirez",
        "given": "Cindy"
      },
      {
        "family": "Rivera",
        "given": "Clara E."
      },
      {
        "family": "Siro",
        "given": "Clemencia"
      },
      {
        "family": "Raffel",
        "given": "Colin"
      },
      {
        "family": "Ashcraft",
        "given": "Courtney"
      },
      {
        "family": "Garbacea",
        "given": "Cristina"
      },
      {
        "family": "Sileo",
        "given": "Damien"
      },
      {
        "family": "Garrette",
        "given": "Dan"
      },
      {
        "family": "Hendrycks",
        "given": "Dan"
      },
      {
        "family": "Kilman",
        "given": "Dan"
      },
      {
        "family": "Roth",
        "given": "Dan"
      },
      {
        "family": "Freeman",
        "given": "Daniel"
      },
      {
        "family": "Khashabi",
        "given": "Daniel"
      },
      {
        "family": "Levy",
        "given": "Daniel"
      },
      {
        "family": "González",
        "given": "Daniel Moseguí"
      },
      {
        "family": "Perszyk",
        "given": "Danielle"
      },
      {
        "family": "Hernandez",
        "given": "Danny"
      },
      {
        "family": "Chen",
        "given": "Danqi"
      },
      {
        "family": "Ippolito",
        "given": "Daphne"
      },
      {
        "family": "Gilboa",
        "given": "Dar"
      },
      {
        "family": "Dohan",
        "given": "David"
      },
      {
        "family": "Drakard",
        "given": "David"
      },
      {
        "family": "Jurgens",
        "given": "David"
      },
      {
        "family": "Datta",
        "given": "Debajyoti"
      },
      {
        "family": "Ganguli",
        "given": "Deep"
      },
      {
        "family": "Emelin",
        "given": "Denis"
      },
      {
        "family": "Kleyko",
        "given": "Denis"
      },
      {
        "family": "Yuret",
        "given": "Deniz"
      },
      {
        "family": "Chen",
        "given": "Derek"
      },
      {
        "family": "Tam",
        "given": "Derek"
      },
      {
        "family": "Hupkes",
        "given": "Dieuwke"
      },
      {
        "family": "Misra",
        "given": "Diganta"
      },
      {
        "family": "Buzan",
        "given": "Dilyar"
      },
      {
        "family": "Mollo",
        "given": "Dimitri Coelho"
      },
      {
        "family": "Yang",
        "given": "Diyi"
      },
      {
        "family": "Lee",
        "given": "Dong-Ho"
      },
      {
        "family": "Schrader",
        "given": "Dylan"
      },
      {
        "family": "Shutova",
        "given": "Ekaterina"
      },
      {
        "family": "Cubuk",
        "given": "Ekin Dogus"
      },
      {
        "family": "Segal",
        "given": "Elad"
      },
      {
        "family": "Hagerman",
        "given": "Eleanor"
      },
      {
        "family": "Barnes",
        "given": "Elizabeth"
      },
      {
        "family": "Donoway",
        "given": "Elizabeth"
      },
      {
        "family": "Pavlick",
        "given": "Ellie"
      },
      {
        "family": "Rodola",
        "given": "Emanuele"
      },
      {
        "family": "Lam",
        "given": "Emma"
      },
      {
        "family": "Chu",
        "given": "Eric"
      },
      {
        "family": "Tang",
        "given": "Eric"
      },
      {
        "family": "Erdem",
        "given": "Erkut"
      },
      {
        "family": "Chang",
        "given": "Ernie"
      },
      {
        "family": "Chi",
        "given": "Ethan A."
      },
      {
        "family": "Dyer",
        "given": "Ethan"
      },
      {
        "family": "Jerzak",
        "given": "Ethan"
      },
      {
        "family": "Kim",
        "given": "Ethan"
      },
      {
        "family": "Manyasi",
        "given": "Eunice Engefu"
      },
      {
        "family": "Zheltonozhskii",
        "given": "Evgenii"
      },
      {
        "family": "Xia",
        "given": "Fanyue"
      },
      {
        "family": "Siar",
        "given": "Fatemeh"
      },
      {
        "family": "Martínez-Plumed",
        "given": "Fernando"
      },
      {
        "family": "Happé",
        "given": "Francesca"
      },
      {
        "family": "Chollet",
        "given": "Francois"
      },
      {
        "family": "Rong",
        "given": "Frieda"
      },
      {
        "family": "Mishra",
        "given": "Gaurav"
      },
      {
        "family": "Winata",
        "given": "Genta Indra"
      },
      {
        "family": "Melo",
        "given": "Gerard",
        "dropping-particle": "de"
      },
      {
        "family": "Kruszewski",
        "given": "Germán"
      },
      {
        "family": "Parascandolo",
        "given": "Giambattista"
      },
      {
        "family": "Mariani",
        "given": "Giorgio"
      },
      {
        "family": "Wang",
        "given": "Gloria"
      },
      {
        "family": "Jaimovitch-López",
        "given": "Gonzalo"
      },
      {
        "family": "Betz",
        "given": "Gregor"
      },
      {
        "family": "Gur-Ari",
        "given": "Guy"
      },
      {
        "family": "Galijasevic",
        "given": "Hana"
      },
      {
        "family": "Kim",
        "given": "Hannah"
      },
      {
        "family": "Rashkin",
        "given": "Hannah"
      },
      {
        "family": "Hajishirzi",
        "given": "Hannaneh"
      },
      {
        "family": "Mehta",
        "given": "Harsh"
      },
      {
        "family": "Bogar",
        "given": "Hayden"
      },
      {
        "family": "Shevlin",
        "given": "Henry"
      },
      {
        "family": "Schütze",
        "given": "Hinrich"
      },
      {
        "family": "Yakura",
        "given": "Hiromu"
      },
      {
        "family": "Zhang",
        "given": "Hongming"
      },
      {
        "family": "Wong",
        "given": "Hugh Mee"
      },
      {
        "family": "Ng",
        "given": "Ian"
      },
      {
        "family": "Noble",
        "given": "Isaac"
      },
      {
        "family": "Jumelet",
        "given": "Jaap"
      },
      {
        "family": "Geissinger",
        "given": "Jack"
      },
      {
        "family": "Kernion",
        "given": "Jackson"
      },
      {
        "family": "Hilton",
        "given": "Jacob"
      },
      {
        "family": "Lee",
        "given": "Jaehoon"
      },
      {
        "family": "Fisac",
        "given": "Jaime Fernández"
      },
      {
        "family": "Simon",
        "given": "James B."
      },
      {
        "family": "Koppel",
        "given": "James"
      },
      {
        "family": "Zheng",
        "given": "James"
      },
      {
        "family": "Zou",
        "given": "James"
      },
      {
        "family": "Kocoń",
        "given": "Jan"
      },
      {
        "family": "Thompson",
        "given": "Jana"
      },
      {
        "family": "Wingfield",
        "given": "Janelle"
      },
      {
        "family": "Kaplan",
        "given": "Jared"
      },
      {
        "family": "Radom",
        "given": "Jarema"
      },
      {
        "family": "Sohl-Dickstein",
        "given": "Jascha"
      },
      {
        "family": "Phang",
        "given": "Jason"
      },
      {
        "family": "Wei",
        "given": "Jason"
      },
      {
        "family": "Yosinski",
        "given": "Jason"
      },
      {
        "family": "Novikova",
        "given": "Jekaterina"
      },
      {
        "family": "Bosscher",
        "given": "Jelle"
      },
      {
        "family": "Marsh",
        "given": "Jennifer"
      },
      {
        "family": "Kim",
        "given": "Jeremy"
      },
      {
        "family": "Taal",
        "given": "Jeroen"
      },
      {
        "family": "Engel",
        "given": "Jesse"
      },
      {
        "family": "Alabi",
        "given": "Jesujoba"
      },
      {
        "family": "Xu",
        "given": "Jiacheng"
      },
      {
        "family": "Song",
        "given": "Jiaming"
      },
      {
        "family": "Tang",
        "given": "Jillian"
      },
      {
        "family": "Waweru",
        "given": "Joan"
      },
      {
        "family": "Burden",
        "given": "John"
      },
      {
        "family": "Miller",
        "given": "John"
      },
      {
        "family": "Balis",
        "given": "John U."
      },
      {
        "family": "Batchelder",
        "given": "Jonathan"
      },
      {
        "family": "Berant",
        "given": "Jonathan"
      },
      {
        "family": "Frohberg",
        "given": "Jörg"
      },
      {
        "family": "Rozen",
        "given": "Jos"
      },
      {
        "family": "Hernandez-Orallo",
        "given": "Jose"
      },
      {
        "family": "Boudeman",
        "given": "Joseph"
      },
      {
        "family": "Guerr",
        "given": "Joseph"
      },
      {
        "family": "Jones",
        "given": "Joseph"
      },
      {
        "family": "Tenenbaum",
        "given": "Joshua B."
      },
      {
        "family": "Rule",
        "given": "Joshua S."
      },
      {
        "family": "Chua",
        "given": "Joyce"
      },
      {
        "family": "Kanclerz",
        "given": "Kamil"
      },
      {
        "family": "Livescu",
        "given": "Karen"
      },
      {
        "family": "Krauth",
        "given": "Karl"
      },
      {
        "family": "Gopalakrishnan",
        "given": "Karthik"
      },
      {
        "family": "Ignatyeva",
        "given": "Katerina"
      },
      {
        "family": "Markert",
        "given": "Katja"
      },
      {
        "family": "Dhole",
        "given": "Kaustubh D."
      },
      {
        "family": "Gimpel",
        "given": "Kevin"
      },
      {
        "family": "Omondi",
        "given": "Kevin"
      },
      {
        "family": "Mathewson",
        "given": "Kory"
      },
      {
        "family": "Chiafullo",
        "given": "Kristen"
      },
      {
        "family": "Shkaruta",
        "given": "Ksenia"
      },
      {
        "family": "Shridhar",
        "given": "Kumar"
      },
      {
        "family": "McDonell",
        "given": "Kyle"
      },
      {
        "family": "Richardson",
        "given": "Kyle"
      },
      {
        "family": "Reynolds",
        "given": "Laria"
      },
      {
        "family": "Gao",
        "given": "Leo"
      },
      {
        "family": "Zhang",
        "given": "Li"
      },
      {
        "family": "Dugan",
        "given": "Liam"
      },
      {
        "family": "Qin",
        "given": "Lianhui"
      },
      {
        "family": "Contreras-Ochando",
        "given": "Lidia"
      },
      {
        "family": "Morency",
        "given": "Louis-Philippe"
      },
      {
        "family": "Moschella",
        "given": "Luca"
      },
      {
        "family": "Lam",
        "given": "Lucas"
      },
      {
        "family": "Noble",
        "given": "Lucy"
      },
      {
        "family": "Schmidt",
        "given": "Ludwig"
      },
      {
        "family": "He",
        "given": "Luheng"
      },
      {
        "family": "Colón",
        "given": "Luis Oliveros"
      },
      {
        "family": "Metz",
        "given": "Luke"
      },
      {
        "family": "Şenel",
        "given": "Lütfi Kerem"
      },
      {
        "family": "Bosma",
        "given": "Maarten"
      },
      {
        "family": "Sap",
        "given": "Maarten"
      },
      {
        "family": "Hoeve",
        "given": "Maartje",
        "dropping-particle": "ter"
      },
      {
        "family": "Farooqi",
        "given": "Maheen"
      },
      {
        "family": "Faruqui",
        "given": "Manaal"
      },
      {
        "family": "Mazeika",
        "given": "Mantas"
      },
      {
        "family": "Baturan",
        "given": "Marco"
      },
      {
        "family": "Marelli",
        "given": "Marco"
      },
      {
        "family": "Maru",
        "given": "Marco"
      },
      {
        "family": "Quintana",
        "given": "Maria Jose Ramírez"
      },
      {
        "family": "Tolkiehn",
        "given": "Marie"
      },
      {
        "family": "Giulianelli",
        "given": "Mario"
      },
      {
        "family": "Lewis",
        "given": "Martha"
      },
      {
        "family": "Potthast",
        "given": "Martin"
      },
      {
        "family": "Leavitt",
        "given": "Matthew L."
      },
      {
        "family": "Hagen",
        "given": "Matthias"
      },
      {
        "family": "Schubert",
        "given": "Mátyás"
      },
      {
        "family": "Baitemirova",
        "given": "Medina Orduna"
      },
      {
        "family": "Arnaud",
        "given": "Melody"
      },
      {
        "family": "McElrath",
        "given": "Melvin"
      },
      {
        "family": "Yee",
        "given": "Michael A."
      },
      {
        "family": "Cohen",
        "given": "Michael"
      },
      {
        "family": "Gu",
        "given": "Michael"
      },
      {
        "family": "Ivanitskiy",
        "given": "Michael"
      },
      {
        "family": "Starritt",
        "given": "Michael"
      },
      {
        "family": "Strube",
        "given": "Michael"
      },
      {
        "family": "Swędrowski",
        "given": "Michał"
      },
      {
        "family": "Bevilacqua",
        "given": "Michele"
      },
      {
        "family": "Yasunaga",
        "given": "Michihiro"
      },
      {
        "family": "Kale",
        "given": "Mihir"
      },
      {
        "family": "Cain",
        "given": "Mike"
      },
      {
        "family": "Xu",
        "given": "Mimee"
      },
      {
        "family": "Suzgun",
        "given": "Mirac"
      },
      {
        "family": "Walker",
        "given": "Mitch"
      },
      {
        "family": "Tiwari",
        "given": "Mo"
      },
      {
        "family": "Bansal",
        "given": "Mohit"
      },
      {
        "family": "Aminnaseri",
        "given": "Moin"
      },
      {
        "family": "Geva",
        "given": "Mor"
      },
      {
        "family": "Gheini",
        "given": "Mozhdeh"
      },
      {
        "family": "T",
        "given": "Mukund Varma"
      },
      {
        "family": "Peng",
        "given": "Nanyun"
      },
      {
        "family": "Chi",
        "given": "Nathan A."
      },
      {
        "family": "Lee",
        "given": "Nayeon"
      },
      {
        "family": "Krakover",
        "given": "Neta Gur-Ari"
      },
      {
        "family": "Cameron",
        "given": "Nicholas"
      },
      {
        "family": "Roberts",
        "given": "Nicholas"
      },
      {
        "family": "Doiron",
        "given": "Nick"
      },
      {
        "family": "Martinez",
        "given": "Nicole"
      },
      {
        "family": "Nangia",
        "given": "Nikita"
      },
      {
        "family": "Deckers",
        "given": "Niklas"
      },
      {
        "family": "Muennighoff",
        "given": "Niklas"
      },
      {
        "family": "Keskar",
        "given": "Nitish Shirish"
      },
      {
        "family": "Iyer",
        "given": "Niveditha S."
      },
      {
        "family": "Constant",
        "given": "Noah"
      },
      {
        "family": "Fiedel",
        "given": "Noah"
      },
      {
        "family": "Wen",
        "given": "Nuan"
      },
      {
        "family": "Zhang",
        "given": "Oliver"
      },
      {
        "family": "Agha",
        "given": "Omar"
      },
      {
        "family": "Elbaghdadi",
        "given": "Omar"
      },
      {
        "family": "Levy",
        "given": "Omer"
      },
      {
        "family": "Evans",
        "given": "Owain"
      },
      {
        "family": "Casares",
        "given": "Pablo Antonio Moreno"
      },
      {
        "family": "Doshi",
        "given": "Parth"
      },
      {
        "family": "Fung",
        "given": "Pascale"
      },
      {
        "family": "Liang",
        "given": "Paul Pu"
      },
      {
        "family": "Vicol",
        "given": "Paul"
      },
      {
        "family": "Alipoormolabashi",
        "given": "Pegah"
      },
      {
        "family": "Liao",
        "given": "Peiyuan"
      },
      {
        "family": "Liang",
        "given": "Percy"
      },
      {
        "family": "Chang",
        "given": "Peter"
      },
      {
        "family": "Eckersley",
        "given": "Peter"
      },
      {
        "family": "Htut",
        "given": "Phu Mon"
      },
      {
        "family": "Hwang",
        "given": "Pinyu"
      },
      {
        "family": "Miłkowski",
        "given": "Piotr"
      },
      {
        "family": "Patil",
        "given": "Piyush"
      },
      {
        "family": "Pezeshkpour",
        "given": "Pouya"
      },
      {
        "family": "Oli",
        "given": "Priti"
      },
      {
        "family": "Mei",
        "given": "Qiaozhu"
      },
      {
        "family": "Lyu",
        "given": "Qing"
      },
      {
        "family": "Chen",
        "given": "Qinlang"
      },
      {
        "family": "Banjade",
        "given": "Rabin"
      },
      {
        "family": "Rudolph",
        "given": "Rachel Etta"
      },
      {
        "family": "Gabriel",
        "given": "Raefer"
      },
      {
        "family": "Habacker",
        "given": "Rahel"
      },
      {
        "family": "Risco",
        "given": "Ramon"
      },
      {
        "family": "Millière",
        "given": "Raphaël"
      },
      {
        "family": "Garg",
        "given": "Rhythm"
      },
      {
        "family": "Barnes",
        "given": "Richard"
      },
      {
        "family": "Saurous",
        "given": "Rif A."
      },
      {
        "family": "Arakawa",
        "given": "Riku"
      },
      {
        "family": "Raymaekers",
        "given": "Robbe"
      },
      {
        "family": "Frank",
        "given": "Robert"
      },
      {
        "family": "Sikand",
        "given": "Rohan"
      },
      {
        "family": "Novak",
        "given": "Roman"
      },
      {
        "family": "Sitelew",
        "given": "Roman"
      },
      {
        "family": "LeBras",
        "given": "Ronan"
      },
      {
        "family": "Liu",
        "given": "Rosanne"
      },
      {
        "family": "Jacobs",
        "given": "Rowan"
      },
      {
        "family": "Zhang",
        "given": "Rui"
      },
      {
        "family": "Salakhutdinov",
        "given": "Ruslan"
      },
      {
        "family": "Chi",
        "given": "Ryan"
      },
      {
        "family": "Lee",
        "given": "Ryan"
      },
      {
        "family": "Stovall",
        "given": "Ryan"
      },
      {
        "family": "Teehan",
        "given": "Ryan"
      },
      {
        "family": "Yang",
        "given": "Rylan"
      },
      {
        "family": "Singh",
        "given": "Sahib"
      },
      {
        "family": "Mohammad",
        "given": "Saif M."
      },
      {
        "family": "Anand",
        "given": "Sajant"
      },
      {
        "family": "Dillavou",
        "given": "Sam"
      },
      {
        "family": "Shleifer",
        "given": "Sam"
      },
      {
        "family": "Wiseman",
        "given": "Sam"
      },
      {
        "family": "Gruetter",
        "given": "Samuel"
      },
      {
        "family": "Bowman",
        "given": "Samuel R."
      },
      {
        "family": "Schoenholz",
        "given": "Samuel S."
      },
      {
        "family": "Han",
        "given": "Sanghyun"
      },
      {
        "family": "Kwatra",
        "given": "Sanjeev"
      },
      {
        "family": "Rous",
        "given": "Sarah A."
      },
      {
        "family": "Ghazarian",
        "given": "Sarik"
      },
      {
        "family": "Ghosh",
        "given": "Sayan"
      },
      {
        "family": "Casey",
        "given": "Sean"
      },
      {
        "family": "Bischoff",
        "given": "Sebastian"
      },
      {
        "family": "Gehrmann",
        "given": "Sebastian"
      },
      {
        "family": "Schuster",
        "given": "Sebastian"
      },
      {
        "family": "Sadeghi",
        "given": "Sepideh"
      },
      {
        "family": "Hamdan",
        "given": "Shadi"
      },
      {
        "family": "Zhou",
        "given": "Sharon"
      },
      {
        "family": "Srivastava",
        "given": "Shashank"
      },
      {
        "family": "Shi",
        "given": "Sherry"
      },
      {
        "family": "Singh",
        "given": "Shikhar"
      },
      {
        "family": "Asaadi",
        "given": "Shima"
      },
      {
        "family": "Gu",
        "given": "Shixiang Shane"
      },
      {
        "family": "Pachchigar",
        "given": "Shubh"
      },
      {
        "family": "Toshniwal",
        "given": "Shubham"
      },
      {
        "family": "Upadhyay",
        "given": "Shyam"
      },
      {
        "family": "Shyamolima",
        "given": ""
      },
      {
        "family": "Debnath",
        "given": ""
      },
      {
        "family": "Shakeri",
        "given": "Siamak"
      },
      {
        "family": "Thormeyer",
        "given": "Simon"
      },
      {
        "family": "Melzi",
        "given": "Simone"
      },
      {
        "family": "Reddy",
        "given": "Siva"
      },
      {
        "family": "Makini",
        "given": "Sneha Priscilla"
      },
      {
        "family": "Lee",
        "given": "Soo-Hwan"
      },
      {
        "family": "Torene",
        "given": "Spencer"
      },
      {
        "family": "Hatwar",
        "given": "Sriharsha"
      },
      {
        "family": "Dehaene",
        "given": "Stanislas"
      },
      {
        "family": "Divic",
        "given": "Stefan"
      },
      {
        "family": "Ermon",
        "given": "Stefano"
      },
      {
        "family": "Biderman",
        "given": "Stella"
      },
      {
        "family": "Lin",
        "given": "Stephanie"
      },
      {
        "family": "Prasad",
        "given": "Stephen"
      },
      {
        "family": "Piantadosi",
        "given": "Steven T."
      },
      {
        "family": "Shieber",
        "given": "Stuart M."
      },
      {
        "family": "Misherghi",
        "given": "Summer"
      },
      {
        "family": "Kiritchenko",
        "given": "Svetlana"
      },
      {
        "family": "Mishra",
        "given": "Swaroop"
      },
      {
        "family": "Linzen",
        "given": "Tal"
      },
      {
        "family": "Schuster",
        "given": "Tal"
      },
      {
        "family": "Li",
        "given": "Tao"
      },
      {
        "family": "Yu",
        "given": "Tao"
      },
      {
        "family": "Ali",
        "given": "Tariq"
      },
      {
        "family": "Hashimoto",
        "given": "Tatsu"
      },
      {
        "family": "Wu",
        "given": "Te-Lin"
      },
      {
        "family": "Desbordes",
        "given": "Théo"
      },
      {
        "family": "Rothschild",
        "given": "Theodore"
      },
      {
        "family": "Phan",
        "given": "Thomas"
      },
      {
        "family": "Wang",
        "given": "Tianle"
      },
      {
        "family": "Nkinyili",
        "given": "Tiberius"
      },
      {
        "family": "Schick",
        "given": "Timo"
      },
      {
        "family": "Kornev",
        "given": "Timofei"
      },
      {
        "family": "Tunduny",
        "given": "Titus"
      },
      {
        "family": "Gerstenberg",
        "given": "Tobias"
      },
      {
        "family": "Chang",
        "given": "Trenton"
      },
      {
        "family": "Neeraj",
        "given": "Trishala"
      },
      {
        "family": "Khot",
        "given": "Tushar"
      },
      {
        "family": "Shultz",
        "given": "Tyler"
      },
      {
        "family": "Shaham",
        "given": "Uri"
      },
      {
        "family": "Misra",
        "given": "Vedant"
      },
      {
        "family": "Demberg",
        "given": "Vera"
      },
      {
        "family": "Nyamai",
        "given": "Victoria"
      },
      {
        "family": "Raunak",
        "given": "Vikas"
      },
      {
        "family": "Ramasesh",
        "given": "Vinay"
      },
      {
        "family": "Prabhu",
        "given": "Vinay Uday"
      },
      {
        "family": "Padmakumar",
        "given": "Vishakh"
      },
      {
        "family": "Srikumar",
        "given": "Vivek"
      },
      {
        "family": "Fedus",
        "given": "William"
      },
      {
        "family": "Saunders",
        "given": "William"
      },
      {
        "family": "Zhang",
        "given": "William"
      },
      {
        "family": "Vossen",
        "given": "Wout"
      },
      {
        "family": "Ren",
        "given": "Xiang"
      },
      {
        "family": "Tong",
        "given": "Xiaoyu"
      },
      {
        "family": "Zhao",
        "given": "Xinran"
      },
      {
        "family": "Wu",
        "given": "Xinyi"
      },
      {
        "family": "Shen",
        "given": "Xudong"
      },
      {
        "family": "Yaghoobzadeh",
        "given": "Yadollah"
      },
      {
        "family": "Lakretz",
        "given": "Yair"
      },
      {
        "family": "Song",
        "given": "Yangqiu"
      },
      {
        "family": "Bahri",
        "given": "Yasaman"
      },
      {
        "family": "Choi",
        "given": "Yejin"
      },
      {
        "family": "Yang",
        "given": "Yichi"
      },
      {
        "family": "Hao",
        "given": "Yiding"
      },
      {
        "family": "Chen",
        "given": "Yifu"
      },
      {
        "family": "Belinkov",
        "given": "Yonatan"
      },
      {
        "family": "Hou",
        "given": "Yu"
      },
      {
        "family": "Hou",
        "given": "Yufang"
      },
      {
        "family": "Bai",
        "given": "Yuntao"
      },
      {
        "family": "Seid",
        "given": "Zachary"
      },
      {
        "family": "Zhao",
        "given": "Zhuoye"
      },
      {
        "family": "Wang",
        "given": "Zijian"
      },
      {
        "family": "Wang",
        "given": "Zijie J."
      },
      {
        "family": "Wang",
        "given": "Zirui"
      },
      {
        "family": "Wu",
        "given": "Ziyi"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 20]]
    },
    "issued": {
      "date-parts": [["2023", 6, 12]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/FFQIYW4U",
    "type": "article-journal",
    "abstract": "Pretrained large models, particularly large language models, have garnered increasing attention, as they have demonstrated remarkable abilities through contextual learning. Pretrained large models are increasingly recognized as fundamental tools for solving various tasks. However, the substantial computational demands of large models have dissuaded most product teams and individuals from running them. In such scenarios, to leverage the exceptional performance of large models, one must solely depend on costly APIs, further burdening product teams and individuals. On the other hand, despite the overall inferior performance of small models compared to large models, there are certain distributions where small models can achieve comparable or even superior results. For instance, during training, small models may become trapped in a local optimum that is unique to certain distributions, leading to superior performance. Hence, we propose Data Shunt (DS), a general paradigm for collaboration of small and large models. DS not only substantially reduces the cost associated with deploying large models but also effectively enhances overall performance. Specifically, DS determines the shunting direction by evaluating the confidence level of small models. When the confidence level falls below a specific threshold, the input data is forwarded to large models. To further leverage the advantages of the small and large models, we introduce Prompt Pruning (PP) and 2-Stage Confidence Distillation (2CD), which facilitate mutual collaboration, leading to better results and less cost. \nThe remarkable performance across diverse modalities and tasks demonstrates the superiority of the proposed DS over large models. For instance, ChatGPT achieves an accuracy of 94.43% on Amazon Product sentiment analysis, and DS achieves an accuracy of 95.64%, while the cost has been reduced to only 31.18%. The code for the proposed method are provided for research purposes https://github.com/Anfeather/Data-Shunt.",
    "container-title": "Proceedings of the AAAI Conference on Artificial Intelligence",
    "DOI": "10.1609/aaai.v38i10.29003",
    "ISSN": "2374-3468",
    "issue": "10",
    "language": "en",
    "license": "Copyright (c) 2024 Association for the Advancement of Artificial Intelligence",
    "note": "number: 10",
    "page": "11249-11257",
    "source": "ojs.aaai.org",
    "title": "Data Shunt: Collaboration of Small and Large Models for Lower Costs and Better Performance",
    "title-short": "Data Shunt",
    "URL": "https://ojs.aaai.org/index.php/AAAI/article/view/29003",
    "volume": "38",
    "author": [
      {
        "family": "Chen",
        "given": "Dong"
      },
      {
        "family": "Zhuang",
        "given": "Yueting"
      },
      {
        "family": "Zhang",
        "given": "Shuo"
      },
      {
        "family": "Liu",
        "given": "Jinfeng"
      },
      {
        "family": "Dong",
        "given": "Su"
      },
      {
        "family": "Tang",
        "given": "Siliang"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 20]]
    },
    "issued": {
      "date-parts": [["2024", 3, 24]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/2WVGAYRQ",
    "type": "article-journal",
    "abstract": "We present Dynamic Skill Adaptation (DSA), an adaptive and dynamic framework to adapt novel and complex skills to Large Language Models (LLMs). Compared with previous work which learns from human-curated and static data in random orders, we propose to first automatically generate and organize the training data by mimicking the learning pathways of human and then dynamically tailor the training data based on the training dynamics. Specifically, inspired by the learning structures and teaching strategies in the human education system, we first construct a skill graph by decomposing complex skills into sub-skills and arranging them based on their dependencies in human syllables. For every skill, we utilize LLMs to generate both textbook-like data which contains detailed descriptions of skills for pre-training and exercise-like data which targets at explicitly utilizing the skills to solve problems for instruction-tuning. Furthermore, during the instruction-tuning, we dynamically update the training data which down-weight easy-to-learn examples, generate more complex examples, and filter out data with errors. Experiments on large language models such as LLAMA and Mistral demonstrate the effectiveness of our proposed methods in adapting math reasoning skills and social study skills.",
    "language": "en",
    "source": "openreview.net",
    "title": "Dynamic Skill Adaptation for Large Language Models",
    "URL": "https://openreview.net/forum?id=whXHZIaRVB",
    "author": [
      {
        "family": "Chen",
        "given": "Jiaao"
      },
      {
        "family": "Yang",
        "given": "Diyi"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 21]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/K5V39BQK",
    "type": "article",
    "abstract": "Data plays a fundamental role in training Large Language Models (LLMs). Efficient data management, particularly in formulating a well-suited training dataset, is significant for enhancing model performance and improving training efficiency during pretraining and supervised fine-tuning stages. Despite the considerable importance of data management, the underlying mechanism of current prominent practices are still unknown. Consequently, the exploration of data management has attracted more and more attention among the research community. This survey aims to provide a comprehensive overview of current research in data management within both the pretraining and supervised fine-tuning stages of LLMs, covering various aspects of data management strategy design. Looking into the future, we extrapolate existing challenges and outline promising directions for development in this field. Therefore, this survey serves as a guiding resource for practitioners aspiring to construct powerful LLMs through efficient data management practices. The collection of the latest papers is available at https://github.com/ZigeW/data_management_LLM.",
    "DOI": "10.48550/arXiv.2312.01700",
    "note": "arXiv:2312.01700 [cs]",
    "number": "arXiv:2312.01700",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Data Management For Training Large Language Models: A Survey",
    "title-short": "Data Management For Training Large Language Models",
    "URL": "http://arxiv.org/abs/2312.01700",
    "author": [
      {
        "family": "Wang",
        "given": "Zige"
      },
      {
        "family": "Zhong",
        "given": "Wanjun"
      },
      {
        "family": "Wang",
        "given": "Yufei"
      },
      {
        "family": "Zhu",
        "given": "Qi"
      },
      {
        "family": "Mi",
        "given": "Fei"
      },
      {
        "family": "Wang",
        "given": "Baojun"
      },
      {
        "family": "Shang",
        "given": "Lifeng"
      },
      {
        "family": "Jiang",
        "given": "Xin"
      },
      {
        "family": "Liu",
        "given": "Qun"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 21]]
    },
    "issued": {
      "date-parts": [["2024", 8, 2]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/QQIQ3J5G",
    "type": "paper-conference",
    "abstract": "Large language models (LLMs) with enormous pre-training tokens and parameters emerge diverse abilities, including math reasoning, codegeneration, and instruction following. These abilities are further enhanced by supervised fine-tuning (SFT). While the open-source community has explored ad-hoc SFT for enhancing individual capabilities, proprietary LLMs exhibit versatility across various skills. Therefore, understanding the facilitation of multiple abilities via SFT is paramount. In this study, we specificially focuses on the interplay of data composition between mathematical reasoning, code generation, and general human-aligning abilities during SFT. We propose four intriguing research questions to explore the association between model performance and various factors including data amount, composition ratio, model size and SFT strategies. Our experiments reveal that distinct capabilities scale differently and larger models generally show superior performance with same amount of data. Mathematical reasoning and code generation consistently improve with increasing data amount, whereas general abilities plateau after roughly a thousand samples. Moreover, we observe data composition appears to enhance various abilities under limited data conditions, yet can lead to performance conflicts when data is plentiful. Our findings also suggest the amount of composition data influences performance more than the composition ratio. In analysis of SFT strategies, we find that sequentially learning multiple skills risks catastrophic forgetting. Our proposed Dual-stage Mixed Fine-tuning (DMT) strategy offers a promising solution to learn multiple abilities with different scaling patterns.",
    "container-title": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "DOI": "10.18653/v1/2024.acl-long.12",
    "event-place": "Bangkok, Thailand",
    "event-title": "ACL 2024",
    "page": "177–198",
    "publisher": "Association for Computational Linguistics",
    "publisher-place": "Bangkok, Thailand",
    "source": "ACLWeb",
    "title": "How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition",
    "URL": "https://aclanthology.org/2024.acl-long.12/",
    "author": [
      {
        "family": "Dong",
        "given": "Guanting"
      },
      {
        "family": "Yuan",
        "given": "Hongyi"
      },
      {
        "family": "Lu",
        "given": "Keming"
      },
      {
        "family": "Li",
        "given": "Chengpeng"
      },
      {
        "family": "Xue",
        "given": "Mingfeng"
      },
      {
        "family": "Liu",
        "given": "Dayiheng"
      },
      {
        "family": "Wang",
        "given": "Wei"
      },
      {
        "family": "Yuan",
        "given": "Zheng"
      },
      {
        "family": "Zhou",
        "given": "Chang"
      },
      {
        "family": "Zhou",
        "given": "Jingren"
      }
    ],
    "editor": [
      {
        "family": "Ku",
        "given": "Lun-Wei"
      },
      {
        "family": "Martins",
        "given": "Andre"
      },
      {
        "family": "Srikumar",
        "given": "Vivek"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 21]]
    },
    "issued": {
      "date-parts": [["2024", 8]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/A4JM496Z",
    "type": "article",
    "abstract": "Scaling the test-time compute of large language models has demonstrated impressive performance on reasoning benchmarks. However, existing evaluations of test-time scaling make the strong assumption that a reasoning system should always give an answer to any question provided. This overlooks concerns about whether a model is confident in its answer, and whether it is appropriate to always provide a response. To address these concerns, we extract confidence scores during reasoning for thresholding model responses. We find that increasing compute budget at inference time not only helps models answer more questions correctly, but also increases confidence in correct responses. We then extend the current paradigm of zero-risk responses during evaluation by considering settings with non-zero levels of response risk, and suggest a recipe for reporting evaluations under these settings.",
    "DOI": "10.48550/arXiv.2502.13962",
    "note": "arXiv:2502.13962 [cs]",
    "number": "arXiv:2502.13962",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Is That Your Final Answer? Test-Time Scaling Improves Selective Question Answering",
    "title-short": "Is That Your Final Answer?",
    "URL": "http://arxiv.org/abs/2502.13962",
    "author": [
      {
        "family": "Jurayj",
        "given": "William"
      },
      {
        "family": "Cheng",
        "given": "Jeffrey"
      },
      {
        "family": "Durme",
        "given": "Benjamin Van"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 22]]
    },
    "issued": {
      "date-parts": [["2025", 2, 19]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/9B464DHQ",
    "type": "article",
    "abstract": "When selecting data for training large-scale models, standard practice is to filter for examples that match human notions of data quality. Such filtering yields qualitatively clean datapoints that intuitively should improve model behavior. However, in practice the opposite can often happen: we find that selecting according to similarity with \"high quality\" data sources may not increase (and can even hurt) performance compared to randomly selecting data. To develop better methods for selecting data, we start by framing dataset selection as an optimization problem that we can directly solve for: given target tasks, a learning algorithm, and candidate data, select the subset that maximizes model performance. This framework thus avoids handpicked notions of data quality, and instead models explicitly how the learning process uses train datapoints to predict on the target tasks. Our resulting method greatly improves language model (LM) performance on both pre-specified tasks and previously unseen tasks. Specifically, choosing target tasks representative of standard LM problems and evaluating on diverse held-out benchmarks, our selected datasets provide a 2x compute multiplier over baseline methods.",
    "DOI": "10.48550/arXiv.2401.12926",
    "note": "arXiv:2401.12926 [cs]",
    "number": "arXiv:2401.12926",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "DsDm: Model-Aware Dataset Selection with Datamodels",
    "title-short": "DsDm",
    "URL": "http://arxiv.org/abs/2401.12926",
    "author": [
      {
        "family": "Engstrom",
        "given": "Logan"
      },
      {
        "family": "Feldmann",
        "given": "Axel"
      },
      {
        "family": "Madry",
        "given": "Aleksander"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 24]]
    },
    "issued": {
      "date-parts": [["2024", 1, 23]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/FVA3QM23",
    "type": "article",
    "abstract": "We present Dynamic Skill Adaptation (DSA), an adaptive and dynamic framework to adapt novel and complex skills to Large Language Models (LLMs). Compared with previous work which learns from human-curated and static data in random orders, we propose to first automatically generate and organize the training data by mimicking the learning pathways of human and then dynamically tailor the training data based on the training dynamics. Specifically, inspired by the learning structures and teaching strategies in the human education system, we first construct a skill graph by decomposing complex skills into sub-skills and arranging them based on their dependencies in human syllables. For every skill, we utilize LLMs to generate both textbook-like data which contains detailed descriptions of skills for pre-training and exercise-like data which targets at explicitly utilizing the skills to solve problems for instruction-tuning. Furthermore, during the instruction-tuning, we dynamically update the training data which down-weight easy-to-learn examples, generate more complex examples, and filter out data with errors. Experiments on large language models such as LLAMA and Mistral demonstrate the effectiveness of our proposed methods in adapting math reasoning skills and social study skills.",
    "DOI": "10.48550/arXiv.2412.19361",
    "language": "en-US",
    "note": "arXiv:2412.19361 [cs]",
    "number": "arXiv:2412.19361",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Dynamic Skill Adaptation for Large Language Models",
    "URL": "http://arxiv.org/abs/2412.19361",
    "author": [
      {
        "family": "Chen",
        "given": "Jiaao"
      },
      {
        "family": "Yang",
        "given": "Diyi"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 25]]
    },
    "issued": {
      "date-parts": [["2024", 12, 26]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/TLC49QTB",
    "type": "paper-conference",
    "abstract": "Synthetic data has been widely used to train large language models, but their generative nature inevitably introduces noisy, non-informative, and misleading learning signals. In this paper, we propose Montessori-Instruct, a novel data synthesis framework that tailors the data synthesis ability of the teacher language model toward the student language model's learning process. Specifically, we utilize local data influence of synthetic training data points on students to characterize students' learning preferences. Then, we train the teacher model with Direct Preference Optimization (DPO) to generate synthetic data tailored toward student learning preferences. Experiments with Llama3-8B-Instruct (teacher) and Llama3-8B (student) on Alpaca Eval and MT-Bench demonstrate that Montessori-Instruct significantly outperforms standard synthesis methods by 18.35\\% and 46.24\\% relatively. Our method also beats data synthesized by a stronger teacher model, GPT-4o. Further analysis confirms the benefits of teacher's learning to generate more influential training data in the student's improved learning, the advantages of local data influence in accurately measuring student preferences, and the robustness of Montessori-Instruct across different student models. Our code, data, and models will be open-sourced.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "Montessori-Instruct: Generate Influential Training Data Tailored for Student Learning",
    "title-short": "Montessori-Instruct",
    "URL": "https://openreview.net/forum?id=9RCT0ngvZP",
    "author": [
      {
        "family": "Li",
        "given": "Xiaochuan"
      },
      {
        "family": "Yu",
        "given": "Zichun"
      },
      {
        "family": "Xiong",
        "given": "Chenyan"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 25]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/5442UJN4",
    "type": "article",
    "abstract": "Emojis are a succinct form of language which can express concrete meanings, emotions, and intentions. Emojis also carry signals that can be used to better understand communicative intent. They have become a ubiquitous part of our daily lives, making them an important part of understanding user-generated content. The emoji prediction task aims at predicting the proper set of emojis associated with a piece of text. Through emoji prediction, models can learn rich representations of the communicative intent of the written text. While existing research on the emoji prediction task focus on a small subset of emoji types closely related to certain emotions, this setting oversimplifies the task and wastes the expressive power of emojis. In this paper, we extend the existing setting of the emoji prediction task to include a richer set of emojis and to allow multi-label classification on the task. We propose novel models for multi-class and multi-label emoji prediction based on Transformer networks. We also construct multiple emoji prediction datasets from Twitter using heuristics. The BERT models achieve state-of-the-art performances on all our datasets under all the settings, with relative improvements of 27.21% to 236.36% in accuracy, 2.01% to 88.28% in top-5 accuracy and 65.19% to 346.79% in F-1 score, compared to the prior state-of-the-art. Our results demonstrate the efficacy of deep Transformer-based models on the emoji prediction task. We also release our datasets at https://github.com/hikari-NYU/Emoji_Prediction_Datasets_MMS for future researchers.",
    "DOI": "10.48550/arXiv.2007.07389",
    "note": "arXiv:2007.07389 [cs]",
    "number": "arXiv:2007.07389",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Emoji Prediction: Extensions and Benchmarking",
    "title-short": "Emoji Prediction",
    "URL": "http://arxiv.org/abs/2007.07389",
    "author": [
      {
        "family": "Ma",
        "given": "Weicheng"
      },
      {
        "family": "Liu",
        "given": "Ruibo"
      },
      {
        "family": "Wang",
        "given": "Lili"
      },
      {
        "family": "Vosoughi",
        "given": "Soroush"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 25]]
    },
    "issued": {
      "date-parts": [["2020", 7, 14]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/5LZ8B7LV",
    "type": "paper-conference",
    "abstract": "Detecting online hate is a complex task, and low-performing models have harmful consequences when used for sensitive applications such as content moderation. Emoji-based hate is an emerging challenge for automated detection. We present HatemojiCheck, a test suite of 3,930 short-form statements that allows us to evaluate performance on hateful language expressed with emoji. Using the test suite, we expose weaknesses in existing hate detection models. To address these weaknesses, we create the HatemojiBuild dataset using a human-and-model-in-the-loop approach. Models built with these 5,912 adversarial examples perform substantially better at detecting emoji-based hate, while retaining strong performance on text-only hate. Both HatemojiCheck and HatemojiBuild are made publicly available.",
    "container-title": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    "DOI": "10.18653/v1/2022.naacl-main.97",
    "event-place": "Seattle, United States",
    "event-title": "NAACL-HLT 2022",
    "page": "1352–1368",
    "publisher": "Association for Computational Linguistics",
    "publisher-place": "Seattle, United States",
    "source": "ACLWeb",
    "title": "Hatemoji: A Test Suite and Adversarially-Generated Dataset for Benchmarking and Detecting Emoji-Based Hate",
    "title-short": "Hatemoji",
    "URL": "https://aclanthology.org/2022.naacl-main.97/",
    "author": [
      {
        "family": "Kirk",
        "given": "Hannah"
      },
      {
        "family": "Vidgen",
        "given": "Bertie"
      },
      {
        "family": "Rottger",
        "given": "Paul"
      },
      {
        "family": "Thrush",
        "given": "Tristan"
      },
      {
        "family": "Hale",
        "given": "Scott A."
      }
    ],
    "editor": [
      {
        "family": "Carpuat",
        "given": "Marine"
      },
      {
        "family": "Marneffe",
        "given": "Marie-Catherine",
        "non-dropping-particle": "de"
      },
      {
        "family": "Meza Ruiz",
        "given": "Ivan Vladimir"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 25]]
    },
    "issued": {
      "date-parts": [["2022", 7]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/CBLBEA2E",
    "type": "paper-conference",
    "abstract": "Data selection is of great significance in pretraining large language models, given the variation in quality within the large-scale available training corpora. To achieve this, researchers are currently investigating the use of data influence to measure the importance of data instances, $i.e.,$ a high influence score indicates that incorporating this instance to the training set is likely to enhance the model performance. Consequently, they select the top-$k$ instances with the highest scores. However, this approach has several limitations. (1) Calculating the accurate influence of all available data is time-consuming. (2) The selected data instances are not diverse enough, which may hinder the pretrained model's ability to generalize effectively to various downstream tasks. In this paper, we introduce $\\texttt{Quad}$, a data selection approach that considers both quality and diversity by using data influence to achieve state-of-the-art pretraining results. To compute the influence ($i.e.,$ the quality) more accurately and efficiently, we incorporate the attention layers to capture more semantic details, which can be accelerated through the Kronecker product. For the diversity, $\\texttt{Quad}$ clusters the dataset into similar data instances within each cluster and diverse instances across different clusters. For each cluster, if we opt to select data from it, we take some samples to evaluate the influence to prevent processing all instances. Overall, we favor clusters with highly influential instances (ensuring high quality) or clusters that have been selected less frequently (ensuring diversity), thereby well balancing between quality and diversity. Experiments on Slimpajama and FineWeb over 7B large language models demonstrate that $\\texttt{Quad}$ significantly outperforms other data selection methods with a low FLOPs consumption. Further analysis also validates the effectiveness of our influence calculation.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "Harnessing Diversity for Important Data Selection in Pretraining Large Language Models",
    "URL": "https://openreview.net/forum?id=bMC1t7eLRc",
    "author": [
      {
        "family": "Zhang",
        "given": "Chi"
      },
      {
        "family": "Zhong",
        "given": "Huaping"
      },
      {
        "family": "Zhang",
        "given": "Kuan"
      },
      {
        "family": "Chai",
        "given": "Chengliang"
      },
      {
        "family": "Wang",
        "given": "Rui"
      },
      {
        "family": "Zhuang",
        "given": "Xinlin"
      },
      {
        "family": "Bai",
        "given": "Tianyi"
      },
      {
        "family": "Jiantao",
        "given": "Qiu"
      },
      {
        "family": "Cao",
        "given": "Lei"
      },
      {
        "family": "Fan",
        "given": "Ju"
      },
      {
        "family": "Yuan",
        "given": "Ye"
      },
      {
        "family": "Wang",
        "given": "Guoren"
      },
      {
        "family": "He",
        "given": "Conghui"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 26]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/F9TK9MHS",
    "type": "paper-conference",
    "abstract": "Synthetic data is increasingly employed for training dataset augmentation in computer vision. However, prior works typically perform a uniform search across the entire category space, overlooking the interaction between synthetic data generation and downstream task training. Furthermore, balancing the diversity of synthetic data while ensuring it remains within the same distribution as real data (i.e., avoiding outliers) remains a significant challenge. In this work, we propose a generative agent to augment target training datasets with synthetic data for model fine-tuning. Our agent iteratively generates relevant data on-the-fly, aligning with the target training dataset distribution. It prioritizes sampling diverse synthetic data that complements marginal training samples, with a focus on synthetic data that exhibit higher variance in gradient updates. Evaluations across diverse supervised image classification tasks demonstrate the effectiveness of our approach.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "GenDataAgent: On-the-fly Dataset Augmentation with Synthetic Data",
    "title-short": "GenDataAgent",
    "URL": "https://openreview.net/forum?id=WoGnnggVCZ",
    "author": [
      {
        "family": "Li",
        "given": "Zhiteng"
      },
      {
        "family": "Chen",
        "given": "Lele"
      },
      {
        "family": "Andrews",
        "given": "Jerone"
      },
      {
        "family": "Ba",
        "given": "Yunhao"
      },
      {
        "family": "Zhang",
        "given": "Yulun"
      },
      {
        "family": "Xiang",
        "given": "Alice"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 26]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/YGWRU4LE",
    "type": "paper-conference",
    "abstract": "Through alignment with human preferences, Large Language Models (LLMs) have advanced significantly in generating honest, harmless, and helpful responses. However, collecting high-quality preference data is a resource-intensive and creativity-demanding process, especially for the continual improvement of LLMs. We introduce SynPO, a self-boosting paradigm that leverages synthetic preference data for model alignment. SynPO employs an iterative mechanism wherein a self-prompt generator creates diverse prompts, and a response improver refines model responses progressively. This approach trains LLMs to autonomously learn the generative rewards for their own outputs and eliminates the need for large-scale annotation of prompts and human preferences. After four SynPO iterations, Llama3-8B and Mistral-7B show significant enhancements in instruction-following abilities, achieving over 22.1% win rate improvements on AlpacaEval 2.0 and ArenaHard. Simultaneously, SynPO improves the general performance of LLMs on various tasks, validated by a 3.2 to 5.0 average score increase on the well-recognized Open LLM leaderboard.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "Self-Boosting Large Language Models with Synthetic Preference Data",
    "URL": "https://openreview.net/forum?id=7visV100Ms",
    "author": [
      {
        "family": "Dong",
        "given": "Qingxiu"
      },
      {
        "family": "Dong",
        "given": "Li"
      },
      {
        "family": "Zhang",
        "given": "Xingxing"
      },
      {
        "family": "Sui",
        "given": "Zhifang"
      },
      {
        "family": "Wei",
        "given": "Furu"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 26]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/KI2YTVY2",
    "type": "paper-conference",
    "abstract": "Synthetic data has gained attention for training large language models, but poor-quality data can harm performance (see, e.g., Shumailov et al. (2023); Seddik et al. (2024)). A potential solution is data pruning, which retains only high-quality data based on a score function (human or machine feedback). Previous work Feng et al. (2024) analyzed models trained on synthetic data as sample size increases. We extend this by using random matrix theory to derive the performance of a binary classifier trained on a mix of real and pruned synthetic data in a high dimensional setting. Our findings identify conditions where synthetic data could improve performance, focusing on the quality of the generative model and verification strategy. We also show a smooth phase transition in synthetic label noise, contrasting with prior sharp behavior in infinite sample limits. Experiments with toy models and large language models validate our theoretical results.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "Maximizing the Potential of Synthetic Data: Insights from Random Matrix Theory",
    "title-short": "Maximizing the Potential of Synthetic Data",
    "URL": "https://openreview.net/forum?id=I9Dsq0cVo9",
    "author": [
      {
        "family": "Firdoussi",
        "given": "Aymane El"
      },
      {
        "family": "Seddik",
        "given": "Mohamed El Amine"
      },
      {
        "family": "Hayou",
        "given": "Soufiane"
      },
      {
        "family": "Alami",
        "given": "Reda"
      },
      {
        "family": "Alzubaidi",
        "given": "Ahmed"
      },
      {
        "family": "Hacid",
        "given": "Hakim"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 26]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/YCPX87SU",
    "type": "paper-conference",
    "abstract": "Large Language Models (LLMs) such as GPT-4 and Llama3 have significantly impacted various fields by enabling high-quality synthetic data generation and reducing dependence on expensive human-generated datasets. Despite this, challenges remain in the areas of generalization, controllability, diversity, and truthfulness within the existing generative frameworks. To address these challenges, this paper presents DataGen, a comprehensive LLM-powered framework designed to produce diverse, accurate, and highly controllable datasets. DataGen is adaptable, supporting all types of text datasets and enhancing the generative process through innovative mechanisms. To augment data diversity, DataGen incorporates an attribute-guided generation module and a group checking feature. For accuracy, it employs a code-based mathematical assessment for label verification alongside a retrieval-augmented generation technique for factual validation. The framework also allows for user-specified constraints, enabling customization of the data generation process to suit particular requirements. Extensive experiments demonstrate the superior quality of data generated by DataGen, and each module within DataGen plays a critical role in this enhancement. Additionally, DataGen is applied in two practical scenarios: benchmarking LLMs and data augmentation. The results indicate that DataGen effectively supports dynamic and evolving benchmarking and that data augmentation improves LLM capabilities in various domains, including agent-oriented abilities and reasoning skills.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "DataGen: Unified Synthetic Dataset Generation via Large Language Models",
    "title-short": "DataGen",
    "URL": "https://openreview.net/forum?id=F5R0lG74Tu",
    "author": [
      {
        "family": "Huang",
        "given": "Yue"
      },
      {
        "family": "Wu",
        "given": "Siyuan"
      },
      {
        "family": "Gao",
        "given": "Chujie"
      },
      {
        "family": "Chen",
        "given": "Dongping"
      },
      {
        "family": "Zhang",
        "given": "Qihui"
      },
      {
        "family": "Wan",
        "given": "Yao"
      },
      {
        "family": "Zhou",
        "given": "Tianyi"
      },
      {
        "family": "Xiao",
        "given": "Chaowei"
      },
      {
        "family": "Gao",
        "given": "Jianfeng"
      },
      {
        "family": "Sun",
        "given": "Lichao"
      },
      {
        "family": "Zhang",
        "given": "Xiangliang"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 26]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/669B9NXL",
    "type": "paper-conference",
    "abstract": "Pretraining on large-scale, unstructured internet text enables language models to acquire a significant amount of world knowledge. However, this knowledge acquisition is data-inefficient---to learn a fact, models must be trained on hundreds to thousands of diverse representations of it. This poses a challenge when adapting a pretrained model to a small corpus of domain-specific documents, where each fact may appear rarely or only once. We propose to bridge this gap with synthetic continued pretraining: using the small domain-specific corpus to synthesize a large corpus more amenable to learning, and then performing continued pretraining on the synthesized corpus. We instantiate this proposal with EntiGraph, a synthetic data augmentation algorithm that extracts salient entities from the source corpus and then generates diverse text by drawing connections between those entities. Synthetic continued pretraining with EntiGraph enables a language model to answer questions and follow generic instructions related to the source documents without access to them. If the source documents are instead available at inference time, we show that the knowledge acquired through our approach compounds with retrieval-augmented generation. To better understand these results, we build a simple mathematical model of EntiGraph, and show how synthetic data augmentation can \"rearrange\" knowledge to enable more data-efficient learning.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "Synthetic continued pretraining",
    "URL": "https://openreview.net/forum?id=07yvxWDSla",
    "author": [
      {
        "family": "Yang",
        "given": "Zitong"
      },
      {
        "family": "Band",
        "given": "Neil"
      },
      {
        "family": "Li",
        "given": "Shuangping"
      },
      {
        "family": "Candes",
        "given": "Emmanuel"
      },
      {
        "family": "Hashimoto",
        "given": "Tatsunori"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 26]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/DRADGNV7",
    "type": "paper-conference",
    "abstract": "Learning dynamics, which describes how the learning of specific training examples influences the model's predictions on other examples, gives us a powerful tool for understanding the behavior of deep learning systems. We study the learning dynamics of large language models during different types of finetuning, by analyzing the step-wise decomposition of how influence accumulates among different potential responses. Our framework allows a uniform interpretation of many interesting observations about the training of popular algorithms for both instruction tuning and preference tuning. In particular, we propose a hypothetical explanation of why specific types of hallucination are strengthened after finetuning, e.g., the model might use phrases or facts in the response for question B to answer question A, or the model might keep repeating similar simple phrases when generating responses. We also extend our framework and highlight a unique ``squeezing effect'' to explain a previously observed phenomenon in off-policy direct preference optimization (DPO), where running DPO for too long makes even the desired outputs less likely. This framework also provides insights into where the benefits of on-policy DPO and other variants come from. The analysis not only provides a novel perspective of understanding LLM's finetuning but also inspires a simple, effective method to improve alignment performance.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "Learning Dynamics of LLM Finetuning",
    "URL": "https://openreview.net/forum?id=tPNHOoZFl9",
    "author": [
      {
        "family": "Ren",
        "given": "Yi"
      },
      {
        "family": "Sutherland",
        "given": "Danica J."
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 26]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/56X7CQCL",
    "type": "paper-conference",
    "abstract": "Pretraining data of large language models composes multiple domains (e.g., web texts, academic papers, codes), whose mixture proportions crucially impact the competence of outcome models. While existing endeavors rely on heuristics or qualitative strategies to tune the proportions, we discover the quantitative predictability of model performance regarding the mixture proportions in function forms, which we refer to as the data mixing laws. Fitting such functions on sample mixtures unveils model performance on unseen mixtures before actual runs, thus guiding the selection of an ideal data mixture. Furthermore, we propose nested use of the scaling laws of training steps, model sizes, and our data mixing laws to predict the performance of large models trained on massive data under various mixtures with only small-scale training. Experimental results verify that our method effectively optimizes the training mixture of a 1B model trained for 100B tokens in RedPajama, reaching a performance comparable to the one trained for 48% more steps on the default mixture. Extending the application of data mixing laws to continual training accurately predicts the critical mixture proportion that avoids catastrophic forgetting and outlooks the potential for dynamic data schedules.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance",
    "title-short": "Data Mixing Laws",
    "URL": "https://openreview.net/forum?id=jjCB27TMK3",
    "author": [
      {
        "family": "Ye",
        "given": "Jiasheng"
      },
      {
        "family": "Liu",
        "given": "Peiju"
      },
      {
        "family": "Sun",
        "given": "Tianxiang"
      },
      {
        "family": "Zhan",
        "given": "Jun"
      },
      {
        "family": "Zhou",
        "given": "Yunhua"
      },
      {
        "family": "Qiu",
        "given": "Xipeng"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 26]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/XVGFZIUP",
    "type": "paper-conference",
    "abstract": "Fine-tuning large language models (LLMs) is essential for enhancing their performance on specific tasks but is often resource-intensive due to redundant or uninformative data. To address this inefficiency, we introduce DELIFT (Data Efficient Language model Instruction Fine-Tuning), a novel algorithm that systematically optimizes data selection across the three key stages of fine-tuning: (1) instruction tuning, (2) task-specific fine-tuning (e.g., reasoning, question-answering), and (3) continual learning (e.g., incorporating new data versions). Unlike existing methods that focus on single-stage optimization or rely on computationally intensive gradient calculations, DELIFT operates efficiently across all stages. Central to our approach is a pairwise utility metric that quantifies how beneficial a data sample is for improving the model's responses to other samples, effectively measuring the informational value relative to the model's current capabilities. By leveraging different submodular functions applied to this metric, DELIFT selects diverse and optimal subsets that are useful across all stages of fine-tuning. Experiments across various tasks and model scales demonstrate that DELIFT can reduce the fine-tuning data size by up to 70% without compromising performance, offering significant computational savings and outperforming existing methods in both efficiency and efficacy.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "DELIFT: Data Efficient Language model Instruction Fine-Tuning",
    "title-short": "DELIFT",
    "URL": "https://openreview.net/forum?id=Fty0wTcemV",
    "author": [
      {
        "family": "Agarwal",
        "given": "Ishika"
      },
      {
        "family": "Killamsetty",
        "given": "Krishnateja"
      },
      {
        "family": "Popa",
        "given": "Lucian"
      },
      {
        "family": "Danilevsky",
        "given": "Marina"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 26]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/4ZW5DE4B",
    "type": "paper-conference",
    "abstract": "As the performance of large language models (LLMs) emerges via data scaling, the significance of pre-training data becomes increasingly evident. Although methods such as deduplication and high-quality sampling have explored data selection, comprehensive criteria for text quality remain underdeveloped, hindering efficient pre-training data selection and composition. This paper establishes guidelines for data selection, fosters consensus on data quality, and introduces a management tool to evaluate data quality and domain types. We believe that robust quality criteria should be applicable across diverse texts, showcasing semantic content understanding, and mutual complement. Previous work mainly relies on intuition and lacks generalizability. To tackle this, we employ reverse thinking—\\emph{prompting LLMs to self-identify the causes of anomalous perplexity (PPL)} in text—and derive 13 quality criteria related to LLM performance, collectively derive a comprehensive metric as \\emph{Overall Score}. We developed a complete prompt that integrates quality criteria and domain types. We use LLM's pointwise ratings and compare the computational complexities of pointwise and pairwise ratings (\\(O(N)\\) v.s. \\(O(N^{2})\\)), showing that pointwise ratings are more feasible for vast datasets, with over 95\\% agreement with human assessments. By annotating 356K documents using GPT-4-turbo and fine-tuning a Qwen2-1.5B model, we created the \\textbf{Data} \\textbf{Man}ager (\\textbf{DataMan}), with an average fine-tuning accuracy across all criteria approaching 80\\% and 81.6\\% for \\emph{Overall Score}. We annotated 447B tokens from the slimpajama corpus by DataMan, and selected a 30B token subset to maximize quality representativeness while ensuring domain diversity to train 1.3B-parameter LLM. Results show that models trained on DataMan-sampled data exceed state-of-the-art benchmarks in in-context learning (ICL) gain by 0.4\\% to 4.3\\% and in instruct following win rate by 34.2\\% to 57\\%. The strongest model \\emph{Overall Score l=5}, significantly surpasses models trained on uniform sampling with 50\\% more data. Continued pre-training on high-rated domain-specific data further boosts ICL performance, validating DataMan's effectiveness in domain mixing. We reveal that PPL and ICL results do not strictly align, underscoring the distinction between understanding and generalization abilities. Our contributions include: i)-developing a data quality criteria system based on LLM PPL features; ii)-creating DataMan for data quality rating and domain identification; and iii)-releasing our code, models, and annotated datasets to facilitate research on the relationship between data and LLMs.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "DataMan: Data Manager for Pre-training Large Language Models",
    "title-short": "DataMan",
    "URL": "https://openreview.net/forum?id=eNbA8Fqir4",
    "author": [
      {
        "family": "Peng",
        "given": "Ru"
      },
      {
        "family": "Yang",
        "given": "Kexin"
      },
      {
        "family": "Zeng",
        "given": "Yawen"
      },
      {
        "family": "Lin",
        "given": "Junyang"
      },
      {
        "family": "Liu",
        "given": "Dayiheng"
      },
      {
        "family": "Zhao",
        "given": "Junbo"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 26]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/RBR759NN",
    "type": "paper-conference",
    "abstract": "Instruction tuning is critical for adapting large language models (LLMs) to downstream tasks, and recent studies have demonstrated that small amounts of human-curated data can outperform larger datasets, challenging traditional data scaling laws. While LLM-based data quality rating systems offer a cost-effective alternative to human annotation, they often suffer from inaccuracies and biases, even in powerful models like GPT-4. In this work, we introduce $DS^2$, a **D**iversity-aware **S**core curation method for **D**ata **S**election. By systematically modeling error patterns through a score transition matrix, $DS^2$ corrects LLM-based scores and promotes diversity in the selected data samples. Our approach shows that a curated subset (just 3.3\\% of the original dataset) outperforms full-scale datasets (300k samples) across various machine-alignment benchmarks, and matches or surpasses human-aligned datasets such as LIMA with the same sample size (1k samples). These findings challenge conventional data scaling assumptions, highlighting that redundant, low-quality samples can degrade performance and reaffirming that ``more can be less''.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "Improving Data Efficiency via Curating LLM-Driven Rating Systems",
    "URL": "https://openreview.net/forum?id=DKkQtRMowq",
    "author": [
      {
        "family": "Pang",
        "given": "Jinlong"
      },
      {
        "family": "Wei",
        "given": "Jiaheng"
      },
      {
        "family": "Shah",
        "given": "Ankit"
      },
      {
        "family": "Zhu",
        "given": "Zhaowei"
      },
      {
        "family": "Wang",
        "given": "Yaxuan"
      },
      {
        "family": "Qian",
        "given": "Chen"
      },
      {
        "family": "Liu",
        "given": "Yang"
      },
      {
        "family": "Bao",
        "given": "Yujia"
      },
      {
        "family": "Wei",
        "given": "Wei"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 26]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/VPNI8JRH",
    "type": "paper-conference",
    "abstract": "High-quality instruction data is critical for aligning large language models (LLMs). Although some models, such as Llama-3-Instruct, have open weights, their alignment data remain private, which hinders the democratization of AI. High human labor costs and a limited, predefined scope for prompting prevent existing open-source data creation methods from scaling effectively, potentially limiting the diversity and quality of public alignment datasets. Is it possible to synthesize high-quality instruction data at scale by extracting it directly from an aligned LLM? We present a self-synthesis method for generating large-scale alignment data named Magpie. Our key observation is that aligned LLMs like Llama-3-Instruct can generate a user query when we input only the pre-query templates up to the position reserved for user messages, thanks to their auto-regressive nature. We use this method to prompt Llama-3-Instruct and generate 4 million instructions along with their corresponding responses. We further introduce extensions of Magpie for filtering, generating multi-turn, preference optimization, domain-specific and multilingual datasets. We perform a comprehensive analysis of the Magpie-generated data. To compare Magpie-generated data with other public instruction datasets (e.g., ShareGPT, WildChat, Evol-Instruct, UltraChat, OpenHermes, Tulu-V2-Mix, GenQA), we fine-tune Llama-3-8B-Base with each dataset and evaluate the performance of the fine-tuned models. Our results indicate that using Magpie for supervised fine-tuning (SFT) solely can surpass the performance of previous public datasets utilized for both SFT and preference optimization, such as direct preference optimization with UltraFeedback. We also show that in some tasks, models supervised fine-tuned with Magpie perform comparably to the official Llama-3-8B-Instruct, despite the latter being enhanced with 10 million data points through SFT and subsequent preference optimization. This advantage is evident on alignment benchmarks such as AlpacaEval, ArenaHard, and WildBench.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing",
    "title-short": "Magpie",
    "URL": "https://openreview.net/forum?id=Pnk7vMbznK",
    "author": [
      {
        "family": "Xu",
        "given": "Zhangchen"
      },
      {
        "family": "Jiang",
        "given": "Fengqing"
      },
      {
        "family": "Niu",
        "given": "Luyao"
      },
      {
        "family": "Deng",
        "given": "Yuntian"
      },
      {
        "family": "Poovendran",
        "given": "Radha"
      },
      {
        "family": "Choi",
        "given": "Yejin"
      },
      {
        "family": "Lin",
        "given": "Bill Yuchen"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 26]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/PEPKDMLD",
    "type": "paper-conference",
    "abstract": "In this paper, we introduce the concept of Knowledge-Orthogonal Reasoning(KOR), where knowledge orthogonality refers to the independence from existing pretrained knowledge. By introducing new rules that are orthogonal to the pretrained knowledge, we minimize its interference to achieve a more accurate evaluation of the model's intrinsic reasoning and planning abilities. Based on this concept, we propose the Knowledge-Orthogonal Reasoning Benchmark (KOR-Bench), which includes five task categories: Operation, Logic, Cipher, Puzzle, and Counterfactual. KOR-Bench focuses on assessing how well models apply new rule descriptions to solve new rule-driven questions. This challenging benchmark shows that leading models like Claude-3.5-Sonnet and GPT-4o achieve only 58.96\\% and 58.00\\%, respectively. We conduct thorough analyses using Stepwise Prompting to identify bottlenecks in Cipher task. Self-correction experiments indicate that two rounds of correction usually result in the best performance. Complex Task Processing evaluates the model's performance across three integrated task settings. Additionally, we analyze the impact of Tricks on puzzle task and visualize rule-focused attention. Our goal is for \\our{} to serve as a valuable tool for evaluating and enhancing the reasoning abilities of models, while also fostering further research and development in this field. All data, inference, evaluation code, and experimental results are available here\\footnote{\\url{https://anonymous.4open.science/r/kor-bench-rebuttal-repo-44F6}}.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "KOR-Bench: Benchmarking Language Models on Knowledge-Orthogonal Reasoning Tasks",
    "title-short": "KOR-Bench",
    "URL": "https://openreview.net/forum?id=SVRRQ8goQo",
    "author": [
      {
        "family": "Ma",
        "given": "Kaijing"
      },
      {
        "family": "Du",
        "given": "Xeron"
      },
      {
        "family": "Wang",
        "given": "Yunran"
      },
      {
        "family": "Zhang",
        "given": "Haoran"
      },
      {
        "family": "ZhoufutuWen",
        "given": ""
      },
      {
        "family": "Qu",
        "given": "Xingwei"
      },
      {
        "family": "Yang",
        "given": "Jian"
      },
      {
        "family": "Liu",
        "given": "Jiaheng"
      },
      {
        "family": "Liu",
        "given": "Minghao"
      },
      {
        "family": "Yue",
        "given": "Xiang"
      },
      {
        "family": "Huang",
        "given": "Wenhao"
      },
      {
        "family": "Zhang",
        "given": "Ge"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 26]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/URWQW729",
    "type": "article",
    "abstract": "Prior research has enhanced the ability of Large Language Models (LLMs) to solve logic puzzles using techniques such as chain-of-thought prompting or introducing a symbolic representation. These frameworks are still usually insufficient to solve complicated logical problems, such as Zebra puzzles, due to the inherent complexity of translating natural language clues into logical statements. We introduce a multi-agent system, ZPS, that integrates LLMs with an off the shelf theorem prover. This system tackles the complex puzzle-solving task by breaking down the problem into smaller, manageable parts, generating SMT (Satisfiability Modulo Theories) code to solve them with a theorem prover, and using feedback between the agents to repeatedly improve their answers. We also introduce an automated grid puzzle grader to assess the correctness of our puzzle solutions and show that the automated grader is reliable by evaluating it in a user-study. Our approach shows improvement in all three LLMs we tested, with GPT-4 showing 166% improvement in the number of fully correct solutions.",
    "DOI": "10.48550/arXiv.2407.03956",
    "note": "arXiv:2407.03956 [cs]",
    "number": "arXiv:2407.03956",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems",
    "URL": "http://arxiv.org/abs/2407.03956",
    "author": [
      {
        "family": "Berman",
        "given": "Shmuel"
      },
      {
        "family": "McKeown",
        "given": "Kathleen"
      },
      {
        "family": "Ray",
        "given": "Baishakhi"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 26]]
    },
    "issued": {
      "date-parts": [["2024", 7, 9]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/L6DXYKBI",
    "type": "article",
    "abstract": "The Connections puzzle published each day by the New York Times tasks players with dividing a bank of sixteen words into four groups of four words that each relate to a common theme. Solving the puzzle requires both common linguistic knowledge (i.e. definitions and typical usage) as well as, in many cases, lateral or abstract thinking. This is because the four categories ascend in complexity, with the most challenging category often requiring thinking about words in uncommon ways or as parts of larger phrases. We investigate the capacity for automated AI systems to play Connections and explore the game's potential as an automated benchmark for abstract reasoning and a way to measure the semantic information encoded by data-driven linguistic systems. In particular, we study both a sentence-embedding baseline and modern large language models (LLMs). We report their accuracy on the task, measure the impacts of chain-of-thought prompting, and discuss their failure modes. Overall, we find that the Connections task is challenging yet feasible, and a strong test-bed for future work.",
    "DOI": "10.48550/arXiv.2404.11730",
    "note": "arXiv:2404.11730 [cs]",
    "number": "arXiv:2404.11730",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Missed Connections: Lateral Thinking Puzzles for Large Language Models",
    "title-short": "Missed Connections",
    "URL": "http://arxiv.org/abs/2404.11730",
    "author": [
      {
        "family": "Todd",
        "given": "Graham"
      },
      {
        "family": "Merino",
        "given": "Tim"
      },
      {
        "family": "Earle",
        "given": "Sam"
      },
      {
        "family": "Togelius",
        "given": "Julian"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 26]]
    },
    "issued": {
      "date-parts": [["2024", 4, 21]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/B4BA7HXB",
    "type": "article",
    "abstract": "Large Language Models (LLMs) have demonstrated notable capabilities across various tasks, showcasing complex problem-solving abilities. Understanding and executing complex rules, along with multi-step planning, are fundamental to logical reasoning and critical for practical LLM agents and decision-making systems. However, evaluating LLMs as effective rule-based executors and planners remains underexplored. In this paper, we introduce LogicGame, a novel benchmark designed to evaluate the comprehensive rule understanding, execution, and planning capabilities of LLMs. Unlike traditional benchmarks, LogicGame provides diverse games that contain a series of rules with an initial state, requiring models to comprehend and apply predefined regulations to solve problems. We create simulated scenarios in which models execute or plan operations to achieve specific outcomes. These game scenarios are specifically designed to distinguish logical reasoning from mere knowledge by relying exclusively on predefined rules. This separation allows for a pure assessment of rule-based reasoning capabilities. The evaluation considers not only final outcomes but also intermediate steps, providing a comprehensive assessment of model performance. Moreover, these intermediate steps are deterministic and can be automatically verified. LogicGame defines game scenarios with varying difficulty levels, from simple rule applications to complex reasoning chains, in order to offer a precise evaluation of model performance on rule understanding and multi-step execution. Utilizing LogicGame, we test various LLMs and identify notable shortcomings in their rule-based logical reasoning abilities.",
    "DOI": "10.48550/arXiv.2408.15778",
    "note": "arXiv:2408.15778 [cs]",
    "number": "arXiv:2408.15778",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "LogicGame: Benchmarking Rule-Based Reasoning Abilities of Large Language Models",
    "title-short": "LogicGame",
    "URL": "http://arxiv.org/abs/2408.15778",
    "author": [
      {
        "family": "Gui",
        "given": "Jiayi"
      },
      {
        "family": "Liu",
        "given": "Yiming"
      },
      {
        "family": "Cheng",
        "given": "Jiale"
      },
      {
        "family": "Gu",
        "given": "Xiaotao"
      },
      {
        "family": "Liu",
        "given": "Xiao"
      },
      {
        "family": "Wang",
        "given": "Hongning"
      },
      {
        "family": "Dong",
        "given": "Yuxiao"
      },
      {
        "family": "Tang",
        "given": "Jie"
      },
      {
        "family": "Huang",
        "given": "Minlie"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 26]]
    },
    "issued": {
      "date-parts": [["2024", 10, 12]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/CZK4D5RP",
    "type": "article-journal",
    "container-title": "Advances in Neural Information Processing Systems",
    "language": "en",
    "page": "127059-127098",
    "source": "proceedings.neurips.cc",
    "title": "PUZZLES: A Benchmark for Neural Algorithmic Reasoning",
    "title-short": "PUZZLES",
    "URL": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/e5d1eaadeed651ba1021c09149db4b92-Abstract-Datasets_and_Benchmarks_Track.html",
    "volume": "37",
    "author": [
      {
        "family": "Estermann",
        "given": "Benjamin"
      },
      {
        "family": "Lanzendörfer",
        "given": "Luca"
      },
      {
        "family": "Niedermayr",
        "given": "Yannick"
      },
      {
        "family": "Wattenhofer",
        "given": "Roger"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 26]]
    },
    "issued": {
      "date-parts": [["2025", 1, 31]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/E327ZB5Z",
    "type": "article",
    "abstract": "The releases of OpenAI's o1 and o3 mark a significant paradigm shift in Large Language Models towards advanced reasoning capabilities. Notably, o3 outperformed humans in novel problem-solving and skill acquisition on the Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI). However, this benchmark is limited to symbolic patterns, whereas humans often perceive and reason about multimodal scenarios involving both vision and language data. Thus, there is an urgent need to investigate advanced reasoning capabilities in multimodal tasks. To this end, we track the evolution of the GPT-[n] and o-[n] series models on challenging multimodal puzzles, requiring fine-grained visual perception with abstract or algorithmic reasoning. The superior performance of o1 comes at nearly 750 times the computational cost of GPT-4o, raising concerns about its efficiency. Our results reveal a clear upward trend in reasoning capabilities across model iterations, with notable performance jumps across GPT-series models and subsequently to o1. Nonetheless, we observe that the o1 model still struggles with simple multimodal puzzles requiring abstract reasoning. Furthermore, its performance in algorithmic puzzles remains poor. We plan to continuously track new models in the series and update our results in this paper accordingly. All resources used in this evaluation are openly available https://github.com/declare-lab/LLM-PuzzleTest.",
    "DOI": "10.48550/arXiv.2502.01081",
    "language": "en-US",
    "note": "arXiv:2502.01081 [cs]",
    "number": "arXiv:2502.01081",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "The Jumping Reasoning Curve? Tracking the Evolution of Reasoning Performance in GPT-[n] and o-[n] Models on Multimodal Puzzles",
    "title-short": "The Jumping Reasoning Curve?",
    "URL": "http://arxiv.org/abs/2502.01081",
    "author": [
      {
        "family": "Toh",
        "given": "Vernon Y. H."
      },
      {
        "family": "Chia",
        "given": "Yew Ken"
      },
      {
        "family": "Ghosal",
        "given": "Deepanway"
      },
      {
        "family": "Poria",
        "given": "Soujanya"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 26]]
    },
    "issued": {
      "date-parts": [["2025", 2, 3]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/VXFT5C2M",
    "type": "paper-conference",
    "abstract": "Large multimodal models extend the impressive capabilities of large language models by integrating multimodal understanding abilities. However, it is not clear how they can emulate the general intelligence and reasoning ability of humans. As recognizing patterns and abstracting concepts are key to general intelligence, we introduce PuzzleVQA, a collection of 2000 puzzle instances based on abstract patterns. With this dataset, we evaluate large multimodal models with abstract patterns based on fundamental concepts, including colors, numbers, sizes, and shapes. Through our experiments on state-of-the-art large multimodal models, we find that they are not able to generalize well to simple abstract patterns. Notably, GPT-4V achieves a score of 46.4% on single-concept puzzles, which shows that state-of-the-art models struggle on our dataset. To diagnose the reasoning challenges in large multimodal models, we progressively guide the models with our ground truth reasoning explanations for visual perception, inductive reasoning, and deductive reasoning. Our systematic analysis finds that the main bottlenecks of GPT-4V are weaker visual perception and inductive reasoning abilities. Through this work, we hope to shed light on the limitations of large multimodal models and how they can better emulate human cognitive processes in the future.",
    "container-title": "Findings of the Association for Computational Linguistics: ACL 2024",
    "DOI": "10.18653/v1/2024.findings-acl.962",
    "event-place": "Bangkok, Thailand",
    "event-title": "Findings 2024",
    "language": "en-US",
    "page": "16259–16273",
    "publisher": "Association for Computational Linguistics",
    "publisher-place": "Bangkok, Thailand",
    "source": "ACLWeb",
    "title": "PuzzleVQA: Diagnosing Multimodal Reasoning Challenges of Language Models with Abstract Visual Patterns",
    "title-short": "PuzzleVQA",
    "URL": "https://aclanthology.org/2024.findings-acl.962/",
    "author": [
      {
        "family": "Chia",
        "given": "Yew Ken"
      },
      {
        "family": "Toh",
        "given": "Vernon"
      },
      {
        "family": "Ghosal",
        "given": "Deepanway"
      },
      {
        "family": "Bing",
        "given": "Lidong"
      },
      {
        "family": "Poria",
        "given": "Soujanya"
      }
    ],
    "editor": [
      {
        "family": "Ku",
        "given": "Lun-Wei"
      },
      {
        "family": "Martins",
        "given": "Andre"
      },
      {
        "family": "Srikumar",
        "given": "Vivek"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 26]]
    },
    "issued": {
      "date-parts": [["2024", 8]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/U3J993IL",
    "type": "paper-conference",
    "abstract": "Exploring the capabilities of Large Language Models (LLMs) in puzzle solving unveils critical insights into their potential and challenges in AI, marking a significant step towards understanding their applicability in complex reasoning tasks. This survey leverages a unique taxonomy—dividing puzzles into rule-based and rule-less categories—to critically assess LLMs through various methodologies, including prompting techniques, neuro-symbolic approaches, and fine-tuning. Through a critical review of relevant datasets and benchmarks, we assess LLMs' performance, identifying significant challenges in complex puzzle scenarios. Our findings highlight the disparity between LLM capabilities and human-like reasoning, particularly in those requiring advanced logical inference. The survey underscores the necessity for novel strategies and richer datasets to advance LLMs' puzzle-solving proficiency and contribute to AI`s logical reasoning and creative problem-solving advancements.",
    "container-title": "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    "DOI": "10.18653/v1/2024.emnlp-main.646",
    "event-place": "Miami, Florida, USA",
    "event-title": "EMNLP 2024",
    "language": "en-US",
    "page": "11574–11591",
    "publisher": "Association for Computational Linguistics",
    "publisher-place": "Miami, Florida, USA",
    "source": "ACLWeb",
    "title": "Puzzle Solving using Reasoning of Large Language Models: A Survey",
    "title-short": "Puzzle Solving using Reasoning of Large Language Models",
    "URL": "https://aclanthology.org/2024.emnlp-main.646/",
    "author": [
      {
        "family": "Giadikiaroglou",
        "given": "Panagiotis"
      },
      {
        "family": "Lymperaiou",
        "given": "Maria"
      },
      {
        "family": "Filandrianos",
        "given": "Giorgos"
      },
      {
        "family": "Stamou",
        "given": "Giorgos"
      }
    ],
    "editor": [
      {
        "family": "Al-Onaizan",
        "given": "Yaser"
      },
      {
        "family": "Bansal",
        "given": "Mohit"
      },
      {
        "family": "Chen",
        "given": "Yun-Nung"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 26]]
    },
    "issued": {
      "date-parts": [["2024", 11]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/ZJUN5ARM",
    "type": "article",
    "abstract": "The ability to adapt beliefs or behaviors in response to unexpected outcomes, reflection, is fundamental to intelligent systems' interaction with the world. From a cognitive science perspective, this serves as a core principle of intelligence applicable to both human and AI systems. To address the debate on the intelligence of large language models (LLMs), we propose Reflection-Bench, a comprehensive benchmark comprising 7 tasks spanning core cognitive functions crucial for reflection, including perception, memory, belief updating, decision-making, prediction, counterfactual thinking, and meta-reflection. We evaluate the performances of 13 prominent LLMs such as OpenAI o1, GPT-4, Claude 3.5 Sonnet, etc. The results indicate that current LLMs still lack satisfactory reflection ability. We discuss the underlying causes of these results and suggest potential avenues for future research. In conclusion, Reflection-Bench offers both evaluation tools and inspiration for developing AI capable of reliably interacting with the environment. Our data and code are available at https://github.com/YabYum/ReflectionBench.",
    "DOI": "10.48550/arXiv.2410.16270",
    "note": "arXiv:2410.16270 [cs]",
    "number": "arXiv:2410.16270",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Reflection-Bench: probing AI intelligence with reflection",
    "title-short": "Reflection-Bench",
    "URL": "http://arxiv.org/abs/2410.16270",
    "author": [
      {
        "family": "Li",
        "given": "Lingyu"
      },
      {
        "family": "Wang",
        "given": "Yixu"
      },
      {
        "family": "Zhao",
        "given": "Haiquan"
      },
      {
        "family": "Kong",
        "given": "Shuqi"
      },
      {
        "family": "Teng",
        "given": "Yan"
      },
      {
        "family": "Li",
        "given": "Chunbo"
      },
      {
        "family": "Wang",
        "given": "Yingchun"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 26]]
    },
    "issued": {
      "date-parts": [["2024", 10, 21]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/6LPD6UUQ",
    "type": "article-journal",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance in various tasks, yet their comprehensive reasoning and planning capabilities in interactive environments remain underexplored. We introduce PuzzlePlex, a benchmark designed to evaluate reasoning and planning capabilities in a multi-turn adversarial environment. PuzzlePlex comprises 24 diverse puzzles, including deterministic and stochastic games, as well as single-player and adversarial scenarios. An important novelty of our benchmark is that it includes multi-step adversarial reasoning games. To succeed in such games, each LLM must maintain a history of its own moves and those of the opponent LLM, generating strategies that outperform the opponent to secure victory. We implement customized game-playing strategies (such as dynamic programming approaches) for comparison. Our findings indicate that the reasoning and planning abilities of current LLMs are currently poor in puzzle-solving contexts. GPT-4 outperforms other models, successfully competing against customized strategies (such as greedy approaches or dynamic programming) in 49% of cases. However, when faced with strict rule sets, it demonstrates diminished reasoning and planning capabilities. In addition to the 14 multi-turn adversarial puzzles, we report on single-player puzzles and incorporate multi-modal challenges that integrate text and images, revealing that LLMs still significantly lag behind even simple heuristics in puzzles. A key feature of our benchmark is its ability to generate game instances with graduated levels of difficulty, allowing it to evolve as LLMs become more sophisticated. This adaptability ensures the continued relevance and utility of PuzzlePlex in assessing the progress of LLM capabilities in reasoning and planning within interactive environments.",
    "language": "en",
    "source": "openreview.net",
    "title": "PuzzlePlex: A Benchmark to Evaluate the Reasoning and Planning of Large Language Models on Puzzles",
    "title-short": "PuzzlePlex",
    "URL": "https://openreview.net/forum?id=GT4gMdvVFp",
    "author": [
      {
        "family": "Long",
        "given": "Yitao"
      },
      {
        "family": "Jiang",
        "given": "Tintin"
      },
      {
        "family": "Zhao",
        "given": "Yilun"
      },
      {
        "family": "Cohan",
        "given": "Arman"
      },
      {
        "family": "Shasha",
        "given": "Dennis"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 26]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/BFBHHI9T",
    "type": "article",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities on various tasks, while the further evolvement is limited to the lack of high-quality training data. In addition, traditional training approaches rely too much on expert-labeled data, setting a ceiling on the performance of LLMs. To address this issue, we propose a novel paradigm named LANCE (LANguage models as Continuous self-Evolving data engineers) that enables LLMs to train themselves by autonomously generating, cleaning, reviewing, and annotating data with preference information. Our approach demonstrates that LLMs can serve as continuous self-evolving data engineers, significantly reducing the time and cost of the post-training data construction. Through iterative fine-tuning on Qwen2 series models, we validate the effectiveness of LANCE across various tasks, showing that it can maintain high-quality data generation and continuously improve model performance. Across multiple benchmark dimensions, LANCE results in an average score enhancement of 3.64 for Qwen2-7B and 1.75 for Qwen2-7B-Instruct. This training paradigm with autonomous data construction not only reduces the reliance on human experts or external models but also ensures that the data aligns with human preferences, paving the way for the development of future superintelligent systems that can exceed human capabilities. Codes are available at: https://github.com/Control-derek/LANCE.",
    "DOI": "10.48550/arXiv.2412.15151",
    "note": "arXiv:2412.15151 [cs]",
    "number": "arXiv:2412.15151",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Language Models as Continuous Self-Evolving Data Engineers",
    "URL": "http://arxiv.org/abs/2412.15151",
    "author": [
      {
        "family": "Wang",
        "given": "Peidong"
      },
      {
        "family": "Wang",
        "given": "Ming"
      },
      {
        "family": "Ma",
        "given": "Zhiming"
      },
      {
        "family": "Yang",
        "given": "Xiaocui"
      },
      {
        "family": "Feng",
        "given": "Shi"
      },
      {
        "family": "Wang",
        "given": "Daling"
      },
      {
        "family": "Zhang",
        "given": "Yifei"
      },
      {
        "family": "Song",
        "given": "Kaisong"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 27]]
    },
    "issued": {
      "date-parts": [["2025", 2, 13]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/TBWDS43Y",
    "type": "article",
    "abstract": "Large language models (LLMs) are increasingly deployed in everyday applications, demanding robust general reasoning capabilities and diverse reasoning skillset. However, current LLM reasoning benchmarks predominantly focus on mathematical and coding abilities, leaving a gap in evaluating broader reasoning proficiencies. One particular exception is the BIG-Bench dataset, which has served as a crucial benchmark for evaluating the general reasoning capabilities of LLMs, thanks to its diverse set of challenging tasks that allowed for a comprehensive assessment of general reasoning across various skills within a unified framework. However, recent advances in LLMs have led to saturation on BIG-Bench, and its harder version BIG-Bench Hard (BBH). State-of-the-art models achieve near-perfect scores on many tasks in BBH, thus diminishing its utility. To address this limitation, we introduce BIG-Bench Extra Hard (BBEH), a new benchmark designed to push the boundaries of LLM reasoning evaluation. BBEH replaces each task in BBH with a novel task that probes a similar reasoning capability but exhibits significantly increased difficulty. We evaluate various models on BBEH and observe a (harmonic) average accuracy of 9.8\\% for the best general-purpose model and 44.8\\% for the best reasoning-specialized model, indicating substantial room for improvement and highlighting the ongoing challenge of achieving robust general reasoning in LLMs. We release BBEH publicly at: https://github.com/google-deepmind/bbeh.",
    "DOI": "10.48550/arXiv.2502.19187",
    "language": "en-US",
    "note": "arXiv:2502.19187 [cs]",
    "number": "arXiv:2502.19187",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "BIG-Bench Extra Hard",
    "URL": "http://arxiv.org/abs/2502.19187",
    "author": [
      {
        "family": "Kazemi",
        "given": "Mehran"
      },
      {
        "family": "Fatemi",
        "given": "Bahare"
      },
      {
        "family": "Bansal",
        "given": "Hritik"
      },
      {
        "family": "Palowitch",
        "given": "John"
      },
      {
        "family": "Anastasiou",
        "given": "Chrysovalantis"
      },
      {
        "family": "Mehta",
        "given": "Sanket Vaibhav"
      },
      {
        "family": "Jain",
        "given": "Lalit K."
      },
      {
        "family": "Aglietti",
        "given": "Virginia"
      },
      {
        "family": "Jindal",
        "given": "Disha"
      },
      {
        "family": "Chen",
        "given": "Peter"
      },
      {
        "family": "Dikkala",
        "given": "Nishanth"
      },
      {
        "family": "Tyen",
        "given": "Gladys"
      },
      {
        "family": "Liu",
        "given": "Xin"
      },
      {
        "family": "Shalit",
        "given": "Uri"
      },
      {
        "family": "Chiappa",
        "given": "Silvia"
      },
      {
        "family": "Olszewska",
        "given": "Kate"
      },
      {
        "family": "Tay",
        "given": "Yi"
      },
      {
        "family": "Tran",
        "given": "Vinh Q."
      },
      {
        "family": "Le",
        "given": "Quoc V."
      },
      {
        "family": "Firat",
        "given": "Orhan"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 2, 28]]
    },
    "issued": {
      "date-parts": [["2025", 2, 26]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/2K7BFDPG",
    "type": "article",
    "abstract": "Despite recent progress achieved by code large language models (LLMs), their remarkable abilities are largely dependent on fine-tuning on the high-quality data, posing challenges for data collection and annotation. To address this, current methods often design various data flywheels to collect complex code instructions, enabling models to handle more intricate tasks. However, these approaches typically rely on off-the-shelf datasets and data augmentation from a limited set of proprietary LLMs (e.g., Claude, GPT4, and so on), which restricts the diversity of the constructed data and makes it prone to systemic biases. In this paper, we propose WarriorCoder, a novel paradigm learns from expert battles to address these limitations. Specifically, we create an arena where leading expert code LLMs challenge each other, with evaluations conducted by impartial judges. This competitive framework generates novel training data from scratch, leveraging the strengths of all participants. Experimental results show that WarriorCoder achieves state-of-the-art performance compared to previous models of the same size, even without relying on proprietary LLMs.",
    "DOI": "10.48550/arXiv.2412.17395",
    "language": "en-US",
    "note": "arXiv:2412.17395 [cs]",
    "number": "arXiv:2412.17395",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "WarriorCoder: Learning from Expert Battles to Augment Code Large Language Models",
    "title-short": "WarriorCoder",
    "URL": "http://arxiv.org/abs/2412.17395",
    "author": [
      {
        "family": "Feng",
        "given": "Huawen"
      },
      {
        "family": "Zhao",
        "given": "Pu"
      },
      {
        "family": "Sun",
        "given": "Qingfeng"
      },
      {
        "family": "Xu",
        "given": "Can"
      },
      {
        "family": "Yang",
        "given": "Fangkai"
      },
      {
        "family": "Wang",
        "given": "Lu"
      },
      {
        "family": "Ma",
        "given": "Qianli"
      },
      {
        "family": "Lin",
        "given": "Qingwei"
      },
      {
        "family": "Rajmohan",
        "given": "Saravan"
      },
      {
        "family": "Zhang",
        "given": "Dongmei"
      },
      {
        "family": "Zhang",
        "given": "Qi"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 3]]
    },
    "issued": {
      "date-parts": [["2025", 2, 18]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/VIUWW82Z",
    "type": "article",
    "abstract": "Multi-agent debate (MAD) has emerged as a promising approach to enhance the factual accuracy and reasoning quality of large language models (LLMs) by engaging multiple agents in iterative discussions during inference. Despite its potential, we argue that current MAD research suffers from critical shortcomings in evaluation practices, including limited dataset overlap and inconsistent baselines, raising significant concerns about generalizability. Correspondingly, this paper presents a systematic evaluation of five representative MAD methods across nine benchmarks using four foundational models. Surprisingly, our findings reveal that MAD methods fail to reliably outperform simple single-agent baselines such as Chain-of-Thought and Self-Consistency, even when consuming additional inference-time computation. From our analysis, we found that model heterogeneity can significantly improve MAD frameworks. We propose Heter-MAD enabling a single LLM agent to access the output from heterogeneous foundation models, which boosts the performance of current MAD frameworks. Finally, we outline potential directions for advancing MAD, aiming to spark a broader conversation and inspire future work in this area.",
    "DOI": "10.48550/arXiv.2502.08788",
    "note": "arXiv:2502.08788 [cs]",
    "number": "arXiv:2502.08788",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "If Multi-Agent Debate is the Answer, What is the Question?",
    "URL": "http://arxiv.org/abs/2502.08788",
    "author": [
      {
        "family": "Zhang",
        "given": "Hangfan"
      },
      {
        "family": "Cui",
        "given": "Zhiyao"
      },
      {
        "family": "Wang",
        "given": "Xinrun"
      },
      {
        "family": "Zhang",
        "given": "Qiaosheng"
      },
      {
        "family": "Wang",
        "given": "Zhen"
      },
      {
        "family": "Wu",
        "given": "Dinghao"
      },
      {
        "family": "Hu",
        "given": "Shuyue"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 3]]
    },
    "issued": {
      "date-parts": [["2025", 2, 17]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/Y5VZ5JLJ",
    "type": "paper-conference",
    "abstract": "Large Language Model (LLM) based agents have proved their ability to perform complex tasks like humans. However, there is still a large gap between open-sourced LLMs and commercial models like the GPT series. In this paper, we focus on improving the agent generalization capabilities of LLMs via instruction tuning. We first observe that the existing agent training corpus exhibits satisfactory results on held-in evaluation sets but fails to generalize to held-out sets. These agent-tuning works face severe formatting errors and are frequently stuck in the same mistake for a long while. We analyze that the poor generalization ability comes from overfitting to several manual agent environments and a lack of adaptation to new situations. They struggle with the wrong action steps and can not learn from the experience but just memorize existing observation-action relations. Inspired by the insight, we propose a novel AgentRefine framework for agent-tuning. The core idea is to enable the model to learn to correct its mistakes via observation in the trajectory. Specifically, we propose an agent synthesis framework to encompass a diverse array of environments and tasks and prompt a strong LLM to refine its error action according to the environment feedback. AgentRefine significantly outperforms state-of-the-art agent-tuning work in terms of generalization ability on diverse agent tasks. It also has better robustness facing perturbation and can generate diversified thought in inference. Our findings establish the correlation between agent generalization and self-refinement and provide a new paradigm for future research.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "AgentRefine: Enhancing Agent Generalization through Refinement Tuning",
    "title-short": "AgentRefine",
    "URL": "https://openreview.net/forum?id=FDimWzmcWn",
    "author": [
      {
        "family": "Fu",
        "given": "Dayuan"
      },
      {
        "family": "He",
        "given": "Keqing"
      },
      {
        "family": "Wang",
        "given": "Yejie"
      },
      {
        "family": "Hong",
        "given": "Wentao"
      },
      {
        "family": "GongQue",
        "given": "Zhuoma"
      },
      {
        "family": "Zeng",
        "given": "Weihao"
      },
      {
        "family": "Wang",
        "given": "Wei"
      },
      {
        "family": "Wang",
        "given": "Jingang"
      },
      {
        "family": "Cai",
        "given": "Xunliang"
      },
      {
        "family": "Xu",
        "given": "Weiran"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 3]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/QN7PME5T",
    "type": "article",
    "abstract": "Common methods for aligning already-capable models with desired behavior rely on the ability of humans to provide supervision. However, future superhuman models will surpass the capability of humans. Therefore, humans will only be able to weakly supervise superhuman models. This expected deficiency of human evaluation would weaken the safety of future AI systems. Scalable oversight and weak-to-strong generalization are two complementary approaches to tackle this issue. In this paper, we attempt to combine the strengths of these two approaches to further improve alignment. Specifically, we investigate ways of improving human supervision with a strong pretrained model and then supervise the strong model with enhanced weak human supervision. To make iterative empirical progress, we consider an analogy: can we use a strong model to improve weak model supervision and then use it to supervise the strong model? We empirically test it by finetuning a small weak model on ground truth labels with the additional help from a large strong model, and then finetuning the strong model on labels generated by the weak model. We find that debate can assist a weak model in extracting trustworthy information from an untrustworthy strong model, which provides leverage as context on samples when training a weak model. We also show that an ensemble of weak models helps exploit long arguments generated by strong model debaters and obtain a more robust supervision estimate. Extensive experiments on the OpenAI weak-to-strong NLP benchmarks show that the combination approach leads to better alignment, which indicates that debate has the potential to help weak-to-strong generalization.",
    "DOI": "10.48550/arXiv.2501.13124",
    "note": "arXiv:2501.13124 [cs]",
    "number": "arXiv:2501.13124",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Debate Helps Weak-to-Strong Generalization",
    "URL": "http://arxiv.org/abs/2501.13124",
    "author": [
      {
        "family": "Lang",
        "given": "Hao"
      },
      {
        "family": "Huang",
        "given": "Fei"
      },
      {
        "family": "Li",
        "given": "Yongbin"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 3]]
    },
    "issued": {
      "date-parts": [["2025", 1, 21]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/XPEHA5IP",
    "type": "article",
    "abstract": "Large language models are usually fine-tuned to align with human preferences. However, fine-tuning a large language model can be challenging. In this work, we introduce $\\textit{weak-to-strong search}$, framing the alignment of a large language model as a test-time greedy search to maximize the log-probability difference between small tuned and untuned models while sampling from the frozen large model. This method serves both as (1) a compute-efficient model up-scaling strategy that avoids directly tuning the large model and as (2) an instance of weak-to-strong generalization that enhances a strong model with weak test-time guidance. Empirically, we demonstrate the flexibility of weak-to-strong search across different tasks. In controlled-sentiment generation and summarization, we use tuned and untuned $\\texttt{gpt2}$s to improve the alignment of large models without additional training. Crucially, in a more difficult instruction-following benchmark, AlpacaEval 2.0, we show that reusing off-the-shelf small models (e.g., $\\texttt{zephyr-7b-beta}$ and its untuned version) can improve the length-controlled win rates of both white-box and black-box large models against $\\texttt{gpt-4-turbo}$ (e.g., $34.4\\% \\rightarrow 37.9\\%$ for $\\texttt{Llama-3-70B-Instruct}$ and $16.0\\% \\rightarrow 20.1\\%$ for $\\texttt{gpt-3.5-turbo-instruct}$), despite the small models' low win rates $\\approx 10.0\\%$.",
    "DOI": "10.48550/arXiv.2405.19262",
    "note": "arXiv:2405.19262 [cs]",
    "number": "arXiv:2405.19262",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Weak-to-Strong Search: Align Large Language Models via Searching over Small Language Models",
    "title-short": "Weak-to-Strong Search",
    "URL": "http://arxiv.org/abs/2405.19262",
    "author": [
      {
        "family": "Zhou",
        "given": "Zhanhui"
      },
      {
        "family": "Liu",
        "given": "Zhixuan"
      },
      {
        "family": "Liu",
        "given": "Jie"
      },
      {
        "family": "Dong",
        "given": "Zhichen"
      },
      {
        "family": "Yang",
        "given": "Chao"
      },
      {
        "family": "Qiao",
        "given": "Yu"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 3]]
    },
    "issued": {
      "date-parts": [["2024", 11, 19]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/QMIN4IMA",
    "type": "article",
    "abstract": "We study self-rewarding reasoning large language models (LLMs), which can simultaneously generate step-by-step reasoning and evaluate the correctness of their outputs during the inference time-without external feedback. This integrated approach allows a single model to independently guide its reasoning process, offering computational advantages for model deployment. We particularly focus on the representative task of self-correction, where models autonomously detect errors in their responses, revise outputs, and decide when to terminate iterative refinement loops. To enable this, we propose a two-staged algorithmic framework for constructing self-rewarding reasoning models using only self-generated data. In the first stage, we employ sequential rejection sampling to synthesize long chain-of-thought trajectories that incorporate both self-rewarding and self-correction mechanisms. Fine-tuning models on these curated data allows them to learn the patterns of self-rewarding and self-correction. In the second stage, we further enhance the models' ability to assess response accuracy and refine outputs through reinforcement learning with rule-based signals. Experiments with Llama-3 and Qwen-2.5 demonstrate that our approach surpasses intrinsic self-correction capabilities and achieves performance comparable to systems that rely on external reward models.",
    "DOI": "10.48550/arXiv.2502.19613",
    "note": "arXiv:2502.19613 [cs]",
    "number": "arXiv:2502.19613",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Self-rewarding correction for mathematical reasoning",
    "URL": "http://arxiv.org/abs/2502.19613",
    "author": [
      {
        "family": "Xiong",
        "given": "Wei"
      },
      {
        "family": "Zhang",
        "given": "Hanning"
      },
      {
        "family": "Ye",
        "given": "Chenlu"
      },
      {
        "family": "Chen",
        "given": "Lichang"
      },
      {
        "family": "Jiang",
        "given": "Nan"
      },
      {
        "family": "Zhang",
        "given": "Tong"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 3]]
    },
    "issued": {
      "date-parts": [["2025", 2, 26]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/99K7FT73",
    "type": "article",
    "abstract": "Many challenging reasoning tasks require not just rapid, intuitive responses, but a more deliberate, multi-step approach. Recent progress in large language models (LLMs) highlights an important shift from the \"System 1\" way of quick reactions to the \"System 2\" style of reflection-and-correction problem solving. However, current benchmarks heavily rely on the final-answer accuracy, leaving much of a model's intermediate reasoning steps unexamined. This fails to assess the model's ability to reflect and rectify mistakes within the reasoning process. To bridge this gap, we introduce FINEREASON, a logic-puzzle benchmark for fine-grained evaluation of LLMs' reasoning capabilities. Each puzzle can be decomposed into atomic steps, making it ideal for rigorous validation of intermediate correctness. Building on this, we introduce two tasks: state checking, and state transition, for a comprehensive evaluation of how models assess the current situation and plan the next move. To support broader research, we also provide a puzzle training set aimed at enhancing performance on general mathematical tasks. We show that models trained on our state checking and transition data demonstrate gains in math reasoning by up to 5.1% on GSM8K.",
    "DOI": "10.48550/arXiv.2502.20238",
    "language": "en-US",
    "note": "arXiv:2502.20238 [cs]",
    "number": "arXiv:2502.20238",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "FINEREASON: Evaluating and Improving LLMs' Deliberate Reasoning through Reflective Puzzle Solving",
    "title-short": "FINEREASON",
    "URL": "http://arxiv.org/abs/2502.20238",
    "author": [
      {
        "family": "Chen",
        "given": "Guizhen"
      },
      {
        "family": "Xu",
        "given": "Weiwen"
      },
      {
        "family": "Zhang",
        "given": "Hao"
      },
      {
        "family": "Chan",
        "given": "Hou Pong"
      },
      {
        "family": "Liu",
        "given": "Chaoqun"
      },
      {
        "family": "Bing",
        "given": "Lidong"
      },
      {
        "family": "Zhao",
        "given": "Deli"
      },
      {
        "family": "Luu",
        "given": "Anh Tuan"
      },
      {
        "family": "Rong",
        "given": "Yu"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 3]]
    },
    "issued": {
      "date-parts": [["2025", 2, 27]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/562CJN7G",
    "type": "article",
    "abstract": "Large Language Models (LLMs) have exhibited exceptional performance in software engineering yet face challenges in adapting to continually evolving code knowledge, particularly regarding the frequent updates of third-party library APIs. This limitation, stemming from static pre-training datasets, often results in non-executable code or implementations with suboptimal safety and efficiency. To this end, this paper introduces CODESYNC, a data engine for identifying outdated code patterns and collecting real-time code knowledge updates from Python third-party libraries. Building upon CODESYNC, we develop CODESYNCBENCH, a comprehensive benchmark for assessing LLMs' ability to stay synchronized with code evolution, which covers real-world updates for 220 APIs from six Python libraries. Our benchmark offers 3,300 test cases across three evaluation tasks and an update-aware instruction tuning dataset consisting of 2,200 training samples. Extensive experiments on 14 state-of-the-art LLMs reveal that they struggle with dynamic code evolution, even with the support of advanced knowledge updating methods (e.g., DPO, ORPO, and SimPO). We believe that our benchmark can offer a strong foundation for the development of more effective methods for real-time code knowledge updating in the future. The experimental code and dataset are publicly available at: https://github.com/Lucky-voyage/Code-Sync.",
    "DOI": "10.48550/arXiv.2502.16645",
    "note": "arXiv:2502.16645 [cs]",
    "number": "arXiv:2502.16645",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "CODESYNC: Synchronizing Large Language Models with Dynamic Code Evolution at Scale",
    "title-short": "CODESYNC",
    "URL": "http://arxiv.org/abs/2502.16645",
    "author": [
      {
        "family": "Wang",
        "given": "Chenlong"
      },
      {
        "family": "Chu",
        "given": "Zhaoyang"
      },
      {
        "family": "Cheng",
        "given": "Zhengxiang"
      },
      {
        "family": "Yang",
        "given": "Xuyi"
      },
      {
        "family": "Qiu",
        "given": "Kaiyue"
      },
      {
        "family": "Wan",
        "given": "Yao"
      },
      {
        "family": "Zhao",
        "given": "Zhou"
      },
      {
        "family": "Shi",
        "given": "Xuanhua"
      },
      {
        "family": "Chen",
        "given": "Dongping"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 3]]
    },
    "issued": {
      "date-parts": [["2025", 2, 23]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/DQECVUEK",
    "type": "article",
    "abstract": "Language model heavily depends on high-quality data for optimal performance. Existing approaches rely on manually designed heuristics, the perplexity of existing models, training classifiers, or careful prompt engineering, which require significant expert experience and human annotation effort while introduce biases. We introduce CritiQ, a novel data selection method that automatically mines criteria from human preferences for data quality with only $\\sim$30 human-annotated pairs and performs efficient data selection. The main component, CritiQ Flow, employs a manager agent to evolve quality criteria and worker agents to make pairwise judgments. We build a knowledge base that extracts quality criteria from previous work to boost CritiQ Flow. Compared to perplexity- and classifier- based methods, verbal criteria are more interpretable and possess reusable value. After deriving the criteria, we train the CritiQ Scorer to give quality scores and perform efficient data selection. We demonstrate the effectiveness of our method in the code, math, and logic domains, achieving high accuracy on human-annotated test sets. To validate the quality of the selected data, we continually train Llama 3.1 models and observe improved performance on downstream tasks compared to uniform sampling. Ablation studies validate the benefits of the knowledge base and the reflection process. We analyze how criteria evolve and the effectiveness of majority voting.",
    "DOI": "10.48550/arXiv.2502.19279",
    "note": "arXiv:2502.19279 [cs]",
    "number": "arXiv:2502.19279",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "CritiQ: Mining Data Quality Criteria from Human Preferences",
    "title-short": "CritiQ",
    "URL": "http://arxiv.org/abs/2502.19279",
    "author": [
      {
        "family": "Guo",
        "given": "Honglin"
      },
      {
        "family": "Lv",
        "given": "Kai"
      },
      {
        "family": "Guo",
        "given": "Qipeng"
      },
      {
        "family": "Liang",
        "given": "Tianyi"
      },
      {
        "family": "Xi",
        "given": "Zhiheng"
      },
      {
        "family": "Song",
        "given": "Demin"
      },
      {
        "family": "Zhang",
        "given": "Qiuyinzhe"
      },
      {
        "family": "Sun",
        "given": "Yu"
      },
      {
        "family": "Chen",
        "given": "Kai"
      },
      {
        "family": "Qiu",
        "given": "Xipeng"
      },
      {
        "family": "Gui",
        "given": "Tao"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 3]]
    },
    "issued": {
      "date-parts": [["2025", 2, 26]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/M5ALFJ4V",
    "type": "article",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities on various tasks, while the further evolvement is limited to the lack of high-quality training data. In addition, traditional training approaches rely too much on expert-labeled data, setting a ceiling on the performance of LLMs. To address this issue, we propose a novel paradigm named LANCE (LANguage models as Continuous self-Evolving data engineers) that enables LLMs to train themselves by autonomously generating, cleaning, reviewing, and annotating data with preference information. Our approach demonstrates that LLMs can serve as continuous self-evolving data engineers, significantly reducing the time and cost of the post-training data construction. Through iterative fine-tuning on Qwen2 series models, we validate the effectiveness of LANCE across various tasks, showing that it can maintain high-quality data generation and continuously improve model performance. Across multiple benchmark dimensions, LANCE results in an average score enhancement of 3.64 for Qwen2-7B and 1.75 for Qwen2-7B-Instruct. This training paradigm with autonomous data construction not only reduces the reliance on human experts or external models but also ensures that the data aligns with human preferences, paving the way for the development of future superintelligent systems that can exceed human capabilities. Codes are available at: https://github.com/Control-derek/LANCE.",
    "DOI": "10.48550/arXiv.2412.15151",
    "language": "en-US",
    "note": "arXiv:2412.15151 [cs]",
    "number": "arXiv:2412.15151",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Language Models as Continuous Self-Evolving Data Engineers",
    "URL": "http://arxiv.org/abs/2412.15151",
    "author": [
      {
        "family": "Wang",
        "given": "Peidong"
      },
      {
        "family": "Wang",
        "given": "Ming"
      },
      {
        "family": "Ma",
        "given": "Zhiming"
      },
      {
        "family": "Yang",
        "given": "Xiaocui"
      },
      {
        "family": "Feng",
        "given": "Shi"
      },
      {
        "family": "Wang",
        "given": "Daling"
      },
      {
        "family": "Zhang",
        "given": "Yifei"
      },
      {
        "family": "Song",
        "given": "Kaisong"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 3]]
    },
    "issued": {
      "date-parts": [["2025", 2, 13]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/4X38Y9H5",
    "type": "article",
    "abstract": "Selecting high-quality pre-training data is important for creating capable language models, but existing methods rely on simple heuristics. We introduce QuRating, a method for selecting pre-training data that can capture human intuitions about data quality. In this paper, we investigate four qualities - writing style, required expertise, facts & trivia, and educational value - and find that LLMs are able to discern these qualities, especially when making pairwise judgments of texts. We train a QuRater model to learn scalar ratings from pairwise judgments, and use it to annotate a 260B training corpus with quality ratings for each of the four criteria. In our experiments, we select 30B tokens according to the different quality ratings and train 1.3B-parameter language models on the selected data. We find that it is important to balance quality and diversity. When we sample using quality ratings as logits over documents, our models obtain lower perplexity and stronger in-context learning performance than baselines. Our best model is based on educational value and performs similarly to a model trained with uniform sampling for 50% more steps. Beyond data selection, we use the quality ratings to construct a training curriculum which improves performance without changing the training dataset. We extensively analyze the quality ratings and discuss their characteristics, biases, and wider implications.",
    "DOI": "10.48550/arXiv.2402.09739",
    "note": "arXiv:2402.09739 [cs]",
    "number": "arXiv:2402.09739",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "QuRating: Selecting High-Quality Data for Training Language Models",
    "title-short": "QuRating",
    "URL": "http://arxiv.org/abs/2402.09739",
    "author": [
      {
        "family": "Wettig",
        "given": "Alexander"
      },
      {
        "family": "Gupta",
        "given": "Aatmik"
      },
      {
        "family": "Malik",
        "given": "Saumya"
      },
      {
        "family": "Chen",
        "given": "Danqi"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 3]]
    },
    "issued": {
      "date-parts": [["2024", 7, 17]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/QKZSRE5C",
    "type": "paper-conference",
    "abstract": "Teaching to improve student models (e.g., knowledge distillation) is an extensively studied methodology in LLMs. However, in human education, teaching enhances not only the students but also the teachers by fostering more rigorous and clearer reasoning, as well as deeper knowledge building. We ask: Can LLMs also learn by teaching (LbT) for better reasoning? If the answer is yes, we can potentially unlock the possibility of continuously advancing the models without solely relying on human-produced data or stronger models. In this paper, we provide a preliminary exploration of this question. We show that LbT ideas can be incorporated into existing LLM training/prompting pipelines and bring improvements. Specifically, we design three methods, each mimicking one of the three levels of LbT: observing students' feedback, learning from the feedback, and learning iteratively, with the goal of improving answer accuracy without training or improving models' inherent capability with fine-tuning. We reveal some findings: (1) Teaching materials that make it easier for students to learn (via in-context learning) have clearer and more accurate logic; (2) Weak-to-strong generalization: LbT might help improve strong models by teaching weak models; (3) Diversity in students might help: teaching multiple students could be better than teaching a single student or the teacher alone. We hope that our exploration can inspire future research on LbT and, more broadly, the adoption of advanced education techniques to improve LLMs. The code and website are at https://github.com/imagination-research/lbt and https://sites.google.com/view/llm-learning-by-teaching.",
    "event-title": "The Thirty-eighth Annual Conference on Neural Information Processing Systems",
    "language": "en",
    "source": "openreview.net",
    "title": "Can LLMs Learn by Teaching for Better Reasoning? A Preliminary Study",
    "title-short": "Can LLMs Learn by Teaching for Better Reasoning?",
    "URL": "https://openreview.net/forum?id=0ZZMUjZJYF&referrer=%5Bthe%20profile%20of%20Matthew%20B.%20Blaschko%5D(%2Fprofile%3Fid%3D~Matthew_B._Blaschko1)",
    "author": [
      {
        "family": "Ning",
        "given": "Xuefei"
      },
      {
        "family": "Wang",
        "given": "Zifu"
      },
      {
        "family": "Li",
        "given": "Shiyao"
      },
      {
        "family": "Lin",
        "given": "Zinan"
      },
      {
        "family": "Yao",
        "given": "Peiran"
      },
      {
        "family": "Fu",
        "given": "Tianyu"
      },
      {
        "family": "Blaschko",
        "given": "Matthew B."
      },
      {
        "family": "Dai",
        "given": "Guohao"
      },
      {
        "family": "Yang",
        "given": "Huazhong"
      },
      {
        "family": "Wang",
        "given": "Yu"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 3]]
    },
    "issued": {
      "date-parts": [["2024", 11, 6]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/HJT3XHL7",
    "type": "paper-conference",
    "abstract": "As large language models (LLMs) grow in sophistication, some of their capabilities surpass human abilities, making it essential to ensure their alignment with human values and intentions, i.e., Superalignment. This superalignment challenge is particularly critical for complex tasks, as annotations provided by humans, as weak supervisors, may be overly simplistic, incomplete, or incorrect. Previous work has demonstrated the potential of training a strong model using the weak dataset generated by a weak model as weak supervision. However, these studies have been limited to a single capability. In this work, we conduct extensive experiments to investigate weak to strong generalization for LLMs with multi-capabilities. The experiments reveal that different capabilities tend to remain relatively independent in this generalization, and the effectiveness of weak supervision is significantly impacted by the quality and diversity of the weak datasets. Moreover, the self-bootstrapping of the strong model leads to performance degradation due to its overconfidence and the limited diversity of its generated dataset. To address these issues, we proposed a novel training framework using reward models to select valuable data, thereby providing weak supervision for strong model training. In addition, we propose a two-stage training method on both weak and selected datasets to train the strong model. Experimental results demonstrate our method significantly improves the weak to strong generalization with multi-capabilities.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "Weak to Strong Generalization for Large Language Models with Multi-capabilities",
    "URL": "https://openreview.net/forum?id=N1vYivuSKq",
    "author": [
      {
        "family": "Zhou",
        "given": "Yucheng"
      },
      {
        "family": "Shen",
        "given": "Jianbing"
      },
      {
        "family": "Cheng",
        "given": "Yu"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 4]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/QXAHIF2Q",
    "type": "article",
    "abstract": "Recently, Large Language Models (LLMs) make remarkable evolutions in language understanding and generation. Following this, various benchmarks for measuring all kinds of capabilities of LLMs have sprung up. In this paper, we challenge the reasoning and understanding abilities of LLMs by proposing a FaLlacy Understanding Benchmark (FLUB) containing cunning texts that are easy for humans to understand but difficult for models to grasp. Specifically, the cunning texts that FLUB focuses on mainly consist of the tricky, humorous, and misleading texts collected from the real internet environment. And we design three tasks with increasing difficulty in the FLUB benchmark to evaluate the fallacy understanding ability of LLMs. Based on FLUB, we investigate the performance of multiple representative and advanced LLMs, reflecting our FLUB is challenging and worthy of more future study. Interesting discoveries and valuable insights are achieved in our extensive experiments and detailed analyses. We hope that our benchmark can encourage the community to improve LLMs' ability to understand fallacies. Our data and codes are available at https://github.com/THUKElab/FLUB.",
    "DOI": "10.48550/arXiv.2402.11100",
    "note": "arXiv:2402.11100 [cs]",
    "number": "arXiv:2402.11100",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "When LLMs Meet Cunning Texts: A Fallacy Understanding Benchmark for Large Language Models",
    "title-short": "When LLMs Meet Cunning Texts",
    "URL": "http://arxiv.org/abs/2402.11100",
    "author": [
      {
        "family": "Li",
        "given": "Yinghui"
      },
      {
        "family": "Zhou",
        "given": "Qingyu"
      },
      {
        "family": "Luo",
        "given": "Yuanzhen"
      },
      {
        "family": "Ma",
        "given": "Shirong"
      },
      {
        "family": "Li",
        "given": "Yangning"
      },
      {
        "family": "Zheng",
        "given": "Hai-Tao"
      },
      {
        "family": "Hu",
        "given": "Xuming"
      },
      {
        "family": "Yu",
        "given": "Philip S."
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 4]]
    },
    "issued": {
      "date-parts": [["2024", 6, 9]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/CV3JUALS",
    "type": "article",
    "abstract": "Selecting high-quality training data from a larger pool is a crucial step when instruction-tuning language models, as carefully curated datasets often produce models that outperform those trained on much larger, noisier datasets. Automated data selection approaches for instruction-tuning are typically tested by selecting small datasets (roughly 10k samples) from small pools (100-200k samples). However, popular deployed instruction-tuned models often train on hundreds of thousands to millions of samples, subsampled from even larger data pools. We present a systematic study of how well data selection methods scale to these settings, selecting up to 2.5M samples from pools of up to 5.8M samples and evaluating across 7 diverse tasks. We show that many recently proposed methods fall short of random selection in this setting (while using more compute), and even decline in performance when given access to larger pools of data to select over. However, we find that a variant of representation-based data selection (RDS+), which uses weighted mean pooling of pretrained LM hidden states, consistently outperforms more complex methods across all settings tested -- all whilst being more compute-efficient. Our findings highlight that the scaling properties of proposed automated selection methods should be more closely examined. We release our code, data, and models at https://github.com/hamishivi/automated-instruction-selection.",
    "DOI": "10.48550/arXiv.2503.01807",
    "note": "arXiv:2503.01807 [cs]",
    "number": "arXiv:2503.01807",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Large-Scale Data Selection for Instruction Tuning",
    "URL": "http://arxiv.org/abs/2503.01807",
    "author": [
      {
        "family": "Ivison",
        "given": "Hamish"
      },
      {
        "family": "Zhang",
        "given": "Muru"
      },
      {
        "family": "Brahman",
        "given": "Faeze"
      },
      {
        "family": "Koh",
        "given": "Pang Wei"
      },
      {
        "family": "Dasigi",
        "given": "Pradeep"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 5]]
    },
    "issued": {
      "date-parts": [["2025", 3, 3]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/T4DM4AFR",
    "type": "article",
    "abstract": "Training LLMs on data containing unfamiliar knowledge during the instruction tuning stage can encourage hallucinations. To address this challenge, we introduce NOVA, a novel framework designed to identify high-quality data that aligns well with the LLM's learned knowledge to reduce hallucinations. NOVA includes Internal Consistency Probing (ICP) and Semantic Equivalence Identification (SEI) to measure how familiar the LLM is with instruction data. Specifically, ICP evaluates the LLM's understanding of the given instruction by calculating the tailored consistency among multiple self-generated responses. SEI further assesses the familiarity of the LLM with the target response by comparing it to the generated responses, using the proposed semantic clustering and well-designed voting strategy. Finally, to ensure the quality of selected samples, we introduce an expert-aligned reward model, considering characteristics beyond just familiarity. By considering data quality and avoiding unfamiliar data, we can utilize the selected data to effectively align LLMs to follow instructions and hallucinate less.",
    "DOI": "10.48550/arXiv.2502.07340",
    "note": "arXiv:2502.07340 [cs]",
    "number": "arXiv:2502.07340",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Aligning Large Language Models to Follow Instructions and Hallucinate Less via Effective Data Filtering",
    "URL": "http://arxiv.org/abs/2502.07340",
    "author": [
      {
        "family": "Si",
        "given": "Shuzheng"
      },
      {
        "family": "Zhao",
        "given": "Haozhe"
      },
      {
        "family": "Chen",
        "given": "Gang"
      },
      {
        "family": "Gao",
        "given": "Cheng"
      },
      {
        "family": "Bai",
        "given": "Yuzhuo"
      },
      {
        "family": "Wang",
        "given": "Zhitong"
      },
      {
        "family": "An",
        "given": "Kaikai"
      },
      {
        "family": "Luo",
        "given": "Kangyang"
      },
      {
        "family": "Qian",
        "given": "Chen"
      },
      {
        "family": "Qi",
        "given": "Fanchao"
      },
      {
        "family": "Chang",
        "given": "Baobao"
      },
      {
        "family": "Sun",
        "given": "Maosong"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 6]]
    },
    "issued": {
      "date-parts": [["2025", 2, 17]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/U3BCTQ7Q",
    "type": "article",
    "abstract": "While large language models (LLMs) equipped with techniques like chain-of-thought prompting have demonstrated impressive capabilities, they still fall short in their ability to reason robustly in complex settings. However, evaluating LLM reasoning is challenging because system capabilities continue to grow while benchmark datasets for tasks like logical deduction have remained static. We introduce MuSR, a dataset for evaluating language models on multistep soft reasoning tasks specified in a natural language narrative. This dataset has two crucial features. First, it is created through a novel neurosymbolic synthetic-to-natural generation algorithm, enabling the construction of complex reasoning instances that challenge GPT-4 (e.g., murder mysteries roughly 1000 words in length) and which can be scaled further as more capable LLMs are released. Second, our dataset instances are free text narratives corresponding to real-world domains of reasoning; this makes it simultaneously much more challenging than other synthetically-crafted benchmarks while remaining realistic and tractable for human annotators to solve with high accuracy. We evaluate a range of LLMs and prompting techniques on this dataset and characterize the gaps that remain for techniques like chain-of-thought to perform robust reasoning.",
    "DOI": "10.48550/arXiv.2310.16049",
    "language": "en-US",
    "note": "arXiv:2310.16049 [cs]",
    "number": "arXiv:2310.16049",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning",
    "title-short": "MuSR",
    "URL": "http://arxiv.org/abs/2310.16049",
    "author": [
      {
        "family": "Sprague",
        "given": "Zayne"
      },
      {
        "family": "Ye",
        "given": "Xi"
      },
      {
        "family": "Bostrom",
        "given": "Kaj"
      },
      {
        "family": "Chaudhuri",
        "given": "Swarat"
      },
      {
        "family": "Durrett",
        "given": "Greg"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 6]]
    },
    "issued": {
      "date-parts": [["2024", 3, 23]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/PAXSGVYM",
    "type": "article",
    "abstract": "Large language models (LLMs) exhibit hallucinations (i.e., unfaithful or nonsensical information) when serving as AI assistants in various domains. Since hallucinations always come with truthful content in the LLM responses, previous factuality alignment methods that conduct response-level preference learning inevitably introduced noises during training. Therefore, this paper proposes a fine-grained factuality alignment method based on Direct Preference Optimization (DPO), called Mask-DPO. Incorporating sentence-level factuality as mask signals, Mask-DPO only learns from factually correct sentences in the preferred samples and prevents the penalty on factual contents in the not preferred samples, which resolves the ambiguity in the preference learning. Extensive experimental results demonstrate that Mask-DPO can significantly improve the factuality of LLMs responses to questions from both in-domain and out-of-domain datasets, although these questions and their corresponding topics are unseen during training. Only trained on the ANAH train set, the score of Llama3.1-8B-Instruct on the ANAH test set is improved from 49.19% to 77.53%, even surpassing the score of Llama3.1-70B-Instruct (53.44%), while its FactScore on the out-of-domain Biography dataset is also improved from 30.29% to 39.39%. We further study the generalization property of Mask-DPO using different training sample scaling strategies and find that scaling the number of topics in the dataset is more effective than the number of questions. We provide a hypothesis of what factual alignment is doing with LLMs, on the implication of this phenomenon, and conduct proof-of-concept experiments to verify it. We hope the method and the findings pave the way for future research on scaling factuality alignment.",
    "DOI": "10.48550/arXiv.2503.02846",
    "note": "arXiv:2503.02846 [cs]",
    "number": "arXiv:2503.02846",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Mask-DPO: Generalizable Fine-grained Factuality Alignment of LLMs",
    "title-short": "Mask-DPO",
    "URL": "http://arxiv.org/abs/2503.02846",
    "author": [
      {
        "family": "Gu",
        "given": "Yuzhe"
      },
      {
        "family": "Zhang",
        "given": "Wenwei"
      },
      {
        "family": "Lyu",
        "given": "Chengqi"
      },
      {
        "family": "Lin",
        "given": "Dahua"
      },
      {
        "family": "Chen",
        "given": "Kai"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 7]]
    },
    "issued": {
      "date-parts": [["2025", 3, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/3W466V6U",
    "type": "article",
    "abstract": "We introduce LADDER (Learning through Autonomous Difficulty-Driven Example Recursion), a framework which enables Large Language Models to autonomously improve their problem-solving capabilities through self-guided learning by recursively generating and solving progressively simpler variants of complex problems. Unlike prior approaches that require curated datasets or human feedback, LADDER leverages a model's own capabilities to generate easier question variants. We demonstrate LADDER's effectiveness in the subject of mathematical integration, improving Llama 3.2 3B's accuracy from 1% to 82% on undergraduate-level problems and enabling Qwen2.5 7B Deepseek-R1 Distilled to achieve 73% on the MIT Integration Bee qualifying examination. We also introduce TTRL (Test-Time Reinforcement Learning), where we perform reinforcement learning on variants of test problems at inference time. TTRL enables Qwen2.5 7B Deepseek-R1 Distilled to achieve a state-of-the-art score of 90% on the MIT Integration Bee qualifying examination, surpassing OpenAI o1's performance. These results show how self-directed strategic learning can achieve significant capability improvements without relying on architectural scaling or human supervision.",
    "DOI": "10.48550/arXiv.2503.00735",
    "note": "arXiv:2503.00735 [cs]",
    "number": "arXiv:2503.00735",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "LADDER: Self-Improving LLMs Through Recursive Problem Decomposition",
    "title-short": "LADDER",
    "URL": "http://arxiv.org/abs/2503.00735",
    "author": [
      {
        "family": "Simonds",
        "given": "Toby"
      },
      {
        "family": "Yoshiyama",
        "given": "Akira"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 7]]
    },
    "issued": {
      "date-parts": [["2025", 3, 5]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/QM3X4PCF",
    "type": "article",
    "abstract": "Collecting ground truth task completion rewards or human demonstrations for multi-step reasoning tasks is often cost-prohibitive and time-consuming, especially in interactive domains like web tasks. To address this bottleneck, we present self-taught lookahead, a self-supervised method that leverages state-transition dynamics to train a value model capable of effectively guiding language model-controlled search. We find that moderately sized (8 billion parameters) open-weight value models improved with self-taught lookahead can match the performance of using a frontier LLM such as gpt-4o as the value model. Furthermore, we find that self-taught lookahead improves performance by 20% while reducing costs 37x compared to previous LLM-based tree search, without relying on ground truth rewards.",
    "DOI": "10.48550/arXiv.2503.02878",
    "note": "arXiv:2503.02878 [cs]",
    "number": "arXiv:2503.02878",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Language Models can Self-Improve at State-Value Estimation for Better Search",
    "URL": "http://arxiv.org/abs/2503.02878",
    "author": [
      {
        "family": "Mendes",
        "given": "Ethan"
      },
      {
        "family": "Ritter",
        "given": "Alan"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 7]]
    },
    "issued": {
      "date-parts": [["2025", 3, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/X9S3BMBZ",
    "type": "article",
    "abstract": "Large Language Models have demonstrated outstanding performance across various downstream tasks and have been widely applied in multiple scenarios. Human-annotated preference data is used for training to further improve LLMs' performance, which is constrained by the upper limit of human performance. Therefore, Self-Rewarding method has been proposed, where LLMs generate training data by rewarding their own outputs. However, the existing self-rewarding paradigm is not effective in mathematical reasoning scenarios and may even lead to a decline in performance. In this work, we propose the Process-based Self-Rewarding pipeline for language models, which introduces long-thought reasoning, step-wise LLM-as-a-Judge, and step-wise preference optimization within the self-rewarding paradigm. Our new paradigm successfully enhances the performance of LLMs on multiple mathematical reasoning benchmarks through iterative Process-based Self-Rewarding, demonstrating the immense potential of self-rewarding to achieve LLM reasoning that may surpass human capabilities.",
    "DOI": "10.48550/arXiv.2503.03746",
    "note": "arXiv:2503.03746 [cs]",
    "number": "arXiv:2503.03746",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Process-based Self-Rewarding Language Models",
    "URL": "http://arxiv.org/abs/2503.03746",
    "author": [
      {
        "family": "Zhang",
        "given": "Shimao"
      },
      {
        "family": "Liu",
        "given": "Xiao"
      },
      {
        "family": "Zhang",
        "given": "Xin"
      },
      {
        "family": "Liu",
        "given": "Junxiao"
      },
      {
        "family": "Luo",
        "given": "Zheheng"
      },
      {
        "family": "Huang",
        "given": "Shujian"
      },
      {
        "family": "Gong",
        "given": "Yeyun"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 7]]
    },
    "issued": {
      "date-parts": [["2025", 3, 5]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/ZFUVV5MS",
    "type": "article",
    "abstract": "Distilling advanced Large Language Models' instruction-following capabilities into smaller models using a selected subset has become a mainstream approach in model training. While existing synthetic instruction data selection strategies rely mainly on single-dimensional signals (i.e., reward scores, model perplexity), they fail to capture the complexity of instruction-following across diverse fields. Therefore, we investigate more diverse signals to capture comprehensive instruction-response pair characteristics and propose three foundational metrics that leverage Multi-LLM wisdom, informed by (1) diverse LLM responses and (2) reward model assessment. Building upon base metrics, we propose CrowdSelect, an integrated metric incorporating a clustering-based approach to maintain response diversity. Our comprehensive experiments demonstrate that our foundation metrics consistently improve performance across 4 base models on MT-bench and Arena-Hard. CrowdSelect, efficiently incorporating all metrics, achieves state-of-the-art performance in both Full and LoRA fine-tuning, showing improvements of 4.81% on Arena-Hard and 11.1% on MT-bench with Llama-3.2-3b-instruct. We hope our findings will bring valuable insights for future research in this direction. Code are available at https://github.com/listentm/crowdselect.",
    "DOI": "10.48550/arXiv.2503.01836",
    "note": "arXiv:2503.01836 [cs]",
    "number": "arXiv:2503.01836",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "CrowdSelect: Synthetic Instruction Data Selection with Multi-LLM Wisdom",
    "title-short": "CrowdSelect",
    "URL": "http://arxiv.org/abs/2503.01836",
    "author": [
      {
        "family": "Li",
        "given": "Yisen"
      },
      {
        "family": "Yang",
        "given": "Lingfeng"
      },
      {
        "family": "Shen",
        "given": "Wenxuan"
      },
      {
        "family": "Zhou",
        "given": "Pan"
      },
      {
        "family": "Wan",
        "given": "Yao"
      },
      {
        "family": "Lin",
        "given": "Weiwei"
      },
      {
        "family": "Chen",
        "given": "Dongping"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 7]]
    },
    "issued": {
      "date-parts": [["2025", 3, 3]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/S3PIAQ4T",
    "type": "article",
    "abstract": "Modern foundation models often undergo iterative ``bootstrapping'' in their post-training phase: a model generates synthetic data, an external verifier filters out low-quality samples, and the high-quality subset is used for further fine-tuning. Over multiple iterations, the model's performance improves--raising a crucial question: how should the total budget on generation and training be allocated across iterations to maximize final performance? In this work, we develop a theoretical framework to analyze budget allocation strategies. Specifically, we show that constant policies fail to converge with high probability, while increasing policies--particularly exponential growth policies--exhibit significant theoretical advantages. Experiments on image denoising with diffusion probabilistic models and math reasoning with large language models show that both exponential and polynomial growth policies consistently outperform constant policies, with exponential policies often providing more stable performance.",
    "DOI": "10.48550/arXiv.2501.18962",
    "note": "arXiv:2501.18962 [cs]",
    "number": "arXiv:2501.18962",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Spend Wisely: Maximizing Post-Training Gains in Iterative Synthetic Data Boostrapping",
    "title-short": "Spend Wisely",
    "URL": "http://arxiv.org/abs/2501.18962",
    "author": [
      {
        "family": "Yang",
        "given": "Pu"
      },
      {
        "family": "Feng",
        "given": "Yunzhen"
      },
      {
        "family": "Chen",
        "given": "Ziyuan"
      },
      {
        "family": "Wu",
        "given": "Yuhang"
      },
      {
        "family": "Li",
        "given": "Zhuoyuan"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 7]]
    },
    "issued": {
      "date-parts": [["2025", 1, 31]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/GLKZYL42",
    "type": "article",
    "abstract": "As language models master existing reasoning benchmarks, we need new challenges to evaluate their cognitive frontiers. Puzzle-solving events are rich repositories of challenging multimodal problems that test a wide range of advanced reasoning and knowledge capabilities, making them a unique testbed for evaluating frontier language models. We introduce EnigmaEval, a dataset of problems and solutions derived from puzzle competitions and events that probes models' ability to perform implicit knowledge synthesis and multi-step deductive reasoning. Unlike existing reasoning and knowledge benchmarks, puzzle solving challenges models to discover hidden connections between seemingly unrelated pieces of information to uncover solution paths. The benchmark comprises 1184 puzzles of varying complexity -- each typically requiring teams of skilled solvers hours to days to complete -- with unambiguous, verifiable solutions that enable efficient evaluation. State-of-the-art language models achieve extremely low accuracy on these puzzles, even lower than other difficult benchmarks such as Humanity's Last Exam, unveiling models' shortcomings when challenged with problems requiring unstructured and lateral reasoning.",
    "DOI": "10.48550/arXiv.2502.08859",
    "note": "arXiv:2502.08859 [cs]",
    "number": "arXiv:2502.08859",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "EnigmaEval: A Benchmark of Long Multimodal Reasoning Challenges",
    "title-short": "EnigmaEval",
    "URL": "http://arxiv.org/abs/2502.08859",
    "author": [
      {
        "family": "Wang",
        "given": "Clinton J."
      },
      {
        "family": "Lee",
        "given": "Dean"
      },
      {
        "family": "Menghini",
        "given": "Cristina"
      },
      {
        "family": "Mols",
        "given": "Johannes"
      },
      {
        "family": "Doughty",
        "given": "Jack"
      },
      {
        "family": "Khoja",
        "given": "Adam"
      },
      {
        "family": "Lynch",
        "given": "Jayson"
      },
      {
        "family": "Hendryx",
        "given": "Sean"
      },
      {
        "family": "Yue",
        "given": "Summer"
      },
      {
        "family": "Hendrycks",
        "given": "Dan"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 13]]
    },
    "issued": {
      "date-parts": [["2025", 2, 14]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/7CBNZ4GN",
    "type": "article",
    "abstract": "As language models master existing reasoning benchmarks, we need new challenges to evaluate their cognitive frontiers. Puzzle-solving events are rich repositories of challenging multimodal problems that test a wide range of advanced reasoning and knowledge capabilities, making them a unique testbed for evaluating frontier language models. We introduce EnigmaEval, a dataset of problems and solutions derived from puzzle competitions and events that probes models' ability to perform implicit knowledge synthesis and multi-step deductive reasoning. Unlike existing reasoning and knowledge benchmarks, puzzle solving challenges models to discover hidden connections between seemingly unrelated pieces of information to uncover solution paths. The benchmark comprises 1184 puzzles of varying complexity -- each typically requiring teams of skilled solvers hours to days to complete -- with unambiguous, verifiable solutions that enable efficient evaluation. State-of-the-art language models achieve extremely low accuracy on these puzzles, even lower than other difficult benchmarks such as Humanity's Last Exam, unveiling models' shortcomings when challenged with problems requiring unstructured and lateral reasoning.",
    "DOI": "10.48550/arXiv.2502.08859",
    "language": "en-US",
    "note": "arXiv:2502.08859 [cs]",
    "number": "arXiv:2502.08859",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "EnigmaEval: A Benchmark of Long Multimodal Reasoning Challenges",
    "title-short": "EnigmaEval",
    "URL": "http://arxiv.org/abs/2502.08859",
    "author": [
      {
        "family": "Wang",
        "given": "Clinton J."
      },
      {
        "family": "Lee",
        "given": "Dean"
      },
      {
        "family": "Menghini",
        "given": "Cristina"
      },
      {
        "family": "Mols",
        "given": "Johannes"
      },
      {
        "family": "Doughty",
        "given": "Jack"
      },
      {
        "family": "Khoja",
        "given": "Adam"
      },
      {
        "family": "Lynch",
        "given": "Jayson"
      },
      {
        "family": "Hendryx",
        "given": "Sean"
      },
      {
        "family": "Yue",
        "given": "Summer"
      },
      {
        "family": "Hendrycks",
        "given": "Dan"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 13]]
    },
    "issued": {
      "date-parts": [["2025", 2, 14]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/9DIDJRA4",
    "type": "article",
    "abstract": "We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token. To achieve efficient inference and cost-effective training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architectures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities. Comprehensive evaluations reveal that DeepSeek-V3 outperforms other open-source models and achieves performance comparable to leading closed-source models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours for its full training. In addition, its training process is remarkably stable. Throughout the entire training process, we did not experience any irrecoverable loss spikes or perform any rollbacks. The model checkpoints are available at https://github.com/deepseek-ai/DeepSeek-V3.",
    "DOI": "10.48550/arXiv.2412.19437",
    "note": "arXiv:2412.19437 [cs]",
    "number": "arXiv:2412.19437",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "DeepSeek-V3 Technical Report",
    "URL": "http://arxiv.org/abs/2412.19437",
    "author": [
      {
        "family": "DeepSeek-AI",
        "given": ""
      },
      {
        "family": "Liu",
        "given": "Aixin"
      },
      {
        "family": "Feng",
        "given": "Bei"
      },
      {
        "family": "Xue",
        "given": "Bing"
      },
      {
        "family": "Wang",
        "given": "Bingxuan"
      },
      {
        "family": "Wu",
        "given": "Bochao"
      },
      {
        "family": "Lu",
        "given": "Chengda"
      },
      {
        "family": "Zhao",
        "given": "Chenggang"
      },
      {
        "family": "Deng",
        "given": "Chengqi"
      },
      {
        "family": "Zhang",
        "given": "Chenyu"
      },
      {
        "family": "Ruan",
        "given": "Chong"
      },
      {
        "family": "Dai",
        "given": "Damai"
      },
      {
        "family": "Guo",
        "given": "Daya"
      },
      {
        "family": "Yang",
        "given": "Dejian"
      },
      {
        "family": "Chen",
        "given": "Deli"
      },
      {
        "family": "Ji",
        "given": "Dongjie"
      },
      {
        "family": "Li",
        "given": "Erhang"
      },
      {
        "family": "Lin",
        "given": "Fangyun"
      },
      {
        "family": "Dai",
        "given": "Fucong"
      },
      {
        "family": "Luo",
        "given": "Fuli"
      },
      {
        "family": "Hao",
        "given": "Guangbo"
      },
      {
        "family": "Chen",
        "given": "Guanting"
      },
      {
        "family": "Li",
        "given": "Guowei"
      },
      {
        "family": "Zhang",
        "given": "H."
      },
      {
        "family": "Bao",
        "given": "Han"
      },
      {
        "family": "Xu",
        "given": "Hanwei"
      },
      {
        "family": "Wang",
        "given": "Haocheng"
      },
      {
        "family": "Zhang",
        "given": "Haowei"
      },
      {
        "family": "Ding",
        "given": "Honghui"
      },
      {
        "family": "Xin",
        "given": "Huajian"
      },
      {
        "family": "Gao",
        "given": "Huazuo"
      },
      {
        "family": "Li",
        "given": "Hui"
      },
      {
        "family": "Qu",
        "given": "Hui"
      },
      {
        "family": "Cai",
        "given": "J. L."
      },
      {
        "family": "Liang",
        "given": "Jian"
      },
      {
        "family": "Guo",
        "given": "Jianzhong"
      },
      {
        "family": "Ni",
        "given": "Jiaqi"
      },
      {
        "family": "Li",
        "given": "Jiashi"
      },
      {
        "family": "Wang",
        "given": "Jiawei"
      },
      {
        "family": "Chen",
        "given": "Jin"
      },
      {
        "family": "Chen",
        "given": "Jingchang"
      },
      {
        "family": "Yuan",
        "given": "Jingyang"
      },
      {
        "family": "Qiu",
        "given": "Junjie"
      },
      {
        "family": "Li",
        "given": "Junlong"
      },
      {
        "family": "Song",
        "given": "Junxiao"
      },
      {
        "family": "Dong",
        "given": "Kai"
      },
      {
        "family": "Hu",
        "given": "Kai"
      },
      {
        "family": "Gao",
        "given": "Kaige"
      },
      {
        "family": "Guan",
        "given": "Kang"
      },
      {
        "family": "Huang",
        "given": "Kexin"
      },
      {
        "family": "Yu",
        "given": "Kuai"
      },
      {
        "family": "Wang",
        "given": "Lean"
      },
      {
        "family": "Zhang",
        "given": "Lecong"
      },
      {
        "family": "Xu",
        "given": "Lei"
      },
      {
        "family": "Xia",
        "given": "Leyi"
      },
      {
        "family": "Zhao",
        "given": "Liang"
      },
      {
        "family": "Wang",
        "given": "Litong"
      },
      {
        "family": "Zhang",
        "given": "Liyue"
      },
      {
        "family": "Li",
        "given": "Meng"
      },
      {
        "family": "Wang",
        "given": "Miaojun"
      },
      {
        "family": "Zhang",
        "given": "Mingchuan"
      },
      {
        "family": "Zhang",
        "given": "Minghua"
      },
      {
        "family": "Tang",
        "given": "Minghui"
      },
      {
        "family": "Li",
        "given": "Mingming"
      },
      {
        "family": "Tian",
        "given": "Ning"
      },
      {
        "family": "Huang",
        "given": "Panpan"
      },
      {
        "family": "Wang",
        "given": "Peiyi"
      },
      {
        "family": "Zhang",
        "given": "Peng"
      },
      {
        "family": "Wang",
        "given": "Qiancheng"
      },
      {
        "family": "Zhu",
        "given": "Qihao"
      },
      {
        "family": "Chen",
        "given": "Qinyu"
      },
      {
        "family": "Du",
        "given": "Qiushi"
      },
      {
        "family": "Chen",
        "given": "R. J."
      },
      {
        "family": "Jin",
        "given": "R. L."
      },
      {
        "family": "Ge",
        "given": "Ruiqi"
      },
      {
        "family": "Zhang",
        "given": "Ruisong"
      },
      {
        "family": "Pan",
        "given": "Ruizhe"
      },
      {
        "family": "Wang",
        "given": "Runji"
      },
      {
        "family": "Xu",
        "given": "Runxin"
      },
      {
        "family": "Zhang",
        "given": "Ruoyu"
      },
      {
        "family": "Chen",
        "given": "Ruyi"
      },
      {
        "family": "Li",
        "given": "S. S."
      },
      {
        "family": "Lu",
        "given": "Shanghao"
      },
      {
        "family": "Zhou",
        "given": "Shangyan"
      },
      {
        "family": "Chen",
        "given": "Shanhuang"
      },
      {
        "family": "Wu",
        "given": "Shaoqing"
      },
      {
        "family": "Ye",
        "given": "Shengfeng"
      },
      {
        "family": "Ye",
        "given": "Shengfeng"
      },
      {
        "family": "Ma",
        "given": "Shirong"
      },
      {
        "family": "Wang",
        "given": "Shiyu"
      },
      {
        "family": "Zhou",
        "given": "Shuang"
      },
      {
        "family": "Yu",
        "given": "Shuiping"
      },
      {
        "family": "Zhou",
        "given": "Shunfeng"
      },
      {
        "family": "Pan",
        "given": "Shuting"
      },
      {
        "family": "Wang",
        "given": "T."
      },
      {
        "family": "Yun",
        "given": "Tao"
      },
      {
        "family": "Pei",
        "given": "Tian"
      },
      {
        "family": "Sun",
        "given": "Tianyu"
      },
      {
        "family": "Xiao",
        "given": "W. L."
      },
      {
        "family": "Zeng",
        "given": "Wangding"
      },
      {
        "family": "Zhao",
        "given": "Wanjia"
      },
      {
        "family": "An",
        "given": "Wei"
      },
      {
        "family": "Liu",
        "given": "Wen"
      },
      {
        "family": "Liang",
        "given": "Wenfeng"
      },
      {
        "family": "Gao",
        "given": "Wenjun"
      },
      {
        "family": "Yu",
        "given": "Wenqin"
      },
      {
        "family": "Zhang",
        "given": "Wentao"
      },
      {
        "family": "Li",
        "given": "X. Q."
      },
      {
        "family": "Jin",
        "given": "Xiangyue"
      },
      {
        "family": "Wang",
        "given": "Xianzu"
      },
      {
        "family": "Bi",
        "given": "Xiao"
      },
      {
        "family": "Liu",
        "given": "Xiaodong"
      },
      {
        "family": "Wang",
        "given": "Xiaohan"
      },
      {
        "family": "Shen",
        "given": "Xiaojin"
      },
      {
        "family": "Chen",
        "given": "Xiaokang"
      },
      {
        "family": "Zhang",
        "given": "Xiaokang"
      },
      {
        "family": "Chen",
        "given": "Xiaosha"
      },
      {
        "family": "Nie",
        "given": "Xiaotao"
      },
      {
        "family": "Sun",
        "given": "Xiaowen"
      },
      {
        "family": "Wang",
        "given": "Xiaoxiang"
      },
      {
        "family": "Cheng",
        "given": "Xin"
      },
      {
        "family": "Liu",
        "given": "Xin"
      },
      {
        "family": "Xie",
        "given": "Xin"
      },
      {
        "family": "Liu",
        "given": "Xingchao"
      },
      {
        "family": "Yu",
        "given": "Xingkai"
      },
      {
        "family": "Song",
        "given": "Xinnan"
      },
      {
        "family": "Shan",
        "given": "Xinxia"
      },
      {
        "family": "Zhou",
        "given": "Xinyi"
      },
      {
        "family": "Yang",
        "given": "Xinyu"
      },
      {
        "family": "Li",
        "given": "Xinyuan"
      },
      {
        "family": "Su",
        "given": "Xuecheng"
      },
      {
        "family": "Lin",
        "given": "Xuheng"
      },
      {
        "family": "Li",
        "given": "Y. K."
      },
      {
        "family": "Wang",
        "given": "Y. Q."
      },
      {
        "family": "Wei",
        "given": "Y. X."
      },
      {
        "family": "Zhu",
        "given": "Y. X."
      },
      {
        "family": "Zhang",
        "given": "Yang"
      },
      {
        "family": "Xu",
        "given": "Yanhong"
      },
      {
        "family": "Xu",
        "given": "Yanhong"
      },
      {
        "family": "Huang",
        "given": "Yanping"
      },
      {
        "family": "Li",
        "given": "Yao"
      },
      {
        "family": "Zhao",
        "given": "Yao"
      },
      {
        "family": "Sun",
        "given": "Yaofeng"
      },
      {
        "family": "Li",
        "given": "Yaohui"
      },
      {
        "family": "Wang",
        "given": "Yaohui"
      },
      {
        "family": "Yu",
        "given": "Yi"
      },
      {
        "family": "Zheng",
        "given": "Yi"
      },
      {
        "family": "Zhang",
        "given": "Yichao"
      },
      {
        "family": "Shi",
        "given": "Yifan"
      },
      {
        "family": "Xiong",
        "given": "Yiliang"
      },
      {
        "family": "He",
        "given": "Ying"
      },
      {
        "family": "Tang",
        "given": "Ying"
      },
      {
        "family": "Piao",
        "given": "Yishi"
      },
      {
        "family": "Wang",
        "given": "Yisong"
      },
      {
        "family": "Tan",
        "given": "Yixuan"
      },
      {
        "family": "Ma",
        "given": "Yiyang"
      },
      {
        "family": "Liu",
        "given": "Yiyuan"
      },
      {
        "family": "Guo",
        "given": "Yongqiang"
      },
      {
        "family": "Wu",
        "given": "Yu"
      },
      {
        "family": "Ou",
        "given": "Yuan"
      },
      {
        "family": "Zhu",
        "given": "Yuchen"
      },
      {
        "family": "Wang",
        "given": "Yuduan"
      },
      {
        "family": "Gong",
        "given": "Yue"
      },
      {
        "family": "Zou",
        "given": "Yuheng"
      },
      {
        "family": "He",
        "given": "Yujia"
      },
      {
        "family": "Zha",
        "given": "Yukun"
      },
      {
        "family": "Xiong",
        "given": "Yunfan"
      },
      {
        "family": "Ma",
        "given": "Yunxian"
      },
      {
        "family": "Yan",
        "given": "Yuting"
      },
      {
        "family": "Luo",
        "given": "Yuxiang"
      },
      {
        "family": "You",
        "given": "Yuxiang"
      },
      {
        "family": "Liu",
        "given": "Yuxuan"
      },
      {
        "family": "Zhou",
        "given": "Yuyang"
      },
      {
        "family": "Wu",
        "given": "Z. F."
      },
      {
        "family": "Ren",
        "given": "Z. Z."
      },
      {
        "family": "Ren",
        "given": "Zehui"
      },
      {
        "family": "Sha",
        "given": "Zhangli"
      },
      {
        "family": "Fu",
        "given": "Zhe"
      },
      {
        "family": "Xu",
        "given": "Zhean"
      },
      {
        "family": "Huang",
        "given": "Zhen"
      },
      {
        "family": "Zhang",
        "given": "Zhen"
      },
      {
        "family": "Xie",
        "given": "Zhenda"
      },
      {
        "family": "Zhang",
        "given": "Zhengyan"
      },
      {
        "family": "Hao",
        "given": "Zhewen"
      },
      {
        "family": "Gou",
        "given": "Zhibin"
      },
      {
        "family": "Ma",
        "given": "Zhicheng"
      },
      {
        "family": "Yan",
        "given": "Zhigang"
      },
      {
        "family": "Shao",
        "given": "Zhihong"
      },
      {
        "family": "Xu",
        "given": "Zhipeng"
      },
      {
        "family": "Wu",
        "given": "Zhiyu"
      },
      {
        "family": "Zhang",
        "given": "Zhongyu"
      },
      {
        "family": "Li",
        "given": "Zhuoshu"
      },
      {
        "family": "Gu",
        "given": "Zihui"
      },
      {
        "family": "Zhu",
        "given": "Zijia"
      },
      {
        "family": "Liu",
        "given": "Zijun"
      },
      {
        "family": "Li",
        "given": "Zilin"
      },
      {
        "family": "Xie",
        "given": "Ziwei"
      },
      {
        "family": "Song",
        "given": "Ziyang"
      },
      {
        "family": "Gao",
        "given": "Ziyi"
      },
      {
        "family": "Pan",
        "given": "Zizheng"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 13]]
    },
    "issued": {
      "date-parts": [["2025", 2, 18]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/6X8MAS7L",
    "type": "article",
    "abstract": "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.",
    "DOI": "10.48550/arXiv.2501.12948",
    "note": "arXiv:2501.12948 [cs]",
    "number": "arXiv:2501.12948",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning",
    "title-short": "DeepSeek-R1",
    "URL": "http://arxiv.org/abs/2501.12948",
    "author": [
      {
        "family": "DeepSeek-AI",
        "given": ""
      },
      {
        "family": "Guo",
        "given": "Daya"
      },
      {
        "family": "Yang",
        "given": "Dejian"
      },
      {
        "family": "Zhang",
        "given": "Haowei"
      },
      {
        "family": "Song",
        "given": "Junxiao"
      },
      {
        "family": "Zhang",
        "given": "Ruoyu"
      },
      {
        "family": "Xu",
        "given": "Runxin"
      },
      {
        "family": "Zhu",
        "given": "Qihao"
      },
      {
        "family": "Ma",
        "given": "Shirong"
      },
      {
        "family": "Wang",
        "given": "Peiyi"
      },
      {
        "family": "Bi",
        "given": "Xiao"
      },
      {
        "family": "Zhang",
        "given": "Xiaokang"
      },
      {
        "family": "Yu",
        "given": "Xingkai"
      },
      {
        "family": "Wu",
        "given": "Yu"
      },
      {
        "family": "Wu",
        "given": "Z. F."
      },
      {
        "family": "Gou",
        "given": "Zhibin"
      },
      {
        "family": "Shao",
        "given": "Zhihong"
      },
      {
        "family": "Li",
        "given": "Zhuoshu"
      },
      {
        "family": "Gao",
        "given": "Ziyi"
      },
      {
        "family": "Liu",
        "given": "Aixin"
      },
      {
        "family": "Xue",
        "given": "Bing"
      },
      {
        "family": "Wang",
        "given": "Bingxuan"
      },
      {
        "family": "Wu",
        "given": "Bochao"
      },
      {
        "family": "Feng",
        "given": "Bei"
      },
      {
        "family": "Lu",
        "given": "Chengda"
      },
      {
        "family": "Zhao",
        "given": "Chenggang"
      },
      {
        "family": "Deng",
        "given": "Chengqi"
      },
      {
        "family": "Zhang",
        "given": "Chenyu"
      },
      {
        "family": "Ruan",
        "given": "Chong"
      },
      {
        "family": "Dai",
        "given": "Damai"
      },
      {
        "family": "Chen",
        "given": "Deli"
      },
      {
        "family": "Ji",
        "given": "Dongjie"
      },
      {
        "family": "Li",
        "given": "Erhang"
      },
      {
        "family": "Lin",
        "given": "Fangyun"
      },
      {
        "family": "Dai",
        "given": "Fucong"
      },
      {
        "family": "Luo",
        "given": "Fuli"
      },
      {
        "family": "Hao",
        "given": "Guangbo"
      },
      {
        "family": "Chen",
        "given": "Guanting"
      },
      {
        "family": "Li",
        "given": "Guowei"
      },
      {
        "family": "Zhang",
        "given": "H."
      },
      {
        "family": "Bao",
        "given": "Han"
      },
      {
        "family": "Xu",
        "given": "Hanwei"
      },
      {
        "family": "Wang",
        "given": "Haocheng"
      },
      {
        "family": "Ding",
        "given": "Honghui"
      },
      {
        "family": "Xin",
        "given": "Huajian"
      },
      {
        "family": "Gao",
        "given": "Huazuo"
      },
      {
        "family": "Qu",
        "given": "Hui"
      },
      {
        "family": "Li",
        "given": "Hui"
      },
      {
        "family": "Guo",
        "given": "Jianzhong"
      },
      {
        "family": "Li",
        "given": "Jiashi"
      },
      {
        "family": "Wang",
        "given": "Jiawei"
      },
      {
        "family": "Chen",
        "given": "Jingchang"
      },
      {
        "family": "Yuan",
        "given": "Jingyang"
      },
      {
        "family": "Qiu",
        "given": "Junjie"
      },
      {
        "family": "Li",
        "given": "Junlong"
      },
      {
        "family": "Cai",
        "given": "J. L."
      },
      {
        "family": "Ni",
        "given": "Jiaqi"
      },
      {
        "family": "Liang",
        "given": "Jian"
      },
      {
        "family": "Chen",
        "given": "Jin"
      },
      {
        "family": "Dong",
        "given": "Kai"
      },
      {
        "family": "Hu",
        "given": "Kai"
      },
      {
        "family": "Gao",
        "given": "Kaige"
      },
      {
        "family": "Guan",
        "given": "Kang"
      },
      {
        "family": "Huang",
        "given": "Kexin"
      },
      {
        "family": "Yu",
        "given": "Kuai"
      },
      {
        "family": "Wang",
        "given": "Lean"
      },
      {
        "family": "Zhang",
        "given": "Lecong"
      },
      {
        "family": "Zhao",
        "given": "Liang"
      },
      {
        "family": "Wang",
        "given": "Litong"
      },
      {
        "family": "Zhang",
        "given": "Liyue"
      },
      {
        "family": "Xu",
        "given": "Lei"
      },
      {
        "family": "Xia",
        "given": "Leyi"
      },
      {
        "family": "Zhang",
        "given": "Mingchuan"
      },
      {
        "family": "Zhang",
        "given": "Minghua"
      },
      {
        "family": "Tang",
        "given": "Minghui"
      },
      {
        "family": "Li",
        "given": "Meng"
      },
      {
        "family": "Wang",
        "given": "Miaojun"
      },
      {
        "family": "Li",
        "given": "Mingming"
      },
      {
        "family": "Tian",
        "given": "Ning"
      },
      {
        "family": "Huang",
        "given": "Panpan"
      },
      {
        "family": "Zhang",
        "given": "Peng"
      },
      {
        "family": "Wang",
        "given": "Qiancheng"
      },
      {
        "family": "Chen",
        "given": "Qinyu"
      },
      {
        "family": "Du",
        "given": "Qiushi"
      },
      {
        "family": "Ge",
        "given": "Ruiqi"
      },
      {
        "family": "Zhang",
        "given": "Ruisong"
      },
      {
        "family": "Pan",
        "given": "Ruizhe"
      },
      {
        "family": "Wang",
        "given": "Runji"
      },
      {
        "family": "Chen",
        "given": "R. J."
      },
      {
        "family": "Jin",
        "given": "R. L."
      },
      {
        "family": "Chen",
        "given": "Ruyi"
      },
      {
        "family": "Lu",
        "given": "Shanghao"
      },
      {
        "family": "Zhou",
        "given": "Shangyan"
      },
      {
        "family": "Chen",
        "given": "Shanhuang"
      },
      {
        "family": "Ye",
        "given": "Shengfeng"
      },
      {
        "family": "Wang",
        "given": "Shiyu"
      },
      {
        "family": "Yu",
        "given": "Shuiping"
      },
      {
        "family": "Zhou",
        "given": "Shunfeng"
      },
      {
        "family": "Pan",
        "given": "Shuting"
      },
      {
        "family": "Li",
        "given": "S. S."
      },
      {
        "family": "Zhou",
        "given": "Shuang"
      },
      {
        "family": "Wu",
        "given": "Shaoqing"
      },
      {
        "family": "Ye",
        "given": "Shengfeng"
      },
      {
        "family": "Yun",
        "given": "Tao"
      },
      {
        "family": "Pei",
        "given": "Tian"
      },
      {
        "family": "Sun",
        "given": "Tianyu"
      },
      {
        "family": "Wang",
        "given": "T."
      },
      {
        "family": "Zeng",
        "given": "Wangding"
      },
      {
        "family": "Zhao",
        "given": "Wanjia"
      },
      {
        "family": "Liu",
        "given": "Wen"
      },
      {
        "family": "Liang",
        "given": "Wenfeng"
      },
      {
        "family": "Gao",
        "given": "Wenjun"
      },
      {
        "family": "Yu",
        "given": "Wenqin"
      },
      {
        "family": "Zhang",
        "given": "Wentao"
      },
      {
        "family": "Xiao",
        "given": "W. L."
      },
      {
        "family": "An",
        "given": "Wei"
      },
      {
        "family": "Liu",
        "given": "Xiaodong"
      },
      {
        "family": "Wang",
        "given": "Xiaohan"
      },
      {
        "family": "Chen",
        "given": "Xiaokang"
      },
      {
        "family": "Nie",
        "given": "Xiaotao"
      },
      {
        "family": "Cheng",
        "given": "Xin"
      },
      {
        "family": "Liu",
        "given": "Xin"
      },
      {
        "family": "Xie",
        "given": "Xin"
      },
      {
        "family": "Liu",
        "given": "Xingchao"
      },
      {
        "family": "Yang",
        "given": "Xinyu"
      },
      {
        "family": "Li",
        "given": "Xinyuan"
      },
      {
        "family": "Su",
        "given": "Xuecheng"
      },
      {
        "family": "Lin",
        "given": "Xuheng"
      },
      {
        "family": "Li",
        "given": "X. Q."
      },
      {
        "family": "Jin",
        "given": "Xiangyue"
      },
      {
        "family": "Shen",
        "given": "Xiaojin"
      },
      {
        "family": "Chen",
        "given": "Xiaosha"
      },
      {
        "family": "Sun",
        "given": "Xiaowen"
      },
      {
        "family": "Wang",
        "given": "Xiaoxiang"
      },
      {
        "family": "Song",
        "given": "Xinnan"
      },
      {
        "family": "Zhou",
        "given": "Xinyi"
      },
      {
        "family": "Wang",
        "given": "Xianzu"
      },
      {
        "family": "Shan",
        "given": "Xinxia"
      },
      {
        "family": "Li",
        "given": "Y. K."
      },
      {
        "family": "Wang",
        "given": "Y. Q."
      },
      {
        "family": "Wei",
        "given": "Y. X."
      },
      {
        "family": "Zhang",
        "given": "Yang"
      },
      {
        "family": "Xu",
        "given": "Yanhong"
      },
      {
        "family": "Li",
        "given": "Yao"
      },
      {
        "family": "Zhao",
        "given": "Yao"
      },
      {
        "family": "Sun",
        "given": "Yaofeng"
      },
      {
        "family": "Wang",
        "given": "Yaohui"
      },
      {
        "family": "Yu",
        "given": "Yi"
      },
      {
        "family": "Zhang",
        "given": "Yichao"
      },
      {
        "family": "Shi",
        "given": "Yifan"
      },
      {
        "family": "Xiong",
        "given": "Yiliang"
      },
      {
        "family": "He",
        "given": "Ying"
      },
      {
        "family": "Piao",
        "given": "Yishi"
      },
      {
        "family": "Wang",
        "given": "Yisong"
      },
      {
        "family": "Tan",
        "given": "Yixuan"
      },
      {
        "family": "Ma",
        "given": "Yiyang"
      },
      {
        "family": "Liu",
        "given": "Yiyuan"
      },
      {
        "family": "Guo",
        "given": "Yongqiang"
      },
      {
        "family": "Ou",
        "given": "Yuan"
      },
      {
        "family": "Wang",
        "given": "Yuduan"
      },
      {
        "family": "Gong",
        "given": "Yue"
      },
      {
        "family": "Zou",
        "given": "Yuheng"
      },
      {
        "family": "He",
        "given": "Yujia"
      },
      {
        "family": "Xiong",
        "given": "Yunfan"
      },
      {
        "family": "Luo",
        "given": "Yuxiang"
      },
      {
        "family": "You",
        "given": "Yuxiang"
      },
      {
        "family": "Liu",
        "given": "Yuxuan"
      },
      {
        "family": "Zhou",
        "given": "Yuyang"
      },
      {
        "family": "Zhu",
        "given": "Y. X."
      },
      {
        "family": "Xu",
        "given": "Yanhong"
      },
      {
        "family": "Huang",
        "given": "Yanping"
      },
      {
        "family": "Li",
        "given": "Yaohui"
      },
      {
        "family": "Zheng",
        "given": "Yi"
      },
      {
        "family": "Zhu",
        "given": "Yuchen"
      },
      {
        "family": "Ma",
        "given": "Yunxian"
      },
      {
        "family": "Tang",
        "given": "Ying"
      },
      {
        "family": "Zha",
        "given": "Yukun"
      },
      {
        "family": "Yan",
        "given": "Yuting"
      },
      {
        "family": "Ren",
        "given": "Z. Z."
      },
      {
        "family": "Ren",
        "given": "Zehui"
      },
      {
        "family": "Sha",
        "given": "Zhangli"
      },
      {
        "family": "Fu",
        "given": "Zhe"
      },
      {
        "family": "Xu",
        "given": "Zhean"
      },
      {
        "family": "Xie",
        "given": "Zhenda"
      },
      {
        "family": "Zhang",
        "given": "Zhengyan"
      },
      {
        "family": "Hao",
        "given": "Zhewen"
      },
      {
        "family": "Ma",
        "given": "Zhicheng"
      },
      {
        "family": "Yan",
        "given": "Zhigang"
      },
      {
        "family": "Wu",
        "given": "Zhiyu"
      },
      {
        "family": "Gu",
        "given": "Zihui"
      },
      {
        "family": "Zhu",
        "given": "Zijia"
      },
      {
        "family": "Liu",
        "given": "Zijun"
      },
      {
        "family": "Li",
        "given": "Zilin"
      },
      {
        "family": "Xie",
        "given": "Ziwei"
      },
      {
        "family": "Song",
        "given": "Ziyang"
      },
      {
        "family": "Pan",
        "given": "Zizheng"
      },
      {
        "family": "Huang",
        "given": "Zhen"
      },
      {
        "family": "Xu",
        "given": "Zhipeng"
      },
      {
        "family": "Zhang",
        "given": "Zhongyu"
      },
      {
        "family": "Zhang",
        "given": "Zhen"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 13]]
    },
    "issued": {
      "date-parts": [["2025", 1, 22]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/GEYIIG2G",
    "type": "document",
    "title": "Gemma 3 Technical Report",
    "URL": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf",
    "accessed": {
      "date-parts": [["2025", 3, 13]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/93Y3QCQN",
    "type": "article",
    "abstract": "This is a book about large language models. As indicated by the title, it primarily focuses on foundational concepts rather than comprehensive coverage of all cutting-edge technologies. The book is structured into four main chapters, each exploring a key area: pre-training, generative models, prompting techniques, and alignment methods. It is intended for college students, professionals, and practitioners in natural language processing and related fields, and can serve as a reference for anyone interested in large language models.",
    "DOI": "10.48550/arXiv.2501.09223",
    "note": "arXiv:2501.09223 [cs]",
    "number": "arXiv:2501.09223",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Foundations of Large Language Models",
    "URL": "http://arxiv.org/abs/2501.09223",
    "author": [
      {
        "family": "Xiao",
        "given": "Tong"
      },
      {
        "family": "Zhu",
        "given": "Jingbo"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 13]]
    },
    "issued": {
      "date-parts": [["2025", 1, 16]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/8BSFD4R2",
    "type": "article",
    "abstract": "Large language models (LLMs) have demonstrated solid zero-shot reasoning capabilities, which is reflected in their performance on the current test tasks. This calls for a more challenging benchmark requiring highly advanced reasoning ability to be solved. In this paper, we introduce such a benchmark, consisting of 191 long-form (1200 words on average) mystery narratives constructed as detective puzzles. Puzzles are sourced from the \"5 Minute Mystery\" platform and include a multiple-choice question for evaluation. Only 47% of humans solve a puzzle successfully on average, while the best human solvers achieve over 80% success rate. We show that GPT-3 models barely outperform random on this benchmark (with 28% accuracy) while state-of-the-art GPT-4 solves only 38% of puzzles. This indicates that there is still a significant gap in the deep reasoning abilities of LLMs and humans and highlights the need for further research in this area. Our work introduces a challenging benchmark for future studies on reasoning in language models and contributes to a better understanding of the limits of LLMs' abilities.",
    "DOI": "10.48550/arXiv.2212.10114",
    "note": "arXiv:2212.10114 [cs]",
    "number": "arXiv:2212.10114",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "True Detective: A Deep Abductive Reasoning Benchmark Undoable for GPT-3 and Challenging for GPT-4",
    "title-short": "True Detective",
    "URL": "http://arxiv.org/abs/2212.10114",
    "author": [
      {
        "family": "Del",
        "given": "Maksym"
      },
      {
        "family": "Fishel",
        "given": "Mark"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 14]]
    },
    "issued": {
      "date-parts": [["2023", 6, 1]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/4PWA5P6F",
    "type": "article",
    "abstract": "We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are \"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.",
    "DOI": "10.48550/arXiv.2311.12022",
    "language": "en-US",
    "note": "arXiv:2311.12022 [cs]",
    "number": "arXiv:2311.12022",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
    "title-short": "GPQA",
    "URL": "http://arxiv.org/abs/2311.12022",
    "author": [
      {
        "family": "Rein",
        "given": "David"
      },
      {
        "family": "Hou",
        "given": "Betty Li"
      },
      {
        "family": "Stickland",
        "given": "Asa Cooper"
      },
      {
        "family": "Petty",
        "given": "Jackson"
      },
      {
        "family": "Pang",
        "given": "Richard Yuanzhe"
      },
      {
        "family": "Dirani",
        "given": "Julien"
      },
      {
        "family": "Michael",
        "given": "Julian"
      },
      {
        "family": "Bowman",
        "given": "Samuel R."
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 16]]
    },
    "issued": {
      "date-parts": [["2023", 11, 20]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/5BD2LWCI",
    "type": "article",
    "abstract": "Large language models (LLMs) have demonstrated remarkable proficiency in mainstream academic disciplines such as mathematics, physics, and computer science. However, human knowledge encompasses over 200 specialized disciplines, far exceeding the scope of existing benchmarks. The capabilities of LLMs in many of these specialized fields-particularly in light industry, agriculture, and service-oriented disciplines-remain inadequately evaluated. To address this gap, we present SuperGPQA, a comprehensive benchmark that evaluates graduate-level knowledge and reasoning capabilities across 285 disciplines. Our benchmark employs a novel Human-LLM collaborative filtering mechanism to eliminate trivial or ambiguous questions through iterative refinement based on both LLM responses and expert feedback. Our experimental results reveal significant room for improvement in the performance of current state-of-the-art LLMs across diverse knowledge domains (e.g., the reasoning-focused model DeepSeek-R1 achieved the highest accuracy of 61.82% on SuperGPQA), highlighting the considerable gap between current model capabilities and artificial general intelligence. Additionally, we present comprehensive insights from our management of a large-scale annotation process, involving over 80 expert annotators and an interactive Human-LLM collaborative system, offering valuable methodological guidance for future research initiatives of comparable scope.",
    "DOI": "10.48550/arXiv.2502.14739",
    "note": "arXiv:2502.14739 [cs]",
    "number": "arXiv:2502.14739",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "SuperGPQA: Scaling LLM Evaluation across 285 Graduate Disciplines",
    "title-short": "SuperGPQA",
    "URL": "http://arxiv.org/abs/2502.14739",
    "author": [
      {
        "family": "Team",
        "given": "M.-A.-P."
      },
      {
        "family": "Du",
        "given": "Xinrun"
      },
      {
        "family": "Yao",
        "given": "Yifan"
      },
      {
        "family": "Ma",
        "given": "Kaijing"
      },
      {
        "family": "Wang",
        "given": "Bingli"
      },
      {
        "family": "Zheng",
        "given": "Tianyu"
      },
      {
        "family": "Zhu",
        "given": "Kang"
      },
      {
        "family": "Liu",
        "given": "Minghao"
      },
      {
        "family": "Liang",
        "given": "Yiming"
      },
      {
        "family": "Jin",
        "given": "Xiaolong"
      },
      {
        "family": "Wei",
        "given": "Zhenlin"
      },
      {
        "family": "Zheng",
        "given": "Chujie"
      },
      {
        "family": "Deng",
        "given": "Kaixin"
      },
      {
        "family": "Jia",
        "given": "Shian"
      },
      {
        "family": "Jiang",
        "given": "Sichao"
      },
      {
        "family": "Liao",
        "given": "Yiyan"
      },
      {
        "family": "Li",
        "given": "Rui"
      },
      {
        "family": "Li",
        "given": "Qinrui"
      },
      {
        "family": "Li",
        "given": "Sirun"
      },
      {
        "family": "Li",
        "given": "Yizhi"
      },
      {
        "family": "Li",
        "given": "Yunwen"
      },
      {
        "family": "Ma",
        "given": "Dehua"
      },
      {
        "family": "Ni",
        "given": "Yuansheng"
      },
      {
        "family": "Que",
        "given": "Haoran"
      },
      {
        "family": "Wang",
        "given": "Qiyao"
      },
      {
        "family": "Wen",
        "given": "Zhoufutu"
      },
      {
        "family": "Wu",
        "given": "Siwei"
      },
      {
        "family": "Xing",
        "given": "Tianshun"
      },
      {
        "family": "Xu",
        "given": "Ming"
      },
      {
        "family": "Yang",
        "given": "Zhenzhu"
      },
      {
        "family": "Wang",
        "given": "Zekun Moore"
      },
      {
        "family": "Zhou",
        "given": "Junting"
      },
      {
        "family": "Bai",
        "given": "Yuelin"
      },
      {
        "family": "Bu",
        "given": "Xingyuan"
      },
      {
        "family": "Cai",
        "given": "Chenglin"
      },
      {
        "family": "Chen",
        "given": "Liang"
      },
      {
        "family": "Chen",
        "given": "Yifan"
      },
      {
        "family": "Cheng",
        "given": "Chengtuo"
      },
      {
        "family": "Cheng",
        "given": "Tianhao"
      },
      {
        "family": "Ding",
        "given": "Keyi"
      },
      {
        "family": "Huang",
        "given": "Siming"
      },
      {
        "family": "Huang",
        "given": "Yun"
      },
      {
        "family": "Li",
        "given": "Yaoru"
      },
      {
        "family": "Li",
        "given": "Yizhe"
      },
      {
        "family": "Li",
        "given": "Zhaoqun"
      },
      {
        "family": "Liang",
        "given": "Tianhao"
      },
      {
        "family": "Lin",
        "given": "Chengdong"
      },
      {
        "family": "Lin",
        "given": "Hongquan"
      },
      {
        "family": "Ma",
        "given": "Yinghao"
      },
      {
        "family": "Pang",
        "given": "Tianyang"
      },
      {
        "family": "Peng",
        "given": "Zhongyuan"
      },
      {
        "family": "Peng",
        "given": "Zifan"
      },
      {
        "family": "Qi",
        "given": "Qige"
      },
      {
        "family": "Qiu",
        "given": "Shi"
      },
      {
        "family": "Qu",
        "given": "Xingwei"
      },
      {
        "family": "Quan",
        "given": "Shanghaoran"
      },
      {
        "family": "Tan",
        "given": "Yizhou"
      },
      {
        "family": "Wang",
        "given": "Zili"
      },
      {
        "family": "Wang",
        "given": "Chenqing"
      },
      {
        "family": "Wang",
        "given": "Hao"
      },
      {
        "family": "Wang",
        "given": "Yiya"
      },
      {
        "family": "Wang",
        "given": "Yubo"
      },
      {
        "family": "Xu",
        "given": "Jiajun"
      },
      {
        "family": "Yang",
        "given": "Kexin"
      },
      {
        "family": "Yuan",
        "given": "Ruibin"
      },
      {
        "family": "Yue",
        "given": "Yuanhao"
      },
      {
        "family": "Zhan",
        "given": "Tianyang"
      },
      {
        "family": "Zhang",
        "given": "Chun"
      },
      {
        "family": "Zhang",
        "given": "Jinyang"
      },
      {
        "family": "Zhang",
        "given": "Xiyue"
      },
      {
        "family": "Zhang",
        "given": "Xingjian"
      },
      {
        "family": "Zhang",
        "given": "Yue"
      },
      {
        "family": "Zhao",
        "given": "Yongchi"
      },
      {
        "family": "Zheng",
        "given": "Xiangyu"
      },
      {
        "family": "Zhong",
        "given": "Chenghua"
      },
      {
        "family": "Gao",
        "given": "Yang"
      },
      {
        "family": "Li",
        "given": "Zhoujun"
      },
      {
        "family": "Liu",
        "given": "Dayiheng"
      },
      {
        "family": "Liu",
        "given": "Qian"
      },
      {
        "family": "Liu",
        "given": "Tianyu"
      },
      {
        "family": "Ni",
        "given": "Shiwen"
      },
      {
        "family": "Peng",
        "given": "Junran"
      },
      {
        "family": "Qin",
        "given": "Yujia"
      },
      {
        "family": "Su",
        "given": "Wenbo"
      },
      {
        "family": "Wang",
        "given": "Guoyin"
      },
      {
        "family": "Wang",
        "given": "Shi"
      },
      {
        "family": "Yang",
        "given": "Jian"
      },
      {
        "family": "Yang",
        "given": "Min"
      },
      {
        "family": "Cao",
        "given": "Meng"
      },
      {
        "family": "Yue",
        "given": "Xiang"
      },
      {
        "family": "Zhang",
        "given": "Zhaoxiang"
      },
      {
        "family": "Zhou",
        "given": "Wangchunshu"
      },
      {
        "family": "Liu",
        "given": "Jiaheng"
      },
      {
        "family": "Lin",
        "given": "Qunshu"
      },
      {
        "family": "Huang",
        "given": "Wenhao"
      },
      {
        "family": "Zhang",
        "given": "Ge"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 16]]
    },
    "issued": {
      "date-parts": [["2025", 3, 5]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/DFUHJPUE",
    "type": "article",
    "abstract": "Various benchmarks have been proposed to assess the performance of large language models (LLMs) in different coding scenarios. We refer to them as code-related benchmarks. However, there are no systematic guidelines by which such a benchmark should be developed to ensure its quality, reliability, and reproducibility. We propose How2Bench, which is comprised of a 55-criteria checklist as a set of guidelines to govern the development of code-related benchmarks comprehensively. Using HOW2BENCH, we profiled 274 benchmarks released within the past decade and found concerning issues. Nearly 70% of the benchmarks did not take measures for data quality assurance; over 10% did not even open source or only partially open source. Many highly cited benchmarks have loopholes, including duplicated samples, incorrect reference codes/tests/prompts, and unremoved sensitive/confidential information. Finally, we conducted a human study involving 49 participants, which revealed significant gaps in awareness of the importance of data quality, reproducibility, and transparency.",
    "DOI": "10.48550/arXiv.2501.10711",
    "note": "arXiv:2501.10711 [cs]",
    "number": "arXiv:2501.10711",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "How Should We Build A Benchmark? Revisiting 274 Code-Related Benchmarks For LLMs",
    "title-short": "How Should We Build A Benchmark?",
    "URL": "http://arxiv.org/abs/2501.10711",
    "author": [
      {
        "family": "Cao",
        "given": "Jialun"
      },
      {
        "family": "Chan",
        "given": "Yuk-Kit"
      },
      {
        "family": "Ling",
        "given": "Zixuan"
      },
      {
        "family": "Wang",
        "given": "Wenxuan"
      },
      {
        "family": "Li",
        "given": "Shuqing"
      },
      {
        "family": "Liu",
        "given": "Mingwei"
      },
      {
        "family": "Qiao",
        "given": "Ruixi"
      },
      {
        "family": "Han",
        "given": "Yuting"
      },
      {
        "family": "Wang",
        "given": "Chaozheng"
      },
      {
        "family": "Yu",
        "given": "Boxi"
      },
      {
        "family": "He",
        "given": "Pinjia"
      },
      {
        "family": "Wang",
        "given": "Shuai"
      },
      {
        "family": "Zheng",
        "given": "Zibin"
      },
      {
        "family": "Lyu",
        "given": "Michael R."
      },
      {
        "family": "Cheung",
        "given": "Shing-Chi"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 17]]
    },
    "issued": {
      "date-parts": [["2025", 2, 17]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/38SQAS23",
    "type": "article",
    "abstract": "Visual reasoning is central to human cognition, enabling individuals to interpret and abstractly understand their environment. Although recent Multimodal Large Language Models (MLLMs) have demonstrated impressive performance across language and vision-language tasks, existing benchmarks primarily measure recognition-based skills and inadequately assess true visual reasoning capabilities. To bridge this critical gap, we introduce VERIFY, a benchmark explicitly designed to isolate and rigorously evaluate the visual reasoning capabilities of state-of-the-art MLLMs. VERIFY compels models to reason primarily from visual information, providing minimal textual context to reduce reliance on domain-specific knowledge and linguistic biases. Each problem is accompanied by a human-annotated reasoning path, making it the first to provide in-depth evaluation of model decision-making processes. Additionally, we propose novel metrics that assess visual reasoning fidelity beyond mere accuracy, highlighting critical imbalances in current model reasoning patterns. Our comprehensive benchmarking of leading MLLMs uncovers significant limitations, underscoring the need for a balanced and holistic approach to both perception and reasoning. For more teaser and testing, visit our project page (https://verify-eqh.pages.dev/).",
    "DOI": "10.48550/arXiv.2503.11557",
    "note": "arXiv:2503.11557 [cs]\nversion: 1",
    "number": "arXiv:2503.11557",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "VERIFY: A Benchmark of Visual Explanation and Reasoning for Investigating Multimodal Reasoning Fidelity",
    "title-short": "VERIFY",
    "URL": "http://arxiv.org/abs/2503.11557",
    "author": [
      {
        "family": "Bi",
        "given": "Jing"
      },
      {
        "family": "Guo",
        "given": "Junjia"
      },
      {
        "family": "Liang",
        "given": "Susan"
      },
      {
        "family": "Sun",
        "given": "Guangyu"
      },
      {
        "family": "Song",
        "given": "Luchuan"
      },
      {
        "family": "Tang",
        "given": "Yunlong"
      },
      {
        "family": "He",
        "given": "Jinxi"
      },
      {
        "family": "Wu",
        "given": "Jiarui"
      },
      {
        "family": "Vosoughi",
        "given": "Ali"
      },
      {
        "family": "Chen",
        "given": "Chen"
      },
      {
        "family": "Xu",
        "given": "Chenliang"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 21]]
    },
    "issued": {
      "date-parts": [["2025", 3, 14]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/XS5QPWVY",
    "type": "article",
    "abstract": "Reasoning and strategic behavior in social interactions is a hallmark of intelligence. This form of reasoning is significantly more sophisticated than isolated planning or reasoning tasks in static settings (e.g., math problem solving). In this paper, we present Strategic Planning, Interaction, and Negotiation (SPIN-Bench), a new multi-domain evaluation designed to measure the intelligence of strategic planning and social reasoning. While many existing benchmarks focus on narrow planning or single-agent reasoning, SPIN-Bench combines classical PDDL tasks, competitive board games, cooperative card games, and multi-agent negotiation scenarios in one unified framework. The framework includes both a benchmark as well as an arena to simulate and evaluate the variety of social settings to test reasoning and strategic behavior of AI agents. We formulate the benchmark SPIN-Bench by systematically varying action spaces, state complexity, and the number of interacting agents to simulate a variety of social settings where success depends on not only methodical and step-wise decision making, but also conceptual inference of other (adversarial or cooperative) participants. Our experiments reveal that while contemporary LLMs handle basic fact retrieval and short-range planning reasonably well, they encounter significant performance bottlenecks in tasks requiring deep multi-hop reasoning over large state spaces and socially adept coordination under uncertainty. We envision SPIN-Bench as a catalyst for future research on robust multi-agent planning, social reasoning, and human--AI teaming. Project Website: https://spinbench.github.io/",
    "DOI": "10.48550/arXiv.2503.12349",
    "note": "arXiv:2503.12349 [cs]",
    "number": "arXiv:2503.12349",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "SPIN-Bench: How Well Do LLMs Plan Strategically and Reason Socially?",
    "title-short": "SPIN-Bench",
    "URL": "http://arxiv.org/abs/2503.12349",
    "author": [
      {
        "family": "Yao",
        "given": "Jianzhu"
      },
      {
        "family": "Wang",
        "given": "Kevin"
      },
      {
        "family": "Hsieh",
        "given": "Ryan"
      },
      {
        "family": "Zhou",
        "given": "Haisu"
      },
      {
        "family": "Zou",
        "given": "Tianqing"
      },
      {
        "family": "Cheng",
        "given": "Zerui"
      },
      {
        "family": "Wang",
        "given": "Zhangyang"
      },
      {
        "family": "Viswanath",
        "given": "Pramod"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 25]]
    },
    "issued": {
      "date-parts": [["2025", 3, 18]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/XHZ2NCP3",
    "type": "article",
    "abstract": "Multi-step spatial reasoning entails understanding and reasoning about spatial relationships across multiple sequential steps, which is crucial for tackling complex real-world applications, such as robotic manipulation, autonomous navigation, and automated assembly. To assess how well current Multimodal Large Language Models (MLLMs) have acquired this fundamental capability, we introduce \\textbf{LEGO-Puzzles}, a scalable benchmark designed to evaluate both \\textbf{spatial understanding} and \\textbf{sequential reasoning} in MLLMs through LEGO-based tasks. LEGO-Puzzles consists of 1,100 carefully curated visual question-answering (VQA) samples spanning 11 distinct tasks, ranging from basic spatial understanding to complex multi-step reasoning. Based on LEGO-Puzzles, we conduct a comprehensive evaluation of state-of-the-art MLLMs and uncover significant limitations in their spatial reasoning capabilities: even the most powerful MLLMs can answer only about half of the test cases, whereas human participants achieve over 90\\% accuracy. In addition to VQA tasks, we evaluate MLLMs' abilities to generate LEGO images following assembly illustrations. Our experiments show that only Gemini-2.0-Flash and GPT-4o exhibit a limited ability to follow these instructions, while other MLLMs either replicate the input image or generate completely irrelevant outputs. Overall, LEGO-Puzzles exposes critical deficiencies in existing MLLMs' spatial understanding and sequential reasoning capabilities, and underscores the need for further advancements in multimodal spatial reasoning.",
    "DOI": "10.48550/arXiv.2503.19990",
    "note": "arXiv:2503.19990 [cs]",
    "number": "arXiv:2503.19990",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "LEGO-Puzzles: How Good Are MLLMs at Multi-Step Spatial Reasoning?",
    "title-short": "LEGO-Puzzles",
    "URL": "http://arxiv.org/abs/2503.19990",
    "author": [
      {
        "family": "Tang",
        "given": "Kexian"
      },
      {
        "family": "Gao",
        "given": "Junyao"
      },
      {
        "family": "Zeng",
        "given": "Yanhong"
      },
      {
        "family": "Duan",
        "given": "Haodong"
      },
      {
        "family": "Sun",
        "given": "Yanan"
      },
      {
        "family": "Xing",
        "given": "Zhening"
      },
      {
        "family": "Liu",
        "given": "Wenran"
      },
      {
        "family": "Lyu",
        "given": "Kaifeng"
      },
      {
        "family": "Chen",
        "given": "Kai"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 28]]
    },
    "issued": {
      "date-parts": [["2025", 3, 25]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/I2NNWMJN",
    "type": "article",
    "abstract": "Supervised fine-tuning (SFT) and reinforcement learning (RL) are widely used post-training techniques for foundation models. However, their roles in enhancing model generalization capabilities remain unclear. This paper studies the difference between SFT and RL on generalization and memorization, focusing on text-based rule variants and visual variants. We introduce GeneralPoints, an arithmetic reasoning card game, and adopt V-IRL, a real-world navigation environment, to assess how models trained with SFT and RL generalize to unseen variants in both textual and visual domains. We show that RL, especially when trained with an outcome-based reward, generalizes across both rule-based textual and visual variants. SFT, in contrast, tends to memorize training data and struggles to generalize out-of-distribution scenarios. Further analysis reveals that RL improves the model's underlying visual recognition capabilities, contributing to its enhanced generalization in the visual domain. Despite RL's superior generalization, we show that SFT remains essential for effective RL training; SFT stabilizes the model's output format, enabling subsequent RL to achieve its performance gains. These findings demonstrates the capability of RL for acquiring generalizable knowledge in complex, multi-modal tasks.",
    "DOI": "10.48550/arXiv.2501.17161",
    "note": "arXiv:2501.17161 [cs]",
    "number": "arXiv:2501.17161",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training",
    "title-short": "SFT Memorizes, RL Generalizes",
    "URL": "http://arxiv.org/abs/2501.17161",
    "author": [
      {
        "family": "Chu",
        "given": "Tianzhe"
      },
      {
        "family": "Zhai",
        "given": "Yuexiang"
      },
      {
        "family": "Yang",
        "given": "Jihan"
      },
      {
        "family": "Tong",
        "given": "Shengbang"
      },
      {
        "family": "Xie",
        "given": "Saining"
      },
      {
        "family": "Schuurmans",
        "given": "Dale"
      },
      {
        "family": "Le",
        "given": "Quoc V."
      },
      {
        "family": "Levine",
        "given": "Sergey"
      },
      {
        "family": "Ma",
        "given": "Yi"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 31]]
    },
    "issued": {
      "date-parts": [["2025", 1, 28]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/TY4YLLEY",
    "type": "article",
    "abstract": "Automated alignment develops alignment systems with minimal human intervention. The key to automated alignment lies in providing learnable and accurate preference signals for preference learning without human annotation. In this paper, we introduce Self-Steering Optimization ($SSO$), an algorithm that autonomously generates high-quality preference signals based on predefined principles during iterative training, eliminating the need for manual annotation. $SSO$ maintains the accuracy of signals by ensuring a consistent gap between chosen and rejected responses while keeping them both on-policy to suit the current policy model's learning capacity. $SSO$ can benefit the online and offline training of the policy model, as well as enhance the training of reward models. We validate the effectiveness of $SSO$ with two foundation models, Qwen2 and Llama3.1, indicating that it provides accurate, on-policy preference signals throughout iterative training. Without any manual annotation or external models, $SSO$ leads to significant performance improvements across six subjective or objective benchmarks. Besides, the preference data generated by $SSO$ significantly enhanced the performance of the reward model on Rewardbench. Our work presents a scalable approach to preference optimization, paving the way for more efficient and effective automated alignment.",
    "DOI": "10.48550/arXiv.2410.17131",
    "note": "arXiv:2410.17131 [cs]",
    "number": "arXiv:2410.17131",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Aligning Large Language Models via Self-Steering Optimization",
    "URL": "http://arxiv.org/abs/2410.17131",
    "author": [
      {
        "family": "Xiang",
        "given": "Hao"
      },
      {
        "family": "Yu",
        "given": "Bowen"
      },
      {
        "family": "Lin",
        "given": "Hongyu"
      },
      {
        "family": "Lu",
        "given": "Keming"
      },
      {
        "family": "Lu",
        "given": "Yaojie"
      },
      {
        "family": "Han",
        "given": "Xianpei"
      },
      {
        "family": "Sun",
        "given": "Le"
      },
      {
        "family": "Zhou",
        "given": "Jingren"
      },
      {
        "family": "Lin",
        "given": "Junyang"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 31]]
    },
    "issued": {
      "date-parts": [["2024", 10, 22]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/F63RYC22",
    "type": "article",
    "abstract": "Harnessing the power of human-annotated data through Supervised Fine-Tuning (SFT) is pivotal for advancing Large Language Models (LLMs). In this paper, we delve into the prospect of growing a strong LLM out of a weak one without the need for acquiring additional human-annotated data. We propose a new fine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a supervised fine-tuned model. At the heart of SPIN lies a self-play mechanism, where the LLM refines its capability by playing against instances of itself. More specifically, the LLM generates its own training data from its previous iterations, refining its policy by discerning these self-generated responses from those obtained from human-annotated data. Our method progressively elevates the LLM from a nascent model to a formidable one, unlocking the full potential of human-annotated demonstration data for SFT. Theoretically, we prove that the global optimum to the training objective function of our method is achieved only when the LLM policy aligns with the target data distribution. Empirically, we evaluate our method on several benchmark datasets including the HuggingFace Open LLM Leaderboard, MT-Bench, and datasets from Big-Bench. Our results show that SPIN can significantly improve the LLM's performance across a variety of benchmarks and even outperform models trained through direct preference optimization (DPO) supplemented with extra GPT-4 preference data. This sheds light on the promise of self-play, enabling the achievement of human-level performance in LLMs without the need for expert opponents. Codes are available at https://github.com/uclaml/SPIN.",
    "DOI": "10.48550/arXiv.2401.01335",
    "note": "arXiv:2401.01335 [cs]",
    "number": "arXiv:2401.01335",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models",
    "URL": "http://arxiv.org/abs/2401.01335",
    "author": [
      {
        "family": "Chen",
        "given": "Zixiang"
      },
      {
        "family": "Deng",
        "given": "Yihe"
      },
      {
        "family": "Yuan",
        "given": "Huizhuo"
      },
      {
        "family": "Ji",
        "given": "Kaixuan"
      },
      {
        "family": "Gu",
        "given": "Quanquan"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 31]]
    },
    "issued": {
      "date-parts": [["2024", 6, 14]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/SXB9Q67G",
    "type": "article",
    "abstract": "Large Language Models (LLMs) are rapidly surpassing human knowledge in many domains. While improving these models traditionally relies on costly human data, recent self-rewarding mechanisms (Yuan et al., 2024) have shown that LLMs can improve by judging their own responses instead of relying on human labelers. However, existing methods have primarily focused on improving model responses rather than judgment capabilities, resulting in rapid saturation during iterative training. To address this issue, we introduce a novel Meta-Rewarding step to the self-improvement process, where the model judges its own judgements and uses that feedback to refine its judgment skills. Surprisingly, this unsupervised approach improves the model's ability to judge {\\em and} follow instructions, as demonstrated by a win rate improvement of Llama-3-8B-Instruct from 22.9% to 39.4% on AlpacaEval 2, and 20.6% to 29.1% on Arena-Hard. These results strongly suggest the potential for self-improving models without human supervision.",
    "DOI": "10.48550/arXiv.2407.19594",
    "note": "arXiv:2407.19594 [cs]",
    "number": "arXiv:2407.19594",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge",
    "title-short": "Meta-Rewarding Language Models",
    "URL": "http://arxiv.org/abs/2407.19594",
    "author": [
      {
        "family": "Wu",
        "given": "Tianhao"
      },
      {
        "family": "Yuan",
        "given": "Weizhe"
      },
      {
        "family": "Golovneva",
        "given": "Olga"
      },
      {
        "family": "Xu",
        "given": "Jing"
      },
      {
        "family": "Tian",
        "given": "Yuandong"
      },
      {
        "family": "Jiao",
        "given": "Jiantao"
      },
      {
        "family": "Weston",
        "given": "Jason"
      },
      {
        "family": "Sukhbaatar",
        "given": "Sainbayar"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 31]]
    },
    "issued": {
      "date-parts": [["2024", 7, 30]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/KEYHP5A5",
    "type": "article",
    "abstract": "Large language models (LLMs) hold the promise of solving diverse tasks when provided with appropriate natural language prompts. However, prompting often leads models to make predictions with lower accuracy compared to finetuning a model with ample training data. On the other hand, while finetuning LLMs on task-specific data generally improves their performance, abundant annotated datasets are not available for all tasks. Previous work has explored generating task-specific data from state-of-the-art LLMs and using this data to finetune smaller models, but this approach requires access to a language model other than the one being trained, which introduces cost, scalability challenges, and legal hurdles associated with continuously relying on more powerful LLMs. In response to these, we propose SELF-GUIDE, a multi-stage mechanism in which we synthesize task-specific input-output pairs from the student LLM, then use these input-output pairs to finetune the student LLM itself. In our empirical evaluation of the Natural Instructions V2 benchmark, we find that SELF-GUIDE improves the performance of LLM by a substantial margin. Specifically, we report an absolute improvement of approximately 15% for classification tasks and 18% for generation tasks in the benchmark's metrics. This sheds light on the promise of self-synthesized data guiding LLMs towards becoming task-specific experts without any external learning signals.",
    "DOI": "10.48550/arXiv.2407.12874",
    "note": "arXiv:2407.12874 [cs]",
    "number": "arXiv:2407.12874",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "SELF-GUIDE: Better Task-Specific Instruction Following via Self-Synthetic Finetuning",
    "title-short": "SELF-GUIDE",
    "URL": "http://arxiv.org/abs/2407.12874",
    "author": [
      {
        "family": "Zhao",
        "given": "Chenyang"
      },
      {
        "family": "Jia",
        "given": "Xueying"
      },
      {
        "family": "Viswanathan",
        "given": "Vijay"
      },
      {
        "family": "Wu",
        "given": "Tongshuang"
      },
      {
        "family": "Neubig",
        "given": "Graham"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 3, 31]]
    },
    "issued": {
      "date-parts": [["2024", 8, 12]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/VFLU9HYB",
    "type": "paper-conference",
    "abstract": "Pretrained large language models (LLMs) are currently state-of-the-art for solving the vast majority of natural language processing tasks. While many real-world applications still require fine-tuning to reach satisfactory levels of performance, many of them are in the low-data regime, making fine-tuning challenging. To address this, we propose LLM2LLM, a targeted and iterative data augmentation strategy that uses a teacher LLM to enhance a small seed dataset by augmenting additional data that can be used for fine-tuning on a specific task. LLM2LLM (1) fine-tunes a baseline student LLM on the initial seed data, (2) evaluates and extracts data points that the model gets wrong, and (3) uses a teacher LLM to generate synthetic data based on these incorrect data points, which are then added back into the training data. This approach amplifies the signal from incorrectly predicted data points by the LLM during training and reintegrates them into the dataset to focus on more challenging examples for the LLM. Our results show that LLM2LLM significantly enhances the performance of LLMs in the low-data regime, outperforming both traditional fine-tuning and other data augmentation baselines. LLM2LLM reduces the dependence on labor-intensive data curation and paves the way for more scalable and performant LLM solutions, allowing us to tackle data-constrained domains and tasks. We achieve improvements up to 24.2% on the GSM8K dataset, 32.6% on CaseHOLD, 32.0% on SNIPS, 52.6% on TREC and 39.8% on SST-2 over regular fine-tuning in the low-data regime using a Llama-2-7B student model. Our code is available at https://github.com/SqueezeAILab/LLM2LLM.",
    "container-title": "Findings of the Association for Computational Linguistics: ACL 2024",
    "DOI": "10.18653/v1/2024.findings-acl.388",
    "event-place": "Bangkok, Thailand",
    "event-title": "Findings 2024",
    "page": "6498–6526",
    "publisher": "Association for Computational Linguistics",
    "publisher-place": "Bangkok, Thailand",
    "source": "ACLWeb",
    "title": "LLM2LLM: Boosting LLMs with Novel Iterative Data Enhancement",
    "title-short": "LLM2LLM",
    "URL": "https://aclanthology.org/2024.findings-acl.388/",
    "author": [
      {
        "family": "Lee",
        "given": "Nicholas"
      },
      {
        "family": "Wattanawong",
        "given": "Thanakul"
      },
      {
        "family": "Kim",
        "given": "Sehoon"
      },
      {
        "family": "Mangalam",
        "given": "Karttikeya"
      },
      {
        "family": "Shen",
        "given": "Sheng"
      },
      {
        "family": "Anumanchipalli",
        "given": "Gopala"
      },
      {
        "family": "Mahoney",
        "given": "Michael"
      },
      {
        "family": "Keutzer",
        "given": "Kurt"
      },
      {
        "family": "Gholami",
        "given": "Amir"
      }
    ],
    "editor": [
      {
        "family": "Ku",
        "given": "Lun-Wei"
      },
      {
        "family": "Martins",
        "given": "Andre"
      },
      {
        "family": "Srikumar",
        "given": "Vivek"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 4, 2]]
    },
    "issued": {
      "date-parts": [["2024", 8]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/PFATWU74",
    "type": "paper-conference",
    "abstract": "How well can NLP models generalize to a variety of unseen tasks when provided with task instructions? To address this question, we first introduce Super-NaturalInstructions, a benchmark of 1,616 diverse NLP tasks and their expert-written instructions. Our collection covers 76 distinct task types, including but not limited to classification, extraction, infilling, sequence tagging, text rewriting, and text composition. This large and diverse collection of tasks enables rigorous benchmarking of cross-task generalization under instructions—training models to follow instructions on a subset of tasks and evaluating them on the remaining unseen ones.Furthermore, we build Tk-Instruct, a transformer model trained to follow a variety of in-context instructions (plain language task definitions or k-shot examples). Our experiments show that Tk-Instruct outperforms existing instruction-following models such as InstructGPT by over 9% on our benchmark despite being an order of magnitude smaller. We further analyze generalization as a function of various scaling parameters, such as the number of observed tasks, the number of instances per task, and model sizes. We hope our dataset and model facilitate future progress towards more general-purpose NLP models.",
    "container-title": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    "DOI": "10.18653/v1/2022.emnlp-main.340",
    "event-place": "Abu Dhabi, United Arab Emirates",
    "event-title": "EMNLP 2022",
    "page": "5085–5109",
    "publisher": "Association for Computational Linguistics",
    "publisher-place": "Abu Dhabi, United Arab Emirates",
    "source": "ACLWeb",
    "title": "Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks",
    "title-short": "Super-NaturalInstructions",
    "URL": "https://aclanthology.org/2022.emnlp-main.340/",
    "author": [
      {
        "family": "Wang",
        "given": "Yizhong"
      },
      {
        "family": "Mishra",
        "given": "Swaroop"
      },
      {
        "family": "Alipoormolabashi",
        "given": "Pegah"
      },
      {
        "family": "Kordi",
        "given": "Yeganeh"
      },
      {
        "family": "Mirzaei",
        "given": "Amirreza"
      },
      {
        "family": "Naik",
        "given": "Atharva"
      },
      {
        "family": "Ashok",
        "given": "Arjun"
      },
      {
        "family": "Dhanasekaran",
        "given": "Arut Selvan"
      },
      {
        "family": "Arunkumar",
        "given": "Anjana"
      },
      {
        "family": "Stap",
        "given": "David"
      },
      {
        "family": "Pathak",
        "given": "Eshaan"
      },
      {
        "family": "Karamanolakis",
        "given": "Giannis"
      },
      {
        "family": "Lai",
        "given": "Haizhi"
      },
      {
        "family": "Purohit",
        "given": "Ishan"
      },
      {
        "family": "Mondal",
        "given": "Ishani"
      },
      {
        "family": "Anderson",
        "given": "Jacob"
      },
      {
        "family": "Kuznia",
        "given": "Kirby"
      },
      {
        "family": "Doshi",
        "given": "Krima"
      },
      {
        "family": "Pal",
        "given": "Kuntal Kumar"
      },
      {
        "family": "Patel",
        "given": "Maitreya"
      },
      {
        "family": "Moradshahi",
        "given": "Mehrad"
      },
      {
        "family": "Parmar",
        "given": "Mihir"
      },
      {
        "family": "Purohit",
        "given": "Mirali"
      },
      {
        "family": "Varshney",
        "given": "Neeraj"
      },
      {
        "family": "Kaza",
        "given": "Phani Rohitha"
      },
      {
        "family": "Verma",
        "given": "Pulkit"
      },
      {
        "family": "Puri",
        "given": "Ravsehaj Singh"
      },
      {
        "family": "Karia",
        "given": "Rushang"
      },
      {
        "family": "Doshi",
        "given": "Savan"
      },
      {
        "family": "Sampat",
        "given": "Shailaja Keyur"
      },
      {
        "family": "Mishra",
        "given": "Siddhartha"
      },
      {
        "family": "Reddy A",
        "given": "Sujan"
      },
      {
        "family": "Patro",
        "given": "Sumanta"
      },
      {
        "family": "Dixit",
        "given": "Tanay"
      },
      {
        "family": "Shen",
        "given": "Xudong"
      }
    ],
    "editor": [
      {
        "family": "Goldberg",
        "given": "Yoav"
      },
      {
        "family": "Kozareva",
        "given": "Zornitsa"
      },
      {
        "family": "Zhang",
        "given": "Yue"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 4, 8]]
    },
    "issued": {
      "date-parts": [["2022", 12]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/24DBBASA",
    "type": "paper-conference",
    "abstract": "Training large language models (LLMs) with open-domain instruction data has yielded remarkable success in aligning to end tasks and human preferences. Extensive research has highlighted the importance of the quality and diversity of instruction data. However, the impact of data complexity, as a crucial metric, remains relatively unexplored from three aspects: (1)where the sustainability of performance improvements with increasing complexity is uncertain; (2)whether the improvement brought by complexity merely comes from introducing more training tokens; and (3)where the potential benefits of incorporating instructions from easy to difficult are not yet fully understood. In this paper, we propose Tree-Instruct to systematically enhance the instruction complexity in a controllable manner. By adding a specified number of nodes to instructions' semantic trees, this approach not only yields new instruction data from the modified tree but also allows us to control the difficulty level of modified instructions. Our preliminary experiments reveal the following insights: (1)Increasing complexity consistently leads to sustained performance improvements of LLMs. (2)Under the same token budget, a few complex instructions outperform diverse yet simple instructions. (3)Curriculum instruction tuning might not yield the anticipated results; focusing on increasing complexity appears to be the key.",
    "container-title": "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    "event-place": "Torino, Italia",
    "event-title": "LREC-COLING 2024",
    "page": "16776–16789",
    "publisher": "ELRA and ICCL",
    "publisher-place": "Torino, Italia",
    "source": "ACLWeb",
    "title": "Tree-Instruct: A Preliminary Study of the Intrinsic Relationship between Complexity and Alignment",
    "title-short": "Tree-Instruct",
    "URL": "https://aclanthology.org/2024.lrec-main.1460/",
    "author": [
      {
        "family": "Zhao",
        "given": "Yingxiu"
      },
      {
        "family": "Yu",
        "given": "Bowen"
      },
      {
        "family": "Hui",
        "given": "Binyuan"
      },
      {
        "family": "Yu",
        "given": "Haiyang"
      },
      {
        "family": "Li",
        "given": "Minghao"
      },
      {
        "family": "Huang",
        "given": "Fei"
      },
      {
        "family": "Zhang",
        "given": "Nevin L."
      },
      {
        "family": "Li",
        "given": "Yongbin"
      }
    ],
    "editor": [
      {
        "family": "Calzolari",
        "given": "Nicoletta"
      },
      {
        "family": "Kan",
        "given": "Min-Yen"
      },
      {
        "family": "Hoste",
        "given": "Veronique"
      },
      {
        "family": "Lenci",
        "given": "Alessandro"
      },
      {
        "family": "Sakti",
        "given": "Sakriani"
      },
      {
        "family": "Xue",
        "given": "Nianwen"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 4, 9]]
    },
    "issued": {
      "date-parts": [["2024", 5]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/FU487YWM",
    "type": "webpage",
    "abstract": "Current multimodal benchmarks often conflate reasoning with domain-specific knowledge, making it difficult to isolate and evaluate general reasoning abilities in non-expert settings. To address this, we introduce VisualPuzzles, a benchmark that targets visual reasoning while deliberately minimizing reliance on specialized knowledge. VisualPuzzles consists of diverse questions spanning five categories: algorithmic, analogical, deductive, inductive, and spatial reasoning. One major source of our questions is manually translated logical reasoning questions from the Chinese Civil Service Examination. Experiments show that VisualPuzzles requires significantly less intensive domain-specific knowledge and more complex reasoning compared to benchmarks like MMMU, enabling us to better evaluate genuine multimodal reasoning. Evaluations show that state-of-the-art multimodal large language models consistently lag behind human performance on VisualPuzzles, and that strong performance on knowledge-intensive benchmarks does not necessarily translate to success on reasoning-focused, knowledge-light tasks. Additionally, reasoning enhancements such as scaling up inference compute (with \"thinking\" modes) yield inconsistent gains across models and task types, and we observe no clear correlation between model size and performance. We also found that models exhibit different reasoning and answering patterns on VisualPuzzles compared to benchmarks with heavier emphasis on knowledge. VisualPuzzles offers a clearer lens through which to evaluate reasoning capabilities beyond factual recall and domain knowledge.",
    "container-title": "arXiv.org",
    "language": "en",
    "title": "VisualPuzzles: Decoupling Multimodal Reasoning Evaluation from Domain Knowledge",
    "title-short": "VisualPuzzles",
    "URL": "https://arxiv.org/abs/2504.10342v1",
    "author": [
      {
        "family": "Song",
        "given": "Yueqi"
      },
      {
        "family": "Ou",
        "given": "Tianyue"
      },
      {
        "family": "Kong",
        "given": "Yibo"
      },
      {
        "family": "Li",
        "given": "Zecheng"
      },
      {
        "family": "Neubig",
        "given": "Graham"
      },
      {
        "family": "Yue",
        "given": "Xiang"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 4, 15]]
    },
    "issued": {
      "date-parts": [["2025", 4, 14]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/U3ZIKJQ7",
    "type": "article-journal",
    "container-title": "Advances in Neural Information Processing Systems",
    "language": "en",
    "page": "15779-15800",
    "source": "proceedings.neurips.cc",
    "title": "Evaluating Large Vision-and-Language Models on Children's Mathematical Olympiads",
    "URL": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/1cc12fb3d4033ad72d33a51f1d0ab5d0-Abstract-Datasets_and_Benchmarks_Track.html",
    "volume": "37",
    "author": [
      {
        "family": "Cherian",
        "given": "Anoop"
      },
      {
        "family": "Peng",
        "given": "Kuan-Chuan"
      },
      {
        "family": "Lohit",
        "given": "Suhas"
      },
      {
        "family": "Matthiesen",
        "given": "Joanna"
      },
      {
        "family": "Smith",
        "given": "Kevin"
      },
      {
        "family": "Tenenbaum",
        "given": "Joshua B."
      }
    ],
    "accessed": {
      "date-parts": [["2025", 4, 17]]
    },
    "issued": {
      "date-parts": [["2024", 12, 16]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/UMNDPJB6",
    "type": "paper-conference",
    "abstract": "We present MEGA-Bench, an evaluation suite that scales multimodal evaluation to over 500 real-world tasks, to address the highly heterogeneous daily use cases of end users. Our objective is to optimize for a set of high-quality data samples that cover a highly diverse and rich set of multimodal tasks, while enabling cost-effective and accurate model evaluation. In particular, we collected 505 realistic tasks encompassing over 8,000 samples from 16 expert annotators to extensively cover the multimodal task space. Instead of unifying these problems into standard multi-choice questions (like MMMU, MM-Bench, and MMT-Bench), we embrace a wide range of output formats like numbers, phrases, code, \\LaTeX, coordinates, JSON, free-form, etc. To accommodate these formats, we developed over 40 metrics to evaluate these tasks. Unlike existing benchmarks, MEGA-Bench offers a fine-grained capability report across multiple dimensions (e.g., application, input type, output format, skill), allowing users to interact with and visualize model capabilities in depth. We evaluate a wide variety of frontier vision-language models on MEGA-Bench to understand their capabilities across these dimensions.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "MEGA-Bench: Scaling Multimodal Evaluation to over 500 Real-World Tasks",
    "title-short": "MEGA-Bench",
    "URL": "https://openreview.net/forum?id=2rWbKbmOuM",
    "author": [
      {
        "family": "Chen",
        "given": "Jiacheng"
      },
      {
        "family": "Liang",
        "given": "Tianhao"
      },
      {
        "family": "Siu",
        "given": "Sherman"
      },
      {
        "family": "Wang",
        "given": "Zhengqing"
      },
      {
        "family": "Wang",
        "given": "Kai"
      },
      {
        "family": "Wang",
        "given": "Yubo"
      },
      {
        "family": "Ni",
        "given": "Yuansheng"
      },
      {
        "family": "Jiang",
        "given": "Ziyan"
      },
      {
        "family": "Zhu",
        "given": "Wang"
      },
      {
        "family": "Lyu",
        "given": "Bohan"
      },
      {
        "family": "Jiang",
        "given": "Dongfu"
      },
      {
        "family": "He",
        "given": "Xuan"
      },
      {
        "family": "Liu",
        "given": "Yuan"
      },
      {
        "family": "Hu",
        "given": "Hexiang"
      },
      {
        "family": "Yue",
        "given": "Xiang"
      },
      {
        "family": "Chen",
        "given": "Wenhu"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 4, 18]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/2GNUEADT",
    "type": "article",
    "abstract": "Pre-training datasets are typically collected from web content and lack inherent domain divisions. For instance, widely used datasets like Common Crawl do not include explicit domain labels, while manually curating labeled datasets such as The Pile is labor-intensive. Consequently, identifying an optimal pre-training data mixture remains a challenging problem, despite its significant benefits for pre-training performance. To address these challenges, we propose CLustering-based Iterative Data Mixture Bootstrapping (CLIMB), an automated framework that discovers, evaluates, and refines data mixtures in a pre-training setting. Specifically, CLIMB embeds and clusters large-scale datasets in a semantic space and then iteratively searches for optimal mixtures using a smaller proxy model and a predictor. When continuously trained on 400B tokens with this mixture, our 1B model exceeds the state-of-the-art Llama-3.2-1B by 2.0%. Moreover, we observe that optimizing for a specific domain (e.g., Social Sciences) yields a 5% improvement over random sampling. Finally, we introduce ClimbLab, a filtered 1.2-trillion-token corpus with 20 clusters as a research playground, and ClimbMix, a compact yet powerful 400-billion-token dataset designed for efficient pre-training that delivers superior performance under an equal token budget. We analyze the final data mixture, elucidating the characteristics of an optimal data mixture. Our data is available at: https://research.nvidia.com/labs/lpr/climb/",
    "DOI": "10.48550/arXiv.2504.13161",
    "language": "en-US",
    "note": "arXiv:2504.13161 [cs]",
    "number": "arXiv:2504.13161",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "CLIMB: CLustering-based Iterative Data Mixture Bootstrapping for Language Model Pre-training",
    "title-short": "CLIMB",
    "URL": "http://arxiv.org/abs/2504.13161",
    "author": [
      {
        "family": "Diao",
        "given": "Shizhe"
      },
      {
        "family": "Yang",
        "given": "Yu"
      },
      {
        "family": "Fu",
        "given": "Yonggan"
      },
      {
        "family": "Dong",
        "given": "Xin"
      },
      {
        "family": "Su",
        "given": "Dan"
      },
      {
        "family": "Kliegl",
        "given": "Markus"
      },
      {
        "family": "Chen",
        "given": "Zijia"
      },
      {
        "family": "Belcak",
        "given": "Peter"
      },
      {
        "family": "Suhara",
        "given": "Yoshi"
      },
      {
        "family": "Yin",
        "given": "Hongxu"
      },
      {
        "family": "Patwary",
        "given": "Mostofa"
      },
      {
        "family": "Yingyan",
        "given": ""
      },
      {
        "family": "Lin",
        "given": ""
      },
      {
        "family": "Kautz",
        "given": "Jan"
      },
      {
        "family": "Molchanov",
        "given": "Pavlo"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 4, 21]]
    },
    "issued": {
      "date-parts": [["2025", 4, 17]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/K7MAD9NI",
    "type": "article",
    "abstract": "Large Language Models (LLMs) applied to code-related applications have emerged as a prominent field, attracting significant interest from both academia and industry. However, as new and improved LLMs are developed, existing evaluation benchmarks (e.g., HumanEval, MBPP) are no longer sufficient for assessing their capabilities. In this work, we propose LiveCodeBench, a comprehensive and contamination-free evaluation of LLMs for code, which continuously collects new problems over time from contests across three competition platforms, namely LeetCode, AtCoder, and CodeForces. Notably, our benchmark also focuses on a broader range of code related capabilities, such as self-repair, code execution, and test output prediction, beyond just code generation. Currently, LiveCodeBench hosts four hundred high-quality coding problems that were published between May 2023 and May 2024. We have evaluated 18 base LLMs and 34 instruction-tuned LLMs on LiveCodeBench. We present empirical findings on contamination, holistic performance comparisons, potential overfitting in existing benchmarks as well as individual model comparisons. We will release all prompts and model completions for further community analysis, along with a general toolkit for adding new scenarios and model",
    "DOI": "10.48550/arXiv.2403.07974",
    "note": "arXiv:2403.07974 [cs]",
    "number": "arXiv:2403.07974",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code",
    "title-short": "LiveCodeBench",
    "URL": "http://arxiv.org/abs/2403.07974",
    "author": [
      {
        "family": "Jain",
        "given": "Naman"
      },
      {
        "family": "Han",
        "given": "King"
      },
      {
        "family": "Gu",
        "given": "Alex"
      },
      {
        "family": "Li",
        "given": "Wen-Ding"
      },
      {
        "family": "Yan",
        "given": "Fanjia"
      },
      {
        "family": "Zhang",
        "given": "Tianjun"
      },
      {
        "family": "Wang",
        "given": "Sida"
      },
      {
        "family": "Solar-Lezama",
        "given": "Armando"
      },
      {
        "family": "Sen",
        "given": "Koushik"
      },
      {
        "family": "Stoica",
        "given": "Ion"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 4, 21]]
    },
    "issued": {
      "date-parts": [["2024", 6, 6]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/HD4BZRL2",
    "type": "article",
    "abstract": "Because large language models are expensive to pretrain on different datasets, using smaller-scale experiments to decide on data is crucial for reducing costs. Which benchmarks and methods of making decisions from observed performance at small scale most accurately predict the datasets that yield the best large models? To empower open exploration of this question, we release models, data, and evaluations in DataDecide -- the most extensive open suite of models over differences in data and scale. We conduct controlled pretraining experiments across 25 corpora with differing sources, deduplication, and filtering up to 100B tokens, model sizes up to 1B parameters, and 3 random seeds. We find that the ranking of models at a single, small size (e.g., 150M parameters) is a strong baseline for predicting best models at our larger target scale (1B) (~80% of com parisons correct). No scaling law methods among 8 baselines exceed the compute-decision frontier of single-scale predictions, but DataDecide can measure improvement in future scaling laws. We also identify that using continuous likelihood metrics as proxies in small experiments makes benchmarks including MMLU, ARC, HellaSwag, MBPP, and HumanEval >80% predictable at the target 1B scale with just 0.01% of the compute.",
    "DOI": "10.48550/arXiv.2504.11393",
    "language": "en-US",
    "note": "arXiv:2504.11393 [cs]",
    "number": "arXiv:2504.11393",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "DataDecide: How to Predict Best Pretraining Data with Small Experiments",
    "title-short": "DataDecide",
    "URL": "http://arxiv.org/abs/2504.11393",
    "author": [
      {
        "family": "Magnusson",
        "given": "Ian"
      },
      {
        "family": "Tai",
        "given": "Nguyen"
      },
      {
        "family": "Bogin",
        "given": "Ben"
      },
      {
        "family": "Heineman",
        "given": "David"
      },
      {
        "family": "Hwang",
        "given": "Jena D."
      },
      {
        "family": "Soldaini",
        "given": "Luca"
      },
      {
        "family": "Bhagia",
        "given": "Akshita"
      },
      {
        "family": "Liu",
        "given": "Jiacheng"
      },
      {
        "family": "Groeneveld",
        "given": "Dirk"
      },
      {
        "family": "Tafjord",
        "given": "Oyvind"
      },
      {
        "family": "Smith",
        "given": "Noah A."
      },
      {
        "family": "Koh",
        "given": "Pang Wei"
      },
      {
        "family": "Dodge",
        "given": "Jesse"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 4, 22]]
    },
    "issued": {
      "date-parts": [["2025", 4, 15]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/UPAIHPFS",
    "type": "article",
    "abstract": "Recent supervised fine-tuning (SFT) approaches have significantly improved language models' performance on mathematical reasoning tasks, even when models are trained at a small scale. However, the specific capabilities enhanced through such fine-tuning remain poorly understood. In this paper, we conduct a detailed analysis of model performance on the AIME24 dataset to understand how reasoning capabilities evolve. We discover a ladder-like structure in problem difficulty, categorize questions into four tiers (Easy, Medium, Hard, and Extremely Hard (Exh)), and identify the specific requirements for advancing between tiers. We find that progression from Easy to Medium tier requires adopting an R1 reasoning style with minimal SFT (500-1K instances), while Hard-level questions suffer from frequent model's errors at each step of the reasoning chain, with accuracy plateauing at around 65% despite logarithmic scaling. Exh-level questions present a fundamentally different challenge; they require unconventional problem-solving skills that current models uniformly struggle with. Additional findings reveal that carefully curated small-scale datasets offer limited advantage-scaling dataset size proves far more effective. Our analysis provides a clearer roadmap for advancing language model capabilities in mathematical reasoning.",
    "DOI": "10.48550/arXiv.2504.11741",
    "language": "en-US",
    "note": "arXiv:2504.11741 [cs]",
    "number": "arXiv:2504.11741",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Climbing the Ladder of Reasoning: What LLMs Can-and Still Can't-Solve after SFT?",
    "title-short": "Climbing the Ladder of Reasoning",
    "URL": "http://arxiv.org/abs/2504.11741",
    "author": [
      {
        "family": "Sun",
        "given": "Yiyou"
      },
      {
        "family": "Zhou",
        "given": "Georgia"
      },
      {
        "family": "Wang",
        "given": "Hao"
      },
      {
        "family": "Li",
        "given": "Dacheng"
      },
      {
        "family": "Dziri",
        "given": "Nouha"
      },
      {
        "family": "Song",
        "given": "Dawn"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 4, 22]]
    },
    "issued": {
      "date-parts": [["2025", 4, 16]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/GYX6HM5T",
    "type": "article",
    "abstract": "As the post-training of large language models (LLMs) advances from instruction-following to complex reasoning tasks, understanding how different data affect finetuning dynamics remains largely unexplored. In this paper, we present a spectral analysis of layer-wise gradients induced by low/high-quality instruction and reasoning data for LLM post-training. Our analysis reveals that widely-studied metrics for data evaluation, e.g., IFD, InsTag, Difficulty, and Reward, can be explained and unified by spectral properties computed from gradients' singular value decomposition (SVD). Specifically, higher-quality data are usually associated with lower nuclear norms and higher effective ranks. Notably, effective rank exhibits better robustness and resolution than nuclear norm in capturing subtle quality differences. For example, reasoning data achieves substantially higher effective ranks than instruction data, implying richer gradient structures on more complex tasks. Our experiments also highlight that models within the same family share similar gradient patterns regardless of their sizes, whereas different model families diverge significantly. Providing a unified view on the effects of data quality across instruction and reasoning data, this work illuminates the interplay between data quality and training stability, shedding novel insights into developing better data exploration strategies for post-training.",
    "DOI": "10.48550/arXiv.2504.10766",
    "note": "arXiv:2504.10766 [cs]",
    "number": "arXiv:2504.10766",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "How Instruction and Reasoning Data shape Post-Training: Data Quality through the Lens of Layer-wise Gradients",
    "title-short": "How Instruction and Reasoning Data shape Post-Training",
    "URL": "http://arxiv.org/abs/2504.10766",
    "author": [
      {
        "family": "Li",
        "given": "Ming"
      },
      {
        "family": "Li",
        "given": "Yanhong"
      },
      {
        "family": "Li",
        "given": "Ziyue"
      },
      {
        "family": "Zhou",
        "given": "Tianyi"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 4, 22]]
    },
    "issued": {
      "date-parts": [["2025", 4, 14]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/HWDX39ME",
    "type": "article",
    "abstract": "Data quality and diversity are key to the construction of effective instruction-tuning datasets. % With the increasing availability of open-source instruction-tuning datasets, it is advantageous to automatically select high-quality and diverse subsets from a vast amount of data. % Existing methods typically prioritize instance quality and use heuristic rules to maintain diversity. % However, this absence of a comprehensive view of the entire collection often leads to suboptimal results. % Moreover, heuristic rules generally focus on distance or clustering within the embedding space, which fails to accurately capture the intent of complex instructions in the semantic space. % To bridge this gap, we propose a unified method for quantifying the information content of datasets. This method models the semantic space by constructing a label graph and quantifies diversity based on the distribution of information within the graph. % Based on such a measurement, we further introduce an efficient sampling method that selects data samples iteratively to \\textbf{M}aximize the \\textbf{I}nformation \\textbf{G}ain (MIG) in semantic space. % Experiments on various datasets and base models demonstrate that MIG consistently outperforms state-of-the-art methods. % Notably, the model fine-tuned with 5\\% Tulu3 data sampled by MIG achieves comparable performance to the official SFT model trained on the full dataset, with improvements of +5.73\\% on AlpacaEval and +6.89\\% on Wildbench.",
    "DOI": "10.48550/arXiv.2504.13835",
    "language": "en-US",
    "note": "arXiv:2504.13835 [cs]",
    "number": "arXiv:2504.13835",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "MIG: Automatic Data Selection for Instruction Tuning by Maximizing Information Gain in Semantic Space",
    "title-short": "MIG",
    "URL": "http://arxiv.org/abs/2504.13835",
    "author": [
      {
        "family": "Chen",
        "given": "Yicheng"
      },
      {
        "family": "Li",
        "given": "Yining"
      },
      {
        "family": "Hu",
        "given": "Kai"
      },
      {
        "family": "Ma",
        "given": "Zerun"
      },
      {
        "family": "Ye",
        "given": "Haochen"
      },
      {
        "family": "Chen",
        "given": "Kai"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 4, 22]]
    },
    "issued": {
      "date-parts": [["2025", 4, 18]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/FQTDC54Z",
    "type": "webpage",
    "abstract": "Visual reasoning is a core component of human intelligence and a critical capability for advanced multimodal models. Yet current reasoning evaluations of multimodal large language models (MLLMs) often rely on text descriptions and allow language-based reasoning shortcuts, failing to measure genuine vision-centric reasoning. To address this, we introduce VisuLogic: a benchmark of 1,000 human-verified problems across six categories (e.g., quantitative shifts, spatial relations, attribute comparisons). These various types of questions can be evaluated to assess the visual reasoning capabilities of MLLMs from multiple perspectives. We evaluate leading MLLMs on this benchmark and analyze their results to identify common failure modes. Most models score below 30% accuracy-only slightly above the 25% random baseline and far below the 51.4% achieved by humans-revealing significant gaps in visual reasoning. Furthermore, we provide a supplementary training dataset and a reinforcement-learning baseline to support further progress.",
    "container-title": "arXiv.org",
    "language": "en",
    "title": "VisuLogic: A Benchmark for Evaluating Visual Reasoning in Multi-modal Large Language Models",
    "title-short": "VisuLogic",
    "URL": "https://arxiv.org/abs/2504.15279v1",
    "author": [
      {
        "family": "Xu",
        "given": "Weiye"
      },
      {
        "family": "Wang",
        "given": "Jiahao"
      },
      {
        "family": "Wang",
        "given": "Weiyun"
      },
      {
        "family": "Chen",
        "given": "Zhe"
      },
      {
        "family": "Zhou",
        "given": "Wengang"
      },
      {
        "family": "Yang",
        "given": "Aijun"
      },
      {
        "family": "Lu",
        "given": "Lewei"
      },
      {
        "family": "Li",
        "given": "Houqiang"
      },
      {
        "family": "Wang",
        "given": "Xiaohua"
      },
      {
        "family": "Zhu",
        "given": "Xizhou"
      },
      {
        "family": "Wang",
        "given": "Wenhai"
      },
      {
        "family": "Dai",
        "given": "Jifeng"
      },
      {
        "family": "Zhu",
        "given": "Jinguo"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 4, 23]]
    },
    "issued": {
      "date-parts": [["2025", 4, 21]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/5YY6WSS5",
    "type": "paper-conference",
    "abstract": "Selecting high-quality pre-training data for large language models (LLMs) is crucial for enhancing their overall performance under limited computation budget, improving both training and sample efficiency. Recent advancements in file selection primarily rely on using an existing or trained proxy model to assess the similarity of samples to a target domain, such as high quality sources BookCorpus and Wikipedia. However, upon revisiting these methods, the domain-similarity selection criteria demonstrates a diversity dilemma, i.e. dimensional collapse in the feature space, improving performance on the domain-related tasks but causing severe degradation on generic performance.To prevent collapse and enhance diversity, we propose a DiverSified File selection algorithm (DiSF), which selects the most decorrelated text files in the feature space. We approach this with a classical greedy algorithm to achieve more uniform eigenvalues in the feature covariance matrix of the selected texts, analyzing its approximation to the optimal solution under a formulation of $\\gamma$-weakly submodular optimization problem. Empirically, we establish a benchmark and conduct extensive experiments on the TinyLlama architecture with models from 120M to 1.1B parameters. Evaluating across nine tasks from the Harness framework, DiSF demonstrates a significant improvement on overall performance. Specifically, DiSF saves 98.5\\% of 590M training files in SlimPajama, outperforming the full-data pre-training within a 50B training budget, and achieving about 1.5x training efficiency and 5x data efficiency. Source code is available at: https://github.com/MediaBrain-SJTU/DiSF.git.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "Combatting Dimensional Collapse in LLM Pre-Training Data via Submodular File Selection",
    "URL": "https://openreview.net/forum?id=f4gF6AIHRy",
    "author": [
      {
        "family": "Fan",
        "given": "Ziqing"
      },
      {
        "family": "Du",
        "given": "Siyuan"
      },
      {
        "family": "Hu",
        "given": "Shengchao"
      },
      {
        "family": "Wang",
        "given": "Pingjie"
      },
      {
        "family": "Shen",
        "given": "Li"
      },
      {
        "family": "Zhang",
        "given": "Ya"
      },
      {
        "family": "Tao",
        "given": "Dacheng"
      },
      {
        "family": "Wang",
        "given": "Yanfeng"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 4, 24]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/JKWNAXPK",
    "type": "paper-conference",
    "abstract": "This work investigates the selection of high-quality pre-training data from massive corpora to enhance LMs' capabilities for downstream usage. We formulate data selection as a generalized Optimal Control problem, which can be solved theoretically by Pontryagin's Maximum Principle (PMP), yielding a set of necessary conditions that characterize the relationship between optimal data selection and LM training dynamics. Based on these theoretical results, we introduce **P**MP-based **D**ata **S**election (**PDS**), a framework that approximates optimal data selection by solving the PMP conditions. In our experiments, we adopt PDS to select data from CommmonCrawl and show that the PDS-selected corpus accelerates the learning of LMs and constantly boosts their performance on a wide range of downstream tasks across various model sizes. Moreover, the benefits of PDS extend to ~400B models trained on ~10T tokens, as evidenced by the extrapolation of the test loss curves according to the Scaling Laws. PDS also improves data utilization when the pre-training data is limited, by reducing the data demand by 1.8 times, which helps mitigate the quick exhaustion of available web-crawled corpora. Our code, model, and data can be found at https://github.com/microsoft/LMOps/tree/main/data_selection.",
    "event-title": "The Thirteenth International Conference on Learning Representations",
    "language": "en",
    "source": "openreview.net",
    "title": "Data Selection via Optimal Control for Language Models",
    "URL": "https://openreview.net/forum?id=dhAL5fy8wS",
    "author": [
      {
        "family": "Gu",
        "given": "Yuxian"
      },
      {
        "family": "Dong",
        "given": "Li"
      },
      {
        "family": "Wang",
        "given": "Hongning"
      },
      {
        "family": "Hao",
        "given": "Yaru"
      },
      {
        "family": "Dong",
        "given": "Qingxiu"
      },
      {
        "family": "Wei",
        "given": "Furu"
      },
      {
        "family": "Huang",
        "given": "Minlie"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 4, 24]]
    },
    "issued": {
      "date-parts": [["2024", 10, 4]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/L62JWH74",
    "type": "article",
    "abstract": "Quality and diversity are two critical metrics for the training data of large language models (LLMs), positively impacting performance. Existing studies often optimize these metrics separately, typically by first applying quality filtering and then adjusting data proportions. However, these approaches overlook the inherent trade-off between quality and diversity, necessitating their joint consideration. Given a fixed training quota, it is essential to evaluate both the quality of each data point and its complementary effect on the overall dataset. In this paper, we introduce a unified data selection framework called QuaDMix, which automatically optimizes the data distribution for LLM pretraining while balancing both quality and diversity. Specifically, we first propose multiple criteria to measure data quality and employ domain classification to distinguish data points, thereby measuring overall diversity. QuaDMix then employs a unified parameterized data sampling function that determines the sampling probability of each data point based on these quality and diversity related labels. To accelerate the search for the optimal parameters involved in the QuaDMix framework, we conduct simulated experiments on smaller models and use LightGBM for parameters searching, inspired by the RegMix method. Our experiments across diverse models and datasets demonstrate that QuaDMix achieves an average performance improvement of 7.2% across multiple benchmarks. These results outperform the independent strategies for quality and diversity, highlighting the necessity and ability to balance data quality and diversity.",
    "DOI": "10.48550/arXiv.2504.16511",
    "note": "arXiv:2504.16511 [cs]",
    "number": "arXiv:2504.16511",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "QuaDMix: Quality-Diversity Balanced Data Selection for Efficient LLM Pretraining",
    "title-short": "QuaDMix",
    "URL": "http://arxiv.org/abs/2504.16511",
    "author": [
      {
        "family": "Liu",
        "given": "Fengze"
      },
      {
        "family": "Zhou",
        "given": "Weidong"
      },
      {
        "family": "Liu",
        "given": "Binbin"
      },
      {
        "family": "Yu",
        "given": "Zhimiao"
      },
      {
        "family": "Zhang",
        "given": "Yifan"
      },
      {
        "family": "Lin",
        "given": "Haobin"
      },
      {
        "family": "Yu",
        "given": "Yifeng"
      },
      {
        "family": "Zhou",
        "given": "Xiaohuan"
      },
      {
        "family": "Wang",
        "given": "Taifeng"
      },
      {
        "family": "Cao",
        "given": "Yong"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 4, 24]]
    },
    "issued": {
      "date-parts": [["2025", 4, 23]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/UM8A4VDD",
    "type": "article",
    "abstract": "Direct Preference Optimization (DPO) simplifies reinforcement learning from human feedback (RLHF) for large language models (LLMs) by directly optimizing human preferences without an explicit reward model. We find that during DPO training, the reference model plays the role of a data weight adjuster. However, the common practice of initializing the policy and reference models identically in DPO can lead to inefficient data utilization and impose a performance ceiling. Meanwhile, the lack of a reference model in Simple Preference Optimization (SimPO) reduces training robustness and necessitates stricter conditions to prevent catastrophic forgetting. In this work, we propose Pre-DPO, a simple yet effective DPO-based training paradigm that enhances preference optimization performance by leveraging a guiding reference model. This reference model provides foresight into the optimal policy state achievable through the training preference data, serving as a guiding mechanism that adaptively assigns higher weights to samples more suitable for the model and lower weights to those less suitable. Extensive experiments on AlpacaEval 2.0 and Arena-Hard v0.1 benchmarks demonstrate that Pre-DPO consistently improves the performance of both DPO and SimPO, without relying on external models or additional data.",
    "DOI": "10.48550/arXiv.2504.15843",
    "note": "arXiv:2504.15843 [cs]",
    "number": "arXiv:2504.15843",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Pre-DPO: Improving Data Utilization in Direct Preference Optimization Using a Guiding Reference Model",
    "title-short": "Pre-DPO",
    "URL": "http://arxiv.org/abs/2504.15843",
    "author": [
      {
        "family": "Pan",
        "given": "Junshu"
      },
      {
        "family": "Shen",
        "given": "Wei"
      },
      {
        "family": "Huang",
        "given": "Shulin"
      },
      {
        "family": "Zhou",
        "given": "Qiji"
      },
      {
        "family": "Zhang",
        "given": "Yue"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 4, 28]]
    },
    "issued": {
      "date-parts": [["2025", 4, 25]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/3D5MFFKA",
    "type": "article",
    "abstract": "IQ testing has served as a foundational methodology for evaluating human cognitive capabilities, deliberately decoupling assessment from linguistic background, language proficiency, or domain-specific knowledge to isolate core competencies in abstraction and reasoning. Yet, artificial intelligence research currently lacks systematic benchmarks to quantify these critical cognitive dimensions in multimodal systems. To address this critical gap, we propose MM-IQ, a comprehensive evaluation framework comprising 2,710 meticulously curated test items spanning 8 distinct reasoning paradigms. Through systematic evaluation of leading open-source and proprietary multimodal models, our benchmark reveals striking limitations: even state-of-the-art architectures achieve only marginally superior performance to random chance (27.49% vs. 25% baseline accuracy). This substantial performance chasm highlights the inadequacy of current multimodal systems in approximating fundamental human reasoning capacities, underscoring the need for paradigm-shifting advancements to bridge this cognitive divide.",
    "DOI": "10.48550/arXiv.2502.00698",
    "language": "en-US",
    "note": "arXiv:2502.00698 [cs]",
    "number": "arXiv:2502.00698",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "MM-IQ: Benchmarking Human-Like Abstraction and Reasoning in Multimodal Models",
    "title-short": "MM-IQ",
    "URL": "http://arxiv.org/abs/2502.00698",
    "author": [
      {
        "family": "Cai",
        "given": "Huanqia"
      },
      {
        "family": "Yang",
        "given": "Yijun"
      },
      {
        "family": "Hu",
        "given": "Winston"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 5, 11]]
    },
    "issued": {
      "date-parts": [["2025", 2, 2]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/XV52RG5K",
    "type": "paper-conference",
    "abstract": "Recently, large language models (LLMs) have achieved superior performance, empowering the development of large multimodal agents (LMAs). An LMA is anticipated to execute practical tasks requires various capabilities including multimodal perception, interaction, reasoning, and decision making. However, existing benchmarks are limited in assessing compositional skills and actions demanded by practical scenarios, where they primarily focused on single tasks and static scenarios. To bridge this gap, we introduce WhodunitBench, a benchmark rooted from murder mystery games, where players are required to utilize the aforementioned skills to achieve their objective (i.e., identifying the `murderer' or hiding themselves), providing a simulated dynamic environment for evaluating LMAs. Specifically, WhodunitBench includes two evaluation modes. The first mode, the arena-style evaluation, is constructed from 50 meticulously curated scripts featuring clear reasoning clues and distinct murderers; The second mode, the chain of evaluation, consists of over 3000 curated multiple-choice questions and open-ended questions, aiming to assess every facet of the murder mystery games for LMAs. Experiments show that although current LMAs show acceptable performance in basic perceptual tasks, they are insufficiently equipped for complex multi-agent collaboration and multi-step reasoning tasks. Furthermore, the full application of the theory of mind to complete games in a manner akin to human behavior remains a significant challenge. We hope this work can illuminate the path forward, providing a solid foundation for the future development of LMAs. Our WhodunitBench is open-source and accessible at: https://github.com/ jun0wanan/WhodunitBench-Murder_Mystery_Games",
    "event-title": "The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track",
    "language": "en",
    "source": "openreview.net",
    "title": "WhodunitBench: Evaluating Large Multimodal Agents via Murder Mystery Games",
    "title-short": "WhodunitBench",
    "URL": "https://openreview.net/forum?id=qmvtDIfbmS",
    "author": [
      {
        "family": "Xie",
        "given": "Junlin"
      },
      {
        "family": "Zhang",
        "given": "Ruifei"
      },
      {
        "family": "Chen",
        "given": "Zhihong"
      },
      {
        "family": "Wan",
        "given": "Xiang"
      },
      {
        "family": "Li",
        "given": "Guanbin"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 5, 11]]
    },
    "issued": {
      "date-parts": [["2024", 11, 13]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/CV3X9Z7X",
    "type": "paper-conference",
    "abstract": "In this paper, we present the LingOly benchmark, a novel benchmark for advanced reasoning abilities in large language models. Using challenging Linguistic Olympiad puzzles, we evaluate (i) capabilities for in-context identification and generalisation of linguistic patterns in very low-resource or extinct languages, and (ii) abilities to follow complex task instructions. The LingOly benchmark covers more than 90 mostly low-resource languages, minimising issues of data contamination, and contains 1,133 problems across 6 formats and 5 levels of human difficulty. We assess performance with both direct accuracy and comparison to a no-context baseline to penalise memorisation. Scores from 11 state-of-the-art LLMs demonstrate the benchmark to be challenging, and models perform poorly on the higher difficulty problems. On harder problems, even the top model only achieved 38.7% accuracy, a 24.7% improvement over the no-context baseline. Large closed models typically outperform open models, and in general, the higher resource the language, the better the scores. These results indicate, in absence of memorisation, true multi-step out-of-domain reasoning remains a challenge for current language models.",
    "event-title": "The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track",
    "language": "en",
    "source": "openreview.net",
    "title": "LINGOLY: A Benchmark of Olympiad-Level Linguistic Reasoning Puzzles in Low Resource and Extinct Languages",
    "title-short": "LINGOLY",
    "URL": "https://openreview.net/forum?id=cLga8GStdk#discussion",
    "author": [
      {
        "family": "Bean",
        "given": "Andrew Michael"
      },
      {
        "family": "Hellsten",
        "given": "Simeon"
      },
      {
        "family": "Mayne",
        "given": "Harry"
      },
      {
        "family": "Magomere",
        "given": "Jabez"
      },
      {
        "family": "Chi",
        "given": "Ethan A."
      },
      {
        "family": "Chi",
        "given": "Ryan Andrew"
      },
      {
        "family": "Hale",
        "given": "Scott A."
      },
      {
        "family": "Kirk",
        "given": "Hannah Rose"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 5, 11]]
    },
    "issued": {
      "date-parts": [["2024", 11, 13]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/36F8MYHG",
    "type": "article",
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities, especially the recent advancements in reasoning, such as o1 and o3, pushing the boundaries of AI. Despite these impressive achievements in mathematics and coding, the reasoning abilities of LLMs in domains requiring cryptographic expertise remain underexplored. In this paper, we introduce CipherBank, a comprehensive benchmark designed to evaluate the reasoning capabilities of LLMs in cryptographic decryption tasks. CipherBank comprises 2,358 meticulously crafted problems, covering 262 unique plaintexts across 5 domains and 14 subdomains, with a focus on privacy-sensitive and real-world scenarios that necessitate encryption. From a cryptographic perspective, CipherBank incorporates 3 major categories of encryption methods, spanning 9 distinct algorithms, ranging from classical ciphers to custom cryptographic techniques. We evaluate state-of-the-art LLMs on CipherBank, e.g., GPT-4o, DeepSeek-V3, and cutting-edge reasoning-focused models such as o1 and DeepSeek-R1. Our results reveal significant gaps in reasoning abilities not only between general-purpose chat LLMs and reasoning-focused LLMs but also in the performance of current reasoning-focused models when applied to classical cryptographic decryption tasks, highlighting the challenges these models face in understanding and manipulating encrypted data. Through detailed analysis and error investigations, we provide several key observations that shed light on the limitations and potential improvement areas for LLMs in cryptographic reasoning. These findings underscore the need for continuous advancements in LLM reasoning capabilities.",
    "DOI": "10.48550/arXiv.2504.19093",
    "note": "arXiv:2504.19093 [cs]",
    "number": "arXiv:2504.19093",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "CipherBank: Exploring the Boundary of LLM Reasoning Capabilities through Cryptography Challenges",
    "title-short": "CipherBank",
    "URL": "http://arxiv.org/abs/2504.19093",
    "author": [
      {
        "family": "Li",
        "given": "Yu"
      },
      {
        "family": "Pei",
        "given": "Qizhi"
      },
      {
        "family": "Sun",
        "given": "Mengyuan"
      },
      {
        "family": "Lin",
        "given": "Honglin"
      },
      {
        "family": "Ming",
        "given": "Chenlin"
      },
      {
        "family": "Gao",
        "given": "Xin"
      },
      {
        "family": "Wu",
        "given": "Jiang"
      },
      {
        "family": "He",
        "given": "Conghui"
      },
      {
        "family": "Wu",
        "given": "Lijun"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 5, 15]]
    },
    "issued": {
      "date-parts": [["2025", 4, 27]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/EUUP2KHG",
    "type": "article",
    "abstract": "Recent Large Reasoning Models (LRMs), such as DeepSeek-R1 and OpenAI o1, have demonstrated strong performance gains by scaling up the length of Chain-of-Thought (CoT) reasoning during inference. However, a growing concern lies in their tendency to produce excessively long reasoning traces, which are often filled with redundant content (e.g., repeated definitions), over-analysis of simple problems, and superficial exploration of multiple reasoning paths for harder tasks. This inefficiency introduces significant challenges for training, inference, and real-world deployment (e.g., in agent-based systems), where token economy is critical. In this survey, we provide a comprehensive overview of recent efforts aimed at improving reasoning efficiency in LRMs, with a particular focus on the unique challenges that arise in this new paradigm. We identify common patterns of inefficiency, examine methods proposed across the LRM lifecycle, i.e., from pretraining to inference, and discuss promising future directions for research. To support ongoing development, we also maintain a real-time GitHub repository tracking recent progress in the field. We hope this survey serves as a foundation for further exploration and inspires innovation in this rapidly evolving area.",
    "DOI": "10.48550/arXiv.2503.21614",
    "note": "arXiv:2503.21614 [cs]",
    "number": "arXiv:2503.21614",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "A Survey of Efficient Reasoning for Large Reasoning Models: Language, Multimodality, and Beyond",
    "title-short": "A Survey of Efficient Reasoning for Large Reasoning Models",
    "URL": "http://arxiv.org/abs/2503.21614",
    "author": [
      {
        "family": "Qu",
        "given": "Xiaoye"
      },
      {
        "family": "Li",
        "given": "Yafu"
      },
      {
        "family": "Su",
        "given": "Zhaochen"
      },
      {
        "family": "Sun",
        "given": "Weigao"
      },
      {
        "family": "Yan",
        "given": "Jianhao"
      },
      {
        "family": "Liu",
        "given": "Dongrui"
      },
      {
        "family": "Cui",
        "given": "Ganqu"
      },
      {
        "family": "Liu",
        "given": "Daizong"
      },
      {
        "family": "Liang",
        "given": "Shuxian"
      },
      {
        "family": "He",
        "given": "Junxian"
      },
      {
        "family": "Li",
        "given": "Peng"
      },
      {
        "family": "Wei",
        "given": "Wei"
      },
      {
        "family": "Shao",
        "given": "Jing"
      },
      {
        "family": "Lu",
        "given": "Chaochao"
      },
      {
        "family": "Zhang",
        "given": "Yue"
      },
      {
        "family": "Hua",
        "given": "Xian-Sheng"
      },
      {
        "family": "Zhou",
        "given": "Bowen"
      },
      {
        "family": "Cheng",
        "given": "Yu"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 5, 16]]
    },
    "issued": {
      "date-parts": [["2025", 3, 27]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/ZRTRCJLN",
    "type": "article",
    "abstract": "Recent Large Reasoning Models (LRMs), such as DeepSeek-R1 and OpenAI o1, have demonstrated strong performance gains by scaling up the length of Chain-of-Thought (CoT) reasoning during inference. However, a growing concern lies in their tendency to produce excessively long reasoning traces, which are often filled with redundant content (e.g., repeated definitions), over-analysis of simple problems, and superficial exploration of multiple reasoning paths for harder tasks. This inefficiency introduces significant challenges for training, inference, and real-world deployment (e.g., in agent-based systems), where token economy is critical. In this survey, we provide a comprehensive overview of recent efforts aimed at improving reasoning efficiency in LRMs, with a particular focus on the unique challenges that arise in this new paradigm. We identify common patterns of inefficiency, examine methods proposed across the LRM lifecycle, i.e., from pretraining to inference, and discuss promising future directions for research. To support ongoing development, we also maintain a real-time GitHub repository tracking recent progress in the field. We hope this survey serves as a foundation for further exploration and inspires innovation in this rapidly evolving area.",
    "DOI": "10.48550/arXiv.2503.21614",
    "note": "arXiv:2503.21614 [cs]",
    "number": "arXiv:2503.21614",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "A Survey of Efficient Reasoning for Large Reasoning Models: Language, Multimodality, and Beyond",
    "title-short": "A Survey of Efficient Reasoning for Large Reasoning Models",
    "URL": "http://arxiv.org/abs/2503.21614",
    "author": [
      {
        "family": "Qu",
        "given": "Xiaoye"
      },
      {
        "family": "Li",
        "given": "Yafu"
      },
      {
        "family": "Su",
        "given": "Zhaochen"
      },
      {
        "family": "Sun",
        "given": "Weigao"
      },
      {
        "family": "Yan",
        "given": "Jianhao"
      },
      {
        "family": "Liu",
        "given": "Dongrui"
      },
      {
        "family": "Cui",
        "given": "Ganqu"
      },
      {
        "family": "Liu",
        "given": "Daizong"
      },
      {
        "family": "Liang",
        "given": "Shuxian"
      },
      {
        "family": "He",
        "given": "Junxian"
      },
      {
        "family": "Li",
        "given": "Peng"
      },
      {
        "family": "Wei",
        "given": "Wei"
      },
      {
        "family": "Shao",
        "given": "Jing"
      },
      {
        "family": "Lu",
        "given": "Chaochao"
      },
      {
        "family": "Zhang",
        "given": "Yue"
      },
      {
        "family": "Hua",
        "given": "Xian-Sheng"
      },
      {
        "family": "Zhou",
        "given": "Bowen"
      },
      {
        "family": "Cheng",
        "given": "Yu"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 5, 16]]
    },
    "issued": {
      "date-parts": [["2025", 3, 27]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/2NH8JNCA",
    "type": "article",
    "abstract": "In this work, we present Qwen3, the latest version of the Qwen model family. Qwen3 comprises a series of large language models (LLMs) designed to advance performance, efficiency, and multilingual capabilities. The Qwen3 series includes models of both dense and Mixture-of-Expert (MoE) architectures, with parameter scales ranging from 0.6 to 235 billion. A key innovation in Qwen3 is the integration of thinking mode (for complex, multi-step reasoning) and non-thinking mode (for rapid, context-driven responses) into a unified framework. This eliminates the need to switch between different models--such as chat-optimized models (e.g., GPT-4o) and dedicated reasoning models (e.g., QwQ-32B)--and enables dynamic mode switching based on user queries or chat templates. Meanwhile, Qwen3 introduces a thinking budget mechanism, allowing users to allocate computational resources adaptively during inference, thereby balancing latency and performance based on task complexity. Moreover, by leveraging the knowledge from the flagship models, we significantly reduce the computational resources required to build smaller-scale models, while ensuring their highly competitive performance. Empirical evaluations demonstrate that Qwen3 achieves state-of-the-art results across diverse benchmarks, including tasks in code generation, mathematical reasoning, agent tasks, etc., competitive against larger MoE models and proprietary models. Compared to its predecessor Qwen2.5, Qwen3 expands multilingual support from 29 to 119 languages and dialects, enhancing global accessibility through improved cross-lingual understanding and generation capabilities. To facilitate reproducibility and community-driven research and development, all Qwen3 models are publicly accessible under Apache 2.0.",
    "DOI": "10.48550/arXiv.2505.09388",
    "note": "arXiv:2505.09388 [cs]",
    "number": "arXiv:2505.09388",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Qwen3 Technical Report",
    "URL": "http://arxiv.org/abs/2505.09388",
    "author": [
      {
        "family": "Yang",
        "given": "An"
      },
      {
        "family": "Li",
        "given": "Anfeng"
      },
      {
        "family": "Yang",
        "given": "Baosong"
      },
      {
        "family": "Zhang",
        "given": "Beichen"
      },
      {
        "family": "Hui",
        "given": "Binyuan"
      },
      {
        "family": "Zheng",
        "given": "Bo"
      },
      {
        "family": "Yu",
        "given": "Bowen"
      },
      {
        "family": "Gao",
        "given": "Chang"
      },
      {
        "family": "Huang",
        "given": "Chengen"
      },
      {
        "family": "Lv",
        "given": "Chenxu"
      },
      {
        "family": "Zheng",
        "given": "Chujie"
      },
      {
        "family": "Liu",
        "given": "Dayiheng"
      },
      {
        "family": "Zhou",
        "given": "Fan"
      },
      {
        "family": "Huang",
        "given": "Fei"
      },
      {
        "family": "Hu",
        "given": "Feng"
      },
      {
        "family": "Ge",
        "given": "Hao"
      },
      {
        "family": "Wei",
        "given": "Haoran"
      },
      {
        "family": "Lin",
        "given": "Huan"
      },
      {
        "family": "Tang",
        "given": "Jialong"
      },
      {
        "family": "Yang",
        "given": "Jian"
      },
      {
        "family": "Tu",
        "given": "Jianhong"
      },
      {
        "family": "Zhang",
        "given": "Jianwei"
      },
      {
        "family": "Yang",
        "given": "Jianxin"
      },
      {
        "family": "Yang",
        "given": "Jiaxi"
      },
      {
        "family": "Zhou",
        "given": "Jing"
      },
      {
        "family": "Zhou",
        "given": "Jingren"
      },
      {
        "family": "Lin",
        "given": "Junyang"
      },
      {
        "family": "Dang",
        "given": "Kai"
      },
      {
        "family": "Bao",
        "given": "Keqin"
      },
      {
        "family": "Yang",
        "given": "Kexin"
      },
      {
        "family": "Yu",
        "given": "Le"
      },
      {
        "family": "Deng",
        "given": "Lianghao"
      },
      {
        "family": "Li",
        "given": "Mei"
      },
      {
        "family": "Xue",
        "given": "Mingfeng"
      },
      {
        "family": "Li",
        "given": "Mingze"
      },
      {
        "family": "Zhang",
        "given": "Pei"
      },
      {
        "family": "Wang",
        "given": "Peng"
      },
      {
        "family": "Zhu",
        "given": "Qin"
      },
      {
        "family": "Men",
        "given": "Rui"
      },
      {
        "family": "Gao",
        "given": "Ruize"
      },
      {
        "family": "Liu",
        "given": "Shixuan"
      },
      {
        "family": "Luo",
        "given": "Shuang"
      },
      {
        "family": "Li",
        "given": "Tianhao"
      },
      {
        "family": "Tang",
        "given": "Tianyi"
      },
      {
        "family": "Yin",
        "given": "Wenbiao"
      },
      {
        "family": "Ren",
        "given": "Xingzhang"
      },
      {
        "family": "Wang",
        "given": "Xinyu"
      },
      {
        "family": "Zhang",
        "given": "Xinyu"
      },
      {
        "family": "Ren",
        "given": "Xuancheng"
      },
      {
        "family": "Fan",
        "given": "Yang"
      },
      {
        "family": "Su",
        "given": "Yang"
      },
      {
        "family": "Zhang",
        "given": "Yichang"
      },
      {
        "family": "Zhang",
        "given": "Yinger"
      },
      {
        "family": "Wan",
        "given": "Yu"
      },
      {
        "family": "Liu",
        "given": "Yuqiong"
      },
      {
        "family": "Wang",
        "given": "Zekun"
      },
      {
        "family": "Cui",
        "given": "Zeyu"
      },
      {
        "family": "Zhang",
        "given": "Zhenru"
      },
      {
        "family": "Zhou",
        "given": "Zhipeng"
      },
      {
        "family": "Qiu",
        "given": "Zihan"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 5, 20]]
    },
    "issued": {
      "date-parts": [["2025", 5, 14]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/IMRE9B7I",
    "type": "article",
    "abstract": "Malicious URL classification represents a crucial aspect of cyber security. Although existing work comprises numerous machine learning and deep learning-based URL classification models, most suffer from generalisation and domain-adaptation issues arising from the lack of representative training datasets. Furthermore, these models fail to provide explanations for a given URL classification in natural human language. In this work, we investigate and demonstrate the use of Large Language Models (LLMs) to address this issue. Specifically, we propose an LLM-based one-shot learning framework that uses Chain-of-Thought (CoT) reasoning to predict whether a given URL is benign or phishing. We evaluate our framework using three URL datasets and five state-of-the-art LLMs and show that one-shot LLM prompting indeed provides performances close to supervised models, with GPT 4-Turbo being the best model, followed by Claude 3 Opus. We conduct a quantitative analysis of the LLM explanations and show that most of the explanations provided by LLMs align with the post-hoc explanations of the supervised classifiers, and the explanations have high readability, coherency, and informativeness.",
    "DOI": "10.48550/arXiv.2409.14306",
    "note": "arXiv:2409.14306 [cs]",
    "number": "arXiv:2409.14306",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "LLMs are One-Shot URL Classifiers and Explainers",
    "URL": "http://arxiv.org/abs/2409.14306",
    "author": [
      {
        "family": "Rashid",
        "given": "Fariza"
      },
      {
        "family": "Ranaweera",
        "given": "Nishavi"
      },
      {
        "family": "Doyle",
        "given": "Ben"
      },
      {
        "family": "Seneviratne",
        "given": "Suranga"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 5, 24]]
    },
    "issued": {
      "date-parts": [["2024", 9, 22]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/WVZAVPUI",
    "type": "paper-conference",
    "abstract": "While target-side monolingual data has been proven to be very useful to improve neural machine translation (briefly, NMT) through back translation, source-side monolingual data is not well investigated. In this work, we study how to use both the source-side and target-side monolingual data for NMT, and propose an effective strategy leveraging both of them. First, we generate synthetic bitext by translating monolingual data from the two domains into the other domain using the models pretrained on genuine bitext. Next, a model is trained on a noised version of the concatenated synthetic bitext where each source sequence is randomly corrupted. Finally, the model is fine-tuned on the genuine bitext and a clean version of a subset of the synthetic bitext without adding any noise. Our approach achieves state-of-the-art results on WMT16, WMT17, WMT18 EnglishłeftrightarrowGerman translations and WMT19 German\\toFrench translations, which demonstrate the effectiveness of our method. We also conduct a comprehensive study on how each part in the pipeline works.",
    "container-title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    "DOI": "10.18653/v1/D19-1430",
    "event-place": "Hong Kong, China",
    "event-title": "EMNLP-IJCNLP 2019",
    "page": "4207–4216",
    "publisher": "Association for Computational Linguistics",
    "publisher-place": "Hong Kong, China",
    "source": "ACLWeb",
    "title": "Exploiting Monolingual Data at Scale for Neural Machine Translation",
    "URL": "https://aclanthology.org/D19-1430/",
    "author": [
      {
        "family": "Wu",
        "given": "Lijun"
      },
      {
        "family": "Wang",
        "given": "Yiren"
      },
      {
        "family": "Xia",
        "given": "Yingce"
      },
      {
        "family": "Qin",
        "given": "Tao"
      },
      {
        "family": "Lai",
        "given": "Jianhuang"
      },
      {
        "family": "Liu",
        "given": "Tie-Yan"
      }
    ],
    "editor": [
      {
        "family": "Inui",
        "given": "Kentaro"
      },
      {
        "family": "Jiang",
        "given": "Jing"
      },
      {
        "family": "Ng",
        "given": "Vincent"
      },
      {
        "family": "Wan",
        "given": "Xiaojun"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 5, 29]]
    },
    "issued": {
      "date-parts": [["2019", 11]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/ZYGAEG2K",
    "type": "paper-conference",
    "abstract": "While very deep neural networks have shown effectiveness for computer vision and text classification applications, how to increase the network depth of the neural machine translation (NMT) models for better translation quality remains a challenging problem. Directly stacking more blocks to the NMT model results in no improvement and even drop in performance. In this work, we propose an effective two-stage approach with three specially designed components to construct deeper NMT models, which result in significant improvements over the strong Transformer baselines on WMT14 English\\toGerman and English\\toFrench translation tasks.",
    "container-title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    "DOI": "10.18653/v1/P19-1558",
    "event-place": "Florence, Italy",
    "event-title": "ACL 2019",
    "language": "en-US",
    "page": "5558–5563",
    "publisher": "Association for Computational Linguistics",
    "publisher-place": "Florence, Italy",
    "source": "ACLWeb",
    "title": "Depth Growing for Neural Machine Translation",
    "URL": "https://aclanthology.org/P19-1558/",
    "author": [
      {
        "family": "Wu",
        "given": "Lijun"
      },
      {
        "family": "Wang",
        "given": "Yiren"
      },
      {
        "family": "Xia",
        "given": "Yingce"
      },
      {
        "family": "Tian",
        "given": "Fei"
      },
      {
        "family": "Gao",
        "given": "Fei"
      },
      {
        "family": "Qin",
        "given": "Tao"
      },
      {
        "family": "Lai",
        "given": "Jianhuang"
      },
      {
        "family": "Liu",
        "given": "Tie-Yan"
      }
    ],
    "editor": [
      {
        "family": "Korhonen",
        "given": "Anna"
      },
      {
        "family": "Traum",
        "given": "David"
      },
      {
        "family": "Màrquez",
        "given": "Lluís"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 5, 29]]
    },
    "issued": {
      "date-parts": [["2019", 7]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/WEU6V3WX",
    "type": "paper-conference",
    "abstract": "While data augmentation is an important trick to boost the accuracy of deep learning methods in computer vision tasks, its study in natural language tasks is still very limited. In this paper, we present a novel data augmentation method for neural machine translation. Different from previous augmentation methods that randomly drop, swap or replace words with other words in a sentence, we softly augment a randomly chosen word in a sentence by its contextual mixture of multiple related words. More accurately, we replace the one-hot representation of a word by a distribution (provided by a language model) over the vocabulary, i.e., replacing the embedding of this word by a weighted combination of multiple semantically similar words. Since the weights of those words depend on the contextual information of the word to be replaced,the newly generated sentences capture much richer information than previous augmentation methods. Experimental results on both small scale and large scale machine translation data sets demonstrate the superiority of our method over strong baselines.",
    "container-title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    "DOI": "10.18653/v1/P19-1555",
    "event-place": "Florence, Italy",
    "event-title": "ACL 2019",
    "language": "en-US",
    "page": "5539–5544",
    "publisher": "Association for Computational Linguistics",
    "publisher-place": "Florence, Italy",
    "source": "ACLWeb",
    "title": "Soft Contextual Data Augmentation for Neural Machine Translation",
    "URL": "https://aclanthology.org/P19-1555/",
    "author": [
      {
        "family": "Gao",
        "given": "Fei"
      },
      {
        "family": "Zhu",
        "given": "Jinhua"
      },
      {
        "family": "Wu",
        "given": "Lijun"
      },
      {
        "family": "Xia",
        "given": "Yingce"
      },
      {
        "family": "Qin",
        "given": "Tao"
      },
      {
        "family": "Cheng",
        "given": "Xueqi"
      },
      {
        "family": "Zhou",
        "given": "Wengang"
      },
      {
        "family": "Liu",
        "given": "Tie-Yan"
      }
    ],
    "editor": [
      {
        "family": "Korhonen",
        "given": "Anna"
      },
      {
        "family": "Traum",
        "given": "David"
      },
      {
        "family": "Màrquez",
        "given": "Lluís"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 5, 29]]
    },
    "issued": {
      "date-parts": [["2019", 7]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/EY2QRYGC",
    "type": "article",
    "abstract": "Teaching is critical to human society: it is with teaching that prospective students are educated and human civilization can be inherited and advanced. A good teacher not only provides his/her students with qualified teaching materials (e.g., textbooks), but also sets up appropriate learning objectives (e.g., course projects and exams) considering different situations of a student. When it comes to artificial intelligence, treating machine learning models as students, the loss functions that are optimized act as perfect counterparts of the learning objective set by the teacher. In this work, we explore the possibility of imitating human teaching behaviors by dynamically and automatically outputting appropriate loss functions to train machine learning models. Different from typical learning settings in which the loss function of a machine learning model is predefined and fixed, in our framework, the loss function of a machine learning model (we call it student) is defined by another machine learning model (we call it teacher). The ultimate goal of teacher model is cultivating the student to have better performance measured on development dataset. Towards that end, similar to human teaching, the teacher, a parametric model, dynamically outputs different loss functions that will be used and optimized by its student model at different training stages. We develop an efficient learning method for the teacher model that makes gradient based optimization possible, exempt of the ineffective solutions such as policy optimization. We name our method as \"learning to teach with dynamic loss functions\" (L2T-DLF for short). Extensive experiments on real world tasks including image classification and neural machine translation demonstrate that our method significantly improves the quality of various student models.",
    "DOI": "10.48550/arXiv.1810.12081",
    "language": "en-US",
    "note": "arXiv:1810.12081 [cs]",
    "number": "arXiv:1810.12081",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Learning to Teach with Dynamic Loss Functions",
    "URL": "http://arxiv.org/abs/1810.12081",
    "author": [
      {
        "family": "Wu",
        "given": "Lijun"
      },
      {
        "family": "Tian",
        "given": "Fei"
      },
      {
        "family": "Xia",
        "given": "Yingce"
      },
      {
        "family": "Fan",
        "given": "Yang"
      },
      {
        "family": "Qin",
        "given": "Tao"
      },
      {
        "family": "Lai",
        "given": "Jianhuang"
      },
      {
        "family": "Liu",
        "given": "Tie-Yan"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 5, 29]]
    },
    "issued": {
      "date-parts": [["2018", 10, 29]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/CY7KRPWC",
    "type": "paper-conference",
    "abstract": "The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships.  In this paper we present several improvements that make the Skip-gram model more expressive and enable it to learn higher quality vectors more rapidly.  We show that by subsampling frequent words we obtain significant speedup,  and also learn higher quality representations as measured by our tasks. We also introduce Negative Sampling, a simplified variant of Noise Contrastive Estimation (NCE) that learns more accurate vectors for frequent words compared to the hierarchical softmax.   An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases.  For example, the meanings of Canada'' and \"Air'' cannot be easily combined to obtain \"Air Canada''.  Motivated by this example, we present a simple and efficient method for finding phrases, and show that their vector representations can be accurately learned by the Skip-gram model. \"",
    "container-title": "Advances in Neural Information Processing Systems",
    "publisher": "Curran Associates, Inc.",
    "source": "Neural Information Processing Systems",
    "title": "Distributed Representations of Words and Phrases and their Compositionality",
    "URL": "https://papers.nips.cc/paper_files/paper/2013/hash/9aa42b31882ec039965f3c4923ce901b-Abstract.html",
    "volume": "26",
    "author": [
      {
        "family": "Mikolov",
        "given": "Tomas"
      },
      {
        "family": "Sutskever",
        "given": "Ilya"
      },
      {
        "family": "Chen",
        "given": "Kai"
      },
      {
        "family": "Corrado",
        "given": "Greg S"
      },
      {
        "family": "Dean",
        "given": "Jeff"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 5, 29]]
    },
    "issued": {
      "date-parts": [["2013"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/JYDEG9QA",
    "type": "article",
    "abstract": "We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.",
    "DOI": "10.48550/arXiv.1301.3781",
    "note": "arXiv:1301.3781 [cs]",
    "number": "arXiv:1301.3781",
    "publisher": "arXiv",
    "source": "arXiv.org",
    "title": "Efficient Estimation of Word Representations in Vector Space",
    "URL": "http://arxiv.org/abs/1301.3781",
    "author": [
      {
        "family": "Mikolov",
        "given": "Tomas"
      },
      {
        "family": "Chen",
        "given": "Kai"
      },
      {
        "family": "Corrado",
        "given": "Greg"
      },
      {
        "family": "Dean",
        "given": "Jeffrey"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 5, 29]]
    },
    "issued": {
      "date-parts": [["2013", 9, 7]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/9YJRHBPE",
    "type": "paper-conference",
    "container-title": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    "DOI": "10.3115/v1/D14-1162",
    "event-place": "Doha, Qatar",
    "event-title": "EMNLP 2014",
    "page": "1532–1543",
    "publisher": "Association for Computational Linguistics",
    "publisher-place": "Doha, Qatar",
    "source": "ACLWeb",
    "title": "GloVe: Global Vectors for Word Representation",
    "title-short": "GloVe",
    "URL": "https://aclanthology.org/D14-1162/",
    "author": [
      {
        "family": "Pennington",
        "given": "Jeffrey"
      },
      {
        "family": "Socher",
        "given": "Richard"
      },
      {
        "family": "Manning",
        "given": "Christopher"
      }
    ],
    "editor": [
      {
        "family": "Moschitti",
        "given": "Alessandro"
      },
      {
        "family": "Pang",
        "given": "Bo"
      },
      {
        "family": "Daelemans",
        "given": "Walter"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 5, 31]]
    },
    "issued": {
      "date-parts": [["2014", 10]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/AMIIAYS2",
    "type": "article-journal",
    "abstract": "Recent trends suggest that neural-network-inspired word embedding models outperform traditional count-based distributional models on word similarity and analogy detection tasks. We reveal that much of the performance gains of word embeddings are due to certain system design choices and hyperparameter optimizations, rather than the embedding algorithms themselves. Furthermore, we show that these modifications can be transferred to traditional distributional models, yielding similar gains. In contrast to prior reports, we observe mostly local or insignificant performance differences between the methods, with no global advantage to any single approach over the others.",
    "container-title": "Transactions of the Association for Computational Linguistics",
    "DOI": "10.1162/tacl_a_00134",
    "note": "publisher-place: Cambridge, MA\npublisher: MIT Press",
    "page": "211–225",
    "source": "ACLWeb",
    "title": "Improving Distributional Similarity with Lessons Learned from Word Embeddings",
    "URL": "https://aclanthology.org/Q15-1016/",
    "volume": "3",
    "author": [
      {
        "family": "Levy",
        "given": "Omer"
      },
      {
        "family": "Goldberg",
        "given": "Yoav"
      },
      {
        "family": "Dagan",
        "given": "Ido"
      }
    ],
    "editor": [
      {
        "family": "Collins",
        "given": "Michael"
      },
      {
        "family": "Lee",
        "given": "Lillian"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 5, 31]]
    },
    "issued": {
      "date-parts": [["2015"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/N5KVMEVD",
    "type": "paper-conference",
    "container-title": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    "DOI": "10.18653/v1/D15-1036",
    "event-place": "Lisbon, Portugal",
    "event-title": "EMNLP 2015",
    "page": "298–307",
    "publisher": "Association for Computational Linguistics",
    "publisher-place": "Lisbon, Portugal",
    "source": "ACLWeb",
    "title": "Evaluation methods for unsupervised word embeddings",
    "URL": "https://aclanthology.org/D15-1036/",
    "author": [
      {
        "family": "Schnabel",
        "given": "Tobias"
      },
      {
        "family": "Labutov",
        "given": "Igor"
      },
      {
        "family": "Mimno",
        "given": "David"
      },
      {
        "family": "Joachims",
        "given": "Thorsten"
      }
    ],
    "editor": [
      {
        "family": "Màrquez",
        "given": "Lluís"
      },
      {
        "family": "Callison-Burch",
        "given": "Chris"
      },
      {
        "family": "Su",
        "given": "Jian"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 5, 31]]
    },
    "issued": {
      "date-parts": [["2015", 9]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/PJPU469U",
    "type": "article-journal",
    "abstract": "Semantic word embeddings represent the meaning of a word via a vector, and are created by diverse methods. Many use nonlinear operations on co-occurrence statistics, and have hand-tuned hyperparameters and reweighting methods. This paper proposes a new generative model, a dynamic version of the log-linear topic model of Mnih and Hinton (2007). The methodological novelty is to use the prior to compute closed form expressions for word statistics. This provides a theoretical justification for nonlinear models like PMI, word2vec, and GloVe, as well as some hyperparameter choices. It also helps explain why low-dimensional semantic embeddings contain linear algebraic structure that allows solution of word analogies, as shown by Mikolov et al. (2013a) and many subsequent papers. Experimental support is provided for the generative model assumptions, the most important of which is that latent word vectors are fairly uniformly dispersed in space.",
    "container-title": "Transactions of the Association for Computational Linguistics",
    "DOI": "10.1162/tacl_a_00106",
    "note": "publisher-place: Cambridge, MA\npublisher: MIT Press",
    "page": "385–399",
    "source": "ACLWeb",
    "title": "A Latent Variable Model Approach to PMI-based Word Embeddings",
    "URL": "https://aclanthology.org/Q16-1028/",
    "volume": "4",
    "author": [
      {
        "family": "Arora",
        "given": "Sanjeev"
      },
      {
        "family": "Li",
        "given": "Yuanzhi"
      },
      {
        "family": "Liang",
        "given": "Yingyu"
      },
      {
        "family": "Ma",
        "given": "Tengyu"
      },
      {
        "family": "Risteski",
        "given": "Andrej"
      }
    ],
    "editor": [
      {
        "family": "Lee",
        "given": "Lillian"
      },
      {
        "family": "Johnson",
        "given": "Mark"
      },
      {
        "family": "Toutanova",
        "given": "Kristina"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 5, 31]]
    },
    "issued": {
      "date-parts": [["2016"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/LAPAWQWW",
    "type": "article-journal",
    "abstract": "Word embeddings are ubiquitous in NLP and information retrieval, but it is unclear what they represent when the word is polysemous. Here it is shown that multiple word senses reside in linear superposition within the word embedding and simple sparse coding can recover vectors that approximately capture the senses. The success of our approach, which applies to several embedding methods, is mathematically explained using a variant of the random walk on discourses model (Arora et al., 2016). A novel aspect of our technique is that each extracted word sense is accompanied by one of about 2000 “discourse atoms” that gives a succinct description of which other words co-occur with that word sense. Discourse atoms can be of independent interest, and make the method potentially more useful. Empirical tests are used to verify and support the theory.",
    "container-title": "Transactions of the Association for Computational Linguistics",
    "DOI": "10.1162/tacl_a_00034",
    "note": "publisher-place: Cambridge, MA\npublisher: MIT Press",
    "page": "483–495",
    "source": "ACLWeb",
    "title": "Linear Algebraic Structure of Word Senses, with Applications to Polysemy",
    "URL": "https://aclanthology.org/Q18-1034/",
    "volume": "6",
    "author": [
      {
        "family": "Arora",
        "given": "Sanjeev"
      },
      {
        "family": "Li",
        "given": "Yuanzhi"
      },
      {
        "family": "Liang",
        "given": "Yingyu"
      },
      {
        "family": "Ma",
        "given": "Tengyu"
      },
      {
        "family": "Risteski",
        "given": "Andrej"
      }
    ],
    "editor": [
      {
        "family": "Lee",
        "given": "Lillian"
      },
      {
        "family": "Johnson",
        "given": "Mark"
      },
      {
        "family": "Toutanova",
        "given": "Kristina"
      },
      {
        "family": "Roark",
        "given": "Brian"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 5, 31]]
    },
    "issued": {
      "date-parts": [["2018"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/2QAQRUS5",
    "type": "paper-conference",
    "abstract": "In this paper, we provide a theoretical understanding of word embedding and its dimensionality. Motivated by the unitary-invariance of word embedding, we propose the Pairwise Inner Product (PIP) loss, a novel metric on the dissimilarity between word embeddings. Using techniques from matrix perturbation theory, we reveal a fundamental bias-variance trade-off in dimensionality selection for word embeddings. This bias-variance trade-off sheds light on many empirical observations which were previously unexplained, for example the existence of an optimal dimensionality. Moreover, new insights and discoveries, like when and how word embeddings are robust to over-fitting, are revealed. By optimizing over the bias-variance trade-off of the PIP loss, we can explicitly answer the open question of dimensionality selection for word embedding.",
    "container-title": "Advances in Neural Information Processing Systems",
    "publisher": "Curran Associates, Inc.",
    "source": "Neural Information Processing Systems",
    "title": "On the Dimensionality of Word Embedding",
    "URL": "https://papers.nips.cc/paper_files/paper/2018/hash/b534ba68236ba543ae44b22bd110a1d6-Abstract.html",
    "volume": "31",
    "author": [
      {
        "family": "Yin",
        "given": "Zi"
      },
      {
        "family": "Shen",
        "given": "Yuanyuan"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 5, 31]]
    },
    "issued": {
      "date-parts": [["2018"]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/SHTKAQQU",
    "type": "article-journal",
    "abstract": "We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal ‘hidden’ units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.",
    "container-title": "Nature",
    "DOI": "10.1038/323533a0",
    "ISSN": "1476-4687",
    "issue": "6088",
    "language": "en",
    "license": "1986 Springer Nature Limited",
    "note": "publisher: Nature Publishing Group",
    "page": "533-536",
    "source": "www.nature.com",
    "title": "Learning representations by back-propagating errors",
    "URL": "https://www.nature.com/articles/323533a0",
    "volume": "323",
    "author": [
      {
        "family": "Rumelhart",
        "given": "David E."
      },
      {
        "family": "Hinton",
        "given": "Geoffrey E."
      },
      {
        "family": "Williams",
        "given": "Ronald J."
      }
    ],
    "accessed": {
      "date-parts": [["2025", 6, 4]]
    },
    "issued": {
      "date-parts": [["1986", 10]]
    }
  },
  {
    "id": "http://zotero.org/users/14620155/items/NICIHV5D",
    "type": "article-journal",
    "abstract": "We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.",
    "container-title": "The Journal of Machine Learning Research",
    "DOI": "10.5555/1953048.2078186",
    "note": "publisher: JMLR.org",
    "page": "2493-2537",
    "source": "dl.acm.org (Atypon)",
    "title": "Natural Language Processing (Almost) from Scratch",
    "URL": "https://dl.acm.org/doi/10.5555/1953048.2078186",
    "volume": "12",
    "author": [
      {
        "family": "Collobert",
        "given": "Ronan"
      },
      {
        "literal": "View Profile"
      },
      {
        "family": "Weston",
        "given": "Jason"
      },
      {
        "literal": "View Profile"
      },
      {
        "family": "Bottou",
        "given": "Léon"
      },
      {
        "literal": "View Profile"
      },
      {
        "family": "Karlen",
        "given": "Michael"
      },
      {
        "literal": "View Profile"
      },
      {
        "family": "Kavukcuoglu",
        "given": "Koray"
      },
      {
        "literal": "View Profile"
      },
      {
        "family": "Kuksa",
        "given": "Pavel"
      },
      {
        "literal": "View Profile"
      }
    ],
    "accessed": {
      "date-parts": [["2025", 6, 4]]
    },
    "issued": {
      "date-parts": [["2011", 11]]
    }
  }
]
